{"id": "/Users/zack.alatrash/Downloads/marker-master/marker_server.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker_server.py", "rel_path": "marker_server.py", "module": "marker_server", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "scripts", "server", "cli", "main", "from", "name"], "ast_kind": "imports", "text": "from marker.scripts.server import server_cli\n\nif __name__ == \"__main__\":\n    server_cli()\n", "n_tokens": 21, "byte_len": 90, "file_sha1": "cd0d696bd316d9d80b950ce59a6b5a906f17a923", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker_app.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker_app.py", "rel_path": "marker_app.py", "module": "marker_app", "ext": "py", "chunk_number": 1, "symbols": ["streamlit", "app", "import", "marker", "run", "scripts", "main", "from", "name"], "ast_kind": "imports", "text": "from marker.scripts.run_streamlit_app import streamlit_app_cli\n\nif __name__ == \"__main__\":\n    streamlit_app_cli()", "n_tokens": 28, "byte_len": 114, "file_sha1": "0cfbc4716030592a450401859857c3ea895b70e5", "start_line": 1, "end_line": 4}
{"id": "/Users/zack.alatrash/Downloads/marker-master/convert.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/convert.py", "rel_path": "convert.py", "module": "convert", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "scripts", "main", "from", "name", "convert", "cli"], "ast_kind": "imports", "text": "from marker.scripts.convert import convert_cli\n\nif __name__ == \"__main__\":\n    convert_cli()\n", "n_tokens": 21, "byte_len": 93, "file_sha1": "213822f1fa6c820522fa514544b7ba6580fe90bf", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/extraction_app.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/extraction_app.py", "rel_path": "extraction_app.py", "module": "extraction_app", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "run", "streamlit", "scripts", "main", "from", "name", "extraction", "app"], "ast_kind": "imports", "text": "from marker.scripts.run_streamlit_app import extraction_app_cli\n\nif __name__ == \"__main__\":\n    extraction_app_cli()\n", "n_tokens": 26, "byte_len": 117, "file_sha1": "47895bca8a0e9c8b08abbd90fa81cdd2ac2be296", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/chunk_convert.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/chunk_convert.py", "rel_path": "chunk_convert.py", "module": "chunk_convert", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "scripts", "chunk", "convert", "from", "main", "name"], "ast_kind": "imports", "text": "from marker.scripts.chunk_convert import chunk_convert_cli\n\nif __name__ == \"__main__\":\n    chunk_convert_cli()", "n_tokens": 24, "byte_len": 110, "file_sha1": "71493b60b418524e131dfd1508bcdde9956cb699", "start_line": 1, "end_line": 4}
{"id": "/Users/zack.alatrash/Downloads/marker-master/convert_single.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/convert_single.py", "rel_path": "convert_single.py", "module": "convert_single", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "scripts", "main", "from", "convert", "single", "name"], "ast_kind": "imports", "text": "from marker.scripts.convert_single import convert_single_cli\n\nif __name__ == \"__main__\":\n    convert_single_cli()\n", "n_tokens": 24, "byte_len": 114, "file_sha1": "14f39e6163703bc29bf66def342e2d2c75322fc8", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 1, "symbols": ["model_dict", "layout_model", "image", "create", "model", "markdown", "dict", "datasets", "layout", "classes", "strings", "blocks", "document", "builder", "builders", "tempfile", "html", "ocr", "pytest", "converters", "schema", "json", "renderer", "providers", "from", "draw", "line", "structure", "register", "block", "detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "config", "pdf_dataset", "temp_doc", "doc_provider", "pdf_document", "pdf_converter", "llm_service", "temp_image", "black", "temp", "pdf", "pdfs", "format", "filename", "return", "override"], "ast_kind": "function_or_method", "text": "import tempfile\nfrom typing import Dict, Type\n\nfrom PIL import Image, ImageDraw\n\nimport datasets\nimport pytest\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.layout import LayoutBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.builders.structure import StructureBuilder\nfrom marker.converters.pdf import PdfConverter\nfrom marker.models import create_model_dict\nfrom marker.providers.registry import provider_from_filepath\nfrom marker.renderers.chunk import ChunkRenderer\nfrom marker.renderers.html import HTMLRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.renderers.json import JSONRenderer\nfrom marker.schema.registry import register_block_class\nfrom marker.util import classes_to_strings, strings_to_classes\n\n\n@pytest.fixture(scope=\"session\")\ndef model_dict():\n    model_dict = create_model_dict()\n    yield model_dict\n    del model_dict\n\n\n@pytest.fixture(scope=\"session\")\ndef layout_model(model_dict):\n    yield model_dict[\"layout_model\"]\n\n", "n_tokens": 212, "byte_len": 1135, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 1, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 2, "symbols": ["detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "config", "pdf_dataset", "block", "type", "args", "split", "table", "rec", "model", "dict", "mark", "datasets", "function", "else", "pdfs", "pytest", "recognition", "node", "request", "return", "datalab", "yield", "register", "override", "get", "closest", "model_dict", "layout_model", "temp_doc", "doc_provider", "pdf_document", "pdf_converter", "renderer", "llm_service", "temp_image", "markdown", "black", "layout", "draw", "strings", "classes", "document", "builder", "temp", "pdf", "ocr"], "ast_kind": "function_or_method", "text": "@pytest.fixture(scope=\"session\")\ndef detection_model(model_dict):\n    yield model_dict[\"detection_model\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef recognition_model(model_dict):\n    yield model_dict[\"recognition_model\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef table_rec_model(model_dict):\n    yield model_dict[\"table_rec_model\"]\n\n\n@pytest.fixture(scope=\"session\")\ndef ocr_error_model(model_dict):\n    yield model_dict[\"ocr_error_model\"]\n\n\n@pytest.fixture(scope=\"function\")\ndef config(request):\n    config_mark = request.node.get_closest_marker(\"config\")\n    config = config_mark.args[0] if config_mark else {}\n\n    override_map: Dict[BlockTypes, Type[Block]] = config.get(\"override_map\", {})\n    for block_type, override_block_type in override_map.items():\n        register_block_class(block_type, override_block_type)\n\n    return config\n\n\n@pytest.fixture(scope=\"session\")\ndef pdf_dataset():\n    return datasets.load_dataset(\"datalab-to/pdfs\", split=\"train\")\n\n", "n_tokens": 203, "byte_len": 957, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 39, "end_line": 75}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 3, "symbols": ["temp_doc", "doc_provider", "args", "split", "function", "temp", "pdf", "else", "tempfile", "pytest", "suffix", "config", "doc", "node", "provider", "cls", "request", "filename", "yield", "get", "closest", "flush", "fixture", "from", "scope", "index", "write", "mark", "adversarial", "dataset", "model_dict", "layout_model", "detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "pdf_dataset", "pdf_document", "pdf_converter", "renderer", "llm_service", "temp_image", "markdown", "black", "layout", "model", "draw", "strings", "classes", "document"], "ast_kind": "function_or_method", "text": "@pytest.fixture(scope=\"function\")\ndef temp_doc(request, pdf_dataset):\n    filename_mark = request.node.get_closest_marker(\"filename\")\n    filename = filename_mark.args[0] if filename_mark else \"adversarial.pdf\"\n\n    idx = pdf_dataset[\"filename\"].index(filename)\n    suffix = filename.split(\".\")[-1]\n\n    temp_pdf = tempfile.NamedTemporaryFile(suffix=f\".{suffix}\")\n    temp_pdf.write(pdf_dataset[\"pdf\"][idx])\n    temp_pdf.flush()\n    yield temp_pdf\n\n\n@pytest.fixture(scope=\"function\")\ndef doc_provider(request, config, temp_doc):\n    provider_cls = provider_from_filepath(temp_doc.name)\n    yield provider_cls(temp_doc.name, config)\n\n", "n_tokens": 138, "byte_len": 633, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 76, "end_line": 95}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 4, "symbols": ["pdf_document", "layout", "model", "function", "document", "builder", "pdf", "structure", "ocr", "pytest", "config", "recognition", "request", "yield", "fixture", "line", "error", "scope", "doc", "provider", "detection", "model_dict", "layout_model", "detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "pdf_dataset", "temp_doc", "doc_provider", "pdf_converter", "renderer", "llm_service", "temp_image", "markdown", "black", "draw", "strings", "classes", "temp", "pdfs", "converters", "format", "filename", "return", "register", "block", "override", "hello", "session"], "ast_kind": "function_or_method", "text": "@pytest.fixture(scope=\"function\")\ndef pdf_document(\n    request,\n    config,\n    doc_provider,\n    layout_model,\n    ocr_error_model,\n    recognition_model,\n    detection_model,\n):\n    layout_builder = LayoutBuilder(layout_model, config)\n    line_builder = LineBuilder(detection_model, ocr_error_model, config)\n    ocr_builder = OcrBuilder(recognition_model, config)\n    builder = DocumentBuilder(config)\n    structure_builder = StructureBuilder(config)\n    document = builder(doc_provider, layout_builder, line_builder, ocr_builder)\n    structure_builder(document)\n    yield document\n\n", "n_tokens": 122, "byte_len": 586, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 96, "end_line": 115}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 5, "symbols": ["pdf_converter", "renderer", "args", "elif", "chunks", "markdown", "model", "dict", "none", "classes", "strings", "llm", "service", "function", "output", "format", "else", "html", "pytest", "json", "config", "pdf", "converter", "node", "request", "return", "yield", "artifact", "get", "closest", "model_dict", "layout_model", "detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "pdf_dataset", "temp_doc", "doc_provider", "pdf_document", "llm_service", "temp_image", "black", "layout", "draw", "document", "builder", "temp", "pdfs", "ocr"], "ast_kind": "function_or_method", "text": "@pytest.fixture(scope=\"function\")\ndef pdf_converter(request, config, model_dict, renderer, llm_service):\n    if llm_service:\n        llm_service = classes_to_strings([llm_service])[0]\n    yield PdfConverter(\n        artifact_dict=model_dict,\n        processor_list=None,\n        renderer=classes_to_strings([renderer])[0],\n        config=config,\n        llm_service=llm_service,\n    )\n\n\n@pytest.fixture(scope=\"function\")\ndef renderer(request, config):\n    if request.node.get_closest_marker(\"output_format\"):\n        output_format = request.node.get_closest_marker(\"output_format\").args[0]\n        if output_format == \"markdown\":\n            return MarkdownRenderer\n        elif output_format == \"json\":\n            return JSONRenderer\n        elif output_format == \"html\":\n            return HTMLRenderer\n        elif output_format == \"chunks\":\n            return ChunkRenderer\n        else:\n            raise ValueError(f\"Unknown output format: {output_format}\")\n    else:\n        return MarkdownRenderer\n\n", "n_tokens": 203, "byte_len": 1008, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 116, "end_line": 146}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/conftest.py", "rel_path": "tests/conftest.py", "module": "tests.conftest", "ext": "py", "chunk_number": 6, "symbols": ["llm_service", "temp_image", "image", "none", "text", "black", "draw", "world", "save", "llm", "service", "strings", "classes", "function", "color", "else", "font", "size", "tempfile", "pytest", "suffix", "config", "request", "yield", "fill", "hello", "flush", "fixture", "with", "scope", "model_dict", "layout_model", "detection_model", "recognition_model", "table_rec_model", "ocr_error_model", "pdf_dataset", "temp_doc", "doc_provider", "pdf_document", "pdf_converter", "renderer", "markdown", "layout", "model", "document", "builder", "temp", "pdf", "pdfs"], "ast_kind": "function_or_method", "text": "@pytest.fixture(scope=\"function\")\ndef llm_service(request, config):\n    llm_service = config.get(\"llm_service\")\n    if not llm_service:\n        yield None\n    else:\n        yield strings_to_classes([llm_service])[0]\n\n\n@pytest.fixture(scope=\"function\")\ndef temp_image():\n    img = Image.new(\"RGB\", (512, 512), color=\"white\")\n    draw = ImageDraw.Draw(img)\n    draw.text((10, 10), \"Hello, World!\", fill=\"black\", font_size=24)\n    with tempfile.NamedTemporaryFile(suffix=\".png\") as f:\n        img.save(f.name)\n        f.flush()\n        yield f\n", "n_tokens": 138, "byte_len": 541, "file_sha1": "522d2fa990e7bc8eed8f59b332abc73376235c57", "start_line": 147, "end_line": 165}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/utils.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/utils.py", "rel_path": "tests/utils.py", "module": "tests.utils", "ext": "py", "chunk_number": 1, "symbols": ["setup_pdf_provider", "split", "none", "datasets", "temp", "pdf", "tempfile", "pdfs", "suffix", "config", "providers", "from", "setup", "filename", "return", "datalab", "flush", "dataset", "provider", "index", "load", "write", "import", "marker", "adversarial", "train", "named", "temporary", "name"], "ast_kind": "function_or_method", "text": "from marker.providers.pdf import PdfProvider\nimport tempfile\n\nimport datasets\n\n\ndef setup_pdf_provider(\n    filename='adversarial.pdf',\n    config=None,\n) -> PdfProvider:\n    dataset = datasets.load_dataset(\"datalab-to/pdfs\", split=\"train\")\n    idx = dataset['filename'].index(filename)\n\n    temp_pdf = tempfile.NamedTemporaryFile(suffix=\".pdf\")\n    temp_pdf.write(dataset['pdf'][idx])\n    temp_pdf.flush()\n\n    provider = PdfProvider(temp_pdf.name, config)\n    return provider\n", "n_tokens": 105, "byte_len": 478, "file_sha1": "57f306f218fcf4961bb41d62f0ef2807ebba2673", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_html_renderer.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_html_renderer.py", "rel_path": "tests/renderers/test_html_renderer.py", "module": "tests.renderers.test_html_renderer", "ext": "py", "chunk_number": 1, "symbols": ["test_html_renderer_block_ids", "add", "block", "assert", "verify", "test", "html", "renderer", "some", "disable", "ocr", "pdf", "document", "pytest", "config", "from", "mark", "paginate", "output", "text", "renderers", "import", "present", "marker", "page", "range", "true"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.renderers.html import HTMLRenderer\n\n\n@pytest.mark.config(\n    {\n        \"page_range\": [0],\n        \"disable_ocr\": True,\n        \"add_block_ids\": True,\n        \"paginate_output\": True,\n    }\n)\ndef test_html_renderer_block_ids(pdf_document, config):\n    renderer = HTMLRenderer(config)\n    html = renderer(pdf_document).html\n\n    # Verify some block IDs are present\n    assert \"/page/0/Text/1\" in html\n", "n_tokens": 102, "byte_len": 427, "file_sha1": "52f28da2b1fb5c5a43a0ed7e88ca1889b0694b24", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py", "rel_path": "tests/renderers/test_markdown_renderer.py", "module": "tests.renderers.test_markdown_renderer", "ext": "py", "chunk_number": 1, "symbols": ["test_markdown_renderer", "test_markdown_renderer_auto_ocr", "test_markdown_renderer_pagination", "training", "markdown", "assert", "verify", "renderer", "blocks", "disable", "ocr", "pdf", "document", "test", "pytest", "schema", "config", "from", "subspace", "mark", "paginate", "output", "adversarial", "block", "types", "renderers", "import", "marker", "page", "range", "test_markdown_renderer_pagination_blank_last_page", "test_markdown_renderer_metadata", "test_markdown_renderer_images", "test_markdown_renderer_tables", "add", "full", "row", "col", "contained", "should", "table", "contents", "pagination", "extract", "images", "metadata", "text", "lines", "trailing", "last"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import TableCell\n\n\n@pytest.mark.config({\"page_range\": [0], \"disable_ocr\": True})\ndef test_markdown_renderer(pdf_document):\n    renderer = MarkdownRenderer()\n    md = renderer(pdf_document).markdown\n\n    # Verify markdown\n    assert \"# Subspace Adversarial Training\" in md\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_markdown_renderer_auto_ocr(pdf_document):\n    renderer = MarkdownRenderer()\n    md = renderer(pdf_document).markdown\n\n    # Verify markdown\n    assert \"Subspace Adversarial Training\" in md\n\n\n@pytest.mark.config({\"page_range\": [0, 1], \"paginate_output\": True})\ndef test_markdown_renderer_pagination(pdf_document):\n    renderer = MarkdownRenderer({\"paginate_output\": True})\n    md = renderer(pdf_document).markdown\n\n    assert \"\\n\\n{0}-\" in md\n    assert \"\\n\\n{1}-\" in md\n\n", "n_tokens": 211, "byte_len": 928, "file_sha1": "29a5796c64455ac8156dd6fcf2845dae66035cd0", "start_line": 1, "end_line": 34}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py", "rel_path": "tests/renderers/test_markdown_renderer.py", "module": "tests.renderers.test_markdown_renderer", "ext": "py", "chunk_number": 2, "symbols": ["test_markdown_renderer_pagination_blank_last_page", "test_markdown_renderer_metadata", "markdown", "assert", "should", "renderer", "table", "contents", "pagination", "pdf", "document", "metadata", "test", "pytest", "config", "trailing", "from", "last", "page", "preserve", "newlines", "mark", "children", "paginate", "output", "structure", "simulate", "pages", "with", "clear", "test_markdown_renderer", "test_markdown_renderer_auto_ocr", "test_markdown_renderer_pagination", "test_markdown_renderer_images", "test_markdown_renderer_tables", "add", "full", "training", "row", "col", "verify", "contained", "blocks", "disable", "ocr", "extract", "images", "schema", "text", "lines"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0, 1], \"paginate_output\": True})\ndef test_markdown_renderer_pagination_blank_last_page(pdf_document):\n    # Clear all children and structure from the last page to simulate a blank page\n    last_page = pdf_document.pages[-1]\n    last_page.children = []\n    last_page.structure = []\n\n    renderer = MarkdownRenderer({\"paginate_output\": True})\n    md = renderer(pdf_document).markdown\n\n    # Should end with pagination marker and preserve trailing newlines\n    assert md.endswith(\"}\\n\\n\") or md.endswith(\n        \"}------------------------------------------------\\n\\n\"\n    )\n\n\n@pytest.mark.config({\"page_range\": [0, 1]})\ndef test_markdown_renderer_metadata(pdf_document):\n    renderer = MarkdownRenderer({\"paginate_output\": True})\n    metadata = renderer(pdf_document).metadata\n    assert \"table_of_contents\" in metadata\n\n", "n_tokens": 177, "byte_len": 855, "file_sha1": "29a5796c64455ac8156dd6fcf2845dae66035cd0", "start_line": 35, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py", "rel_path": "tests/renderers/test_markdown_renderer.py", "module": "tests.renderers.test_markdown_renderer", "ext": "py", "chunk_number": 3, "symbols": ["test_markdown_renderer_images", "images", "mark", "markdown", "pdf", "document", "assert", "pytest", "config", "output", "extract", "page", "range", "false", "renderer", "test", "test_markdown_renderer", "test_markdown_renderer_auto_ocr", "test_markdown_renderer_pagination", "test_markdown_renderer_pagination_blank_last_page", "test_markdown_renderer_metadata", "test_markdown_renderer_tables", "add", "full", "training", "row", "col", "verify", "contained", "blocks", "should", "table", "contents", "pagination", "disable", "ocr", "metadata", "schema", "text", "lines", "trailing", "from", "subspace", "last", "preserve", "newlines", "children", "colspan", "paginate", "math"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0, 1]})\ndef test_markdown_renderer_images(pdf_document):\n    renderer = MarkdownRenderer({\"extract_images\": False})\n    markdown_output = renderer(pdf_document)\n\n    assert len(markdown_output.images) == 0\n    assert \"![](\" not in markdown_output.markdown\n\n", "n_tokens": 65, "byte_len": 293, "file_sha1": "29a5796c64455ac8156dd6fcf2845dae66035cd0", "start_line": 58, "end_line": 66}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_markdown_renderer.py", "rel_path": "tests/renderers/test_markdown_renderer.py", "module": "tests.renderers.test_markdown_renderer", "ext": "py", "chunk_number": 4, "symbols": ["test_markdown_renderer_tables", "add", "full", "col", "row", "markdown", "assert", "test", "contained", "blocks", "renderer", "pdf", "document", "pytest", "text", "lines", "config", "table", "cell", "mark", "colspan", "math", "structure", "header", "block", "types", "pages", "page", "polygon", "range", "test_markdown_renderer", "test_markdown_renderer_auto_ocr", "test_markdown_renderer_pagination", "test_markdown_renderer_pagination_blank_last_page", "test_markdown_renderer_metadata", "test_markdown_renderer_images", "training", "verify", "should", "contents", "pagination", "disable", "ocr", "extract", "images", "metadata", "schema", "trailing", "from", "subspace"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [5]})\ndef test_markdown_renderer_tables(pdf_document):\n    table = pdf_document.contained_blocks((BlockTypes.Table,))[0]\n    page = pdf_document.pages[0]\n\n    cell = TableCell(\n        polygon=table.polygon,\n        text_lines=[\"54<i>.45</i>67<br>89<math>x</math>\"],\n        rowspan=1,\n        colspan=1,\n        row_id=0,\n        col_id=0,\n        is_header=False,\n        page_id=page.page_id,\n    )\n    page.add_full_block(cell)\n    table.structure = []\n    table.add_structure(cell)\n\n    renderer = MarkdownRenderer()\n    md = renderer(pdf_document).markdown\n    assert \"54 <i>.45</i> 67<br>89 $x$\" in md\n", "n_tokens": 170, "byte_len": 644, "file_sha1": "29a5796c64455ac8156dd6fcf2845dae66035cd0", "start_line": 67, "end_line": 89}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_json_renderer.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_json_renderer.py", "rel_path": "tests/renderers/test_json_renderer.py", "module": "tests.renderers.test_json_renderer", "ext": "py", "chunk_number": 1, "symbols": ["test_markdown_renderer_pagination", "block", "type", "assert", "renderer", "page", "pdf", "document", "section", "header", "pytest", "json", "config", "from", "test", "markdown", "mark", "children", "pages", "renderers", "import", "marker", "range"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.renderers.json import JSONRenderer\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_markdown_renderer_pagination(pdf_document):\n    renderer = JSONRenderer()\n    pages = renderer(pdf_document).children\n\n    assert len(pages) == 1\n    assert pages[0].block_type == \"Page\"\n    assert pages[0].children[0].block_type == \"SectionHeader\"", "n_tokens": 84, "byte_len": 362, "file_sha1": "7807a129663f6a4f10739f802bccd7b9e3b20a2b", "start_line": 1, "end_line": 13}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_extract_images.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_extract_images.py", "rel_path": "tests/renderers/test_extract_images.py", "module": "tests.renderers.test_extract_images", "ext": "py", "chunk_number": 1, "symbols": ["test_disable_extract_images", "test_extract_images", "markdown", "assert", "test", "extract", "verify", "renderer", "pdf", "document", "images", "pytest", "config", "from", "filename", "mark", "disable", "flight", "plan", "renderers", "import", "marker", "page", "range", "false", "jpeg"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.renderers.markdown import MarkdownRenderer\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"A17_FlightPlan.pdf\")\ndef test_disable_extract_images(pdf_document):\n    renderer = MarkdownRenderer({\"extract_images\": False})\n    md = renderer(pdf_document).markdown\n\n    # Verify markdown\n    assert len(md) == 0\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"A17_FlightPlan.pdf\")\ndef test_extract_images(pdf_document):\n    renderer = MarkdownRenderer()\n    md = renderer(pdf_document).markdown\n\n    # Verify markdown\n    assert \"jpeg\" in md", "n_tokens": 131, "byte_len": 598, "file_sha1": "605f21a6708aa1f500e49d74575fa57d9b25bacc", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_chunk_renderer.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_chunk_renderer.py", "rel_path": "tests/renderers/test_chunk_renderer.py", "module": "tests.renderers.test_chunk_renderer", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "pytest", "from", "chunk", "renderers", "renderer", "test_chunk_renderer", "block", "type", "bbox", "captions", "assert", "none", "test", "blocks", "pdf", "document", "images", "section", "header", "html", "config", "page", "info", "figure", "group", "mark", "output", "figures", "groups", "polygon", "caption", "range"], "ast_kind": "imports", "text": "import pytest\n\nfrom marker.renderers.chunk import ChunkRenderer\n\n", "n_tokens": 12, "byte_len": 65, "file_sha1": "c90fe8b09b0dc24d849bf1630dc5da31459a4b13", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_chunk_renderer.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/renderers/test_chunk_renderer.py", "rel_path": "tests/renderers/test_chunk_renderer.py", "module": "tests.renderers.test_chunk_renderer", "ext": "py", "chunk_number": 2, "symbols": ["test_chunk_renderer", "block", "type", "bbox", "captions", "assert", "none", "renderer", "test", "chunk", "blocks", "pdf", "document", "images", "section", "header", "html", "pytest", "config", "page", "info", "figure", "group", "mark", "output", "figures", "groups", "polygon", "caption", "range", "from", "renderers", "import", "marker"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0]})\ndef test_chunk_renderer(pdf_document):\n    renderer = ChunkRenderer()\n    chunk_output = renderer(pdf_document)\n    blocks = chunk_output.blocks\n    page_info = chunk_output.page_info\n\n    assert len(blocks) == 14\n    assert blocks[0].block_type == \"SectionHeader\"\n    assert page_info[0][\"bbox\"] is not None\n    assert page_info[0][\"polygon\"] is not None\n\n    figure_groups = [block for block in blocks if block.block_type == \"FigureGroup\"]\n    figures = [block for block in blocks if block.block_type == \"Figure\"]\n    captions = [block for block in blocks if block.block_type == \"Caption\"]\n\n    assert len(figure_groups) == 1\n    assert len(figures) == 0\n    assert len(captions) == 0\n\n    figure_group = figure_groups[0]\n    assert figure_group.images is not None\n    assert len(figure_group.images) == 1\n    assert \"<img src='/page/0/Figure/9'>\" in figure_group.html", "n_tokens": 228, "byte_len": 911, "file_sha1": "c90fe8b09b0dc24d849bf1630dc5da31459a4b13", "start_line": 6, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_blank_page.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_blank_page.py", "rel_path": "tests/builders/test_blank_page.py", "module": "tests.builders.test_blank_page", "ext": "py", "chunk_number": 1, "symbols": ["surya", "import", "marker", "document", "schema", "from", "line", "layout", "builder", "result", "builders", "test_blank_page", "bbox", "assert", "merge", "blocks", "model", "test", "blank", "config", "add", "children", "ocr", "lines", "provider", "structure", "error", "build", "pages", "page", "doc", "list", "polygon", "isinstance", "detection", "results", "bboxes", "image"], "ast_kind": "imports", "text": "from surya.layout.schema import LayoutResult\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.layout import LayoutBuilder\nfrom marker.builders.line import LineBuilder\n\n", "n_tokens": 33, "byte_len": 194, "file_sha1": "379fae3b2f37455ca5f28033c6816d085a9a08de", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_blank_page.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_blank_page.py", "rel_path": "tests/builders/test_blank_page.py", "module": "tests.builders.test_blank_page", "ext": "py", "chunk_number": 2, "symbols": ["test_blank_page", "bbox", "assert", "merge", "blocks", "layout", "model", "document", "builder", "test", "blank", "config", "add", "children", "ocr", "lines", "provider", "structure", "line", "error", "build", "pages", "page", "doc", "list", "polygon", "isinstance", "detection", "results", "bboxes", "builders", "schema", "from", "surya", "import", "marker", "result", "image"], "ast_kind": "function_or_method", "text": "def test_blank_page(config, doc_provider, layout_model, ocr_error_model, detection_model):\n    layout_builder = LayoutBuilder(layout_model, config)\n    line_builder = LineBuilder(detection_model, ocr_error_model)\n    builder = DocumentBuilder(config)\n    document = builder.build_document(doc_provider)\n\n    layout_results = [LayoutResult(\n        bboxes=[],\n        image_bbox=p.polygon.bbox,\n    ) for p in document.pages]\n    provider_lines = {p.page_id: [] for p in document.pages}\n    ocr_lines = {p.page_id: [] for p in document.pages}\n\n    layout_builder.add_blocks_to_pages(document.pages, layout_results)\n    line_builder.merge_blocks(document, provider_lines, ocr_lines)\n\n    assert all([isinstance(p.children, list) for p in document.pages])\n    assert all([isinstance(p.structure, list) for p in document.pages])", "n_tokens": 186, "byte_len": 824, "file_sha1": "379fae3b2f37455ca5f28033c6816d085a9a08de", "start_line": 8, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_structure.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_structure.py", "rel_path": "tests/builders/test_structure.py", "module": "tests.builders.test_structure", "ext": "py", "chunk_number": 1, "symbols": ["test_structure_builder", "import", "structure", "builder", "marker", "pdf", "document", "assert", "pytest", "test", "config", "from", "page", "range", "pages", "mark", "builders"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.builders.structure import StructureBuilder\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_structure_builder(pdf_document):\n    structure = StructureBuilder()\n    structure(pdf_document)\n    assert len(pdf_document.pages[0].structure) > 0\n", "n_tokens": 54, "byte_len": 270, "file_sha1": "6d9ff3b8901fae686e0d504f5a92959befe65e0b", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py", "rel_path": "tests/builders/test_ocr_pipeline.py", "module": "tests.builders.test_ocr_pipeline", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "pytest", "schema", "text", "from", "line", "block", "types", "_ocr_pipeline_test", "test_ocr_pipeline", "test_ocr_with_inline_pipeline", "type", "bbox", "training", "end", "assert", "blocks", "contained", "force", "ocr", "scale", "pdf", "document", "section", "header", "lines", "config", "max", "subspace", "span", "layout", "being", "same", "get", "boxes", "mark", "extraction", "properly", "surya", "ensure", "first", "sizes", "adversarial", "strip", "structure", "pages", "makes", "pipeline", "page"], "ast_kind": "imports", "text": "import pytest\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.text.line import Line\n\n", "n_tokens": 18, "byte_len": 94, "file_sha1": "766c8d7ba9446bb4063f38a762e32c0d7ff69d00", "start_line": 1, "end_line": 6}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py", "rel_path": "tests/builders/test_ocr_pipeline.py", "module": "tests.builders.test_ocr_pipeline", "ext": "py", "chunk_number": 2, "symbols": ["_ocr_pipeline_test", "block", "type", "bbox", "training", "end", "assert", "text", "blocks", "contained", "scale", "line", "pdf", "document", "section", "header", "lines", "max", "subspace", "layout", "span", "being", "same", "get", "boxes", "extraction", "properly", "surya", "ensure", "first", "test_ocr_pipeline", "test_ocr_with_inline_pipeline", "force", "ocr", "pytest", "schema", "config", "from", "mark", "sizes", "adversarial", "strip", "structure", "types", "pages", "makes", "pipeline", "page", "import", "source"], "ast_kind": "function_or_method", "text": "def _ocr_pipeline_test(pdf_document):\n    first_page = pdf_document.pages[0]\n    assert first_page.structure[0] == \"/page/0/SectionHeader/0\"\n\n    first_block = first_page.get_block(first_page.structure[0])\n    assert first_block.text_extraction_method == \"surya\"\n    assert first_block.block_type == BlockTypes.SectionHeader\n\n    first_text_block: Line = first_page.get_block(first_block.structure[0])\n    assert first_text_block.block_type == BlockTypes.Line\n\n    first_span = first_page.get_block(first_text_block.structure[0])\n    assert first_span.block_type == BlockTypes.Span\n    assert first_span.text.strip() == \"Subspace Adversarial Training\"\n\n    # Ensure we match all text lines up properly\n    # Makes sure the OCR bbox is being scaled to the same scale as the layout boxes\n    text_lines = first_page.contained_blocks(pdf_document, (BlockTypes.Line,))\n    text_blocks = first_page.contained_blocks(\n        pdf_document, (BlockTypes.Text, BlockTypes.TextInlineMath)\n    )\n    # assert len(text_lines) == 83\n\n    # Ensure the bbox sizes match up\n    max_line_position = max([line.polygon.y_end for line in text_lines])\n    max_block_position = max(\n        [block.polygon.y_end for block in text_blocks if block.source == \"layout\"]\n    )\n    assert max_line_position <= (max_block_position * 1.02)\n\n", "n_tokens": 303, "byte_len": 1311, "file_sha1": "766c8d7ba9446bb4063f38a762e32c0d7ff69d00", "start_line": 7, "end_line": 37}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_pipeline.py", "rel_path": "tests/builders/test_ocr_pipeline.py", "module": "tests.builders.test_ocr_pipeline", "ext": "py", "chunk_number": 3, "symbols": ["test_ocr_pipeline", "test_ocr_with_inline_pipeline", "pdf", "document", "use", "llm", "pytest", "test", "ocr", "force", "config", "page", "range", "true", "pipeline", "mark", "_ocr_pipeline_test", "block", "type", "bbox", "training", "end", "assert", "text", "blocks", "contained", "scale", "line", "section", "header", "schema", "lines", "max", "from", "subspace", "span", "layout", "being", "same", "get", "boxes", "extraction", "properly", "surya", "ensure", "first", "sizes", "adversarial", "strip", "structure"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"force_ocr\": True, \"page_range\": [0]})\ndef test_ocr_pipeline(pdf_document):\n    _ocr_pipeline_test(pdf_document)\n\n\n@pytest.mark.config({\"force_ocr\": True, \"page_range\": [0], \"use_llm\": True})\ndef test_ocr_with_inline_pipeline(pdf_document):\n    _ocr_pipeline_test(pdf_document)\n", "n_tokens": 75, "byte_len": 299, "file_sha1": "766c8d7ba9446bb4063f38a762e32c0d7ff69d00", "start_line": 38, "end_line": 46}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_strip_existing_ocr.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_strip_existing_ocr.py", "rel_path": "tests/builders/test_strip_existing_ocr.py", "module": "tests.builders.test_strip_existing_ocr", "ext": "py", "chunk_number": 1, "symbols": ["test_strip_ocr", "test_keep_ocr", "import", "page", "lines", "ensure", "strip", "existing", "assert", "pytest", "test", "config", "text", "range", "keep", "handwritten", "true", "filename", "doc", "provider", "extracted", "mark", "that"], "ast_kind": "function_or_method", "text": "import pytest\n\n\n@pytest.mark.config({\"page_range\": [0], \"strip_existing_ocr\": True})\n@pytest.mark.filename(\"handwritten.pdf\")\ndef test_strip_ocr(doc_provider):\n    # Ensure that the OCR text isn't extracted\n    assert len(doc_provider.page_lines) == 0\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"handwritten.pdf\")\ndef test_keep_ocr(doc_provider):\n    assert len(doc_provider.page_lines) == 1\n", "n_tokens": 98, "byte_len": 414, "file_sha1": "2d46c17f9d9e0f172da597097d5632d090e87805", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_builder.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_ocr_builder.py", "rel_path": "tests/builders/test_ocr_builder.py", "module": "tests.builders.test_ocr_builder", "ext": "py", "chunk_number": 1, "symbols": ["test_blank_char_builder", "image", "test", "assert", "none", "builders", "ocr", "builder", "spans", "from", "char", "recognition", "model", "blank", "with", "import", "marker", "empty", "list"], "ast_kind": "function_or_method", "text": "from PIL import Image\n\nfrom marker.builders.ocr import OcrBuilder\n\n\ndef test_blank_char_builder(recognition_model):\n    builder = OcrBuilder(recognition_model)\n    image = Image.new(\"RGB\", (100, 100))\n    spans = builder.spans_from_html_chars([], None, image)  # Test with empty char list\n    assert len(spans) == 0\n", "n_tokens": 80, "byte_len": 316, "file_sha1": "4fa235e22e89c0e20a98dba81face0089d20e620", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_document_builder.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_document_builder.py", "rel_path": "tests/builders/test_document_builder.py", "module": "tests.builders.test_document_builder", "ext": "py", "chunk_number": 1, "symbols": ["test_document_builder", "block", "type", "assert", "text", "thinkpython", "line", "pdf", "document", "think", "formats", "section", "header", "roma", "pytest", "schema", "config", "from", "span", "filename", "mark", "get", "extraction", "first", "structure", "python", "urw", "palladio", "types", "pages", "test_document_builder_inline_eq", "training", "subspace", "bold", "surya", "adversarial", "test", "strip", "page", "import", "font", "marker", "pdftext", "range", "plain"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.text.line import Line\n\n\n@pytest.mark.filename(\"thinkpython.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_document_builder(pdf_document):\n    first_page = pdf_document.pages[0]\n    assert first_page.structure[0] == \"/page/0/SectionHeader/0\"\n\n    first_block = first_page.get_block(first_page.structure[0])\n    assert first_block.block_type == BlockTypes.SectionHeader\n    assert first_block.text_extraction_method == \"pdftext\"\n\n    first_text_block: Line = first_page.get_block(first_block.structure[0])\n    assert first_text_block.block_type == BlockTypes.Line\n\n    first_span = first_page.get_block(first_text_block.structure[0])\n    assert first_span.block_type == BlockTypes.Span\n    assert first_span.text == \"Think Python\"\n    assert first_span.font == \"URWPalladioL-Roma\"\n    assert first_span.formats == [\"plain\"]\n\n", "n_tokens": 201, "byte_len": 903, "file_sha1": "aeb45504c5871ca652e2c09f067a0b6d4368c287", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_document_builder.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_document_builder.py", "rel_path": "tests/builders/test_document_builder.py", "module": "tests.builders.test_document_builder", "ext": "py", "chunk_number": 2, "symbols": ["test_document_builder_inline_eq", "block", "type", "training", "assert", "text", "line", "pdf", "document", "formats", "section", "header", "pytest", "config", "subspace", "span", "bold", "get", "mark", "extraction", "surya", "first", "adversarial", "test", "strip", "structure", "types", "pages", "page", "range", "test_document_builder", "thinkpython", "think", "roma", "schema", "from", "filename", "python", "urw", "palladio", "import", "font", "marker", "pdftext", "plain"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0]})\ndef test_document_builder_inline_eq(pdf_document):\n    first_page = pdf_document.pages[0]\n    assert first_page.structure[0] == \"/page/0/SectionHeader/0\"\n\n    first_block = first_page.get_block(first_page.structure[0])\n    assert first_block.block_type == BlockTypes.SectionHeader\n    assert first_block.text_extraction_method == \"surya\"\n\n    first_text_block: Line = first_page.get_block(first_block.structure[0])\n    assert first_text_block.block_type == BlockTypes.Line\n\n    first_span = first_page.get_block(first_text_block.structure[0])\n    assert first_span.block_type == BlockTypes.Span\n    assert first_span.text.strip() == \"Subspace Adversarial Training\"\n    assert \"bold\" in first_span.formats\n", "n_tokens": 169, "byte_len": 746, "file_sha1": "aeb45504c5871ca652e2c09f067a0b6d4368c287", "start_line": 27, "end_line": 43}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_pdf_links.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_pdf_links.py", "rel_path": "tests/builders/test_pdf_links.py", "module": "tests.builders.test_pdf_links", "ext": "py", "chunk_number": 1, "symbols": ["import", "pdf", "converter", "document", "marker", "markdown", "util", "pytest", "converters", "schema", "from", "output", "classes", "strings", "block", "types", "renderers", "test_pdf_links", "find", "assert", "section", "header", "model", "dict", "contained", "blocks", "text", "renderer", "break", "format", "disable", "ocr", "findall", "else", "raw", "reference", "config", "temp", "doc", "processor", "test", "span", "first", "arxiv", "theoretical", "filename", "mark", "artifact", "could", "refs"], "ast_kind": "imports", "text": "import re\n\nimport pytest\n\nfrom marker.converters.pdf import PdfConverter\nfrom marker.renderers.markdown import MarkdownOutput\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.util import classes_to_strings\n\n", "n_tokens": 47, "byte_len": 251, "file_sha1": "6c1388bfe3d2fa7bb5885e54953d1bcb5525dff3", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_pdf_links.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_pdf_links.py", "rel_path": "tests/builders/test_pdf_links.py", "module": "tests.builders.test_pdf_links", "ext": "py", "chunk_number": 2, "symbols": ["test_pdf_links", "find", "markdown", "assert", "section", "header", "model", "dict", "contained", "blocks", "text", "output", "renderer", "classes", "strings", "break", "disable", "ocr", "pdf", "document", "format", "findall", "else", "raw", "reference", "pytest", "processor", "first", "config", "found", "converters", "schema", "temp", "doc", "from", "test", "converter", "span", "arxiv", "theoretical", "filename", "mark", "artifact", "could", "refs", "processors", "block", "types", "renderers", "pages"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"arxiv_test.pdf\")\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"disable_ocr\": True})\ndef test_pdf_links(pdf_document: Document, config, renderer, model_dict, temp_doc):\n    first_page = pdf_document.pages[1]\n\n    processors = [\"marker.processors.reference.ReferenceProcessor\"]\n    pdf_converter = PdfConverter(\n        artifact_dict=model_dict,\n        processor_list=processors,\n        renderer=classes_to_strings([renderer])[0],\n        config=config,\n    )\n\n    for section_header_span in first_page.contained_blocks(\n        pdf_document, (BlockTypes.Span,)\n    ):\n        if \"II.\" in section_header_span.text:\n            assert section_header_span.url == \"#page-1-0\"\n            break\n    else:\n        raise ValueError(\"Could not find II. in the first page\")\n\n    section_header_block = first_page.contained_blocks(\n        pdf_document, (BlockTypes.SectionHeader,)\n    )[0]\n    assert section_header_block.raw_text(pdf_document) == \"II. THEORETICAL FRAMEWORK\\n\"\n\n    assert first_page.refs[0].ref == \"page-1-0\"\n\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    assert \"[II.](#page-1-0)\" in markdown\n    assert '<span id=\"page-1-0\"></span>II. THEORETICAL FRAMEWORK' in markdown\n\n    for ref in set(\n        [\n            f'<span id=\"page-{m[0]}-{m[1]}\">'\n            for m in re.findall(r\"\\]\\(#page-(\\d+)-(\\d+)\\)\", markdown)\n        ]\n    ):\n        assert ref in markdown, f\"Reference {ref} not found in markdown\"\n", "n_tokens": 366, "byte_len": 1523, "file_sha1": "6c1388bfe3d2fa7bb5885e54953d1bcb5525dff3", "start_line": 12, "end_line": 55}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_rotated_bboxes.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_rotated_bboxes.py", "rel_path": "tests/builders/test_rotated_bboxes.py", "module": "tests.builders.test_rotated_bboxes", "ext": "py", "chunk_number": 1, "symbols": ["test_rotated_bboxes", "bbox", "text", "blocks", "assert", "contained", "line", "pdf", "document", "pytest", "schema", "lines", "config", "adversarial", "rot", "max", "from", "layout", "block", "filename", "mark", "properly", "ensure", "sizes", "types", "pages", "test", "rotated", "first", "page", "import", "source", "inline", "marker", "polygon", "range", "match", "end"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.schema import BlockTypes\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"adversarial_rot.pdf\")\ndef test_rotated_bboxes(pdf_document):\n    first_page = pdf_document.pages[0]\n\n    # Ensure we match all text lines up properly\n    text_lines = first_page.contained_blocks(pdf_document, (BlockTypes.Line,))\n    text_blocks = first_page.contained_blocks(\n        pdf_document, (BlockTypes.Text, BlockTypes.TextInlineMath)\n    )\n    # assert len(text_lines) == 84\n\n    # Ensure the bbox sizes match up\n    max_line_position = max([line.polygon.x_end for line in text_lines])\n    max_block_position = max(\n        [block.polygon.x_end for block in text_blocks if block.source == \"layout\"]\n    )\n    assert max_line_position <= max_block_position\n", "n_tokens": 180, "byte_len": 783, "file_sha1": "2d7b0a8138c057379a4ea92c7a6e5e9fc51b5989", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_overriding.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_overriding.py", "rel_path": "tests/builders/test_overriding.py", "module": "tests.builders.test_overriding", "ext": "py", "chunk_number": 1, "symbols": ["test_overriding", "get_lines", "NewSectionHeader", "NewLine", "block", "type", "class", "assert", "new", "line", "text", "none", "test", "overriding", "blocks", "pdf", "document", "section", "header", "pytest", "schema", "utils", "config", "providers", "cls", "from", "setup", "get", "page", "lines", "test_overriding_mp", "results", "starmap", "adversarial", "rot", "pool", "return", "mark", "register", "multiprocessing", "structure", "processes", "provider", "types", "pages", "with", "import", "override", "map", "marker"], "ast_kind": "class_or_type", "text": "import multiprocessing as mp\n\nimport pytest\n\nfrom marker.providers.pdf import PdfProvider\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import SectionHeader\nfrom marker.schema.document import Document\nfrom marker.schema.registry import register_block_class\nfrom marker.schema.text import Line\nfrom tests.utils import setup_pdf_provider\n\n\nclass NewSectionHeader(SectionHeader):\n    pass\n\n\nclass NewLine(Line):\n    pass\n\n\n@pytest.mark.config({\n    \"page_range\": [0],\n    \"override_map\": {BlockTypes.SectionHeader: NewSectionHeader}\n})\ndef test_overriding(pdf_document: Document):\n    assert pdf_document.pages[0]\\\n        .get_block(pdf_document.pages[0].structure[0]).__class__ == NewSectionHeader\n\n\ndef get_lines(pdf: str, config=None):\n    for block_type, block_cls in config[\"override_map\"].items():\n        register_block_class(block_type, block_cls)\n\n    provider: PdfProvider = setup_pdf_provider(pdf, config)\n    return provider.get_page_lines(0)\n\n", "n_tokens": 206, "byte_len": 971, "file_sha1": "cf8f38fe93b149ae7d366b5ab1ae79593aba84e1", "start_line": 1, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_overriding.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_overriding.py", "rel_path": "tests/builders/test_overriding.py", "module": "tests.builders.test_overriding", "ext": "py", "chunk_number": 2, "symbols": ["test_overriding_mp", "results", "assert", "new", "line", "starmap", "config", "adversarial", "rot", "pool", "get", "lines", "class", "processes", "block", "types", "with", "override", "map", "test", "overriding", "page", "range", "pdf", "list", "test_overriding", "get_lines", "NewSectionHeader", "NewLine", "type", "text", "none", "blocks", "document", "section", "header", "pytest", "schema", "utils", "providers", "cls", "from", "setup", "return", "mark", "register", "multiprocessing", "structure", "provider", "pages"], "ast_kind": "function_or_method", "text": "def test_overriding_mp():\n    config = {\n        \"page_range\": [0],\n        \"override_map\": {BlockTypes.Line: NewLine}\n    }\n\n    pdf_list = [\"adversarial.pdf\", \"adversarial_rot.pdf\"]\n\n    with mp.Pool(processes=2) as pool:\n        results = pool.starmap(get_lines, [(pdf, config) for pdf in pdf_list])\n        assert all([r[0].line.__class__ == NewLine for r in results])\n", "n_tokens": 103, "byte_len": 373, "file_sha1": "cf8f38fe93b149ae7d366b5ab1ae79593aba84e1", "start_line": 39, "end_line": 50}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_layout_replace.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_layout_replace.py", "rel_path": "tests/builders/test_layout_replace.py", "module": "tests.builders.test_layout_replace", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "markdown", "pytest", "document", "schema", "from", "line", "layout", "registry", "builder", "get", "block", "types", "renderers", "renderer", "builders", "test_layout_replace", "assert", "rendered", "text", "thinkpython", "contained", "blocks", "model", "merged", "think", "raw", "config", "append", "sure", "new", "request", "filename", "generated", "mark", "replaces", "properly", "strip", "structure", "python", "test", "ocr", "error", "build", "pages", "doc", "provider", "page", "inline"], "ast_kind": "imports", "text": "import pytest\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.layout import LayoutBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.registry import get_block_class\n\n", "n_tokens": 53, "byte_len": 306, "file_sha1": "3fea1d50be362a7d5310e97ce67f5daf7f1e3492", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_layout_replace.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_layout_replace.py", "rel_path": "tests/builders/test_layout_replace.py", "module": "tests.builders.test_layout_replace", "ext": "py", "chunk_number": 2, "symbols": ["test_layout_replace", "markdown", "assert", "rendered", "text", "thinkpython", "contained", "blocks", "layout", "model", "renderer", "document", "builder", "merged", "think", "raw", "pytest", "append", "config", "new", "request", "filename", "generated", "block", "mark", "replaces", "properly", "python", "strip", "structure", "builders", "schema", "from", "line", "sure", "get", "test", "types", "ocr", "error", "renderers", "build", "pages", "doc", "provider", "page", "import", "inline", "marker", "this"], "ast_kind": "class_or_type", "text": "@pytest.mark.filename(\"thinkpython.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_layout_replace(\n    request, config, doc_provider, layout_model, ocr_error_model, detection_model\n):\n    # The llm layout builder replaces blocks - this makes sure text is still merged properly\n    layout_builder = LayoutBuilder(layout_model, config)\n    line_builder = LineBuilder(detection_model, ocr_error_model, config)\n    builder = DocumentBuilder(config)\n    document = builder.build_document(doc_provider)\n    layout_builder(document, doc_provider)\n    page = document.pages[0]\n    new_blocks = []\n    for block in page.contained_blocks(document, (BlockTypes.Text,)):\n        generated_block_class = get_block_class(BlockTypes.TextInlineMath)\n        generated_block = generated_block_class(\n            polygon=block.polygon,\n            page_id=block.page_id,\n            structure=block.structure,\n        )\n        page.replace_block(block, generated_block)\n        new_blocks.append(generated_block)\n    line_builder(document, doc_provider)\n\n    for block in new_blocks:\n        assert block.raw_text(document).strip()\n\n    renderer = MarkdownRenderer(config)\n    rendered = renderer(document)\n\n    assert \"Think Python\" in rendered.markdown\n", "n_tokens": 253, "byte_len": 1246, "file_sha1": "3fea1d50be362a7d5310e97ce67f5daf7f1e3492", "start_line": 11, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py", "rel_path": "tests/builders/test_garbled_pdf.py", "module": "tests.builders.test_garbled_pdf", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "pytest", "document", "schema", "from", "line", "processors", "builder", "table", "processor", "block", "types", "builders", "test_garbled_pdf", "test_garbled_builder", "test_nongarbled_builder", "type", "assert", "rec", "contained", "blocks", "test", "nongarbled", "water", "damage", "ocr", "error", "disable", "pdf", "raw", "text", "label", "garbled", "config", "labels", "recognition", "model", "bad", "good", "filename", "mark", "get", "page", "lines", "cell", "structure", "pages", "with", "doc"], "ast_kind": "imports", "text": "import pytest\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.processors.table import TableProcessor\nfrom marker.schema import BlockTypes\n\n", "n_tokens": 35, "byte_len": 202, "file_sha1": "77a853888f0919f5deb598db64bc790c67132ca5", "start_line": 1, "end_line": 8}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py", "rel_path": "tests/builders/test_garbled_pdf.py", "module": "tests.builders.test_garbled_pdf", "ext": "py", "chunk_number": 2, "symbols": ["test_garbled_pdf", "block", "type", "assert", "table", "rec", "contained", "blocks", "water", "damage", "line", "processor", "pdf", "document", "raw", "text", "pytest", "recognition", "model", "filename", "get", "mark", "cell", "test", "garbled", "structure", "types", "pages", "with", "only", "test_garbled_builder", "test_nongarbled_builder", "nongarbled", "ocr", "error", "builder", "disable", "builders", "label", "schema", "config", "labels", "from", "bad", "good", "page", "lines", "processors", "doc", "provider"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"water_damage.pdf\")\ndef test_garbled_pdf(pdf_document, recognition_model, table_rec_model, detection_model):\n    assert pdf_document.pages[0].structure[0] == \"/page/0/Table/0\"\n\n    table_block = pdf_document.pages[0].get_block(pdf_document.pages[0].structure[0])\n    assert table_block.block_type == BlockTypes.Table\n    assert table_block.structure[0] == \"/page/0/Line/1\"\n\n    table_cell = pdf_document.pages[0].get_block(table_block.structure[0])\n    assert table_cell.block_type == BlockTypes.Line\n\n    # We don't OCR in the initial pass, only with the TableProcessor\n    processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    processor(pdf_document)\n\n    table = pdf_document.pages[0].contained_blocks(pdf_document, (BlockTypes.Table,))[0]\n    assert \"\" in table.raw_text(pdf_document)\n\n    table_cell = pdf_document.pages[0].get_block(table_block.structure[0])\n    assert table_cell.block_type == BlockTypes.TableCell\n\n", "n_tokens": 234, "byte_len": 989, "file_sha1": "77a853888f0919f5deb598db64bc790c67132ca5", "start_line": 9, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py", "rel_path": "tests/builders/test_garbled_pdf.py", "module": "tests.builders.test_garbled_pdf", "ext": "py", "chunk_number": 3, "symbols": ["test_garbled_builder", "assert", "ocr", "error", "document", "builder", "disable", "label", "test", "garbled", "pytest", "config", "labels", "bad", "filename", "mark", "page", "lines", "line", "build", "pages", "doc", "provider", "detection", "model", "range", "hindi", "judgement", "true", "test_garbled_pdf", "test_nongarbled_builder", "block", "type", "table", "rec", "contained", "blocks", "nongarbled", "water", "damage", "processor", "pdf", "builders", "raw", "text", "schema", "from", "recognition", "good", "get"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"hindi_judgement.pdf\")\n@pytest.mark.config({\"page_range\": [2, 3], \"disable_ocr\": True})\ndef test_garbled_builder(config, doc_provider, detection_model, ocr_error_model):\n    line_builder = LineBuilder(detection_model, ocr_error_model, config)\n    builder = DocumentBuilder(config)\n    document = builder.build_document(doc_provider)\n\n    bad_ocr_results = line_builder.ocr_error_detection(\n        document.pages, doc_provider.page_lines\n    )\n    assert len(bad_ocr_results.labels) == 2\n    assert any([label == \"bad\" for label in bad_ocr_results.labels])\n\n", "n_tokens": 139, "byte_len": 580, "file_sha1": "77a853888f0919f5deb598db64bc790c67132ca5", "start_line": 31, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/builders/test_garbled_pdf.py", "rel_path": "tests/builders/test_garbled_pdf.py", "module": "tests.builders.test_garbled_pdf", "ext": "py", "chunk_number": 4, "symbols": ["test_nongarbled_builder", "assert", "test", "nongarbled", "ocr", "error", "document", "builder", "disable", "label", "pytest", "config", "labels", "good", "bad", "filename", "mark", "page", "lines", "line", "build", "pages", "doc", "provider", "adversarial", "detection", "model", "range", "true", "test_garbled_pdf", "test_garbled_builder", "block", "type", "table", "rec", "contained", "blocks", "water", "damage", "processor", "pdf", "builders", "raw", "text", "garbled", "schema", "from", "recognition", "get", "cell"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"adversarial.pdf\")\n@pytest.mark.config({\"page_range\": [2, 3], \"disable_ocr\": True})\ndef test_nongarbled_builder(config, doc_provider, detection_model, ocr_error_model):\n    line_builder = LineBuilder(detection_model, ocr_error_model, config)\n    builder = DocumentBuilder(config)\n    document = builder.build_document(doc_provider)\n\n    bad_ocr_results = line_builder.ocr_error_detection(\n        document.pages, doc_provider.page_lines\n    )\n    assert len(bad_ocr_results.labels) == 2\n    assert all([label == \"good\" for label in bad_ocr_results.labels])\n", "n_tokens": 138, "byte_len": 579, "file_sha1": "77a853888f0919f5deb598db64bc790c67132ca5", "start_line": 45, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py", "rel_path": "tests/config/test_config.py", "module": "tests.config.test_config", "ext": "py", "chunk_number": 1, "symbols": ["capture_kwargs", "parse_args", "click", "parser", "original", "argv", "system", "exit", "capture", "kwargs", "config", "from", "contextlib", "return", "suppress", "captured", "parse", "args", "custom", "with", "crawler", "import", "common", "options", "marker", "finally", "update", "printer", "command", "test_config_parser", "test_config_none", "test_config_llm", "test_config_force_ocr", "ease", "assert", "none", "test", "force", "ocr", "some", "disable", "multiprocessing", "become", "validate", "pdftext", "workers", "generate", "kwarg", "does", "disabling"], "ast_kind": "function_or_method", "text": "import sys\nfrom contextlib import suppress\nimport click\n\nfrom marker.config.printer import CustomClickPrinter\nfrom marker.config.crawler import crawler\nfrom marker.config.parser import ConfigParser\n\n\ndef capture_kwargs(argv):\n    command = click.command(cls=CustomClickPrinter)\n    captured_kwargs = {}\n\n    def parse_args(**kwargs):\n        captured_kwargs.update(kwargs)\n        return kwargs\n\n    original_argv = sys.argv\n    sys.argv = argv\n    try:\n        with suppress(SystemExit):\n            command(ConfigParser.common_options(parse_args))()\n    finally:\n        sys.argv = original_argv\n\n    return captured_kwargs\n\n", "n_tokens": 123, "byte_len": 627, "file_sha1": "4a1f71f41ba88a21e87d74de3bfeabd4bdabe2d5", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py", "rel_path": "tests/config/test_config.py", "module": "tests.config.test_config", "ext": "py", "chunk_number": 2, "symbols": ["test_config_parser", "test_config_none", "ease", "assert", "none", "test", "parser", "config", "some", "become", "disable", "multiprocessing", "validate", "pdftext", "workers", "generate", "force", "capture", "kwargs", "kwarg", "does", "disabling", "height", "tolerance", "dict", "capturing", "attr", "set", "this", "options", "capture_kwargs", "parse_args", "test_config_llm", "test_config_force_ocr", "ocr", "click", "original", "argv", "system", "exit", "from", "contextlib", "return", "suppress", "captured", "parse", "args", "output", "dir", "flags"], "ast_kind": "function_or_method", "text": "def test_config_parser():\n    sys.argv = [\n        \"test\",\n        \"--disable_multiprocessing\",\n        \"--output_dir\",\n        \"output_dir\",\n        \"--height_tolerance\",\n        \"0.5\",\n    ]\n    kwargs = capture_kwargs(sys.argv)\n    parser = ConfigParser(kwargs)\n    config_dict = parser.generate_config_dict()\n\n    # Validate kwarg capturing\n    assert kwargs[\"disable_multiprocessing\"]\n    assert kwargs[\"output_dir\"] == \"output_dir\"\n\n    assert config_dict[\"pdftext_workers\"] == 1  # disabling multiprocessing does this\n    assert config_dict[\"height_tolerance\"] == 0.5\n    assert \"output_dir\" not in config_dict  # This is not a config key\n\n\ndef test_config_none():\n    kwargs = capture_kwargs([\"test\"])\n\n    for key in crawler.attr_set:\n        # We force some options to become flags for ease of use on the CLI\n        value = None\n        assert kwargs.get(key) is value\n\n", "n_tokens": 199, "byte_len": 881, "file_sha1": "4a1f71f41ba88a21e87d74de3bfeabd4bdabe2d5", "start_line": 29, "end_line": 59}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/config/test_config.py", "rel_path": "tests/config/test_config.py", "module": "tests.config.test_config", "ext": "py", "chunk_number": 3, "symbols": ["test_config_llm", "test_config_force_ocr", "test", "config", "dict", "generate", "assert", "capture", "kwargs", "capturing", "kwarg", "parser", "force", "ocr", "use", "llm", "validate", "capture_kwargs", "parse_args", "test_config_parser", "test_config_none", "ease", "none", "click", "original", "argv", "some", "system", "exit", "disable", "multiprocessing", "become", "pdftext", "workers", "from", "does", "disabling", "contextlib", "return", "height", "tolerance", "suppress", "captured", "parse", "args", "this", "output", "dir", "attr", "set"], "ast_kind": "function_or_method", "text": "def test_config_llm():\n    kwargs = capture_kwargs([\"test\", \"--use_llm\"])\n    parser = ConfigParser(kwargs)\n    config_dict = parser.generate_config_dict()\n\n    # Validate kwarg capturing\n    assert config_dict[\"use_llm\"]\n\n\ndef test_config_force_ocr():\n    kwargs = capture_kwargs([\"test\", \"--force_ocr\"])\n    parser = ConfigParser(kwargs)\n    config_dict = parser.generate_config_dict()\n\n    # Validate kwarg capturing\n    assert config_dict[\"force_ocr\"]\n", "n_tokens": 104, "byte_len": 456, "file_sha1": "4a1f71f41ba88a21e87d74de3bfeabd4bdabe2d5", "start_line": 60, "end_line": 76}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_pdf_provider.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_pdf_provider.py", "rel_path": "tests/providers/test_pdf_provider.py", "module": "tests.providers.test_pdf_provider", "ext": "py", "chunk_number": 1, "symbols": ["test_pdf_provider", "training", "test", "pdf", "assert", "text", "formats", "pytest", "config", "spans", "subspace", "size", "get", "page", "images", "mark", "lines", "nimbus", "rom", "adversarial", "medi", "doc", "provider", "import", "font", "range", "plain"], "ast_kind": "function_or_method", "text": "import pytest\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_pdf_provider(doc_provider):\n    assert len(doc_provider) == 12\n    assert doc_provider.get_images([0], 72)[0].size == (612, 792)\n    assert doc_provider.get_images([0], 96)[0].size == (816, 1056)\n\n    page_lines = doc_provider.get_page_lines(0)\n    assert len(page_lines) == 85\n\n    spans = page_lines[0].spans\n    assert len(spans) == 2\n    assert spans[0].text == \"Subspace Adversarial Training\"\n    assert spans[0].font == \"NimbusRomNo9L-Medi\"\n    assert spans[0].formats == [\"plain\"]\n", "n_tokens": 163, "byte_len": 554, "file_sha1": "48e7ca54941248e4af1c1faa4b9c611f1f74099c", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py", "rel_path": "tests/providers/test_document_providers.py", "module": "tests.providers.test_document_providers", "ext": "py", "chunk_number": 1, "symbols": ["test_pptx_provider", "calculus", "assert", "text", "programming", "pytest", "config", "spans", "languages", "size", "get", "page", "filename", "images", "mark", "lines", "test", "pptx", "doc", "provider", "import", "lambda", "range", "principles", "test_epub_provider", "test_html_provider", "test_docx_provider", "test_xlsx_provider", "china", "gutenberg", "content", "book", "ebook", "single", "sheet", "html", "project", "gatsby", "themes", "xlsx", "manual", "docx", "epub", "simple", "jump", "sheet1"], "ast_kind": "function_or_method", "text": "import pytest\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"lambda.pptx\")\ndef test_pptx_provider(doc_provider):\n    assert doc_provider.get_images([0], 72)[0].size == (842, 596)\n\n    page_lines = doc_provider.get_page_lines(0)\n\n    spans = page_lines[0].spans\n    assert spans[0].text == \"Lambda Calculus\"\n\n    spans = page_lines[1].spans\n    assert spans[0].text == \"CSE 340  Principles of Programming Languages\"\n\n", "n_tokens": 119, "byte_len": 438, "file_sha1": "d4c13e252fca6206369550b9d667664d56cbd6f2", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py", "rel_path": "tests/providers/test_document_providers.py", "module": "tests.providers.test_document_providers", "ext": "py", "chunk_number": 2, "symbols": ["test_epub_provider", "test_html_provider", "assert", "text", "china", "gutenberg", "content", "book", "ebook", "html", "pytest", "project", "config", "spans", "test", "size", "get", "page", "filename", "images", "mark", "lines", "manual", "doc", "provider", "epub", "simple", "jump", "range", "test_pptx_provider", "test_docx_provider", "test_xlsx_provider", "calculus", "single", "sheet", "programming", "languages", "gatsby", "themes", "xlsx", "pptx", "docx", "import", "lambda", "principles", "sheet1"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"manual.epub\")\ndef test_epub_provider(doc_provider):\n    assert doc_provider.get_images([0], 72)[0].size == (596, 842)\n\n    page_lines = doc_provider.get_page_lines(0)\n\n    spans = page_lines[0].spans\n    assert spans[0].text == \"The Project Gutenberg eBook of Simple\"\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"china.html\")\ndef test_html_provider(doc_provider):\n    assert doc_provider.get_images([0], 72)[0].size == (596, 842)\n\n    page_lines = doc_provider.get_page_lines(0)\n\n    spans = page_lines[0].spans\n    assert spans[0].text == \"Jump to content\"\n", "n_tokens": 169, "byte_len": 643, "file_sha1": "d4c13e252fca6206369550b9d667664d56cbd6f2", "start_line": 18, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_document_providers.py", "rel_path": "tests/providers/test_document_providers.py", "module": "tests.providers.test_document_providers", "ext": "py", "chunk_number": 3, "symbols": ["test_docx_provider", "test_xlsx_provider", "assert", "text", "single", "sheet", "pytest", "config", "spans", "size", "get", "page", "gatsby", "filename", "themes", "test", "xlsx", "images", "mark", "lines", "doc", "provider", "docx", "range", "sheet1", "test_pptx_provider", "test_epub_provider", "test_html_provider", "calculus", "china", "gutenberg", "content", "book", "ebook", "programming", "html", "project", "languages", "pptx", "manual", "epub", "import", "simple", "lambda", "jump", "principles"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"gatsby.docx\")\ndef test_docx_provider(doc_provider):\n    assert doc_provider.get_images([0], 72)[0].size == (596, 842)\n\n    page_lines = doc_provider.get_page_lines(0)\n\n    spans = page_lines[0].spans\n    assert spans[0].text == \"Themes\"\n\n\n@pytest.mark.config({\"page_range\": [0]})\n@pytest.mark.filename(\"single_sheet.xlsx\")\ndef test_xlsx_provider(doc_provider):\n    assert doc_provider.get_images([0], 72)[0].size == (842, 596)\n\n    page_lines = doc_provider.get_page_lines(0)\n\n    spans = page_lines[0].spans\n    assert spans[0].text == \"Sheet1\"", "n_tokens": 165, "byte_len": 609, "file_sha1": "d4c13e252fca6206369550b9d667664d56cbd6f2", "start_line": 39, "end_line": 58}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_image_provider.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/providers/test_image_provider.py", "rel_path": "tests/providers/test_image_provider.py", "module": "tests.providers.test_image_provider", "ext": "py", "chunk_number": 1, "symbols": ["test_image_provider", "test_image_provider_conversion", "markdown", "assert", "world", "output", "test", "image", "config", "provider", "providers", "from", "pdf", "converter", "size", "get", "page", "images", "lines", "hello", "renderers", "temp", "import", "marker", "name"], "ast_kind": "function_or_method", "text": "from marker.providers.image import ImageProvider\nfrom marker.renderers.markdown import MarkdownOutput\n\n\ndef test_image_provider(config, temp_image):\n    provider = ImageProvider(temp_image.name, config)\n    assert len(provider) == 1\n    assert provider.get_images([0], 72)[0].size == (512, 512)\n\n    page_lines = provider.get_page_lines(0)\n    assert len(page_lines) == 0\n\ndef test_image_provider_conversion(pdf_converter, temp_image):\n    markdown_output: MarkdownOutput = pdf_converter(temp_image.name)\n    assert \"Hello, World!\" in markdown_output.markdown\n\n\n", "n_tokens": 126, "byte_len": 562, "file_sha1": "d4d758c327e241494d4ee2a8da14c7a44ff96266", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py", "rel_path": "tests/converters/test_ocr_converter.py", "module": "tests.converters.test_ocr_converter", "ext": "py", "chunk_number": 1, "symbols": ["_ocr_converter", "block", "type", "ocrjson", "page", "assert", "model", "dict", "ocr", "converter", "temp", "pdf", "pytest", "converters", "config", "from", "line", "return", "json", "children", "equation", "artifact", "renderers", "count", "pages", "import", "marker", "output", "name", "check_bboxes", "test_ocr_converter", "test_ocr_converter_force", "test_ocr_converter_keep", "bbox", "size", "test", "force", "check", "bboxes", "doc", "filename", "mark", "pres", "lines", "outside", "keep", "chars", "child", "range", "true"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.converters.ocr import OCRConverter\nfrom marker.renderers.ocr_json import OCRJSONOutput, OCRJSONPageOutput\n\n\ndef _ocr_converter(config, model_dict, temp_pdf, line_count: int, eq_count: int):\n    converter = OCRConverter(artifact_dict=model_dict, config=config)\n\n    ocr_json: OCRJSONOutput = converter(temp_pdf.name)\n    pages = ocr_json.children\n\n    assert len(pages) == 1\n    # assert len(pages[0].children) == line_count\n    eqs = [line for line in pages[0].children if line.block_type == \"Equation\"]\n    assert len(eqs) == eq_count\n    return pages\n\n", "n_tokens": 148, "byte_len": 581, "file_sha1": "a89b19d0c7b2837328ea1b067ed91f7505089994", "start_line": 1, "end_line": 19}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py", "rel_path": "tests/converters/test_ocr_converter.py", "module": "tests.converters.test_ocr_converter", "ext": "py", "chunk_number": 2, "symbols": ["check_bboxes", "test_ocr_converter", "bbox", "ocrjson", "page", "size", "assert", "model", "dict", "check", "bboxes", "pytest", "ocr", "converter", "config", "temp", "doc", "line", "mark", "children", "lines", "outside", "child", "test", "range", "_ocr_converter", "test_ocr_converter_force", "test_ocr_converter_keep", "block", "type", "force", "pdf", "converters", "from", "filename", "return", "json", "equation", "artifact", "pres", "renderers", "count", "pages", "keep", "chars", "import", "marker", "true", "output", "name"], "ast_kind": "function_or_method", "text": "def check_bboxes(page: OCRJSONPageOutput, lines):\n    page_size = page.bbox\n    for line in lines:\n        assert len(line.children) > 0\n        for child in line.children:\n            bbox = child.bbox\n            assert all(\n                [\n                    bbox[0] >= page_size[0],\n                    bbox[1] >= page_size[1],\n                    bbox[2] <= page_size[2],\n                    bbox[3] <= page_size[3],\n                ]\n            ), \"Child bbox is outside page bbox\"\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_ocr_converter(config, model_dict, temp_doc):\n    _ocr_converter(config, model_dict, temp_doc, 85, 2)\n\n", "n_tokens": 154, "byte_len": 646, "file_sha1": "a89b19d0c7b2837328ea1b067ed91f7505089994", "start_line": 20, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_ocr_converter.py", "rel_path": "tests/converters/test_ocr_converter.py", "module": "tests.converters.test_ocr_converter", "ext": "py", "chunk_number": 3, "symbols": ["test_ocr_converter_force", "test_ocr_converter_keep", "block", "type", "test", "ocr", "force", "model", "dict", "line", "check", "bboxes", "pytest", "converter", "config", "temp", "doc", "filename", "mark", "children", "pres", "lines", "pages", "keep", "chars", "page", "range", "true", "_ocr_converter", "check_bboxes", "test_ocr_converter", "bbox", "ocrjson", "size", "assert", "pdf", "converters", "from", "return", "json", "equation", "artifact", "outside", "renderers", "count", "import", "child", "marker", "output", "name"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"pres.pdf\")\n@pytest.mark.config({\"page_range\": [1], \"force_ocr\": True, \"keep_chars\": True})\ndef test_ocr_converter_force(config, model_dict, temp_doc):\n    pages = _ocr_converter(config, model_dict, temp_doc, 10, 0)\n    lines = [line for line in pages[0].children if line.block_type == \"Line\"]\n    check_bboxes(pages[0], lines)\n\n\n@pytest.mark.filename(\"pres.pdf\")\n@pytest.mark.config({\"page_range\": [1], \"keep_chars\": True})\ndef test_ocr_converter_keep(config, model_dict, temp_doc):\n    pages = _ocr_converter(config, model_dict, temp_doc, 10, 0)\n    lines = [line for line in pages[0].children if line.block_type == \"Line\"]\n    check_bboxes(pages[0], lines)\n", "n_tokens": 183, "byte_len": 682, "file_sha1": "a89b19d0c7b2837328ea1b067ed91f7505089994", "start_line": 41, "end_line": 55}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_table_converter.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_table_converter.py", "rel_path": "tests/converters/test_table_converter.py", "module": "tests.converters.test_table_converter", "ext": "py", "chunk_number": 1, "symbols": ["_table_converter", "test_table_converter", "markdown", "assert", "model", "dict", "none", "output", "classes", "strings", "renderer", "format", "temp", "pdf", "pytest", "converters", "config", "table", "converter", "doc", "from", "mark", "cyclic", "artifact", "renderers", "import", "test", "marker", "util", "page", "test_table_converter_ocr", "force", "ocr", "range", "processor", "list", "true", "name"], "ast_kind": "function_or_method", "text": "import pytest\nfrom marker.converters.table import TableConverter\nfrom marker.renderers.markdown import MarkdownOutput\nfrom marker.util import classes_to_strings\n\ndef _table_converter(config, model_dict, renderer, temp_pdf):\n    converter = TableConverter(\n        artifact_dict=model_dict,\n        processor_list=None,\n        renderer=classes_to_strings([renderer])[0],\n        config=config\n    )\n\n    markdown_output: MarkdownOutput = converter(temp_pdf.name)\n    markdown = markdown_output.markdown\n\n    assert len(markdown) > 0\n    assert \"cyclic\" in markdown\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [5]})\ndef test_table_converter(config, model_dict, renderer, temp_doc):\n    _table_converter(config, model_dict, renderer, temp_doc)\n", "n_tokens": 162, "byte_len": 774, "file_sha1": "51ffc3c903fa51cdab075443872a71187f301139", "start_line": 1, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_table_converter.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_table_converter.py", "rel_path": "tests/converters/test_table_converter.py", "module": "tests.converters.test_table_converter", "ext": "py", "chunk_number": 2, "symbols": ["test_table_converter_ocr", "test", "table", "markdown", "pytest", "force", "ocr", "config", "model", "dict", "temp", "doc", "page", "range", "converter", "renderer", "true", "output", "format", "mark", "_table_converter", "test_table_converter", "assert", "none", "classes", "strings", "pdf", "converters", "from", "cyclic", "artifact", "renderers", "import", "marker", "util", "processor", "list", "name"], "ast_kind": "function_or_method", "text": "@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [5], \"force_ocr\": True})\ndef test_table_converter_ocr(config, model_dict, renderer, temp_doc):\n    _table_converter(config, model_dict, renderer, temp_doc)\n\n", "n_tokens": 54, "byte_len": 231, "file_sha1": "51ffc3c903fa51cdab075443872a71187f301139", "start_line": 26, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py", "rel_path": "tests/converters/test_extraction_converter.py", "module": "tests.converters.test_extraction_converter", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "mock_llm_service", "MockLLMService", "prompt", "elif", "services", "class", "none", "response", "schema", "extraction", "document", "analysis", "page", "image", "notes", "test", "value", "pytest", "converters", "self", "mock", "llm", "from", "detailed", "kwargs", "description", "return", "converter", "base", "extraction_converter", "test_extraction_converter", "test_extraction_converter_multiple_pages", "markdown", "results", "assert", "model", "dict", "service", "output", "format", "config", "required", "temp", "doc", "result", "properties", "mark", "invalid", "dumps"], "ast_kind": "class_or_type", "text": "import json\nimport pytest\n\nfrom marker.converters.extraction import ExtractionConverter\nfrom marker.extractors.page import PageExtractionSchema\nfrom marker.extractors.document import DocumentExtractionSchema\nfrom marker.services import BaseService\n\n\nclass MockLLMService(BaseService):\n    def __call__(self, prompt, image=None, page=None, response_schema=None, **kwargs):\n        if response_schema == PageExtractionSchema:\n            return {\n                \"description\": \"Mock extraction description\",\n                \"detailed_notes\": \"Mock detailed notes for page extraction\",\n            }\n        elif response_schema == DocumentExtractionSchema:\n            return {\n                \"analysis\": \"Mock document analysis\",\n                \"document_json\": json.dumps({\"test_key\": \"test_value\"}),\n            }\n        return {}\n\n\n@pytest.fixture\ndef mock_llm_service():\n    return MockLLMService\n\n", "n_tokens": 170, "byte_len": 905, "file_sha1": "6d985a648658d90cdca89ff27510e2c19c56e403", "start_line": 1, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py", "rel_path": "tests/converters/test_extraction_converter.py", "module": "tests.converters.test_extraction_converter", "ext": "py", "chunk_number": 2, "symbols": ["extraction_converter", "test", "schema", "markdown", "model", "dict", "none", "llm", "service", "output", "format", "pytest", "required", "config", "mock", "page", "properties", "return", "extraction", "converter", "dumps", "artifact", "default", "fixture", "json", "string", "type", "title", "object", "key", "__call__", "mock_llm_service", "test_extraction_converter", "test_extraction_converter_multiple_pages", "MockLLMService", "prompt", "elif", "services", "class", "results", "assert", "response", "document", "analysis", "image", "notes", "value", "converters", "self", "from"], "ast_kind": "function_or_method", "text": "@pytest.fixture\ndef extraction_converter(config, model_dict, mock_llm_service):\n    test_schema = {\n        \"title\": \"TestSchema\",\n        \"type\": \"object\",\n        \"properties\": {\"test_key\": {\"title\": \"Test Key\", \"type\": \"string\"}},\n        \"required\": [\"test_key\"],\n    }\n\n    config[\"page_schema\"] = json.dumps(test_schema)\n    config[\"output_format\"] = \"markdown\"\n    model_dict[\"llm_service\"] = mock_llm_service\n\n    converter = ExtractionConverter(\n        artifact_dict=model_dict, processor_list=None, config=config\n    )\n    converter.llm_service = mock_llm_service\n    converter.default_llm_service = MockLLMService\n    return converter\n\n", "n_tokens": 151, "byte_len": 648, "file_sha1": "6d985a648658d90cdca89ff27510e2c19c56e403", "start_line": 30, "end_line": 50}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_extraction_converter.py", "rel_path": "tests/converters/test_extraction_converter.py", "module": "tests.converters.test_extraction_converter", "ext": "py", "chunk_number": 3, "symbols": ["test_extraction_converter", "test_extraction_converter_multiple_pages", "results", "assert", "model", "dict", "none", "llm", "service", "analysis", "test", "value", "pytest", "document", "config", "temp", "doc", "page", "schema", "result", "mark", "invalid", "extraction", "converter", "mock", "artifact", "json", "loads", "range", "key", "__call__", "mock_llm_service", "extraction_converter", "MockLLMService", "prompt", "elif", "services", "class", "markdown", "response", "output", "format", "image", "notes", "converters", "self", "required", "from", "detailed", "kwargs"], "ast_kind": "function_or_method", "text": "@pytest.mark.config({\"page_range\": [0]})\ndef test_extraction_converter(config, model_dict, mock_llm_service, temp_doc):\n    config[\"page_schema\"] = \"invalid json\"\n\n    model_dict[\"llm_service\"] = mock_llm_service\n    converter = ExtractionConverter(\n        artifact_dict=model_dict, processor_list=None, config=config\n    )\n    converter.artifact_dict[\"llm_service\"] = mock_llm_service()\n\n    results = converter(temp_doc.name)\n    assert results.document_json == '{\"test_key\": \"test_value\"}'\n\n\n@pytest.mark.config({\"page_range\": [0, 1]})\ndef test_extraction_converter_multiple_pages(extraction_converter, temp_doc):\n    result = extraction_converter(temp_doc.name)\n\n    assert result is not None\n    assert result.document_json is not None\n    assert json.loads(result.document_json) == {\"test_key\": \"test_value\"}\n    assert result.analysis == \"Mock document analysis\"\n", "n_tokens": 190, "byte_len": 871, "file_sha1": "6d985a648658d90cdca89ff27510e2c19c56e403", "start_line": 51, "end_line": 73}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py", "rel_path": "tests/converters/test_pdf_converter.py", "module": "tests.converters.test_pdf_converter", "ext": "py", "chunk_number": 1, "symbols": ["import", "pdf", "converter", "marker", "markdown", "pytest", "converters", "from", "output", "renderers", "test_pdf_converter", "test_epub_converter", "test_xlsx_converter", "test_html_converter", "test_docx_converter", "test_pptx_converter", "test_pdf_converter_bytes", "training", "china", "disable", "ocr", "single", "sheet", "field", "highly", "config", "test", "pptx", "wide", "manual", "filename", "mark", "open", "republic", "columns", "epub", "four", "assertions", "which", "adversarial", "true", "decline", "sabotage", "temp", "doc", "remain", "xlsx", "similar", "american", "across"], "ast_kind": "imports", "text": "import io\n\nimport pytest\nfrom marker.converters.pdf import PdfConverter\nfrom marker.renderers.markdown import MarkdownOutput\n\n", "n_tokens": 25, "byte_len": 126, "file_sha1": "30007fa2dd8d92b11af7314843752c4d25f984dd", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py", "rel_path": "tests/converters/test_pdf_converter.py", "module": "tests.converters.test_pdf_converter", "ext": "py", "chunk_number": 2, "symbols": ["test_pdf_converter", "training", "markdown", "however", "assert", "output", "these", "range", "disable", "ocr", "format", "more", "methods", "pytest", "highly", "choices", "config", "temp", "doc", "pdf", "converter", "subspace", "line", "basic", "wide", "solutions", "natural", "mark", "rely", "joining", "test_epub_converter", "test_xlsx_converter", "test_html_converter", "test_docx_converter", "test_pptx_converter", "test_pdf_converter_bytes", "china", "single", "sheet", "field", "converters", "test", "pptx", "manual", "filename", "open", "republic", "columns", "epub", "four"], "ast_kind": "function_or_method", "text": "@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [0, 1, 2, 3, 7], \"disable_ocr\": True})\ndef test_pdf_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert len(markdown) > 0\n    assert \"# Subspace Adversarial Training\" in markdown\n\n    # Some assertions for line joining across pages\n    assert (\n        \"AT solutions. However, these methods highly rely on specifically\" in markdown\n    )  # pgs: 1-2\n    assert (\n        \"(with adversarial perturbations), which harms natural accuracy, \" in markdown\n    )  # pgs: 3-4\n\n    # Some assertions for line joining across columns\n    assert \"remain similar across a wide range of choices.\" in markdown  # pg: 2\n    assert \"a new scheme for designing more robust and efficient\" in markdown  # pg: 8\n\n", "n_tokens": 226, "byte_len": 906, "file_sha1": "30007fa2dd8d92b11af7314843752c4d25f984dd", "start_line": 8, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py", "rel_path": "tests/converters/test_pdf_converter.py", "module": "tests.converters.test_pdf_converter", "ext": "py", "chunk_number": 3, "symbols": ["test_epub_converter", "test_xlsx_converter", "test_html_converter", "markdown", "assert", "output", "china", "test", "xlsx", "single", "sheet", "sabotage", "html", "field", "pytest", "config", "temp", "doc", "pdf", "converter", "epub", "basic", "manual", "filename", "mark", "republic", "four", "assertions", "simple", "page", "test_pdf_converter", "test_docx_converter", "test_pptx_converter", "test_pdf_converter_bytes", "training", "disable", "ocr", "converters", "highly", "pptx", "wide", "open", "columns", "marker", "which", "adversarial", "true", "decline", "remain", "similar"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"manual.epub\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_epub_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert \"Simple Sabotage Field Manual\" in markdown\n\n\n@pytest.mark.filename(\"single_sheet.xlsx\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_xlsx_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert \"four\" in markdown\n\n\n@pytest.mark.filename(\"china.html\")\n@pytest.mark.config({\"page_range\": [10]})\ndef test_html_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert \"Republic of China\" in markdown\n\n", "n_tokens": 203, "byte_len": 957, "file_sha1": "30007fa2dd8d92b11af7314843752c4d25f984dd", "start_line": 31, "end_line": 60}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py", "rel_path": "tests/converters/test_pdf_converter.py", "module": "tests.converters.test_pdf_converter", "ext": "py", "chunk_number": 4, "symbols": ["test_docx_converter", "test_pptx_converter", "markdown", "assert", "output", "decline", "pytest", "config", "temp", "doc", "pdf", "converter", "test", "pptx", "basic", "gatsby", "filename", "mark", "american", "docx", "assertions", "lambda", "page", "range", "dream", "adam", "name", "test_pdf_converter", "test_epub_converter", "test_xlsx_converter", "test_html_converter", "test_pdf_converter_bytes", "training", "china", "disable", "ocr", "single", "sheet", "field", "converters", "highly", "wide", "manual", "open", "republic", "columns", "epub", "four", "marker", "which"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"gatsby.docx\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_docx_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert \"The Decline of the American Dream in the 1920s\" in markdown\n\n\n@pytest.mark.filename(\"lambda.pptx\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_pptx_converter(pdf_converter: PdfConverter, temp_doc):\n    markdown_output: MarkdownOutput = pdf_converter(temp_doc.name)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert \"Adam Doup\" in markdown\n\n", "n_tokens": 149, "byte_len": 658, "file_sha1": "30007fa2dd8d92b11af7314843752c4d25f984dd", "start_line": 61, "end_line": 80}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/converters/test_pdf_converter.py", "rel_path": "tests/converters/test_pdf_converter.py", "module": "tests.converters.test_pdf_converter", "ext": "py", "chunk_number": 5, "symbols": ["test_pdf_converter_bytes", "training", "markdown", "however", "assert", "output", "these", "range", "disable", "ocr", "format", "more", "test", "pdf", "methods", "pytest", "highly", "choices", "config", "temp", "doc", "converter", "subspace", "line", "basic", "wide", "solutions", "natural", "mark", "rely", "test_pdf_converter", "test_epub_converter", "test_xlsx_converter", "test_html_converter", "test_docx_converter", "test_pptx_converter", "china", "single", "sheet", "field", "converters", "pptx", "manual", "filename", "open", "republic", "columns", "epub", "four", "assertions"], "ast_kind": "function_or_method", "text": "@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [0, 1, 2, 3, 7], \"disable_ocr\": True})\ndef test_pdf_converter_bytes(pdf_converter: PdfConverter, temp_doc):\n    with open(temp_doc.name, \"rb\") as f:\n        data = f.read()\n\n    input_bytes = io.BytesIO(data)\n    markdown_output: MarkdownOutput = pdf_converter(input_bytes)\n    markdown = markdown_output.markdown\n\n    # Basic assertions\n    assert len(markdown) > 0\n    assert \"# Subspace Adversarial Training\" in markdown\n\n    # Some assertions for line joining across pages\n    assert (\n        \"AT solutions. However, these methods highly rely on specifically\" in markdown\n    )  # pgs: 1-2\n    assert (\n        \"(with adversarial perturbations), which harms natural accuracy, \" in markdown\n    )  # pgs: 3-4\n\n    # Some assertions for line joining across columns\n    assert \"remain similar across a wide range of choices.\" in markdown  # pg: 2\n    assert \"a new scheme for designing more robust and efficient\" in markdown  # pg: 8\n", "n_tokens": 254, "byte_len": 1010, "file_sha1": "30007fa2dd8d92b11af7314843752c4d25f984dd", "start_line": 81, "end_line": 106}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/schema/groups/test_list_grouping.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/schema/groups/test_list_grouping.py", "rel_path": "tests/schema/groups/test_list_grouping.py", "module": "tests.schema.groups.test_list_grouping", "ext": "py", "chunk_number": 1, "symbols": ["test_list_grouping", "block", "type", "assert", "model", "test", "list", "pdf", "document", "builders", "pytest", "schema", "append", "config", "from", "since", "mark", "group", "structure", "builder", "children", "breaks", "types", "pages", "groups", "import", "marker", "this", "equations", "page", "range"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.builders.structure import StructureBuilder\nfrom marker.schema import BlockTypes\n\n\n@pytest.mark.config({\"page_range\": [4]})\ndef test_list_grouping(pdf_document):\n    structure = StructureBuilder()\n    structure(pdf_document)\n\n    page = pdf_document.pages[0]\n    list_groups = []\n    for block in page.children:\n        if block.block_type == BlockTypes.ListGroup:\n            list_groups.append(block)\n\n    # The model breaks this up, since it has equations in it\n    assert len(list_groups) == 3\n", "n_tokens": 110, "byte_len": 524, "file_sha1": "869c2137ac50d265efa16218c58c733d9cf8631b", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_equation_processor.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_equation_processor.py", "rel_path": "tests/processors/test_equation_processor.py", "module": "tests.processors.test_equation_processor", "ext": "py", "chunk_number": 1, "symbols": ["test_equation_processor", "block", "type", "assert", "equation", "none", "processor", "pdf", "document", "html", "pytest", "schema", "config", "test", "from", "recognition", "model", "mark", "children", "processors", "types", "pages", "import", "marker", "page", "range"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.schema import BlockTypes\nfrom marker.processors.equation import EquationProcessor\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_equation_processor(pdf_document, recognition_model):\n    processor = EquationProcessor(recognition_model)\n    processor(pdf_document)\n\n    for block in pdf_document.pages[0].children:\n        if block.block_type == BlockTypes.Equation:\n            assert block.html is not None", "n_tokens": 86, "byte_len": 438, "file_sha1": "af063447340f233b4043a61f324d5ea19c50ce02", "start_line": 1, "end_line": 14}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py", "rel_path": "tests/processors/test_table_processor.py", "module": "tests.processors.test_table_processor", "ext": "py", "chunk_number": 1, "symbols": ["test_table_processor", "block", "type", "markdown", "assert", "table", "rec", "contained", "blocks", "schedule", "renderer", "processor", "test", "pdf", "document", "pytest", "schema", "config", "from", "recognition", "model", "mark", "children", "list", "processors", "typing", "types", "renderers", "pages", "import", "test_avoid_double_ocr", "test_overlap_blocks", "test_ocr_table", "test_split_rows", "row", "force", "ocr", "tables", "line", "split", "raw", "text", "overlap", "multicol", "cells", "filename", "principle", "participants", "auxiliary", "problem"], "ast_kind": "function_or_method", "text": "from typing import List\n\nimport pytest\n\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.schema import BlockTypes\nfrom marker.processors.table import TableProcessor\nfrom marker.schema.blocks import TableCell\n\n\n@pytest.mark.config({\"page_range\": [5]})\ndef test_table_processor(\n    pdf_document, recognition_model, table_rec_model, detection_model\n):\n    processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    processor(pdf_document)\n\n    for block in pdf_document.pages[0].children:\n        if block.block_type == BlockTypes.Table:\n            children = block.contained_blocks(pdf_document, (BlockTypes.TableCell,))\n            assert children\n            assert len(children) > 0\n            assert isinstance(children[0], TableCell)\n\n    assert len(pdf_document.contained_blocks((BlockTypes.Table,))) == 2\n\n    renderer = MarkdownRenderer()\n    table_output = renderer(pdf_document)\n    assert \"Schedule\" in table_output.markdown\n\n", "n_tokens": 195, "byte_len": 981, "file_sha1": "72819551ec97be5624f56e32d7d6917105e0e8b7", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py", "rel_path": "tests/processors/test_table_processor.py", "module": "tests.processors.test_table_processor", "ext": "py", "chunk_number": 2, "symbols": ["test_avoid_double_ocr", "markdown", "assert", "table", "rec", "force", "ocr", "tables", "contained", "blocks", "line", "renderer", "processor", "pdf", "document", "pytest", "config", "recognition", "model", "filename", "mark", "participants", "lines", "block", "types", "test", "avoid", "detection", "page", "range", "test_table_processor", "test_overlap_blocks", "test_ocr_table", "test_split_rows", "type", "row", "schedule", "split", "raw", "text", "schema", "from", "overlap", "multicol", "cells", "principle", "children", "list", "auxiliary", "problem"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"table_ex.pdf\")\n@pytest.mark.config({\"page_range\": [0], \"force_ocr\": True})\ndef test_avoid_double_ocr(\n    pdf_document, recognition_model, table_rec_model, detection_model\n):\n    tables = pdf_document.contained_blocks((BlockTypes.Table,))\n    lines = tables[0].contained_blocks(pdf_document, (BlockTypes.Line,))\n    assert len(lines) == 0\n\n    processor = TableProcessor(\n        recognition_model, table_rec_model, detection_model, config={\"force_ocr\": True}\n    )\n    processor(pdf_document)\n\n    renderer = MarkdownRenderer()\n    table_output = renderer(pdf_document)\n    assert \"Participants\" in table_output.markdown\n\n", "n_tokens": 144, "byte_len": 646, "file_sha1": "72819551ec97be5624f56e32d7d6917105e0e8b7", "start_line": 32, "end_line": 50}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py", "rel_path": "tests/processors/test_table_processor.py", "module": "tests.processors.test_table_processor", "ext": "py", "chunk_number": 3, "symbols": ["test_overlap_blocks", "assert", "table", "rec", "blocks", "processor", "pdf", "document", "raw", "text", "pytest", "config", "test", "overlap", "recognition", "model", "multicol", "filename", "principle", "mark", "auxiliary", "problem", "pages", "cascading", "detection", "page", "range", "test_table_processor", "test_avoid_double_ocr", "test_ocr_table", "test_split_rows", "block", "type", "markdown", "row", "force", "ocr", "contained", "schedule", "tables", "line", "renderer", "split", "schema", "from", "cells", "participants", "children", "list", "processors"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"multicol-blocks.pdf\")\n@pytest.mark.config({\"page_range\": [3]})\ndef test_overlap_blocks(\n    pdf_document, detection_model, recognition_model, table_rec_model\n):\n    page = pdf_document.pages[0]\n    assert \"Cascading, and the Auxiliary Problem Principle\" in page.raw_text(\n        pdf_document\n    )\n\n    processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    processor(pdf_document)\n\n    assert \"Cascading, and the Auxiliary Problem Principle\" in page.raw_text(\n        pdf_document\n    )\n\n", "n_tokens": 118, "byte_len": 542, "file_sha1": "72819551ec97be5624f56e32d7d6917105e0e8b7", "start_line": 51, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_processor.py", "rel_path": "tests/processors/test_table_processor.py", "module": "tests.processors.test_table_processor", "ext": "py", "chunk_number": 4, "symbols": ["test_ocr_table", "test_split_rows", "markdown", "row", "assert", "table", "rec", "contained", "blocks", "test", "ocr", "renderer", "processor", "pdf", "document", "split", "pytest", "config", "recognition", "model", "cells", "filename", "mark", "list", "pres", "block", "types", "detection", "page", "range", "test_table_processor", "test_avoid_double_ocr", "test_overlap_blocks", "type", "force", "schedule", "tables", "line", "raw", "text", "schema", "from", "overlap", "multicol", "principle", "participants", "children", "auxiliary", "problem", "processors"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"pres.pdf\")\n@pytest.mark.config({\"page_range\": [4]})\ndef test_ocr_table(pdf_document, recognition_model, table_rec_model, detection_model):\n    processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    processor(pdf_document)\n\n    renderer = MarkdownRenderer()\n    table_output = renderer(pdf_document)\n    assert \"1.2E-38\" in table_output.markdown\n\n\n@pytest.mark.config({\"page_range\": [11]})\ndef test_split_rows(pdf_document, recognition_model, table_rec_model, detection_model):\n    processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    processor(pdf_document)\n\n    table = pdf_document.contained_blocks((BlockTypes.Table,))[-1]\n    cells: List[TableCell] = table.contained_blocks(\n        pdf_document, (BlockTypes.TableCell,)\n    )\n    unique_rows = len(set([cell.row_id for cell in cells]))\n    assert unique_rows == 6\n", "n_tokens": 199, "byte_len": 902, "file_sha1": "72819551ec97be5624f56e32d7d6917105e0e8b7", "start_line": 69, "end_line": 91}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 1, "symbols": ["llm", "equation", "image", "markdown", "table", "processor", "form", "blocks", "pytest", "schema", "mock", "from", "meta", "complex", "magic", "processors", "unittest", "block", "types", "renderers", "import", "marker", "simple", "region", "renderer", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "column", "replace", "about", "lst", "config", "exclude", "gemini", "api", "dict", "new", "filename", "contained", "pictures", "description", "mark", "children", "test"], "ast_kind": "imports", "text": "from unittest.mock import MagicMock, Mock\n\nimport pytest\nfrom marker.processors.llm.llm_complex import LLMComplexRegionProcessor\nfrom marker.processors.llm.llm_equation import LLMEquationProcessor\n\nfrom marker.processors.llm.llm_form import LLMFormProcessor\nfrom marker.processors.llm.llm_image_description import LLMImageDescriptionProcessor\nfrom marker.processors.llm.llm_meta import LLMSimpleBlockMetaProcessor\nfrom marker.processors.llm.llm_table import LLMTableProcessor\nfrom marker.processors.table import TableProcessor\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import ComplexRegion\n\n", "n_tokens": 142, "byte_len": 667, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 2, "symbols": ["test_llm_form_processor_no_config", "assert", "none", "contained", "blocks", "llm", "service", "test", "pdf", "document", "html", "pytest", "processor", "lst", "config", "filename", "mark", "forms", "form", "block", "types", "simple", "page", "range", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "markdown", "column", "renderer", "replace", "about", "table", "image", "mock", "exclude", "gemini", "api", "dict", "new", "pictures", "description", "children", "processors", "value", "cls"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"form_1040.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_form_processor_no_config(pdf_document, llm_service):\n    processor_lst = [LLMFormProcessor()]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, llm_service)\n    processor(pdf_document)\n\n    forms = pdf_document.contained_blocks((BlockTypes.Form,))\n    assert forms[0].html is None\n\n", "n_tokens": 90, "byte_len": 384, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 17, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 3, "symbols": ["test_llm_form_processor_no_cells", "test", "llm", "assert", "none", "contained", "blocks", "service", "pdf", "document", "html", "pytest", "processor", "lst", "config", "gemini", "api", "filename", "mark", "forms", "form", "block", "types", "simple", "page", "range", "true", "use", "test_llm_form_processor_no_config", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "markdown", "column", "renderer", "replace", "about", "table", "image", "mock", "exclude", "dict", "new", "pictures", "description", "children", "processors"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"form_1040.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_form_processor_no_cells(pdf_document, llm_service):\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\"}\n    processor_lst = [LLMFormProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, llm_service, config)\n    processor(pdf_document)\n\n    forms = pdf_document.contained_blocks((BlockTypes.Form,))\n    assert forms[0].html is None\n\n", "n_tokens": 112, "byte_len": 454, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 28, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 4, "symbols": ["test_llm_form_processor", "test", "llm", "return", "value", "markdown", "assert", "table", "rec", "corrected", "contained", "blocks", "processor", "pdf", "document", "cell", "html", "pytest", "lst", "config", "gemini", "api", "recognition", "model", "filename", "mark", "forms", "form", "mock", "strip", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "column", "renderer", "replace", "about", "image", "exclude", "dict", "new", "block", "pictures", "description", "children", "processors"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"form_1040.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_form_processor(pdf_document, table_rec_model, recognition_model, detection_model):\n    corrected_html = \"<em>This is corrected markdown.</em>\\n\" * 100\n    corrected_html = \"<p>\" + corrected_html.strip() + \"</p>\\n\"\n\n    mock_cls = Mock()\n    mock_cls.return_value = {\"corrected_html\": corrected_html}\n\n    cell_processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    cell_processor(pdf_document)\n\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\"}\n    processor_lst = [LLMFormProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, mock_cls, config)\n    processor(pdf_document)\n\n    forms = pdf_document.contained_blocks((BlockTypes.Form,))\n    assert forms[0].html == corrected_html.strip()\n\n\n", "n_tokens": 197, "byte_len": 842, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 40, "end_line": 61}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 5, "symbols": ["test_llm_table_processor", "return", "value", "markdown", "assert", "table", "rec", "text", "test", "tables", "contained", "blocks", "column", "processor", "pdf", "document", "cell", "pytest", "config", "gemini", "api", "recognition", "model", "llm", "cells", "filename", "mark", "mock", "math", "strip", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "renderer", "form", "replace", "about", "image", "lst", "exclude", "dict", "new", "block", "pictures", "description", "children"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"table_ex2.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_table_processor(pdf_document, table_rec_model, recognition_model, detection_model):\n    corrected_html = \"\"\"\n<table>\n    <tr>\n        <td>Column 1</td>\n        <td>Column 2</td>\n        <td>Column 3</td>\n        <td>Column 4</td>\n    </tr>\n    <tr>\n        <td>Value 1 <math>x</math></td>\n        <td>Value 2</td>\n        <td>Value 3</td>\n        <td>Value 4</td>\n    </tr>\n    <tr>\n        <td>Value 5</td>\n        <td>Value 6</td>\n        <td>Value 7</td>\n        <td>Value 8</td>\n    </tr>\n</table>\n    \"\"\".strip()\n\n    mock_cls = Mock()\n    mock_cls.return_value = {\"corrected_html\": corrected_html}\n\n    cell_processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    cell_processor(pdf_document)\n\n    processor = LLMTableProcessor(mock_cls, {\"use_llm\": True, \"gemini_api_key\": \"test\"})\n    processor(pdf_document)\n\n    tables = pdf_document.contained_blocks((BlockTypes.Table,))\n    table_cells = tables[0].contained_blocks(pdf_document, (BlockTypes.TableCell,))\n    assert table_cells[0].text == \"Column 1\"\n\n    markdown = MarkdownRenderer()(pdf_document).markdown\n    assert \"Value 1 $x$\" in markdown\n\n", "n_tokens": 344, "byte_len": 1228, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 62, "end_line": 104}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 6, "symbols": ["test_llm_caption_processor_disabled", "llm", "image", "assert", "none", "test", "contained", "blocks", "pdf", "document", "pytest", "processor", "lst", "config", "gemini", "api", "filename", "pictures", "picture", "mark", "description", "magic", "mock", "figure", "flight", "plan", "block", "types", "cls", "simple", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor", "test_llm_complex_region_processor", "test_multi_llm_processors", "markdown", "column", "renderer", "form", "replace", "about", "table", "exclude", "dict", "new", "children", "processors", "value"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"A17_FlightPlan.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_caption_processor_disabled(pdf_document):\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\"}\n    mock_cls = MagicMock()\n    processor_lst = [LLMImageDescriptionProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, mock_cls, config)\n    processor(pdf_document)\n\n    contained_pictures = pdf_document.contained_blocks((BlockTypes.Picture, BlockTypes.Figure))\n    assert all(picture.description is None for picture in contained_pictures)\n", "n_tokens": 127, "byte_len": 563, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 105, "end_line": 116}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 7, "symbols": ["test_llm_caption_processor", "return", "value", "llm", "image", "markdown", "assert", "includes", "test", "contained", "blocks", "renderer", "pdf", "document", "extract", "images", "pytest", "rendering", "processor", "lst", "config", "gemini", "api", "description", "filename", "pictures", "mark", "picture", "ensure", "mock", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_complex_region_processor", "test_multi_llm_processors", "column", "form", "replace", "about", "table", "exclude", "dict", "new", "block", "children", "processors", "cls", "marker"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"A17_FlightPlan.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_caption_processor(pdf_document):\n    description = \"This is an image description.\"\n    mock_cls = Mock()\n    mock_cls.return_value = {\"image_description\": description}\n\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\", \"extract_images\": False}\n    processor_lst = [LLMImageDescriptionProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, mock_cls, config)\n    processor(pdf_document)\n\n    contained_pictures = pdf_document.contained_blocks((BlockTypes.Picture, BlockTypes.Figure))\n    assert all(picture.description == description for picture in contained_pictures)\n\n    # Ensure the rendering includes the description\n    renderer = MarkdownRenderer({\"extract_images\": False})\n    md = renderer(pdf_document).markdown\n\n    assert description in md\n\n", "n_tokens": 189, "byte_len": 879, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 117, "end_line": 138}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 8, "symbols": ["test_llm_complex_region_processor", "return", "value", "block", "type", "test", "markdown", "assert", "includes", "renderer", "some", "replace", "pdf", "document", "complex", "use", "llm", "pytest", "rendering", "processor", "lst", "config", "exclude", "rendered", "gemini", "api", "old", "dict", "new", "corrected", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_multi_llm_processors", "column", "form", "about", "table", "image", "mock", "filename", "contained", "pictures", "description", "mark", "children", "processors"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"A17_FlightPlan.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_llm_complex_region_processor(pdf_document):\n    md = \"This is some *markdown* for a complex region.\"\n    mock_cls = Mock()\n    mock_cls.return_value = {\"corrected_markdown\": md * 25}\n\n    # Replace the block with a complex region\n    old_block = pdf_document.pages[0].children[0]\n    new_block = ComplexRegion(\n        **old_block.dict(exclude=[\"id\", \"block_id\", \"block_type\"]),\n    )\n    pdf_document.pages[0].replace_block(old_block, new_block)\n\n    # Test processor\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\"}\n    processor_lst = [LLMComplexRegionProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, mock_cls, config)\n    processor(pdf_document)\n\n    # Ensure the rendering includes the description\n    renderer = MarkdownRenderer()\n    rendered_md = renderer(pdf_document).markdown\n\n    assert md in rendered_md\n", "n_tokens": 226, "byte_len": 948, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 139, "end_line": 164}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_llm_processors.py", "rel_path": "tests/processors/test_llm_processors.py", "module": "tests.processors.test_llm_processors", "ext": "py", "chunk_number": 9, "symbols": ["test_multi_llm_processors", "return", "value", "llm", "image", "here", "assert", "equation", "test", "contained", "blocks", "about", "equations", "pdf", "document", "extract", "images", "min", "html", "pytest", "processor", "lst", "config", "print", "gemini", "api", "description", "filename", "corrected", "mark", "test_llm_form_processor_no_config", "test_llm_form_processor_no_cells", "test_llm_form_processor", "test_llm_table_processor", "test_llm_caption_processor_disabled", "test_llm_caption_processor", "test_llm_complex_region_processor", "markdown", "column", "renderer", "form", "replace", "table", "mock", "exclude", "dict", "new", "block", "pictures", "children"], "ast_kind": "function_or_method", "text": "@pytest.mark.filename(\"adversarial.pdf\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_multi_llm_processors(pdf_document):\n    description = \"<math>This is an image description.  And here is a lot of writing about it.</math>\" * 10\n    mock_cls = Mock()\n    mock_cls.return_value = {\"image_description\": description, \"corrected_equation\": description}\n\n    config = {\"use_llm\": True, \"gemini_api_key\": \"test\", \"extract_images\": False, \"min_equation_height\": .001}\n    processor_lst = [LLMImageDescriptionProcessor(config), LLMEquationProcessor(config)]\n    processor = LLMSimpleBlockMetaProcessor(processor_lst, mock_cls, config)\n    processor(pdf_document)\n\n    contained_pictures = pdf_document.contained_blocks((BlockTypes.Picture, BlockTypes.Figure))\n    assert all(picture.description == description for picture in contained_pictures)\n\n    contained_equations = pdf_document.contained_blocks((BlockTypes.Equation,))\n    print([equation.html for equation in contained_equations])\n    assert all(equation.html == description for equation in contained_equations)", "n_tokens": 240, "byte_len": 1067, "file_sha1": "56ab78f4d2476bbd508c9ecf93eb04772f359ea9", "start_line": 165, "end_line": 182}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_footnote_processor.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_footnote_processor.py", "rel_path": "tests/processors/test_footnote_processor.py", "module": "tests.processors.test_footnote_processor", "ext": "py", "chunk_number": 1, "symbols": ["test_footnote_processor", "assert", "test", "footnote", "contained", "blocks", "startswith", "pdf", "document", "raw", "text", "pytest", "schema", "processor", "config", "from", "filename", "mark", "population", "stats", "strip", "processors", "block", "types", "pages", "import", "marker", "page", "footnotes", "range"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.processors.footnote import FootnoteProcessor\nfrom marker.schema import BlockTypes\n\n\n@pytest.mark.filename(\"population_stats.pdf\")\n@pytest.mark.config({\"page_range\": [4]})\ndef test_footnote_processor(pdf_document):\n    processor = FootnoteProcessor()\n    processor(pdf_document)\n\n    page0_footnotes = pdf_document.pages[0].contained_blocks(pdf_document, [BlockTypes.Footnote])\n    assert len(page0_footnotes) >= 2\n\n    assert page0_footnotes[-1].raw_text(pdf_document).strip().startswith(\"5\")\n", "n_tokens": 116, "byte_len": 520, "file_sha1": "8c6851ba722cac0bf6682bcd058933def0bee2e9", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_merge.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_table_merge.py", "rel_path": "tests/processors/test_table_merge.py", "module": "tests.processors.test_table_merge", "ext": "py", "chunk_number": 1, "symbols": ["test_llm_table_processor_nomerge", "return", "value", "llm", "table", "assert", "rec", "tables", "contained", "blocks", "test", "processor", "true", "pdf", "document", "mocker", "cell", "pytest", "schema", "mock", "from", "gemini", "api", "recognition", "model", "filename", "mark", "direction", "processors", "unittest", "block", "types", "cls", "import", "marker", "merge", "detection", "right", "use"], "ast_kind": "function_or_method", "text": "from unittest.mock import Mock\n\nimport pytest\n\nfrom marker.processors.llm.llm_table_merge import LLMTableMergeProcessor\nfrom marker.processors.table import TableProcessor\nfrom marker.schema import BlockTypes\n\n\n@pytest.mark.filename(\"table_ex2.pdf\")\ndef test_llm_table_processor_nomerge(pdf_document, table_rec_model, recognition_model, detection_model, mocker):\n    mock_cls = Mock()\n    mock_cls.return_value = {\n        \"merge\": \"true\",\n        \"direction\": \"right\"\n    }\n\n    cell_processor = TableProcessor(recognition_model, table_rec_model, detection_model)\n    cell_processor(pdf_document)\n\n    tables = pdf_document.contained_blocks((BlockTypes.Table,))\n    assert len(tables) == 3\n\n    processor = LLMTableMergeProcessor(mock_cls, {\"use_llm\": True, \"gemini_api_key\": \"test\"})\n    processor(pdf_document)\n\n    tables = pdf_document.contained_blocks((BlockTypes.Table,))\n    assert len(tables) == 3", "n_tokens": 203, "byte_len": 905, "file_sha1": "9318bad43995bf14903fed3af2f709403f03766e", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_document_toc_processor.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_document_toc_processor.py", "rel_path": "tests/processors/test_document_toc_processor.py", "module": "tests.processors.test_document_toc_processor", "ext": "py", "chunk_number": 1, "symbols": ["test_document_toc_processor", "training", "assert", "table", "rec", "contents", "document", "toc", "pdf", "pytest", "config", "from", "subspace", "recognition", "model", "processor", "mark", "test", "adversarial", "processors", "import", "marker", "title", "detection", "page", "range"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.processors.document_toc import DocumentTOCProcessor\n\n\n@pytest.mark.config({\"page_range\": [0]})\ndef test_document_toc_processor(pdf_document, detection_model, recognition_model, table_rec_model):\n    processor = DocumentTOCProcessor()\n    processor(pdf_document)\n\n    assert len(pdf_document.table_of_contents) == 3\n    assert pdf_document.table_of_contents[0][\"title\"] == \"Subspace Adversarial Training\"\n", "n_tokens": 92, "byte_len": 431, "file_sha1": "9a71a54ca2a3d47daae8bf590c8955bd8dfe0271", "start_line": 1, "end_line": 13}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_ignoretext.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/processors/test_ignoretext.py", "rel_path": "tests/processors/test_ignoretext.py", "module": "tests.processors.test_ignoretext", "ext": "py", "chunk_number": 1, "symbols": ["test_ignoretext_processor", "assert", "contained", "blocks", "ignoretext", "range", "pdf", "document", "ignore", "for", "raw", "text", "pytest", "schema", "test", "config", "bio", "from", "processor", "filename", "mark", "processors", "block", "types", "pages", "page", "header", "import", "marker", "rxiv", "true", "list"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.processors.ignoretext import IgnoreTextProcessor\nfrom marker.schema import BlockTypes\n\n\n@pytest.mark.filename(\"bio_pdf.pdf\")\n@pytest.mark.config({\"page_range\": list(range(10))})\ndef test_ignoretext_processor(pdf_document):\n    processor = IgnoreTextProcessor()\n    processor(pdf_document)\n\n    page1_header = pdf_document.pages[1].contained_blocks(pdf_document, [BlockTypes.Text])[0]\n    assert \"bioRxiv\" in page1_header.raw_text(pdf_document)\n\n    assert page1_header.ignore_for_output is True\n", "n_tokens": 112, "byte_len": 522, "file_sha1": "9da368f309b89d8b23d04afeb5328c1fb3eafde1", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py", "rel_path": "tests/services/test_service_init.py", "module": "tests.services.test_service_init", "ext": "py", "chunk_number": 1, "symbols": ["test_empty_llm", "test_llm_no_keys", "services", "markdown", "openai", "assert", "none", "model", "dict", "test", "llm", "service", "output", "format", "google", "vertex", "pytest", "converters", "ollama", "config", "temp", "doc", "from", "empty", "pdf", "converter", "assertion", "error", "mark", "raises", "test_llm_gemini", "test_llm_vertex", "test_llm_ollama", "test_llm_openai", "test_llm_azure_openai", "api", "https", "azure", "endpoint", "gemini", "project", "deployment", "name", "open", "artifact", "with", "import", "marker", "example", "isinstance"], "ast_kind": "function_or_method", "text": "import pytest\n\nfrom marker.converters.pdf import PdfConverter\nfrom marker.services.gemini import GoogleGeminiService\nfrom marker.services.ollama import OllamaService\nfrom marker.services.vertex import GoogleVertexService\nfrom marker.services.openai import OpenAIService\nfrom marker.services.azure_openai import AzureOpenAIService\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [0]})\ndef test_empty_llm(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is None\n    assert pdf_converter.llm_service is None\n\n\ndef test_llm_no_keys(model_dict, config):\n    with pytest.raises(AssertionError):\n        PdfConverter(artifact_dict=model_dict, config={\"use_llm\": True})\n\n", "n_tokens": 161, "byte_len": 736, "file_sha1": "86f9665640d0dea866e7633add2a75ddb4092c7f", "start_line": 1, "end_line": 22}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py", "rel_path": "tests/services/test_service_init.py", "module": "tests.services.test_service_init", "ext": "py", "chunk_number": 2, "symbols": ["test_llm_gemini", "services", "markdown", "assert", "none", "test", "llm", "service", "output", "format", "google", "vertex", "pytest", "config", "temp", "doc", "gemini", "api", "pdf", "converter", "project", "mark", "artifact", "dict", "marker", "isinstance", "page", "range", "true", "use", "test_empty_llm", "test_llm_no_keys", "test_llm_vertex", "test_llm_ollama", "test_llm_openai", "test_llm_azure_openai", "openai", "model", "https", "azure", "endpoint", "converters", "ollama", "from", "empty", "assertion", "error", "raises", "deployment", "name"], "ast_kind": "function_or_method", "text": "@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config({\"page_range\": [0], \"use_llm\": True, \"gemini_api_key\": \"test\"})\ndef test_llm_gemini(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is not None\n    assert isinstance(pdf_converter.llm_service, GoogleGeminiService)\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config(\n    {\n        \"page_range\": [0],\n        \"use_llm\": True,\n        \"vertex_project_id\": \"test\",\n        \"llm_service\": \"marker.services.vertex.GoogleVertexService\",\n    }\n)", "n_tokens": 133, "byte_len": 552, "file_sha1": "86f9665640d0dea866e7633add2a75ddb4092c7f", "start_line": 23, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py", "rel_path": "tests/services/test_service_init.py", "module": "tests.services.test_service_init", "ext": "py", "chunk_number": 3, "symbols": ["test_llm_vertex", "test_llm_ollama", "services", "markdown", "openai", "assert", "none", "api", "test", "llm", "service", "output", "format", "pytest", "ollama", "config", "temp", "doc", "pdf", "converter", "mark", "open", "artifact", "dict", "marker", "isinstance", "page", "range", "true", "google", "test_empty_llm", "test_llm_no_keys", "test_llm_gemini", "test_llm_openai", "test_llm_azure_openai", "model", "https", "vertex", "azure", "endpoint", "converters", "from", "empty", "assertion", "error", "gemini", "project", "raises", "deployment", "name"], "ast_kind": "function_or_method", "text": "def test_llm_vertex(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is not None\n    assert isinstance(pdf_converter.llm_service, GoogleVertexService)\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config(\n    {\n        \"page_range\": [0],\n        \"use_llm\": True,\n        \"llm_service\": \"marker.services.ollama.OllamaService\",\n    }\n)\ndef test_llm_ollama(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is not None\n    assert isinstance(pdf_converter.llm_service, OllamaService)\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config(\n    {\n        \"page_range\": [0],\n        \"use_llm\": True,\n        \"llm_service\": \"marker.services.openai.OpenAIService\",\n        \"openai_api_key\": \"test\",\n    }\n)", "n_tokens": 195, "byte_len": 801, "file_sha1": "86f9665640d0dea866e7633add2a75ddb4092c7f", "start_line": 39, "end_line": 65}
{"id": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/tests/services/test_service_init.py", "rel_path": "tests/services/test_service_init.py", "module": "tests.services.test_service_init", "ext": "py", "chunk_number": 4, "symbols": ["test_llm_openai", "test_llm_azure_openai", "services", "markdown", "openai", "assert", "none", "test", "llm", "model", "service", "https", "output", "format", "azure", "endpoint", "pytest", "config", "temp", "doc", "pdf", "converter", "mark", "deployment", "name", "open", "artifact", "dict", "marker", "example", "test_empty_llm", "test_llm_no_keys", "test_llm_gemini", "test_llm_vertex", "test_llm_ollama", "api", "google", "vertex", "converters", "ollama", "from", "empty", "assertion", "error", "gemini", "project", "raises", "with", "import", "isinstance"], "ast_kind": "function_or_method", "text": "def test_llm_openai(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is not None\n    assert isinstance(pdf_converter.llm_service, OpenAIService)\n\n\n@pytest.mark.output_format(\"markdown\")\n@pytest.mark.config(\n    {\n        \"page_range\": [0],\n        \"use_llm\": True,\n        \"llm_service\": \"marker.services.azure_openai.AzureOpenAIService\",\n        \"azure_endpoint\": \"https://example.openai.azure.com\",\n        \"azure_api_key\": \"test\",\n        \"deployment_name\": \"test-model\",\n        \"azure_api_version\": \"1\",\n    }\n)\ndef test_llm_azure_openai(pdf_converter: PdfConverter, temp_doc):\n    assert pdf_converter.artifact_dict[\"llm_service\"] is not None\n    assert isinstance(pdf_converter.llm_service, AzureOpenAIService)\n", "n_tokens": 181, "byte_len": 763, "file_sha1": "86f9665640d0dea866e7633add2a75ddb4092c7f", "start_line": 66, "end_line": 86}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 1, "symbols": ["import", "modal", "conversion", "service", "datalab", "deployment", "marker", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors", "found", "responses", "logging", "volume", "asynccontextmanager", "file", "deploy", "starting", "loaded", "torch", "full", "load", "basic", "config", "your", "model", "llm", "local", "entrypoint", "listdir", "lower", "models", "dict"], "ast_kind": "imports", "text": "\"\"\"\nModal deployment for Datalab Marker PDF conversion service.\n\"\"\"\n\nimport modal", "n_tokens": 15, "byte_len": 81, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 2, "symbols": ["image", "persistent", "volume", "type", "gpu", "model", "wget", "uvicorn", "debian", "slim", "dependencies", "from", "name", "full", "define", "torchvision", "pip", "install", "models", "modal", "caching", "datalab", "torc", "device", "apt", "typing", "torchaudio", "with", "container", "create", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors"], "ast_kind": "imports", "text": "import os\nfrom typing import Optional\n\n# Define the Modal app\napp = modal.App(\"datalab-marker-modal-demo\")\nGPU_TYPE = \"L40S\"\nMODEL_PATH_PREFIX = \"/root/.cache/datalab/models\"\n\n# Define the container image with all dependencies\nimage = (\n    modal.Image.debian_slim(python_version=\"3.10\")\n    .apt_install([\"git\", \"wget\"])\n    .env({\"TORCH_DEVICE\": \"cuda\"})\n    .pip_install([\n        \"marker-pdf[full]\",\n        \"fastapi==0.104.1\",\n        \"uvicorn==0.24.0\",\n        \"python-multipart==0.0.6\",\n        \"torch>=2.2.2,<3.0.0\",\n        \"torchvision>=0.17.0\",\n        \"torchaudio>=2.2.0\",\n    ])\n)\n\n# Create a persistent volume for model caching\nmodels_volume = modal.Volume.from_name(\"marker-models-modal-demo\", create_if_missing=True)\n", "n_tokens": 209, "byte_len": 733, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 6, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 3, "symbols": ["setup_models_with_cache_check", "checking", "import", "models", "setup", "create", "shared", "cache", "false", "logging", "handle", "function", "logger", "commit", "volume", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors", "found", "marker", "modal", "responses", "asynccontextmanager", "file", "deploy", "starting", "loaded", "torch", "full", "load", "basic", "config", "your", "model"], "ast_kind": "function_or_method", "text": "def setup_models_with_cache_check(logger, commit_volume=False):\n    \"\"\"\n    Shared function to create models and handle cache checking/logging.\n    \"\"\"\n    import os", "n_tokens": 31, "byte_len": 165, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 33, "end_line": 37}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 4, "symbols": ["download", "check", "create", "model", "commit", "volume", "type", "gpu", "exist", "take", "exists", "timeout", "function", "attempting", "several", "image", "else", "existing", "found", "from", "path", "listdir", "return", "models", "dir", "contents", "loading", "cached", "downloaded", "successfully", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "base", "base64", "get", "processors", "marker"], "ast_kind": "imports", "text": "    import gc\n    from marker.models import create_model_dict\n\n    # Check if models exist in cache\n    models_dir_exists = os.path.exists(MODEL_PATH_PREFIX)\n    models_dir_contents = os.listdir(MODEL_PATH_PREFIX) if models_dir_exists else []\n\n    logger.info(f\"Models cache directory exists: {models_dir_exists}\")\n    logger.info(f\"Models cache directory contents: {models_dir_contents}\")\n\n    if models_dir_exists and models_dir_contents:\n        logger.info(\"Found existing models in volume cache, loading from cache...\")\n    else:\n        logger.warning(\"No models found in volume cache. Models will be downloaded now (this may take several minutes).\")\n\n    # Create/load models\n    models = create_model_dict()\n    logger.info(f\"Successfully loaded {len(models)} models\")\n\n    # Check what was downloaded/cached\n    if os.path.exists(MODEL_PATH_PREFIX):\n        contents = os.listdir(MODEL_PATH_PREFIX)\n        logger.info(f\"Models in cache: {contents}\")\n\n    # Commit volume if requested (for download function)\n    if commit_volume:\n        gc.collect()\n        logger.info(\"Attempting to commit volume...\")\n        models_volume.commit()\n        logger.info(\"Volume committed successfully\")\n\n    return models\n\n@app.function(\n    image=image,\n    volumes={MODEL_PATH_PREFIX: models_volume},\n    gpu=GPU_TYPE,\n    timeout=600,\n)", "n_tokens": 281, "byte_len": 1335, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 38, "end_line": 76}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 5, "symbols": ["download_models", "load_models", "MarkerModalDemoService", "download", "exception", "persistent", "failed", "basic", "config", "class", "load", "models", "minute", "large", "volume", "into", "type", "gpu", "timeout", "function", "commit", "image", "mounted", "enter", "self", "get", "logger", "used", "logging", "error", "setup_models_with_cache_check", "marker_api", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "processors", "found", "marker", "modal", "responses", "asynccontextmanager"], "ast_kind": "class_or_type", "text": "def download_models():\n    \"\"\"\n    Helper function to download models used in marker into a Modal volume.\n    \"\"\"\n    import logging\n\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(__name__)\n\n    logger.info(\"Downloading models to persistent volume...\")\n    logger.info(f\"Volume mounted at: {MODEL_PATH_PREFIX}\")\n\n    try:\n        models = setup_models_with_cache_check(logger, commit_volume=True)\n        return f\"Models downloaded successfully: {list(models.keys())}\"\n    except Exception as e:\n        logger.error(f\"Failed to download models: {e}\")\n        raise\n\n@app.cls(\n    image=image,\n    gpu=GPU_TYPE,\n    memory=16384,\n    timeout=600,   # 10 minute timeout for large documents\n    volumes={MODEL_PATH_PREFIX: models_volume},\n    scaledown_window=300,\n)\nclass MarkerModalDemoService:\n    @modal.enter()\n    def load_models(self):\n        \"\"\"Load models once per container using @modal.enter() for efficiency.\"\"\"", "n_tokens": 202, "byte_len": 951, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 77, "end_line": 107}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 6, "symbols": ["marker_api", "exception", "basic", "config", "levelname", "asgi", "app", "none", "traceback", "loading", "marker", "commit", "volume", "base", "base64", "api", "self", "enter", "get", "logger", "logging", "error", "name", "format", "info", "except", "setup", "models", "asctime", "message", "setup_models_with_cache_check", "download_models", "load_models", "MarkerModalDemoService", "failed", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "processors", "found", "modal", "responses", "asynccontextmanager", "file"], "ast_kind": "function_or_method", "text": "        import logging\n        import traceback\n\n        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n        logger = logging.getLogger(__name__)\n\n        logger.info(\"Loading Marker models using @modal.enter()...\")\n        try:\n            self.models = setup_models_with_cache_check(logger, commit_volume=True)\n        except Exception as e:\n            logger.error(f\"Error loading models: {e}\")\n            traceback.print_exc()\n            self.models = None\n\n    @modal.asgi_app()\n    def marker_api(self):\n        import traceback\n        import io\n        import base64", "n_tokens": 122, "byte_len": 625, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 108, "end_line": 126}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 7, "symbols": ["basic", "config", "levelname", "parser", "pathlib", "upload", "file", "converters", "responses", "settings", "from", "get", "logger", "logging", "name", "format", "contextlib", "asynccontextmanager", "info", "form", "http", "exception", "typing", "asctime", "path", "optional", "message", "import", "pdf", "converter", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "processors", "found"], "ast_kind": "imports", "text": "        import logging\n        from contextlib import asynccontextmanager\n        from typing import Optional\n        from pathlib import Path\n\n        from fastapi import FastAPI, Form, File, UploadFile, HTTPException\n        from fastapi.responses import JSONResponse\n\n        from marker.converters.pdf import PdfConverter\n        from marker.config.parser import ConfigParser\n        from marker.settings import settings\n\n        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n        logger = logging.getLogger(__name__)\n", "n_tokens": 107, "byte_len": 571, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 127, "end_line": 141}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 8, "symbols": ["already", "markdown", "datalab", "marker", "version", "html", "web", "app", "enter", "down", "description", "asynccontextmanager", "modal", "yield", "demo", "shutting", "lifespan", "starting", "logger", "async", "loaded", "conversion", "models", "title", "service", "convert", "documents", "using", "create", "fast", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors"], "ast_kind": "unknown", "text": "        @asynccontextmanager\n        async def lifespan(app: FastAPI):\n            # Models are already loaded in @modal.enter()\n            logger.info(\"Datalab Marker / Modal demo app starting up...\")\n            yield\n            logger.info(\"Datalab Marker / Modal demo app shutting down...\")\n\n        # Create FastAPI app\n        web_app = FastAPI(\n            title=\"Datalab Marker PDF Conversion Service - Modal Demo\",\n            description=\"Convert PDFs and documents to markdown, JSON, or HTML using Marker, deployed on Modal\",\n            version=\"1.0.0\",\n            lifespan=lifespan\n        )\n", "n_tokens": 127, "byte_len": 608, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 142, "end_line": 156}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 9, "symbols": ["check", "debugging", "none", "model", "count", "exists", "cache", "dir", "health", "else", "web", "app", "self", "path", "listdir", "volume", "return", "status", "contents", "loading", "models", "loaded", "mode", "pat", "async", "hasattr", "healthy", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "code", "validate", "byte", "stream", "base", "base64", "get", "processors", "found", "marker", "modal", "responses", "logging", "asynccontextmanager"], "ast_kind": "unknown", "text": "        @web_app.get(\"/health\")\n        async def health_check():\n            models_loaded = hasattr(self, 'models') and self.models is not None\n            model_count = len(self.models) if models_loaded else 0\n\n            # Check volume contents for debugging\n            cache_exists = os.path.exists(MODEL_PATH_PREFIX)\n            cache_contents = os.listdir(MODEL_PATH_PREFIX) if cache_exists else []\n\n            return {\n                \"status\": \"healthy\" if models_loaded else \"loading\",\n                \"models_loaded\": models_loaded,\n                \"model_count\": model_count,\n                \"cache_dir\": MODEL_PATH_PREFIX,\n                \"cache_exists\": cache_exists,\n                \"cache_contents\": cache_contents[:10]\n            }\n", "n_tokens": 146, "byte_len": 753, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 157, "end_line": 174}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 10, "symbols": ["exception", "markdown", "conversion", "based", "traceback", "renderer", "exists", "configure", "status", "code", "validate", "pdftext", "workers", "unsupported", "byte", "stream", "completed", "page", "stats", "base", "base64", "get", "processors", "document", "config", "save", "tiff", "model", "dump", "error", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "testing", "health", "check", "found", "marker", "modal", "responses", "logging", "volume", "asynccontextmanager", "file", "deploy", "starting", "loaded"], "ast_kind": "imports", "text": "        @web_app.post(\"/convert\")\n        async def convert_document(\n            file: UploadFile = File(..., description=\"Document to convert\"),\n            page_range: Optional[str] = Form(None),\n            force_ocr: bool = Form(False),\n            paginate_output: bool = Form(False),\n            output_format: str = Form(\"markdown\"),\n            use_llm: bool = Form(False),\n        ):\n            \"\"\"Convert uploaded document to specified format.\"\"\"\n\n            if not hasattr(self, 'models') or self.models is None:\n                logger.error(\"Models not available for conversion\")\n                raise HTTPException(status_code=503, detail=\"Models not loaded yet. Please wait for model initialization.\")\n\n            # Validate file type\n            allowed_extensions = {'.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.bmp'}\n            file_ext = Path(file.filename).suffix.lower()\n            if file_ext not in allowed_extensions:\n                raise HTTPException(\n                    status_code=400,\n                    detail=f\"Unsupported file type: {file_ext}. Supported: {allowed_extensions}\"\n                )\n\n            # Validate output format\n            if output_format not in [\"markdown\", \"json\", \"html\", \"chunks\"]:\n                raise HTTPException(\n                    status_code=400,\n                    detail=\"Output format must be one of: markdown, json, html, chunks\"\n                )\n\n            try:\n                # Read file content\n                file_content = await file.read()\n\n                # Save to temporary file\n                temp_path = f\"/tmp/{file.filename}\"\n                with open(temp_path, \"wb\") as temp_file:\n                    temp_file.write(file_content)\n\n                # Configure conversion parameters\n                config = {\n                    \"filepath\": temp_path,\n                    \"page_range\": page_range,\n                    \"force_ocr\": force_ocr,\n                    \"paginate_output\": paginate_output,\n                    \"output_format\": output_format,\n                    \"use_llm\": use_llm,\n                }\n\n                # Create converter\n                config_parser = ConfigParser(config)\n                config_dict = config_parser.generate_config_dict()\n                config_dict[\"pdftext_workers\"] = 1\n\n                converter = PdfConverter(\n                    config=config_dict,\n                    artifact_dict=self.models,\n                    processor_list=config_parser.get_processors(),\n                    renderer=config_parser.get_renderer(),\n                    llm_service=config_parser.get_llm_service() if use_llm else None,\n                )\n\n                # Convert document - converter already applies the appropriate renderer\n                logger.info(f\"Converting {file.filename} to {output_format}...\")\n                rendered_output = converter(temp_path)\n\n                # Extract content based on output format\n                json_content = None\n                html_content = None\n                markdown_content = None\n                encoded_images = {}\n\n                if output_format == \"json\":\n                    # For JSON, return the structured data directly\n                    json_content = rendered_output.model_dump()\n                else:\n                    from marker.output import text_from_rendered\n                    text, _, images = text_from_rendered(rendered_output)\n\n                    # Assign to appropriate content field\n                    if output_format == \"html\":\n                        html_content = text\n                    else:\n                        markdown_content = text\n\n                    # Encode images as base64\n                    for img_name, img_obj in images.items():\n                        byte_stream = io.BytesIO()\n                        img_obj.save(byte_stream, format=settings.OUTPUT_IMAGE_FORMAT)\n                        encoded_images[img_name] = base64.b64encode(byte_stream.getvalue()).decode('utf-8')\n\n                metadata = rendered_output.metadata\n\n                logger.info(f\"Conversion completed for {file.filename}\")\n\n                # Clean up temp file\n                os.unlink(temp_path)\n\n                return JSONResponse({\n                    \"success\": True,\n                    \"filename\": file.filename,\n                    \"output_format\": output_format,\n                    \"json\": json_content,\n                    \"html\": html_content,\n                    \"markdown\": markdown_content,\n                    \"images\": encoded_images,\n                    \"metadata\": metadata,\n                    \"page_count\": len(metadata.get(\"page_stats\", [])),\n                })\n\n            except Exception as e:\n                # Clean up temp file if it exists\n                if os.path.exists(temp_path):\n                    os.unlink(temp_path)\n\n                logger.error(f\"Conversion error for {file.filename}: {str(e)}\")\n                traceback.print_exc()\n\n                raise HTTPException(\n                    status_code=500,\n                    detail=f\"Conversion failed: {str(e)}\"\n                )\n\n        return web_app\n\n", "n_tokens": 887, "byte_len": 5182, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 175, "end_line": 301}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 11, "symbols": ["markdown", "entrypoint", "invoke", "conversion", "your", "none", "test", "deployment", "marker", "output", "format", "endpoint", "local", "modal", "store", "from", "pdf", "file", "path", "does", "usage", "useful", "this", "optional", "that", "import", "async", "main", "machine", "requests", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "testing", "renderer", "status", "code", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors"], "ast_kind": "imports", "text": "#\n# This does not get deployed. It's a useful entrypoint from your local CLI\n#    that you can use to test your deployment. It'll store the\n#    API response in a new file on your machine.\n#\n@app.local_entrypoint()\nasync def invoke_conversion(\n    pdf_file: Optional[str] = None,\n    output_format: str = \"markdown\",\n    env: str = 'main'\n):\n    \"\"\"\n    Local entrypoint to test your deployed Marker endpoint in Modal.\n\n    Usage:\n        modal run marker_modal_deployment.py::invoke_conversion --pdf-file /path/to/file.pdf --output-format markdown\n    \"\"\"\n    import requests", "n_tokens": 133, "byte_len": 576, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 302, "end_line": 319}
{"id": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/examples/marker_modal_deployment.py", "rel_path": "examples/marker_modal_deployment.py", "module": "examples.marker_modal_deployment", "ext": "py", "chunk_number": 12, "symbols": ["exception", "conversion", "web", "url", "testing", "exists", "status", "code", "endpoint", "saved", "found", "marker", "modal", "result", "dump", "pages", "format", "convert", "filename", "return", "file", "except", "images", "deploy", "models", "loaded", "files", "open", "response", "service", "setup_models_with_cache_check", "download_models", "load_models", "marker_api", "MarkerModalDemoService", "failed", "traceback", "renderer", "validate", "byte", "stream", "health", "check", "base", "base64", "get", "processors", "responses", "logging", "volume"], "ast_kind": "imports", "text": "    import json\n    from pathlib import Path\n\n    if not pdf_file:\n        print(\"No PDF file specified. Use --pdf-file /path/to/your.pdf\")\n        return\n\n    pdf_path = Path(pdf_file)\n    if not pdf_path.exists():\n        print(f\"File not found: {pdf_file}\")\n        return\n\n    #\n    # Get the web URL for our deployed service\n    #\n    try:\n        service = modal.Cls.from_name(\n            \"datalab-marker-modal-demo\",\n            \"MarkerModalDemoService\",\n            environment_name=env\n        )\n        web_url = service().marker_api.get_web_url()\n        print(f\"Found deployed service at: {web_url}\")\n    except Exception as e:\n        print(f\"Error getting web URL: {e}\")\n        print(\"Make sure you've deployed the service first with: modal deploy marker_modal_deployment.py\")\n        return\n\n    print(f\"Testing conversion of: {pdf_path.name}\")\n    print(f\"Output format: {output_format}\")\n\n    #\n    # Test health endpoint first\n    #\n    try:\n        health_response = requests.get(f\"{web_url}/health\")\n        health_data = health_response.json()\n        print(f\"Service health: {health_data['status']}\")\n        print(f\"Models loaded: {health_data['models_loaded']} ({health_data['model_count']} models)\")\n\n        if not health_data['models_loaded']:\n            print(\"Warning: Models not loaded yet. First request may be slow.\")\n\n    except Exception as e:\n        print(f\"Health check failed: {e}\")\n\n    #\n    # Make conversion request\n    #\n    try:\n        with open(pdf_path, 'rb') as f:\n            files = {'file': (pdf_path.name, f, 'application/pdf')}\n            data = {'output_format': output_format}\n\n            print(f\"Sending request to {web_url}/convert...\")\n            response = requests.post(f\"{web_url}/convert\", files=files, data=data)\n\n        if response.status_code == 200:\n            result = response.json()\n            print(f\" Conversion successful!\")\n            print(f\"Filename: {result['filename']}\")\n            print(f\"Format: {result['output_format']}\")\n            print(f\"Pages: {result['page_count']}\")\n\n            output_file = f\"{pdf_path.stem}_response.json\"\n            with open(output_file, 'w', encoding='utf-8') as f:\n                json.dump(result, f, indent=2, ensure_ascii=False)\n            print(f\"Full API response saved to: {output_file}\")\n\n            if result['images']:\n                print(f\"Images extracted: {len(result['images'])}\")\n\n        else:\n            print(f\" Conversion failed: {response.status_code}\")\n            print(f\"Error: {response.text}\")\n\n    except Exception as e:\n        print(f\"Request failed: {e}\")\n", "n_tokens": 592, "byte_len": 2621, "file_sha1": "0d242fdb001ad437ef19e715f1eadce1e367c5e8", "start_line": 320, "end_line": 398}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/verify_scores.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/verify_scores.py", "rel_path": "benchmarks/verify_scores.py", "module": "benchmarks.verify_scores", "ext": "py", "chunk_number": 1, "symbols": ["verify_scores", "verify", "scores", "marker", "raw", "data", "file", "json", "open", "with", "raise", "argparse", "below", "import", "score", "heuristic", "value", "error", "path", "load", "verify_table_scores", "args", "elif", "argument", "parser", "default", "required", "name", "description", "benchmark", "help", "table", "main", "parse", "type", "average", "add", "threshold"], "ast_kind": "function_or_method", "text": "import json\nimport argparse\n\n\ndef verify_scores(file_path):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    raw_scores = [data[\"scores\"][k] for k in data[\"scores\"]]\n    marker_scores = [r[\"marker\"][\"heuristic\"][\"score\"] for r in raw_scores]\n    marker_score = sum(marker_scores) / len(marker_scores)\n    if marker_score < 90:\n        raise ValueError(\"Marker score below 90\")\n\n", "n_tokens": 100, "byte_len": 404, "file_sha1": "4ab6cd8cae91afeffb88510ed26e73c94fd6aa22", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/verify_scores.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/verify_scores.py", "rel_path": "benchmarks/verify_scores.py", "module": "benchmarks.verify_scores", "ext": "py", "chunk_number": 2, "symbols": ["verify_table_scores", "args", "elif", "verify", "scores", "argument", "parser", "default", "required", "name", "description", "data", "benchmark", "file", "help", "table", "main", "parse", "type", "open", "json", "with", "path", "raise", "below", "argparse", "marker", "score", "value", "error", "verify_scores", "raw", "import", "heuristic", "average", "load", "add", "threshold"], "ast_kind": "function_or_method", "text": "def verify_table_scores(file_path):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    avg = sum([r[\"marker_score\"] for r in data[\"marker\"]]) / len(data)\n    if avg < 0.7:\n        raise ValueError(\"Average score is below the required threshold of 0.7\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Verify benchmark scores\")\n    parser.add_argument(\"file_path\", type=str, help=\"Path to the json file\")\n    parser.add_argument(\"--type\", type=str, help=\"Type of file to verify\", default=\"marker\")\n    args = parser.parse_args()\n    if args.type == \"marker\":\n        verify_scores(args.file_path)\n    elif args.type == \"table\":\n        verify_table_scores(args.file_path)\n", "n_tokens": 172, "byte_len": 726, "file_sha1": "4ab6cd8cae91afeffb88510ed26e73c94fd6aa22", "start_line": 16, "end_line": 34}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py", "rel_path": "benchmarks/table/scoring.py", "module": "benchmarks.table.scoring", "ext": "py", "chunk_number": 1, "symbols": ["wrap_table_html", "__init__", "TableTree", "table", "html", "class", "init", "sets", "none", "helpers", "https", "content", "teds", "tree", "self", "config", "from", "wrap", "collections", "code", "name", "body", "github", "return", "apted", "deque", "super", "children", "lxml", "colspan", "bracket", "maximum", "normalized_distance", "rename", "tokenize", "tree_convert_html", "similarity_eval_html", "CustomConfig", "samples", "getchildren", "new", "node", "required", "global", "result", "node1", "format", "cells", "nodes", "pred"], "ast_kind": "class_or_type", "text": "\"\"\"\"\nTEDS Code Adapted from https://github.com/ibm-aur-nlp/EDD\n\"\"\"\n\nimport distance\nfrom apted import APTED, Config\nfrom apted.helpers import Tree\nfrom lxml import html\nfrom collections import deque\n\ndef wrap_table_html(table_html:str)->str:\n    return f'<html><body>{table_html}</body></html>'\n\nclass TableTree(Tree):\n    def __init__(self, tag, colspan=None, rowspan=None, content=None, *children):\n        self.tag = tag\n        self.colspan = colspan\n        self.rowspan = rowspan\n        self.content = content\n\n        # Sets self.name and self.children\n        super().__init__(tag, *children)\n", "n_tokens": 151, "byte_len": 602, "file_sha1": "2ac87a0504a2d193b18c6ee73109af51f8c2f1e0", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py", "rel_path": "benchmarks/table/scoring.py", "module": "benchmarks.table.scoring", "ext": "py", "chunk_number": 2, "symbols": ["bracket", "maximum", "normalized_distance", "CustomConfig", "brackets", "class", "show", "text", "notation", "float", "custom", "config", "tree", "content", "else", "self", "result", "sequences", "format", "return", "children", "colspan", "staticmethod", "normalized", "distance", "child", "levenshtein", "using", "rowspan", "wrap_table_html", "__init__", "rename", "tokenize", "tree_convert_html", "similarity_eval_html", "TableTree", "samples", "getchildren", "https", "new", "node", "required", "global", "node1", "code", "cells", "github", "nodes", "pred", "ground"], "ast_kind": "class_or_type", "text": "    def bracket(self):\n        \"\"\"Show tree using brackets notation\"\"\"\n        if self.tag == 'td':\n            result = '\"tag\": %s, \"colspan\": %d, \"rowspan\": %d, \"text\": %s' % \\\n                     (self.tag, self.colspan, self.rowspan, self.content)\n        else:\n            result = '\"tag\": %s' % self.tag\n        for child in self.children:\n            result += child.bracket()\n        return \"{{{}}}\".format(result)\n\nclass CustomConfig(Config):\n    @staticmethod\n    def maximum(*sequences):\n        return max(map(len, sequences))\n\n    def normalized_distance(self, *sequences):\n        return float(distance.levenshtein(*sequences)) / self.maximum(*sequences)\n", "n_tokens": 157, "byte_len": 670, "file_sha1": "2ac87a0504a2d193b18c6ee73109af51f8c2f1e0", "start_line": 24, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py", "rel_path": "benchmarks/table/scoring.py", "module": "benchmarks.table.scoring", "ext": "py", "chunk_number": 3, "symbols": ["rename", "tokenize", "tokens", "node", "node2", "text", "none", "getchildren", "content", "append", "self", "global", "node1", "cells", "return", "colspan", "normalized", "distance", "table", "tail", "tokenizes", "list", "rowspan", "wrap_table_html", "__init__", "bracket", "maximum", "normalized_distance", "tree_convert_html", "similarity_eval_html", "TableTree", "CustomConfig", "samples", "https", "tree", "new", "required", "result", "code", "format", "github", "nodes", "pred", "ground", "children", "true", "staticmethod", "adapted", "similarity", "eval"], "ast_kind": "function_or_method", "text": "    def rename(self, node1, node2):\n        if (node1.tag != node2.tag) or (node1.colspan != node2.colspan) or (node1.rowspan != node2.rowspan):\n            return 1.\n        if node1.tag == 'td':\n            if node1.content or node2.content:\n                return self.normalized_distance(node1.content, node2.content)\n        return 0.\n\ndef tokenize(node):\n    \"\"\"\n    Tokenizes table cells\n    \"\"\"\n    global __tokens__\n    __tokens__.append('<%s>' % node.tag)\n    if node.text is not None:\n        __tokens__ += list(node.text)\n    for n in node.getchildren():\n        tokenize(n)\n    if node.tag != 'unk':\n        __tokens__.append('</%s>' % node.tag)\n    if node.tag != 'td' and node.tail is not None:\n            __tokens__ += list(node.tail)\n", "n_tokens": 194, "byte_len": 752, "file_sha1": "2ac87a0504a2d193b18c6ee73109af51f8c2f1e0", "start_line": 43, "end_line": 65}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py", "rel_path": "benchmarks/table/scoring.py", "module": "benchmarks.table.scoring", "ext": "py", "chunk_number": 4, "symbols": ["tree_convert_html", "tokens", "none", "getchildren", "converts", "tree", "else", "table", "parent", "html", "new", "node", "required", "append", "global", "format", "return", "deque", "children", "colspan", "copy", "apted", "attrib", "convert", "false", "tokenize", "cell", "rowspan", "wrap_table_html", "__init__", "bracket", "maximum", "normalized_distance", "rename", "similarity_eval_html", "TableTree", "CustomConfig", "samples", "https", "result", "node1", "code", "cells", "github", "nodes", "pred", "ground", "true", "staticmethod", "adapted"], "ast_kind": "function_or_method", "text": "def tree_convert_html(node, convert_cell=False, parent=None):\n    \"\"\"\n    Converts HTML tree to the format required by apted\n    \"\"\"\n    global __tokens__\n    if node.tag == 'td':\n        if convert_cell:\n            __tokens__ = []\n            tokenize(node)\n            cell = __tokens__[1:-1].copy()\n        else:\n            cell = []\n        new_node = TableTree(node.tag,\n                             int(node.attrib.get('colspan', '1')),\n                             int(node.attrib.get('rowspan', '1')),\n                             cell, *deque())\n    else:\n        new_node = TableTree(node.tag, None, None, None, *deque())\n    if parent is not None:\n        parent.children.append(new_node)\n    if node.tag != 'td':\n        for n in node.getchildren():\n            tree_convert_html(n, convert_cell, new_node)\n    if parent is None:\n        return new_node\n", "n_tokens": 189, "byte_len": 868, "file_sha1": "2ac87a0504a2d193b18c6ee73109af51f8c2f1e0", "start_line": 66, "end_line": 91}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/scoring.py", "rel_path": "benchmarks/table/scoring.py", "module": "benchmarks.table.scoring", "ext": "py", "chunk_number": 5, "symbols": ["similarity_eval_html", "samples", "nodes", "true", "float", "custom", "config", "teds", "between", "else", "html", "computes", "body", "compute", "edit", "return", "pred", "tree", "apted", "ground", "xpath", "given", "table", "similarity", "eval", "structure", "only", "truth", "distance", "false", "wrap_table_html", "__init__", "bracket", "maximum", "normalized_distance", "rename", "tokenize", "tree_convert_html", "TableTree", "CustomConfig", "getchildren", "https", "new", "node", "required", "global", "result", "node1", "code", "format"], "ast_kind": "function_or_method", "text": "def similarity_eval_html(pred, true, structure_only=False):\n    \"\"\"\n    Computes TEDS score between the prediction and the ground truth of a given samples\n    \"\"\"\n    pred, true = html.fromstring(pred), html.fromstring(true)\n    if pred.xpath('body/table') and true.xpath('body/table'):\n        pred = pred.xpath('body/table')[0]\n        true = true.xpath('body/table')[0]\n        n_nodes_pred = len(pred.xpath(\".//*\"))\n        n_nodes_true = len(true.xpath(\".//*\"))\n        tree_pred = tree_convert_html(pred, convert_cell=not structure_only)\n        tree_true = tree_convert_html(true, convert_cell=not structure_only)\n        n_nodes = max(n_nodes_pred, n_nodes_true)\n        distance = APTED(tree_pred, tree_true, CustomConfig()).compute_edit_distance()\n        return 1.0 - (float(distance) / n_nodes)\n    else:\n        return 0.0\n\n", "n_tokens": 196, "byte_len": 837, "file_sha1": "2ac87a0504a2d193b18c6ee73109af51f8c2f1e0", "start_line": 92, "end_line": 110}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/gemini.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/gemini.py", "rel_path": "benchmarks/table/gemini.py", "module": "benchmarks.table.gemini", "ext": "py", "chunk_number": 1, "symbols": ["image", "prompt", "determine", "analyze", "tables", "into", "thead", "output", "provided", "pydantic", "html", "document", "guidelines", "make", "types", "settings", "from", "good", "google", "only", "sure", "possible", "analyst", "following", "convert", "concise", "contents", "base", "model", "genai", "gemini_table_rec", "TableSchema", "config", "responses", "temperature", "googl", "key", "client", "format", "return", "gemini", "table", "colspan", "turning", "schema", "flash", "tags", "necessary", "starting", "marker"], "ast_kind": "imports", "text": "import json\nfrom PIL import Image\nfrom google import genai\nfrom google.genai import types\nfrom io import BytesIO\nfrom pydantic import BaseModel\n\nfrom marker.settings import settings\n\nprompt = \"\"\"\nYou're an expert document analyst who is good at turning tables in documents into HTML.  Analyze the provided image, and convert it to a faithful HTML representation.\n \nGuidelines:\n- Keep the HTML simple and concise.\n- Only include the <table> tag and contents.\n- Only use <table>, <tr>, and <td> tags.  Only use the colspan and rowspan attributes if necessary.  Do not use <tbody>, <thead>, or <th> tags.\n- Make sure the table is as faithful to the image as possible with the given tags.\n\n**Instructions**\n1. Analyze the image, and determine the table structure.\n2. Convert the table image to HTML, following the guidelines above.\n3. Output only the HTML for the table, starting with the <table> tag and ending with the </table> tag.\n\"\"\".strip()\n", "n_tokens": 218, "byte_len": 943, "file_sha1": "8e98273728fb40db847af498520eb1827a3ec61b", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/gemini.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/gemini.py", "rel_path": "benchmarks/table/gemini.py", "module": "benchmarks.table.gemini", "ext": "py", "chunk_number": 2, "symbols": ["gemini_table_rec", "TableSchema", "table", "html", "image", "client", "prompt", "class", "api", "key", "part", "better", "text", "model", "save", "response", "schema", "timeout", "according", "docs", "content", "performs", "first", "types", "settings", "responses", "generate", "googl", "config", "temperature", "determine", "analyze", "document", "analyst", "format", "convert", "return", "gemini", "colspan", "turning", "flash", "tags", "necessary", "starting", "only", "output", "marker", "documents", "faithful", "simple"], "ast_kind": "class_or_type", "text": "class TableSchema(BaseModel):\n    table_html: str\n\ndef gemini_table_rec(image: Image.Image):\n    client = genai.Client(\n        api_key=settings.GOOGLE_API_KEY,\n        http_options={\"timeout\": 60000}\n    )\n\n    image_bytes = BytesIO()\n    image.save(image_bytes, format=\"PNG\")\n\n    responses = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=[types.Part.from_bytes(data=image_bytes.getvalue(), mime_type=\"image/png\"), prompt],  # According to gemini docs, it performs better if the image is the first element\n        config={\n            \"temperature\": 0,\n            \"response_schema\": TableSchema,\n            \"response_mime_type\": \"application/json\",\n        },\n    )\n\n    output = responses.candidates[0].content.parts[0].text\n    return json.loads(output)[\"table_html\"]", "n_tokens": 182, "byte_len": 810, "file_sha1": "8e98273728fb40db847af498520eb1827a3ec61b", "start_line": 25, "end_line": 48}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py", "rel_path": "benchmarks/table/inference.py", "module": "benchmarks.table.inference", "ext": "py", "chunk_number": 1, "symbols": ["extract_tables", "block", "type", "elif", "create", "model", "tables", "parser", "matrix", "intersection", "table", "processor", "json", "numpy", "pypdfium", "pypdfium2", "tempfile", "base", "base64", "converters", "schema", "benchmarks", "config", "append", "converter", "from", "llm", "return", "children", "list", "fix_table_html", "inference_tables", "exception", "find", "well", "already", "use", "gemini", "marker", "renderer", "alignments", "skipping", "aligned", "found", "pct", "idx", "images", "rescale", "sorted", "max"], "ast_kind": "function_or_method", "text": "from typing import List\n\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport pypdfium2 as pdfium\nfrom tqdm import tqdm\nimport base64\nimport tempfile\n\nfrom benchmarks.table.gemini import gemini_table_rec\nfrom marker.config.parser import ConfigParser\nfrom marker.converters.table import TableConverter\nfrom marker.models import create_model_dict\nfrom marker.processors.llm.llm_table import LLMTableProcessor\nfrom marker.processors.table import TableProcessor\nfrom marker.renderers.json import JSONBlockOutput\nfrom marker.schema.polygon import PolygonBox\nfrom marker.util import matrix_intersection_area\n\n\ndef extract_tables(children: List[JSONBlockOutput]):\n    tables = []\n    for child in children:\n        if child.block_type == 'Table':\n            tables.append(child)\n        elif child.children:\n            tables.extend(extract_tables(child.children))\n    return tables\n", "n_tokens": 179, "byte_len": 881, "file_sha1": "5bc75ccb5cf2e9f9336cf247f7c6515dc2768724", "start_line": 1, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py", "rel_path": "benchmarks/table/inference.py", "module": "benchmarks.table.inference", "ext": "py", "chunk_number": 2, "symbols": ["fix_table_html", "fix", "table", "html", "find", "new", "string", "marker", "all", "parser", "spaces", "uses", "instead", "newlines", "return", "unwrap", "replace", "with", "tag", "tbody", "beautiful", "soup", "fintabnet", "name", "extract_tables", "inference_tables", "exception", "well", "already", "use", "gemini", "matrix", "intersection", "tables", "renderer", "alignments", "skipping", "aligned", "base", "base64", "converters", "found", "pct", "config", "idx", "llm", "images", "rescale", "sorted", "max"], "ast_kind": "function_or_method", "text": "def fix_table_html(table_html: str) -> str:\n    marker_table_soup = BeautifulSoup(table_html, 'html.parser')\n    tbody = marker_table_soup.find('tbody')\n    if tbody:\n        tbody.unwrap()\n    for th_tag in marker_table_soup.find_all('th'):\n        th_tag.name = 'td'\n    for br_tag in marker_table_soup.find_all('br'):\n        br_tag.replace_with(marker_table_soup.new_string(''))\n\n    marker_table_html = str(marker_table_soup)\n    marker_table_html = marker_table_html.replace(\"\\n\", \" \")  # Fintabnet uses spaces instead of newlines\n    return marker_table_html\n\n", "n_tokens": 132, "byte_len": 567, "file_sha1": "5bc75ccb5cf2e9f9336cf247f7c6515dc2768724", "start_line": 30, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/inference.py", "rel_path": "benchmarks/table/inference.py", "module": "benchmarks.table.inference", "ext": "py", "chunk_number": 3, "symbols": ["inference_tables", "exception", "well", "already", "use", "gemini", "marker", "table", "matrix", "intersection", "tables", "renderer", "alignments", "skipping", "aligned", "base", "base64", "pct", "found", "config", "idx", "llm", "images", "rescale", "return", "sorted", "max", "area", "except", "children", "extract_tables", "fix_table_html", "find", "converters", "replace", "with", "temp", "pdf", "argmax", "processors", "pdfium", "tags", "used", "document", "continue", "bool", "fintabnet", "util", "which", "converter"], "ast_kind": "function_or_method", "text": "def inference_tables(dataset, use_llm: bool, table_rec_batch_size: int | None, max_rows: int, use_gemini: bool):\n    models = create_model_dict()\n    config_parser = ConfigParser({'output_format': 'json', \"use_llm\": use_llm, \"table_rec_batch_size\": table_rec_batch_size, \"disable_tqdm\": True})\n    total_unaligned = 0\n    results = []\n\n    iterations = len(dataset)\n    if max_rows is not None:\n        iterations = min(max_rows, len(dataset))\n\n    for i in tqdm(range(iterations), desc='Converting Tables'):\n        try:\n            row = dataset[i]\n            pdf_binary = base64.b64decode(row['pdf'])\n            gt_tables = row['tables']  # Already sorted by reading order, which is what marker returns\n\n            # Only use the basic table processors\n            converter = TableConverter(\n                config=config_parser.generate_config_dict(),\n                artifact_dict=models,\n                processor_list=[\n                    \"marker.processors.table.TableProcessor\",\n                    \"marker.processors.llm.llm_table.LLMTableProcessor\",\n                ],\n                renderer=config_parser.get_renderer()\n            )\n\n            with tempfile.NamedTemporaryFile(suffix=\".pdf\", mode=\"wb\") as temp_pdf_file:\n                temp_pdf_file.write(pdf_binary)\n                temp_pdf_file.seek(0)\n                marker_json = converter(temp_pdf_file.name).children\n\n                doc = pdfium.PdfDocument(temp_pdf_file.name)\n                page_image = doc[0].render(scale=96/72).to_pil()\n                doc.close()\n\n            if len(marker_json) == 0 or len(gt_tables) == 0:\n                print(f'No tables detected, skipping...')\n                total_unaligned += len(gt_tables)\n                continue\n\n            marker_tables = extract_tables(marker_json)\n            marker_table_boxes = [table.bbox for table in marker_tables]\n            page_bbox = marker_json[0].bbox\n\n            if len(marker_tables) != len(gt_tables):\n                print(f'Number of tables do not match, skipping...')\n                total_unaligned += len(gt_tables)\n                continue\n\n            table_images = [\n                page_image.crop(\n                    PolygonBox.from_bbox(bbox)\n                    .rescale(\n                        (page_bbox[2], page_bbox[3]), (page_image.width, page_image.height)\n                    ).bbox\n                )\n                for bbox\n                in marker_table_boxes\n            ]\n\n            # Normalize the bboxes\n            for bbox in marker_table_boxes:\n                bbox[0] = bbox[0] / page_bbox[2]\n                bbox[1] = bbox[1] / page_bbox[3]\n                bbox[2] = bbox[2] / page_bbox[2]\n                bbox[3] = bbox[3] / page_bbox[3]\n\n            gt_boxes = [table['normalized_bbox'] for table in gt_tables]\n            gt_areas = [(bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) for bbox in gt_boxes]\n            marker_areas = [(bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) for bbox in marker_table_boxes]\n            table_alignments = matrix_intersection_area(gt_boxes, marker_table_boxes)\n\n            aligned_tables = []\n            used_tables = set()\n            unaligned_tables = set()\n            for table_idx, alignment in enumerate(table_alignments):\n                try:\n                    max_area = np.max(alignment)\n                    aligned_idx = np.argmax(alignment)\n                except ValueError:\n                    # No alignment found\n                    unaligned_tables.add(table_idx)\n                    continue\n\n                if max_area <= .01:\n                    # No alignment found\n                    unaligned_tables.add(table_idx)\n                    continue\n\n                if aligned_idx in used_tables:\n                    # Marker table already aligned with another gt table\n                    unaligned_tables.add(table_idx)\n                    continue\n\n                # Gt table doesn't align well with any marker table\n                gt_table_pct = gt_areas[table_idx] / max_area\n                if not .85 < gt_table_pct < 1.15:\n                    unaligned_tables.add(table_idx)\n                    continue\n\n                # Marker table doesn't align with gt table\n                marker_table_pct = marker_areas[aligned_idx] / max_area\n                if not .85 < marker_table_pct < 1.15:\n                    unaligned_tables.add(table_idx)\n                    continue\n\n                gemini_html = \"\"\n                if use_gemini:\n                    try:\n                        gemini_html = gemini_table_rec(table_images[aligned_idx])\n                    except Exception as e:\n                        print(f'Gemini failed: {e}')\n\n                aligned_tables.append(\n                    (marker_tables[aligned_idx], gt_tables[table_idx], gemini_html)\n                )\n                used_tables.add(aligned_idx)\n\n            total_unaligned += len(unaligned_tables)\n\n            for marker_table, gt_table, gemini_table in aligned_tables:\n                gt_table_html = gt_table['html']\n\n                # marker wraps the table in <tbody> which fintabnet data doesn't\n                # Fintabnet doesn't use th tags, need to be replaced for fair comparison\n                marker_table_html = fix_table_html(marker_table.html)\n                gemini_table_html = fix_table_html(gemini_table)\n\n                results.append({\n                    \"marker_table\": marker_table_html,\n                    \"gt_table\": gt_table_html,\n                    \"gemini_table\": gemini_table_html\n                })\n        except pdfium.PdfiumError:\n            print('Broken PDF, Skipping...')\n            continue\n    return results, total_unaligned", "n_tokens": 1142, "byte_len": 5725, "file_sha1": "5bc75ccb5cf2e9f9336cf247f7c6515dc2768724", "start_line": 45, "end_line": 182}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/table.py", "rel_path": "benchmarks/table/table.py", "module": "benchmarks.table.table", "ext": "py", "chunk_number": 1, "symbols": ["update_teds_score", "supported", "datasets", "click", "futures", "repeat", "pathlib", "isin", "inference", "tables", "ground", "truth", "score", "scoring", "update", "teds", "itertools", "benchmarks", "settings", "result", "from", "wrap", "table", "prefix", "pytorc", "enabl", "uses", "return", "time", "transformers", "main", "start", "use", "gemini", "process", "benchmark", "saved", "dump", "maximum", "github", "predicted", "path", "seed", "max", "workers", "open", "similarity", "eval", "mkdir", "bool"], "ast_kind": "function_or_method", "text": "import os\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"  # Transformers uses .isin for an op, which is not supported on MPS\n\nfrom pathlib import Path\nfrom itertools import repeat\nfrom typing import List\n\nimport time\nimport datasets\nfrom tqdm import tqdm\nimport click\nfrom tabulate import tabulate\nimport json\nfrom concurrent.futures import ProcessPoolExecutor\n\nfrom marker.settings import settings\nfrom benchmarks.table.inference import inference_tables\n\nfrom scoring import wrap_table_html, similarity_eval_html\n\ndef update_teds_score(result, prefix: str = \"marker\"):\n    prediction, ground_truth = result[f'{prefix}_table'], result['gt_table']\n    prediction, ground_truth = wrap_table_html(prediction), wrap_table_html(ground_truth)\n    score = similarity_eval_html(prediction, ground_truth)\n    result.update({f'{prefix}_score':score})\n    return result\n\n", "n_tokens": 187, "byte_len": 861, "file_sha1": "e2c10665b87f1605ea35e1f7c904348773711f6b", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/table.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/table/table.py", "rel_path": "benchmarks/table/table.py", "module": "benchmarks.table.table", "ext": "py", "chunk_number": 2, "symbols": ["main", "start", "use", "gemini", "click", "process", "score", "benchmark", "update", "teds", "saved", "dump", "maximum", "github", "predicted", "time", "result", "path", "seed", "max", "workers", "open", "mkdir", "bool", "fintabnet", "marker", "number", "total", "conversion", "executor", "update_teds_score", "futures", "scoring", "itertools", "prefix", "pytorc", "enabl", "return", "similarity", "eval", "which", "environ", "indent", "true", "tqdm", "flag", "command", "split", "tables", "parents"], "ast_kind": "function_or_method", "text": "@click.command(help=\"Benchmark Table to HTML Conversion\")\n@click.option(\"--result_path\", type=str, default=os.path.join(settings.OUTPUT_DIR, \"benchmark\", \"table\"), help=\"Output path for results.\")\n@click.option(\"--dataset\", type=str, default=\"datalab-to/fintabnet_bench_marker\", help=\"Dataset to use\")\n@click.option(\"--max_rows\", type=int, default=None, help=\"Maximum number of PDFs to process\")\n@click.option(\"--max_workers\", type=int, default=16, help=\"Maximum number of workers to use\")\n@click.option(\"--use_llm\", is_flag=True, help=\"Use LLM for improving table recognition.\")\n@click.option(\"--table_rec_batch_size\", type=int, default=None, help=\"Batch size for table recognition.\")\n@click.option(\"--use_gemini\", is_flag=True, help=\"Evaluate Gemini for table recognition.\")\ndef main(\n        result_path: str,\n        dataset: str,\n        max_rows: int,\n        max_workers: int,\n        use_llm: bool,\n        table_rec_batch_size: int | None,\n        use_gemini: bool = False\n):\n    start = time.time()\n\n\n    dataset = datasets.load_dataset(dataset, split='train')\n    dataset = dataset.shuffle(seed=0)\n\n    results, total_unaligned = inference_tables(dataset, use_llm, table_rec_batch_size, max_rows, use_gemini)\n\n    print(f\"Total time: {time.time() - start}.\")\n    print(f\"Could not align {total_unaligned} tables from fintabnet.\")\n\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        marker_results = list(\n            tqdm(\n                executor.map(update_teds_score, results), desc='Computing alignment scores', total=len(results)\n            )\n        )\n\n    avg_score = sum([r[\"marker_score\"] for r in marker_results]) / len(marker_results)\n    headers = [\"Avg score\", \"Total tables\"]\n    data = [f\"{avg_score:.3f}\", len(marker_results)]\n    gemini_results = None\n    if use_gemini:\n        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n            gemini_results = list(\n                tqdm(\n                    executor.map(update_teds_score, results, repeat(\"gemini\")), desc='Computing Gemini scores',\n                    total=len(results)\n                )\n            )\n        avg_gemini_score = sum([r[\"gemini_score\"] for r in gemini_results]) / len(gemini_results)\n        headers.append(\"Avg Gemini score\")\n        data.append(f\"{avg_gemini_score:.3f}\")\n\n    table = tabulate([data], headers=headers, tablefmt=\"github\")\n    print(table)\n    print(\"Avg score computed by comparing marker predicted HTML with original HTML\")\n\n    results = {\n        \"marker\": marker_results,\n        \"gemini\": gemini_results\n    }\n\n    out_path = Path(result_path)\n    out_path.mkdir(parents=True, exist_ok=True)\n    with open(out_path / \"table.json\", \"w+\") as f:\n        json.dump(results, f, indent=2)\n\n    print(f\"Results saved to {out_path}.\")\n\nif __name__ == '__main__':\n    main()", "n_tokens": 653, "byte_len": 2837, "file_sha1": "e2c10665b87f1605ea35e1f7c904348773711f6b", "start_line": 29, "end_line": 97}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py", "rel_path": "benchmarks/throughput/main.py", "module": "benchmarks.throughput.main", "ext": "py", "chunk_number": 1, "symbols": ["get_next_pdf", "get", "context", "datasets", "click", "futures", "pypdfium", "pypdfium2", "tempfile", "while", "from", "filename", "return", "next", "time", "multiprocessing", "pdfium", "endswith", "import", "concurrent", "process", "pool", "torch", "true", "tqdm", "dataset", "single_batch", "main", "reset", "peak", "markdown", "conversion", "single", "batch", "throughput", "start", "recognitio", "mode", "benchmark", "pdfs", "threads", "omp", "converters", "config", "result", "cpu", "count", "chunk", "future", "max"], "ast_kind": "function_or_method", "text": "import os\nimport tempfile\nimport time\nfrom multiprocessing import get_context\nfrom concurrent.futures import ProcessPoolExecutor\nimport torch\n\nimport click\nimport pypdfium2 as pdfium\nfrom tqdm import tqdm\n\nimport datasets\n\n\ndef get_next_pdf(ds: datasets.Dataset, i: int):\n    while True:\n        pdf = ds[i][\"pdf\"]\n        filename = ds[i][\"filename\"]\n        if pdf and filename.endswith(\".pdf\"):\n            return pdf, filename, i + 1\n        i += 1\n        if i >= len(ds):\n            i = 0\n\n", "n_tokens": 120, "byte_len": 497, "file_sha1": "f195b169844848e65d95c41fe2a39835a28ddba6", "start_line": 1, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py", "rel_path": "benchmarks/throughput/main.py", "module": "benchmarks.throughput.main", "ext": "py", "chunk_number": 2, "symbols": ["single_batch", "reset", "peak", "markdown", "single", "batch", "start", "recognitio", "mode", "pdfs", "threads", "omp", "converters", "config", "chunk", "return", "get", "next", "time", "max", "pdfium", "output", "pdf", "document", "bool", "marker", "total", "torch", "environ", "named", "get_next_pdf", "main", "conversion", "throughput", "click", "futures", "benchmark", "result", "cpu", "count", "future", "filename", "processes", "characters", "workers", "vrams", "context", "executor", "min", "temporary"], "ast_kind": "function_or_method", "text": "def single_batch(\n    batch_size: int,\n    num_threads: int,\n    force_ocr: bool,\n    quantize: bool,\n    compile: bool,\n    worker_id: int,\n    chunksize: int = 100,\n):\n    if quantize:\n        os.environ[\"RECOGNITION_MODEL_QUANTIZE\"] = \"true\"\n    if compile:\n        os.environ[\"COMPILE_ALL\"] = \"true\"\n\n    for item in [\n        \"DETECTOR_POSTPROCESSING_CPU_WORKERS\",\n        \"OPENBLAS_NUM_THREADS\",\n        \"PDFTEXT_CPU_WORKERS\",\n        \"OMP_NUM_THREADS\",\n    ]:\n        os.environ[item] = f\"{num_threads}\"\n\n    torch.set_num_threads(num_threads)\n\n    from marker.converters.pdf import PdfConverter\n    from marker.models import create_model_dict\n    from marker.output import text_from_rendered\n\n    ds = datasets.load_dataset(\"datalab-to/pdfs\", split=\"train\")\n    model_dict = create_model_dict()\n    torch.cuda.reset_peak_memory_stats()\n\n    times = []\n    i = 0\n    pages = 0\n    chars = 0\n\n    min_time = time.time()\n    for _ in range(batch_size):\n        pdf, fname, i = get_next_pdf(ds, i)\n        print(f\"Inferencing {fname} on worker {worker_id}...\")\n\n        pdf_doc = pdfium.PdfDocument(pdf)\n        page_count = len(pdf_doc)\n        pdf_doc.close()\n        pages += page_count\n\n        with tempfile.NamedTemporaryFile(suffix=\".pdf\") as f:\n            f.write(pdf)\n            f.flush()\n            page_range_chunks = list(range(0, page_count, chunksize))\n            for chunk_start in page_range_chunks:\n                chunk_end = min(chunk_start + chunksize, page_count)\n                page_range = list(range(chunk_start, chunk_end))\n\n                block_converter = PdfConverter(\n                    artifact_dict=model_dict,\n                    config={\n                        \"disable_tqdm\": worker_id > 0,\n                        \"page_range\": page_range,\n                        \"force_ocr\": force_ocr,\n                    },\n                )\n                start = time.time()\n                rendered = block_converter(f.name)\n                markdown, _, _ = text_from_rendered(rendered)\n                chars += len(markdown)\n\n                total = time.time() - start\n                times.append(total)\n\n    max_gpu_vram = torch.cuda.max_memory_reserved() / 1024**3\n    max_time = time.time()\n    return sum(times), min_time, max_time, max_gpu_vram, pages, chars\n\n", "n_tokens": 527, "byte_len": 2306, "file_sha1": "f195b169844848e65d95c41fe2a39835a28ddba6", "start_line": 26, "end_line": 101}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/throughput/main.py", "rel_path": "benchmarks/throughput/main.py", "module": "benchmarks.throughput.main", "ext": "py", "chunk_number": 3, "symbols": ["main", "conversion", "single", "batch", "throughput", "start", "click", "futures", "benchmark", "result", "cpu", "count", "future", "time", "max", "processes", "characters", "workers", "vrams", "context", "bool", "marker", "executor", "min", "torch", "page", "true", "tqdm", "flag", "command", "get_next_pdf", "single_batch", "reset", "peak", "markdown", "recognitio", "mode", "pdfs", "threads", "omp", "converters", "config", "chunk", "filename", "return", "get", "next", "pdfium", "output", "pdf"], "ast_kind": "function_or_method", "text": "@click.command(help=\"Benchmark PDF to MD conversion throughput.\")\n@click.option(\"--workers\", default=1, help=\"Number of workers to use.\")\n@click.option(\"--batch_size\", default=1, help=\"Batch size for inference.\")\n@click.option(\"--force_ocr\", is_flag=True, help=\"Force OCR on all pages.\")\n@click.option(\"--quantize\", is_flag=True, help=\"Use quantized model.\")\n@click.option(\"--compile\", is_flag=True, help=\"Use compiled model.\")\ndef main(\n    workers: int,\n    batch_size: int,\n    force_ocr: bool,\n    quantize: bool,\n    compile: bool,\n):\n    total_cpus = os.cpu_count()\n    start = time.time()\n    current_gpu_vram = torch.cuda.memory_reserved() / 1024**3\n    with ProcessPoolExecutor(\n        max_workers=workers, mp_context=get_context(\"spawn\")\n    ) as executor:\n        cpus_per_worker = min(8, max(2, total_cpus // workers))\n        futures = [\n            executor.submit(\n                single_batch,\n                batch_size,\n                cpus_per_worker,\n                force_ocr,\n                quantize,\n                compile,\n                i,\n            )\n            for i in range(workers)\n        ]\n        all_times = []\n        min_time = None\n        max_time = time.time()\n        vrams = []\n        page_count = 0\n        char_count = 0\n        for future in tqdm(futures, desc=\"Running marker workers...\"):\n            times, min_time_worker, max_time_worker, max_vram, pages, chars = (\n                future.result()\n            )\n            vrams.append(max_vram - current_gpu_vram)\n            all_times.append(times)\n            page_count += pages\n            char_count += chars\n            min_time = (\n                min(min_time_worker, min_time)\n                if min_time is not None\n                else min_time_worker\n            )\n            max_time = max(max_time, max_time_worker)\n\n    end = time.time() - start\n    all_worker_time = max_time - min_time\n\n    print(f\"Average time per worker: {sum(all_times) / len(all_times)}\")\n    print(f\"Max time per worker: {max(all_times)}\")\n    print(f\"End to end time (counting model loading), all processes: {end}\")\n    print(f\"End to end time (no model loading), all processes: {all_worker_time}\")\n    print(f\"Total pages: {page_count}\")\n    print(f\"Total characters: {char_count}\")\n    print(f\"Time per page: {all_worker_time / page_count:.2f}\")\n    print(f\"Characters per second: {char_count / all_worker_time:.2f}\")\n    print(f\"Max GPU VRAM: {max(vrams):.2f} GB\")\n    print(f\"Average GPU VRAM: {sum(vrams) / len(vrams):.2f} GB\")\n\n\nif __name__ == \"__main__\":\n    main()\n", "n_tokens": 616, "byte_len": 2573, "file_sha1": "f195b169844848e65d95c41fe2a39835a28ddba6", "start_line": 102, "end_line": 172}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 1, "symbols": ["image", "import", "time", "list", "defaultdict", "tuple", "random", "from", "literal", "click", "collections", "typing", "tabulate", "json", "dataclasses", "dataclass", "dict", "__init__", "__call__", "llm_rater", "llm_response_wrapper", "display_win_rates_table", "main", "ComparerSchema", "Comparer", "exception", "identified", "samples", "markdown", "conversion", "well", "compare", "based", "header", "argument", "process", "section", "comparer", "schema", "method", "effectively", "win", "rates", "project", "recognized", "scoring", "document", "config", "responses", "temperature"], "ast_kind": "imports", "text": "import json\nimport random\nimport time\nimport os\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Tuple, Literal\nfrom PIL import Image\nfrom collections import defaultdict\nimport tabulate\n\nimport click", "n_tokens": 46, "byte_len": 215, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 2, "symbols": ["identified", "samples", "markdown", "well", "compare", "based", "header", "process", "section", "image", "effectively", "recognized", "scoring", "document", "unreadable", "carefully", "correct", "here", "version", "description", "images", "language", "than", "been", "notes", "value", "marker", "which", "this", "completely", "__init__", "__call__", "llm_rater", "llm_response_wrapper", "display_win_rates_table", "main", "ComparerSchema", "Comparer", "exception", "conversion", "argument", "click", "comparer", "schema", "method", "win", "rates", "project", "config", "responses"], "ast_kind": "imports", "text": "import datasets\nfrom google import genai\nfrom google.genai.errors import APIError\nfrom pydantic import BaseModel\nfrom tqdm import tqdm\n\nfrom marker.settings import settings\n\nrating_prompt = \"\"\"\nYou're a document analysis expert who is comparing two different markdown samples to an image to see which one represents the content of the image better. The markdown will be called version A and version B.\n\nHere are some notes on the image and markdown:\n- Some parts of the page may have been recognized as images and linked from the markdown, like `![](_page_0_Picture_0.jpeg)`.\n- Tables will be formatted as Github flavored markdown.\n- Block equations will be in LaTeX.\n- The image and markdown may be in any language.\n- The markdown is based on the text extracted from the document, and sometimes the document may have had bad OCR applied to it, resulting in gibberish text.\n\nThe markdown should fully capture the meaning and formatting of the text in the image. You'll evaluate the markdown based on the image provided.\n\n**Instructions**\nFollow this process to evaluate the markdown:\n1. Carefully examine the image.\n2. Carefully examine the first markdown input provided.\n3. Describe how well version a represents the image.\n4. Carefully examine the second markdown input provided.\n5. Describe how well version B represents the image.\n6. Compare version A and version B.\n7. Decide which markdown representation is better, based on the criteria below.  Output version_a if version a is better, and version_b if version b is better.\n\nUse these criteria when judging the markdown:\n- Overall - the overall quality of the markdown as compared to the image.\n- Text quality - the quality of the text extraction from the image.\n- Formatting quality - the quality of the formatting applied to the markdown, as compared to the image.\n- Tables - how effectively the tables have been extracted and formatted.\n- Forms - how effectively the forms have extracted and formatted.\n- Equations - how effectively block equations have been converted to LaTeX.\n- Lists - if the lists have been properly extracted and formatted.\n- Images - if images are identified and placed correctly.\n\nNotes on scoring:\n- Perfect markdown will include all of the important text from the image, and the formatting will be correct (minor mistakes okay).  It's okay to omit some text that isn't important to the meaning, like page numbers and chapter headings.  If the entire page is an image, it's okay if the markdown is just a link to the image, unless the image would be better represented as text.\n- Bad markdown will have major missing text segments from the markdown or completely unreadable formatting.  It may also have key values that are different from the values in the image.\n\nOutput json, like in the example below.\n\n**Example**\nVersion A\n```markdown\n# *Section 1*\nThis is some *markdown* extracted from a document.  Here is a block equation:\n$$\\frac{ab \\cdot x^5 + x^2 + 2 \\cdot x + 123}{t}$$\n```\nVersion B\n```markdown\n# Section 1\nThis is some markdown extracted from a document.  Here is a block equation:\n$$\\frac{ab \\cdot x^5 + x^2 + 2 \\cdot x + 124}{t}$$\n```\nOutput\n```json\n{\n    \"image_description\": \"In the image, there is a section header 'Section 1', followed by some text and a block equation.\",\n    \"version_a_description\": \"In the markdown, there is a section header 'Section 1', followed by some text and a block equation.\",\n    \"version_b_description\": \"In the markdown, there is a section header 'Section 1', followed by some text and a block equation.  The formatting in version b is slightly different from the image.  The value 124 is also different from the image.\",\n    \"comparison\": \"Version A is better than version B.  The text and formatting in version A matches the image better than version B.  Version B also has an incorrect value.\",\n    \"winner\": \"version_a\",\n}\n```\n**Input**\nVersion A\n```markdown\n{{version_a}}\n```\nVersion B\n```markdown\n{{version_b}}\n```\n**Output**\n\"\"\"\n", "n_tokens": 886, "byte_len": 3973, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 12, "end_line": 92}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "ComparerSchema", "Comparer", "exception", "image", "elif", "class", "init", "none", "winner", "comparer", "schema", "llm", "rater", "self", "print", "return", "version", "base", "model", "hydrated", "prompt", "description", "except", "replace", "error", "comparison", "rating", "pass", "llm_rater", "llm_response_wrapper", "display_win_rates_table", "main", "identified", "samples", "markdown", "conversion", "well", "compare", "based", "header", "argument", "click", "process", "section", "method", "effectively", "win", "rates"], "ast_kind": "class_or_type", "text": "class ComparerSchema(BaseModel):\n    image_description: str\n    version_a_description: str\n    version_b_description: str\n    comparison: str\n    winner: Literal[\"version_a\", \"version_b\"]\n\n\nclass Comparer:\n    def __init__(self):\n        pass\n\n    def __call__(\n        self,\n        img: Image.Image,\n        version_a: str,\n        version_b: str\n    ) -> str | None:\n        if version_a is None and version_b is not None:\n            return \"version_b\"\n        elif version_b is None and version_a is not None:\n            return \"version_a\"\n\n        hydrated_prompt = rating_prompt.replace(\"{{version_a}}\", version_a).replace(\"{{version_b}}\", version_b)\n        try:\n            rating = self.llm_rater(img, hydrated_prompt)\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return\n        return rating\n\n", "n_tokens": 194, "byte_len": 836, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 93, "end_line": 124}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 4, "symbols": ["llm_rater", "image", "prompt", "missing", "llm", "rater", "assert", "self", "winner", "response", "comparer", "schema", "return", "__init__", "__call__", "llm_response_wrapper", "display_win_rates_table", "main", "ComparerSchema", "Comparer", "exception", "identified", "samples", "markdown", "conversion", "well", "compare", "based", "header", "argument", "click", "process", "section", "method", "effectively", "win", "rates", "project", "recognized", "scoring", "document", "config", "responses", "temperature", "row", "unreadable", "location", "dict", "vertexai", "client"], "ast_kind": "function_or_method", "text": "    def llm_rater(self, img: Image.Image, prompt: str):\n        response = self.llm_response_wrapper(\n            [img, prompt],\n            ComparerSchema\n        )\n        assert \"winner\" in response, f\"Response missing 'winner' key: {response}\"\n        return response[\"winner\"]\n", "n_tokens": 65, "byte_len": 282, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 125, "end_line": 132}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 5, "symbols": ["llm_response_wrapper", "exception", "client", "prompt", "verte", "location", "text", "response", "schema", "model", "gemini", "timeout", "llm", "content", "project", "self", "config", "responses", "generate", "temperature", "candidates", "print", "vertexai", "return", "contents", "except", "genai", "projec", "flash", "error", "__init__", "__call__", "llm_rater", "display_win_rates_table", "main", "ComparerSchema", "Comparer", "identified", "samples", "markdown", "conversion", "well", "compare", "based", "header", "argument", "click", "process", "section", "comparer"], "ast_kind": "function_or_method", "text": "    def llm_response_wrapper(\n        self,\n        prompt,\n        response_schema,\n    ):\n        client = genai.Client(\n            http_options={\"timeout\": 60000},\n            vertexai=True,\n            project=os.getenv(\"VERTEX_PROJECT_ID\"),\n            location=os.getenv(\"VERTEX_LOCATION\"),\n        )\n        try:\n            responses = client.models.generate_content(\n                model=\"gemini-2.0-flash-001\",\n                contents=prompt,\n                config={\n                    \"temperature\": 0,\n                    \"response_schema\": response_schema,\n                    \"response_mime_type\": \"application/json\",\n                },\n            )\n            output = responses.candidates[0].content.parts[0].text\n            return json.loads(output)\n        except APIError as e:\n            print(f\"Hit Gemini rate limit\")\n            return\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return\n\n", "n_tokens": 180, "byte_len": 952, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 133, "end_line": 163}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 6, "symbols": ["display_win_rates_table", "results", "headers", "losses", "win", "rates", "tablefmt", "append", "print", "method", "dict", "loss", "pretty", "wins", "display", "tabulate", "table", "items", "__init__", "__call__", "llm_rater", "llm_response_wrapper", "main", "ComparerSchema", "Comparer", "exception", "identified", "samples", "markdown", "conversion", "well", "compare", "based", "header", "argument", "click", "process", "section", "comparer", "schema", "image", "effectively", "project", "recognized", "scoring", "document", "config", "responses", "temperature", "row"], "ast_kind": "function_or_method", "text": "def display_win_rates_table(win_rates: dict):\n    table = []\n    headers = [\"Method A\", \"Method B\", \"Wins\", \"Losses\", \"Win %\"]\n    for method_a, method_b_dict in win_rates.items():\n        row = [method_a]\n        for method_b, results in method_b_dict.items():\n            row = [method_a, method_b, results[\"win\"], results[\"loss\"], (results[\"win\"] / (results[\"win\"] + results[\"loss\"])) * 100]\n            table.append(row)\n    print(tabulate.tabulate(table, headers=headers, tablefmt=\"pretty\"))\n\n", "n_tokens": 127, "byte_len": 498, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 164, "end_line": 174}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/elo.py", "rel_path": "benchmarks/overall/elo.py", "module": "benchmarks.overall.elo", "ext": "py", "chunk_number": 7, "symbols": ["main", "samples", "split", "conversion", "none", "argument", "datasets", "winner", "click", "desc", "process", "random", "default", "range", "number", "shuffle", "method", "methods", "win", "rates", "else", "document", "version", "mathpix", "row", "maximum", "loss", "bias", "name", "comparer", "__init__", "__call__", "llm_rater", "llm_response_wrapper", "display_win_rates_table", "ComparerSchema", "Comparer", "exception", "identified", "markdown", "well", "compare", "based", "header", "section", "schema", "image", "effectively", "project", "recognized"], "ast_kind": "function_or_method", "text": "@click.command(\"Calculate win rates for document conversion methods\")\n@click.argument(\"dataset\", type=str)\n@click.option(\"--methods\", type=str, help=\"List of methods to compare: comma separated like marker,mathpix\")\n@click.option(\"--row_samples\", type=int, default=2, help=\"Number of samples per row\")\n@click.option(\"--max_rows\", type=int, default=None, help=\"Maximum number of rows to process\")\ndef main(\n    dataset: str,\n    methods: str,\n    row_samples: int,\n    max_rows: int\n):\n    ds = datasets.load_dataset(dataset, split=\"train\")\n    method_lst = methods.split(\",\")\n    win_rates = {m: defaultdict(lambda: defaultdict(int)) for m in method_lst}\n    comparer = Comparer()\n    max_rows = max_rows or len(ds)\n\n    for i in tqdm(range(max_rows), desc=\"Calculating win rates...\"):\n        row = ds[i]\n        # Avoid any bias in ordering\n        random.shuffle(method_lst)\n\n        for j, method_a in enumerate(method_lst[:-1]):\n            for z, method_b in enumerate(method_lst[j:]):\n                if method_a == method_b:\n                    continue\n\n                method_a_md = row[f\"{method_a}_md\"]\n                method_b_md = row[f\"{method_b}_md\"]\n                winner = comparer(row[\"img\"], method_a_md, method_b_md)\n                if not winner:\n                    continue\n\n                if winner == \"version_a\":\n                    win_rates[method_a][method_b][\"win\"] += 1\n                    win_rates[method_b][method_a][\"loss\"] += 1\n                else:\n                    win_rates[method_b][method_a][\"win\"] += 1\n                    win_rates[method_a][method_b][\"loss\"] += 1\n        if i % 10 == 0:\n            display_win_rates_table(win_rates)\n\n    display_win_rates_table(win_rates)\n\n\nif __name__ == \"__main__\":\n    main()", "n_tokens": 397, "byte_len": 1764, "file_sha1": "48c9e314a6815a6963cbbf15316966688125d6c0", "start_line": 175, "end_line": 221}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/registry.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/registry.py", "rel_path": "benchmarks/overall/registry.py", "module": "benchmarks.overall.registry", "ext": "py", "chunk_number": 1, "symbols": ["scorers", "metho", "registry", "method", "gtmethod", "olm", "ocr", "methods", "docling", "benchmarks", "mathpix", "from", "olmocr", "mistral", "llm", "scorer", "llamaparse", "import", "marker", "heuristic", "scor", "overall", "llama", "parse"], "ast_kind": "imports", "text": "from benchmarks.overall.methods.docling import DoclingMethod\nfrom benchmarks.overall.methods.gt import GTMethod\nfrom benchmarks.overall.methods.llamaparse import LlamaParseMethod\nfrom benchmarks.overall.methods.marker import MarkerMethod\nfrom benchmarks.overall.methods.mathpix import MathpixMethod\nfrom benchmarks.overall.methods.mistral import MistralMethod\nfrom benchmarks.overall.methods.olmocr import OlmOCRMethod\nfrom benchmarks.overall.scorers.heuristic import HeuristicScorer\nfrom benchmarks.overall.scorers.llm import LLMScorer\n\nSCORE_REGISTRY = {\n    \"heuristic\": HeuristicScorer,\n    \"llm\": LLMScorer\n}\n\nMETHOD_REGISTRY = {\n    \"marker\": MarkerMethod,\n    \"gt\": GTMethod,\n    \"mathpix\": MathpixMethod,\n    \"llamaparse\": LlamaParseMethod,\n    \"docling\": DoclingMethod,\n    \"olmocr\": OlmOCRMethod,\n    \"mistral\": MistralMethod\n}", "n_tokens": 210, "byte_len": 837, "file_sha1": "e5479a06972e45106d20da077108f844ff593699", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py", "rel_path": "benchmarks/overall/overall.py", "module": "benchmarks.overall.overall", "ext": "py", "chunk_number": 1, "symbols": ["create", "model", "metho", "registry", "build", "dataset", "datasets", "traceback", "click", "print", "scores", "pathlib", "display", "schema", "benchmarks", "settings", "from", "collections", "list", "typing", "json", "full", "result", "models", "path", "logger", "configure", "logging", "table", "import", "get_method_scores", "main", "exception", "markdown", "failed", "conversion", "cls", "process", "sample", "functions", "break", "comma", "method", "benchmark", "private", "scoring", "filter", "dump", "dict", "maximum"], "ast_kind": "imports", "text": "import json\nimport os\nimport traceback\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import List\n\nimport click\nimport datasets\nimport torch\nfrom tqdm import tqdm\n\nfrom benchmarks.overall.display.dataset import build_dataset\nfrom benchmarks.overall.registry import SCORE_REGISTRY, METHOD_REGISTRY\nfrom benchmarks.overall.schema import FullResult\nfrom marker.logger import configure_logging\nfrom marker.models import create_model_dict\nfrom marker.settings import settings\nfrom benchmarks.overall.display.table import print_scores\n\nconfigure_logging()\n\n", "n_tokens": 103, "byte_len": 577, "file_sha1": "4690e702cac6c0e3a8bf651dbd259fbb45acde47", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py", "rel_path": "benchmarks/overall/overall.py", "module": "benchmarks.overall.overall", "ext": "py", "chunk_number": 2, "symbols": ["get_method_scores", "exception", "scorers", "classification", "block", "type", "metho", "registry", "markdown", "failed", "running", "artifacts", "none", "datasets", "total", "rows", "traceback", "desc", "cls", "process", "sample", "break", "method", "doc", "out", "data", "methods", "append", "print", "benchmark", "main", "conversion", "build", "dataset", "display", "click", "scores", "functions", "comma", "private", "scoring", "filter", "result", "dump", "dict", "maximum", "olmocr", "model", "return", "marker"], "ast_kind": "function_or_method", "text": "def get_method_scores(benchmark_dataset: datasets.Dataset, methods: List[str], score_types: List[str], artifacts: dict, max_rows=None) -> FullResult:\n    bench_scores = {}\n    averages_by_type = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n    averages_by_block_type = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n    average_times = defaultdict(list)\n    markdown_by_method = defaultdict(dict)\n    total_rows = len(benchmark_dataset)\n    if max_rows:\n        total_rows = min(max_rows, total_rows)\n    for idx, sample in tqdm(enumerate(benchmark_dataset), desc=\"Running benchmark\", total=total_rows):\n        if max_rows is not None and idx >= max_rows:\n            break\n\n        doc_type = sample[\"classification\"]\n        gt_cls = METHOD_REGISTRY[\"gt\"]\n        gt_blocks = json.loads(sample[\"gt_blocks\"])\n        gt_md = gt_cls(**artifacts)(sample)[\"markdown\"]\n        markdown_by_method[idx][\"gt\"] = gt_md\n\n        out_data = defaultdict(dict)\n\n        try:\n            for method in methods:\n                method_cls = METHOD_REGISTRY[method](**artifacts)\n                method_info = method_cls(sample)\n                method_md = method_info[\"markdown\"]\n                if method_md is None:\n                    method_md = \"\" # Avoid None values\n\n                average_times[method].append(method_info[\"time\"])\n                markdown_by_method[idx][method] = method_md\n\n                for score_type in score_types:\n                    score_cls = SCORE_REGISTRY[score_type]()\n                    try:\n                        scores = score_cls(sample, gt_md, method_md)\n                    except Exception as e:\n                        # Some scorers can fail, like the LLM one\n                        print(f\"Failed to score {method} with {score_type}: {e}\")\n                        continue\n\n                    out_data[method][score_type] = scores\n\n                    averages_by_type[method][score_type][doc_type].append(scores[\"score\"])\n\n                    if \"by_block\" in scores[\"specific_scores\"]: # Not all scorers support this\n                        for score, gt_block in zip(scores[\"specific_scores\"][\"by_block\"], gt_blocks):\n                            averages_by_block_type[method][score_type][gt_block[\"block_type\"]].append(score)\n        except Exception as e:\n            print(f\"Failed to process {idx}: {e}\")\n            traceback.print_exc()\n            if idx in markdown_by_method:\n                del markdown_by_method[idx]\n            continue\n\n        bench_scores[idx] = out_data\n\n    return {\n        \"scores\": bench_scores,\n        \"markdown\": markdown_by_method,\n        \"averages_by_type\": averages_by_type,\n        \"averages_by_block_type\": averages_by_block_type,\n        \"average_times\": average_times,\n    }\n", "n_tokens": 551, "byte_len": 2797, "file_sha1": "4690e702cac6c0e3a8bf651dbd259fbb45acde47", "start_line": 24, "end_line": 88}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/overall.py", "rel_path": "benchmarks/overall/overall.py", "module": "benchmarks.overall.overall", "ext": "py", "chunk_number": 3, "symbols": ["main", "conversion", "build", "dataset", "display", "click", "process", "print", "scores", "functions", "comma", "benchmark", "private", "scoring", "filter", "result", "dump", "maximum", "olmocr", "model", "marker", "language", "path", "open", "mkdir", "output", "bool", "number", "score", "mathpix", "get_method_scores", "exception", "markdown", "failed", "traceback", "cls", "sample", "break", "method", "dict", "return", "time", "except", "block", "continue", "average", "times", "info", "this", "total"], "ast_kind": "function_or_method", "text": "@click.command(help=\"Benchmark PDF to MD conversion.\")\n@click.option(\"--dataset\", type=str, help=\"Path to the benchmark dataset\", default=\"datalab-to/marker_benchmark\")\n@click.option(\"--out_dataset\", type=str, help=\"Path to the output dataset\", default=None)\n@click.option(\"--methods\", type=str, help=\"Comma separated list of other methods to compare against.  Possible values: marker,mathpix,llamaparse,docling,mistral\", default=\"marker\")\n@click.option(\"--scores\", type=str, help=\"Comma separated list of scoring functions to use.  Possible values: heuristic,llm\", default=\"heuristic\")\n@click.option(\"--result_path\", type=str, default=os.path.join(settings.OUTPUT_DIR, \"benchmark\", \"overall\"), help=\"Output path for results.\")\n@click.option(\"--max_rows\", type=int, default=None, help=\"Maximum number of rows to process.\")\n@click.option(\"--use_llm\", is_flag=True, help=\"Use the LLM model for better marker quality.\")\n@click.option(\"--languages\", type=str, help=\"Comma separated list of languages to use for LLM\", default=None)\ndef main(\n        dataset: str,\n        out_dataset: str,\n        methods: str,\n        scores: str,\n        result_path: str,\n        max_rows: int,\n        use_llm: bool,\n        languages: str\n):\n    out_path = Path(result_path)\n    out_path.mkdir(parents=True, exist_ok=True)\n\n    methods = methods.split(\",\")\n    for method in methods:\n        if method not in METHOD_REGISTRY:\n            raise ValueError(f\"Method {method} not allowed.  Allowed methods are {METHOD_REGISTRY.keys()}\")\n\n    # Ensure marker is always first\n    all_methods = list(set(methods))\n    methods = [\"marker\"] if \"marker\" in all_methods else []\n    methods += [m for m in all_methods if m != \"marker\"]\n\n    score_types = scores.split(\",\")\n    for score_type in score_types:\n        if score_type not in SCORE_REGISTRY:\n            raise ValueError(f\"Score type {score_type} not allowed.  Allowed types are {SCORE_REGISTRY.keys()}\")\n\n    if languages:\n        languages = languages.split(\",\")\n    else:\n        languages = None\n\n    benchmark_dataset = datasets.load_dataset(dataset, split=\"train\")\n    if languages:\n        benchmark_dataset = benchmark_dataset.filter(lambda x: x[\"language\"] in languages)\n\n    artifacts = {\n        \"model_dict\": create_model_dict(),\n        \"use_llm\": use_llm,\n        \"mathpix_ds\": None,\n        \"llamaparse_ds\": None,\n    }\n\n    if \"mathpix\" in methods:\n        artifacts[\"mathpix_ds\"] = datasets.load_dataset(\"datalab-to/marker_benchmark_mathpix\", split=\"train\")\n\n    if \"llamaparse\" in methods:\n        artifacts[\"llamaparse_ds\"] = datasets.load_dataset(\"datalab-to/marker_benchmark_llamaparse\", split=\"train\")\n\n    if \"mistral\" in methods:\n        artifacts[\"mistral_ds\"] = datasets.load_dataset(\"datalab-to/marker_benchmark_mistral\", split=\"train\")\n\n    if \"olmocr\" in methods:\n        from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n        model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\",\n                                                                torch_dtype=torch.bfloat16).eval()\n        processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n        model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n        artifacts[\"olmocr_model\"] = {\"model\": model, \"processor\": processor}\n\n    print(f\"Running benchmark with methods: {methods} and scores: {score_types}\")\n    result = get_method_scores(benchmark_dataset, methods, score_types, artifacts, max_rows=max_rows)\n\n    # Display benchmark scoring tables\n    print_scores(result, out_path, methods, score_types, default_method=methods[0], default_score_type=score_types[0])\n\n    # Write to json\n    with open(out_path / \"result.json\", \"w\") as f:\n        json.dump(result, f)\n\n    if out_dataset:\n        if use_llm:\n            out_dataset += \"_llm\"\n        dataset = build_dataset(benchmark_dataset, result, score_types, max_rows=max_rows)\n        dataset.push_to_hub(out_dataset, private=True)\n\n\nif __name__ == \"__main__\":\n    main()\n\n", "n_tokens": 935, "byte_len": 4046, "file_sha1": "4690e702cac6c0e3a8bf651dbd259fbb45acde47", "start_line": 89, "end_line": 179}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/schema.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/schema.py", "rel_path": "benchmarks/overall/schema.py", "module": "benchmarks.overall.schema", "ext": "py", "chunk_number": 1, "symbols": ["FullResult", "scorers", "class", "markdown", "float", "schema", "benchmarks", "from", "scores", "typed", "dict", "list", "block", "type", "avg", "typing", "full", "result", "import", "average", "times", "averages", "overall"], "ast_kind": "class_or_type", "text": "from typing import TypedDict, List, Dict\n\nfrom benchmarks.overall.scorers.schema import BlockScores\n\nAVG_TYPE = Dict[str, Dict[str, Dict[str, List[float]]]]\n\nclass FullResult(TypedDict):\n    scores: Dict[int, Dict[str, Dict[str, BlockScores]]]\n    averages_by_type: AVG_TYPE\n    averages_by_block_type: AVG_TYPE\n    average_times: Dict[str, List[float]]\n    markdown: Dict[int, Dict[str, str]]\n", "n_tokens": 100, "byte_len": 394, "file_sha1": "45924273ada6823d493828df1a78a35c9c376c0e", "start_line": 1, "end_line": 13}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/mistral.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/mistral.py", "rel_path": "benchmarks/overall/methods/mistral.py", "module": "benchmarks.overall.methods.mistral", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "MistralMethod", "find", "class", "markdown", "none", "datasets", "sample", "break", "methods", "benchmarks", "self", "from", "return", "data", "time", "call", "base", "method", "could", "mistral", "raise", "import", "benchmark", "result", "value", "error", "overall", "uuid", "dataset"], "ast_kind": "class_or_type", "text": "import datasets\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n\nclass MistralMethod(BaseMethod):\n    mistral_ds: datasets.Dataset = None\n\n    def __call__(self, sample) -> BenchmarkResult:\n        uuid = sample[\"uuid\"]\n        data = None\n        for row in self.mistral_ds:\n            if str(row[\"uuid\"]) == str(uuid):\n                data = row\n                break\n        if not data:\n            raise ValueError(f\"Could not find data for uuid {uuid}\")\n\n        return {\n            \"markdown\": data[\"md\"],\n            \"time\": data[\"time\"]\n        }", "n_tokens": 126, "byte_len": 578, "file_sha1": "b1523b810dfa01b6ca2dc262e68cccca3f90c5d2", "start_line": 1, "end_line": 22}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/mathpix.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/mathpix.py", "rel_path": "benchmarks/overall/methods/mathpix.py", "module": "benchmarks.overall.methods.mathpix", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "MathpixMethod", "find", "class", "markdown", "none", "datasets", "sample", "break", "methods", "benchmarks", "self", "from", "mathpix", "method", "return", "data", "time", "call", "base", "could", "raise", "import", "benchmark", "result", "value", "error", "overall", "uuid", "dataset"], "ast_kind": "class_or_type", "text": "import datasets\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n\nclass MathpixMethod(BaseMethod):\n    mathpix_ds: datasets.Dataset = None\n\n    def __call__(self, sample) -> BenchmarkResult:\n        uuid = sample[\"uuid\"]\n        data = None\n        for row in self.mathpix_ds:\n            if str(row[\"uuid\"]) == str(uuid):\n                data = row\n                break\n        if not data:\n            raise ValueError(f\"Could not find data for uuid {uuid}\")\n\n        return {\n            \"markdown\": data[\"md\"],\n            \"time\": data[\"time\"]\n        }", "n_tokens": 125, "byte_len": 578, "file_sha1": "e4e283f384932e5d95e62c7df9146ed61047f9be", "start_line": 1, "end_line": 22}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/docling.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/docling.py", "rel_path": "benchmarks/overall/methods/docling.py", "module": "benchmarks.overall.methods.docling", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "DoclingMethod", "class", "markdown", "start", "model", "dict", "none", "document", "converter", "mode", "sample", "tempfile", "methods", "docling", "method", "suffix", "benchmarks", "self", "result", "from", "convert", "return", "time", "single", "base", "this", "with", "export", "write", "import", "benchmark", "bool", "total", "false", "pdf", "bytes", "overall", "page", "named", "temporary", "use", "llm", "call", "name"], "ast_kind": "class_or_type", "text": "import tempfile\nimport time\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n\nclass DoclingMethod(BaseMethod):\n    model_dict: dict = None\n    use_llm: bool = False\n\n    def __call__(self, sample) -> BenchmarkResult:\n        from docling.document_converter import DocumentConverter\n        pdf_bytes = sample[\"pdf\"]  # This is a single page PDF\n        converter = DocumentConverter()\n\n        with tempfile.NamedTemporaryFile(suffix=\".pdf\", mode=\"wb\") as f:\n            f.write(pdf_bytes)\n            start = time.time()\n            result = converter.convert(f.name)\n            total = time.time() - start\n\n        return {\n            \"markdown\": result.document.export_to_markdown(),\n            \"time\": total\n        }\n\n", "n_tokens": 156, "byte_len": 746, "file_sha1": "5431234a0a16d5d09cf58ca6cd122a3fd36c252b", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/gt.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/gt.py", "rel_path": "benchmarks/overall/methods/gt.py", "module": "benchmarks.overall.methods.gt", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "render", "GTMethod", "image", "markdown", "class", "method", "gtmethod", "head", "sample", "methods", "html", "benchmarks", "self", "joined", "from", "body", "blocks", "return", "time", "list", "base", "convert", "strip", "typing", "json", "loads", "import", "benchmark", "result", "block", "overall", "join", "call"], "ast_kind": "class_or_type", "text": "from typing import List\nimport json\n\nfrom PIL import Image\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n\nclass GTMethod(BaseMethod):\n    def __call__(self, sample) -> BenchmarkResult:\n        gt_blocks = json.loads(sample[\"gt_blocks\"])\n        gt_html = [block[\"html\"] for block in gt_blocks if len(block[\"html\"]) > 0]\n        gt_markdown = [self.convert_to_md(block) for block in gt_html]\n        return {\n            \"markdown\": gt_markdown,\n            \"time\": 0\n        }\n\n    def render(self, html: List[str]) -> Image.Image:\n        joined = \"\\n\\n\".join(html)\n        html = f\"\"\"\n<html>\n<head></head>\n<body>\n{joined}\n</body>\n</html>\n\"\"\".strip()\n        return self.html_to_image(html)", "n_tokens": 174, "byte_len": 714, "file_sha1": "277e51b55867920a2cc71fad73972f7da8c62004", "start_line": 1, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py", "rel_path": "benchmarks/overall/methods/__init__.py", "module": "benchmarks.overall.methods.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "convert_to_md", "__call__", "render", "convert_to_html", "BaseMethod", "sync", "playwright", "image", "markdown", "class", "init", "tuple", "random", "sample", "methods", "html", "inline", "placeholders", "schema", "benchmarks", "api", "self", "kwarg", "from", "convert", "kwargs", "not", "implemented", "return", "block_sub", "inline_sub", "html_to_image", "math", "elements", "full", "page", "new", "chromium", "replace", "https", "document", "href", "block", "sub", "staticmethod", "extension", "open", "marker", "vcz"], "ast_kind": "class_or_type", "text": "import io\nimport random\nimport re\nfrom typing import Tuple\n\nimport markdown2\nfrom PIL import Image\nfrom playwright.sync_api import sync_playwright\n\nfrom benchmarks.overall.methods.schema import BenchmarkResult\nfrom marker.renderers.markdown import MarkdownRenderer\n\n\nclass BaseMethod:\n    def __init__(self, **kwargs):\n        for kwarg in kwargs:\n            if hasattr(self, kwarg):\n                setattr(self, kwarg, kwargs[kwarg])\n\n    @staticmethod\n    def convert_to_md(html: str):\n        md = MarkdownRenderer()\n        markdown = md.md_cls.convert(html)\n        return markdown\n\n    def __call__(self, sample) -> BenchmarkResult:\n        raise NotImplementedError()\n\n    def render(self, markdown: str):\n        return self.html_to_image(self.convert_to_html(markdown))\n\n    @staticmethod\n    def convert_to_html(md: str):\n        block_placeholders = []\n        inline_placeholders = []\n", "n_tokens": 189, "byte_len": 899, "file_sha1": "ea2441b2c779c9735804adbfae8c72f8e6ed52f0", "start_line": 1, "end_line": 36}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py", "rel_path": "benchmarks/overall/methods/__init__.py", "module": "benchmarks.overall.methods.__init__", "ext": "py", "chunk_number": 2, "symbols": ["block_sub", "block", "sub", "append", "math", "placeholder", "placeholders", "group", "match", "content", "return", "__init__", "convert_to_md", "__call__", "render", "convert_to_html", "inline_sub", "html_to_image", "BaseMethod", "elements", "markdown", "full", "page", "new", "chromium", "replace", "sample", "https", "document", "convert", "href", "playwright", "staticmethod", "extension", "html", "image", "open", "inline", "marker", "vcz", "ztlz", "set", "right", "overall", "dotall", "true", "call", "sync", "jsdelivr", "extras"], "ast_kind": "function_or_method", "text": "        # Add placeholders for the math\n        def block_sub(match):\n            content = match.group(1)\n            placeholder = f\"1BLOCKMATH{len(block_placeholders)}1\"\n            block_placeholders.append((placeholder, f\"$${content}$$\"))\n            return placeholder\n", "n_tokens": 58, "byte_len": 275, "file_sha1": "ea2441b2c779c9735804adbfae8c72f8e6ed52f0", "start_line": 37, "end_line": 43}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py", "rel_path": "benchmarks/overall/methods/__init__.py", "module": "benchmarks.overall.methods.__init__", "ext": "py", "chunk_number": 3, "symbols": ["inline_sub", "markdown", "extras", "tables", "replace", "group", "placeholders", "content", "html", "inline", "append", "math", "str", "return", "block", "sub", "flags", "placeholder", "dotall", "match", "markdown2", "__init__", "convert_to_md", "__call__", "render", "convert_to_html", "block_sub", "html_to_image", "BaseMethod", "elements", "full", "page", "new", "chromium", "sample", "https", "document", "convert", "href", "playwright", "staticmethod", "extension", "image", "open", "marker", "vcz", "ztlz", "set", "right", "overall"], "ast_kind": "function_or_method", "text": "        def inline_sub(match):\n            content = match.group(1)\n            placeholder = f\"1INLINEMATH{len(inline_placeholders)}1\"\n            inline_placeholders.append((placeholder, f\"${content}$\"))\n            return placeholder\n\n        md = re.sub(r'\\${2}(.*?)\\${2}', block_sub, md, flags=re.DOTALL)\n        md = re.sub(r'\\$(.*?)\\$', inline_sub, md)\n\n        html = markdown2.markdown(md, extras=['tables'])\n\n        # Replace placeholders\n        for placeholder, math_str in block_placeholders:\n            html = html.replace(placeholder, math_str)\n        for placeholder, math_str in inline_placeholders:\n            html = html.replace(placeholder, math_str)\n\n        return html\n", "n_tokens": 158, "byte_len": 696, "file_sha1": "ea2441b2c779c9735804adbfae8c72f8e6ed52f0", "start_line": 44, "end_line": 62}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/__init__.py", "rel_path": "benchmarks/overall/methods/__init__.py", "module": "benchmarks.overall.methods.__init__", "ext": "py", "chunk_number": 4, "symbols": ["html_to_image", "render", "math", "elements", "full", "page", "new", "chromium", "https", "document", "return", "href", "extension", "html", "image", "open", "set", "content", "vcz", "ztlz", "right", "true", "sync", "playwright", "jsdelivr", "text", "head", "dist", "islj", "zh0cislj", "__init__", "convert_to_md", "__call__", "convert_to_html", "block_sub", "inline_sub", "BaseMethod", "markdown", "replace", "sample", "convert", "block", "sub", "staticmethod", "inline", "marker", "overall", "dotall", "match", "call"], "ast_kind": "function_or_method", "text": "    def html_to_image(self, html: str) -> Image.Image:\n        with sync_playwright() as p:\n            browser = p.chromium.launch()\n            page = browser.new_page()\n            html_str = f\"\"\"\n            <!DOCTYPE html>\n            <html>\n                <head>\n                    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css\" integrity=\"sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib\" crossorigin=\"anonymous\">\n                    <!-- The loading of KaTeX is deferred to speed up page rendering -->\n                    <script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js\" integrity=\"sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh\" crossorigin=\"anonymous\"></script>\n                    <!-- To automatically render math in text elements, include the auto-render extension: -->\n                    <script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js\" integrity=\"sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh\" crossorigin=\"anonymous\"></script>\n                </head>\n                <body>\n                    {html}\n                        <script>\n                        document.addEventListener(\"DOMContentLoaded\", function() {{\n                            renderMathInElement(document.body, {{\n                                delimiters: [\n                                    {{left: '$$', right: '$$', display: true}},\n                                    {{left: '$', right: '$', display: false}}\n                                ],\n                                throwOnError : false\n                            }});\n                        }});\n                        </script>\n                </body>\n            </html>\n            \"\"\".strip()\n            page.set_viewport_size({\"width\": 1200, \"height\": 800})\n            page.set_content(html_str)\n            page.wait_for_load_state(\"domcontentloaded\")\n            page.wait_for_timeout(500)  # Wait for KaTeX to render\n            screenshot_bytes = page.screenshot(full_page=True)\n            browser.close()\n\n        return Image.open(io.BytesIO(screenshot_bytes))", "n_tokens": 526, "byte_len": 2233, "file_sha1": "ea2441b2c779c9735804adbfae8c72f8e6ed52f0", "start_line": 63, "end_line": 100}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/marker.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/marker.py", "rel_path": "benchmarks/overall/methods/marker.py", "module": "benchmarks.overall.methods.marker", "ext": "py", "chunk_number": 1, "symbols": ["MarkerMethod", "class", "model", "dict", "none", "parser", "tempfile", "methods", "converters", "benchmarks", "config", "from", "time", "base", "method", "import", "benchmark", "result", "pdf", "converter", "marker", "bool", "false", "overall", "use", "llm", "__call__", "services", "markdown", "rendered", "disable", "tqdm", "start", "mode", "service", "sample", "google", "vertex", "generate", "self", "suffix", "project", "redo", "inline", "return", "get", "single", "artifact", "verte", "projec"], "ast_kind": "class_or_type", "text": "import os\nimport tempfile\nimport time\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\nfrom marker.config.parser import ConfigParser\nfrom marker.converters.pdf import PdfConverter\n\n\nclass MarkerMethod(BaseMethod):\n    model_dict: dict = None\n    use_llm: bool = False\n", "n_tokens": 61, "byte_len": 287, "file_sha1": "b7afe1ad2d881ae9a6958fd69321308d722a0f5f", "start_line": 1, "end_line": 13}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/marker.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/marker.py", "rel_path": "benchmarks/overall/methods/marker.py", "module": "benchmarks.overall.methods.marker", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "services", "markdown", "rendered", "disable", "tqdm", "start", "model", "dict", "parser", "mode", "llm", "service", "sample", "google", "vertex", "tempfile", "generate", "config", "suffix", "self", "project", "redo", "inline", "return", "get", "time", "single", "artifact", "verte", "MarkerMethod", "class", "none", "methods", "converters", "benchmarks", "from", "projec", "base", "method", "this", "with", "block", "converter", "import", "benchmark", "result", "pdf", "marker", "bool"], "ast_kind": "function_or_method", "text": "    def __call__(self, sample) -> BenchmarkResult:\n        pdf_bytes = sample[\"pdf\"]  # This is a single page PDF\n        parser = ConfigParser({\n                \"page_range\": \"0\",\n                \"disable_tqdm\": True,\n                \"use_llm\": self.use_llm,\n                \"redo_inline_math\": self.use_llm,\n                \"llm_service\": \"marker.services.vertex.GoogleVertexService\",\n                \"vertex_project_id\": os.getenv(\"VERTEX_PROJECT_ID\"),\n            })\n\n        block_converter = PdfConverter(\n            artifact_dict=self.model_dict,\n            config=parser.generate_config_dict(),\n            llm_service=parser.get_llm_service()\n        )\n\n        with tempfile.NamedTemporaryFile(suffix=\".pdf\", mode=\"wb\") as f:\n            f.write(pdf_bytes)\n            start = time.time()\n            rendered = block_converter(f.name)\n            total = time.time() - start\n\n        return {\n            \"markdown\": rendered.markdown,\n            \"time\": total\n        }\n\n", "n_tokens": 204, "byte_len": 986, "file_sha1": "b7afe1ad2d881ae9a6958fd69321308d722a0f5f", "start_line": 14, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/llamaparse.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/llamaparse.py", "rel_path": "benchmarks/overall/methods/llamaparse.py", "module": "benchmarks.overall.methods.llamaparse", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "LlamaParseMethod", "find", "class", "markdown", "none", "datasets", "sample", "break", "methods", "benchmarks", "self", "from", "return", "data", "llamaparse", "time", "call", "base", "method", "could", "raise", "import", "benchmark", "result", "value", "error", "overall", "llama", "parse", "uuid", "dataset"], "ast_kind": "class_or_type", "text": "import datasets\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n\nclass LlamaParseMethod(BaseMethod):\n    llamaparse_ds: datasets.Dataset = None\n\n    def __call__(self, sample) -> BenchmarkResult:\n        uuid = sample[\"uuid\"]\n        data = None\n        for row in self.llamaparse_ds:\n            if str(row[\"uuid\"]) == str(uuid):\n                data = row\n                break\n        if not data:\n            raise ValueError(f\"Could not find data for uuid {uuid}\")\n\n        return {\n            \"markdown\": data[\"md\"],\n            \"time\": data[\"time\"]\n        }", "n_tokens": 129, "byte_len": 587, "file_sha1": "5b95753fe14e066ec0a13106f850dd4508a8d4fb", "start_line": 1, "end_line": 22}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py", "rel_path": "benchmarks/overall/methods/olmocr.py", "module": "benchmarks.overall.methods.olmocr", "ext": "py", "chunk_number": 1, "symbols": ["tempfile", "import", "time", "image", "methods", "benchmark", "result", "base", "base64", "bytes", "bytesio", "benchmarks", "torch", "method", "from", "overall", "json", "convert_single_page", "__call__", "OlmOCRMethod", "exception", "markdown", "start", "shape", "sample", "text", "output", "olm", "ocr", "user", "full", "document", "temperature", "messages", "dict", "filename", "olmocr", "model", "return", "decode", "except", "tensors", "open", "bool", "value", "tokenizer", "total", "page", "named", "temporary"], "ast_kind": "imports", "text": "import base64\nimport json\nimport tempfile\nimport time\nfrom io import BytesIO\n\nimport torch\nfrom PIL import Image\n\nfrom benchmarks.overall.methods import BaseMethod, BenchmarkResult\n\n", "n_tokens": 39, "byte_len": 182, "file_sha1": "79aa7b3e75cca36b50c476b7065fc7e25352784b", "start_line": 1, "end_line": 12}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py", "rel_path": "benchmarks/overall/methods/olmocr.py", "module": "benchmarks.overall.methods.olmocr", "ext": "py", "chunk_number": 2, "symbols": ["convert_single_page", "exception", "shape", "text", "output", "image", "user", "base", "base64", "full", "document", "temperature", "messages", "filename", "return", "decode", "except", "tensors", "open", "value", "tokenizer", "generate", "true", "render", "pdf", "prompt", "split", "anchor", "prompts", "model", "__call__", "OlmOCRMethod", "markdown", "start", "sample", "olm", "ocr", "result", "dict", "olmocr", "time", "bool", "total", "torch", "overall", "page", "named", "temporary", "call", "num"], "ast_kind": "function_or_method", "text": "def convert_single_page(filename: str, model, processor, device):\n    from olmocr.data.renderpdf import render_pdf_to_base64png\n    from olmocr.prompts import build_finetuning_prompt\n    from olmocr.prompts.anchor import get_anchor_text\n\n    image_base64 = render_pdf_to_base64png(filename, 1, target_longest_image_dim=1024)\n\n    # Build the prompt, using document metadata\n    anchor_text = get_anchor_text(filename, 1, pdf_engine=\"pdfreport\", target_length=4000)\n    prompt = build_finetuning_prompt(anchor_text)\n\n    # Build the full prompt\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": prompt},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n            ],\n        }\n    ]\n\n    # Apply the chat template and processor\n    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n\n    inputs = processor(\n        text=[text],\n        images=[main_image],\n        padding=True,\n        return_tensors=\"pt\",\n    )\n    inputs = {key: value.to(device) for (key, value) in inputs.items()}\n\n    # Generate the output\n    output = model.generate(\n        **inputs,\n        temperature=0.8,\n        max_new_tokens=8192,\n        num_return_sequences=1,\n        do_sample=True,\n    )\n\n    # Decode the output\n    prompt_length = inputs[\"input_ids\"].shape[1]\n    new_tokens = output[:, prompt_length:]\n    text_output = processor.tokenizer.batch_decode(\n        new_tokens, skip_special_tokens=True\n    )[0]\n\n    try:\n        text_output = json.loads(text_output)\n        text = text_output[\"natural_text\"]\n    except Exception:\n        try:\n            text = text_output.split(\"natural_text\")[1].strip()\n        except Exception:\n            text = \"\"\n\n    return text\n\n", "n_tokens": 439, "byte_len": 1897, "file_sha1": "79aa7b3e75cca36b50c476b7065fc7e25352784b", "start_line": 13, "end_line": 74}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/olmocr.py", "rel_path": "benchmarks/overall/methods/olmocr.py", "module": "benchmarks.overall.methods.olmocr", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "OlmOCRMethod", "class", "markdown", "start", "none", "model", "mode", "sample", "olm", "ocr", "tempfile", "suffix", "self", "device", "result", "dict", "processor", "olmocr", "return", "time", "single", "base", "method", "this", "with", "write", "bool", "benchmark", "convert", "convert_single_page", "exception", "shape", "text", "output", "image", "user", "base64", "full", "document", "temperature", "messages", "filename", "decode", "except", "tensors", "open", "value", "tokenizer", "total"], "ast_kind": "class_or_type", "text": "class OlmOCRMethod(BaseMethod):\n    olmocr_model: dict = None\n    use_llm: bool = False\n\n    def __call__(self, sample) -> BenchmarkResult:\n        pdf_bytes = sample[\"pdf\"]  # This is a single page PDF\n\n        with tempfile.NamedTemporaryFile(suffix=\".pdf\", mode=\"wb\") as f:\n            f.write(pdf_bytes)\n            start = time.time()\n            result = convert_single_page(f.name, self.olmocr_model[\"model\"], self.olmocr_model[\"processor\"], self.olmocr_model[\"model\"].device)\n            total = time.time() - start\n\n        return {\n            \"markdown\": result,\n            \"time\": total\n        }\n", "n_tokens": 147, "byte_len": 610, "file_sha1": "79aa7b3e75cca36b50c476b7065fc7e25352784b", "start_line": 75, "end_line": 92}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/schema.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/methods/schema.py", "rel_path": "benchmarks/overall/methods/schema.py", "module": "benchmarks.overall.methods.schema", "ext": "py", "chunk_number": 1, "symbols": ["BenchmarkResult", "import", "benchmark", "result", "time", "class", "markdown", "list", "none", "from", "float", "typing", "typed", "dict"], "ast_kind": "class_or_type", "text": "from typing import TypedDict, List\n\n\nclass BenchmarkResult(TypedDict):\n    markdown: str | List[str]\n    time: float | None", "n_tokens": 29, "byte_len": 123, "file_sha1": "98ea1d842261277935bc5816e6ea2b7b37a6309b", "start_line": 1, "end_line": 6}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py", "rel_path": "benchmarks/overall/scorers/clean.py", "module": "benchmarks.overall.scorers.clean", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "MarkdownCleaner", "tempfile", "import", "converter", "class", "init", "subprocess", "self", "markdown", "cleaner", "pass", "from", "pathlib", "path", "latex", "mathml", "__call__", "normalize_markdown", "standardize_math", "clean_latex", "exception", "failed", "header", "replace", "https", "back", "image", "expression", "error", "convert", "unicode", "return", "temp", "decode", "except", "staticmethod", "tags", "output", "write", "text", "normalized", "math", "content", "span", "true", "match", "call", "formatting", "latexml"], "ast_kind": "class_or_type", "text": "import re\nimport subprocess\nimport tempfile\nfrom pathlib import Path\n\nimport latex2mathml.converter\n\nclass MarkdownCleaner:\n    def __init__(self):\n        pass\n", "n_tokens": 36, "byte_len": 161, "file_sha1": "7153c3124581b3a80cb57584411326bd883a6a94", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py", "rel_path": "benchmarks/overall/scorers/clean.py", "module": "benchmarks.overall.scorers.clean", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "errors", "markdown", "urls", "header", "expressions", "remove", "formatting", "stray", "headers", "characters", "replace", "latexml", "generic", "period", "https", "content", "image", "pattern", "standardize", "math", "html", "normalize", "periods", "self", "lower", "unicode", "return", "encode", "contents", "__init__", "normalize_markdown", "standardize_math", "clean_latex", "MarkdownCleaner", "exception", "failed", "back", "expression", "error", "convert", "temp", "decode", "except", "staticmethod", "tags", "output", "converter", "write", "text"], "ast_kind": "function_or_method", "text": "    def __call__(self, markdown):\n        markdown = self.normalize_markdown(markdown)  # Use pandoc to normalize\n\n        # Replace math expressions with latexml\n        pattern = r'(?<!\\\\)\\$(?:\\$([^$]+)\\$\\$|\\s*([^$\\n]+?)\\s*\\$)'\n        markdown = re.sub(pattern, self.standardize_math, markdown)\n\n        # Replace image urls with a generic tag\n        pattern = r'!\\[(.*?)\\]\\((https?://[^\\s\\)]+)\\)'\n        markdown = re.sub(pattern, r'![link]', markdown)\n\n        # Clean up stray html tags\n        markdown = markdown.replace(\"<br>\", \"\\n\")\n        markdown = re.sub(r\"<sub>(.*?)</sub>\", r\"\\1\", markdown)\n        markdown = re.sub(r\"<sup>(.*?)</sup>\", r\"\\1\", markdown)\n        markdown = re.sub(r\"<span.*?>(.*?)</span>\", r\"\\1\", markdown)  # Remove span tags and keep content\n\n        # Clean up markdown formatting\n        markdown = re.sub(r\"\\s+\", \" \", markdown)\n        markdown = re.sub(r\"\\n+\", \"\\n\", markdown)\n        markdown = re.sub(\"\\\\.+\", \".\",\n                          markdown)  # Replace repeated periods with a single period, like in table of contents\n        markdown = re.sub(\"#+\", \"#\", markdown)  # Replace repeated headers with a single header\n        markdown = markdown.encode().decode('unicode-escape', errors=\"ignore\")  # Decode unicode characters properly\n        return markdown.strip().lower()\n", "n_tokens": 327, "byte_len": 1322, "file_sha1": "7153c3124581b3a80cb57584411326bd883a6a94", "start_line": 12, "end_line": 37}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py", "rel_path": "benchmarks/overall/scorers/clean.py", "module": "benchmarks.overall.scorers.clean", "ext": "py", "chunk_number": 3, "symbols": ["normalize_markdown", "input", "markdown", "subprocess", "check", "back", "tempfile", "html", "output", "file", "dirpath", "quiet", "return", "temp", "tmp", "dir", "staticmethod", "with", "tex", "math", "path", "temporary", "directory", "write", "text", "normalized", "pandoc", "read", "normalize", "true", "__init__", "__call__", "standardize_math", "clean_latex", "MarkdownCleaner", "exception", "failed", "header", "replace", "https", "image", "expression", "error", "convert", "unicode", "decode", "except", "tags", "converter", "pass"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def normalize_markdown(md_text: str) -> str:\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dirpath = Path(tmp_dir)\n            input_file = dirpath / 'input.md'\n            input_file.write_text(md_text, encoding='utf-8')\n\n            # Markdown to HTML\n            html_file = dirpath / 'temp.html'\n            subprocess.run(\n                [\n                    'pandoc',\n                    str(input_file),\n                    '-f', 'markdown+tex_math_dollars',\n                    '-t', 'html',\n                    '-o', str(html_file),\n                    '--quiet'\n                ],\n                check=True\n            )\n\n            # HTML to Markdown\n            output_file = dirpath / 'output.md'\n            subprocess.run(\n                [\n                    'pandoc',\n                    str(html_file),\n                    '-f', 'html',\n                    '-t', 'markdown+tex_math_dollars',\n                    '-o', str(output_file),\n                    '--quiet'\n                ],\n                check=True\n            )\n\n            # Read back the normalized Markdown\n            normalized_md = output_file.read_text(encoding='utf-8')\n\n        return normalized_md\n", "n_tokens": 236, "byte_len": 1239, "file_sha1": "7153c3124581b3a80cb57584411326bd883a6a94", "start_line": 38, "end_line": 77}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py", "rel_path": "benchmarks/overall/scorers/clean.py", "module": "benchmarks.overall.scorers.clean", "ext": "py", "chunk_number": 4, "symbols": ["standardize_math", "exception", "failed", "startswith", "standardize", "group", "else", "math", "delim", "self", "print", "expression", "error", "convert", "return", "latex", "mathml", "except", "clean", "with", "converter", "content", "match", "__init__", "__call__", "normalize_markdown", "clean_latex", "MarkdownCleaner", "markdown", "header", "replace", "https", "back", "image", "unicode", "temp", "decode", "staticmethod", "tags", "output", "write", "text", "normalized", "pass", "span", "true", "call", "subprocess", "formatting", "latexml"], "ast_kind": "function_or_method", "text": "    def standardize_math(self, match):\n        try:\n            delim = \"$$\" if match.group(0).startswith('$$') else \"$\"\n            math_content = match.group(1) or match.group(2)\n            if delim == \"$$\":\n                math_content = latex2mathml.converter.convert(math_content)\n            else:\n                math_content = self.clean_latex(math_content)\n            return f'{delim}{math_content}{delim}'\n        except Exception as e:\n            print(f\"Failed to standardize math expression: {match.group(0)} with error: {e}\")\n            return match.group(0)\n", "n_tokens": 128, "byte_len": 577, "file_sha1": "7153c3124581b3a80cb57584411326bd883a6a94", "start_line": 78, "end_line": 90}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/clean.py", "rel_path": "benchmarks/overall/scorers/clean.py", "module": "benchmarks.overall.scorers.clean", "ext": "py", "chunk_number": 5, "symbols": ["clean_latex", "latex", "str", "clean", "text", "replace", "return", "strip", "staticmethod", "rightarrow", "cdot", "replacements", "items", "mathbf", "mathrm", "times", "textbf", "__init__", "__call__", "normalize_markdown", "standardize_math", "MarkdownCleaner", "exception", "markdown", "failed", "header", "https", "back", "image", "expression", "error", "convert", "unicode", "temp", "decode", "except", "tags", "output", "converter", "write", "normalized", "pass", "math", "content", "span", "true", "match", "call", "subprocess", "formatting"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def clean_latex(latex_str):\n        latex_str = re.sub(r'\\s+', ' ', latex_str.strip())\n        for tag in [r'\\\\text', r'\\\\mathrm', r'\\\\mathbf', r'\\\\textbf']:\n            latex_str = re.sub(tag + r'\\{([^}]+)\\}', r'\\1', latex_str)\n\n        replacements = {\n            '\\\\times': '*',\n            '\\\\cdot': '*',\n            '\\\\div': '/',\n            '\\\\le': '<=',\n            '\\\\ge': '>=',\n            '\\\\neq': '!=',\n            '\\\\to': '\\\\rightarrow',\n        }\n\n        for old, new in replacements.items():\n            latex_str = latex_str.replace(old, new)\n\n        return latex_str\n\n\n\n", "n_tokens": 156, "byte_len": 611, "file_sha1": "7153c3124581b3a80cb57584411326bd883a6a94", "start_line": 91, "end_line": 114}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/__init__.py", "rel_path": "benchmarks/overall/scorers/__init__.py", "module": "benchmarks.overall.scorers.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__call__", "BaseScorer", "scorers", "markdown", "class", "init", "sample", "schema", "benchmarks", "self", "from", "not", "implemented", "list", "block", "scores", "typing", "raise", "base", "scorer", "import", "pass", "method", "overall", "call"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom benchmarks.overall.scorers.schema import BlockScores\n\n\nclass BaseScorer:\n    def __init__(self):\n        pass\n\n    def __call__(self, sample, gt_markdown: List[str], method_markdown: str) -> BlockScores:\n        raise NotImplementedError()", "n_tokens": 62, "byte_len": 269, "file_sha1": "5cb9ed1533c390ccf8ce284394111ef738434f70", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py", "rel_path": "benchmarks/overall/scorers/llm.py", "module": "benchmarks.overall.scorers.llm", "ext": "py", "chunk_number": 1, "symbols": ["tempfile", "import", "time", "image", "errors", "genai", "list", "api", "error", "from", "google", "typing", "json", "__call__", "llm_rater", "llm_response_wrapper", "LLMScorer", "identified", "elements", "markdown", "header", "compare", "based", "seconds", "text", "keys", "process", "section", "sample", "object", "small", "make", "effectively", "project", "recognized", "full", "document", "scoring", "required", "config", "responses", "temperature", "unreadable", "location", "vertexai", "assign", "client", "correct", "carefully", "properties"], "ast_kind": "imports", "text": "import json\nimport os\nimport tempfile\nimport time\nfrom typing import List\n\nfrom PIL import Image\nfrom google.genai.errors import APIError\nfrom google import genai", "n_tokens": 36, "byte_len": 162, "file_sha1": "bbb6823828c3c5d8e1dcaee3617f601d8fb438ce", "start_line": 1, "end_line": 9}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py", "rel_path": "benchmarks/overall/scorers/llm.py", "module": "benchmarks.overall.scorers.llm", "ext": "py", "chunk_number": 2, "symbols": ["identified", "elements", "markdown", "header", "compare", "based", "text", "keys", "process", "section", "small", "image", "make", "effectively", "recognized", "full", "document", "scoring", "unreadable", "assign", "correct", "carefully", "here", "description", "score", "images", "language", "than", "been", "pdfium", "__call__", "llm_rater", "llm_response_wrapper", "LLMScorer", "seconds", "sample", "object", "project", "required", "config", "responses", "temperature", "location", "vertexai", "client", "properties", "return", "missing", "time", "except"], "ast_kind": "imports", "text": "import pypdfium2 as pdfium\n\nfrom benchmarks.overall.scorers import BaseScorer, BlockScores\nfrom marker.settings import settings\n\nrating_prompt = \"\"\"\nYou're a document analysis expert who is comparing some markdown to an image to make sure the markdown is correct. You're rating how effectively the provided markdown represents the full text and formatting in the image provided.\nYou're given an image, along with the extracted markdown:\n- Some parts of the page may have been recognized as images and linked from the markdown, like `![](_page_0_Picture_0.jpeg)`.\n- Tables will be formatted as Github flavored markdown.\n- Block equations will be in LaTeX.\n- The image and markdown may be in any language.\n- The markdown is based on the text extracted from the document, and sometimes the document may have had bad OCR applied to it, resulting in gibberish text.\n\nThe markdown should fully capture the meaning and formatting of the text in the image. You'll evaluate the markdown based on the image provided.\n\n**Instructions**\nFollow this process to evaluate the markdown:\n1. Carefully examine the image.\n2. Carefully examine the markdown input provided.\n3. Compare the image to the markdown representation.  Does the markdown representation properly represent the important text and formatting in the image?\n4. Assign component scores, as described below.\n\nThese are the primary scores:\n- Overall - the overall quality of the markdown as compared to the image.\n- Text quality - the quality of the text extraction from the image.\n- Formatting quality - the quality of the formatting applied to the markdown, as compared to the image.\n\nDepending on which elements are present in the markdown, you will assign element-specific scores.\n- Tables - how effectively the tables have been extracted and formatted.\n- Forms - how effectively the forms have extracted and formatted.\n- Equations - how effectively block equations have been converted to LaTeX.\n- Section headers - if all of the section headers have been detected, and the right levels set.\n- Lists - if the lists have been properly extracted and formatted.\n- Images - if images are identified and placed correctly.\n\nNotes on scoring:\n- To get a 5/5, all of the important text from the image must appear in the markdown, and the formatting should be correct (minor mistakes okay).  It's okay to omit some text that isn't important to the meaning, like page numbers and chapter headings.  If the entire page is an image, it's okay if the markdown is just a link to the image, unless the image would be better represented as text.\n- A 3/5 may have small missing text elements from the markdown and/or moderate formatting issues.\n- A 1/5 will have major missing text segments from the markdown or completely unreadable formatting.\n- Use 0/5 if a field isn't applicable, like if the image doesn't contain a table.\n\nIf text that is important to the meaning of the document is missing, do not score higher than 3/5.\n\nOutput json, like in the example below.\n\n**Example**\nInput\n```markdown\n# Section 1\nThis is some *markdown* extracted from a document.  Here is a block equation:\n$$\\frac{ab \\cdot x^5 + x^2 + 2 \\cdot x + 123}{t}$$\n```\nOutput\n```json\n{\n    \"image_description\": \"In the image, there is a section header 'Section 1', followed by some text and a block equation.\",\n    \"markdown_description\": \"In the markdown, there is a section header 'Section 1', followed by some text and a block equation.\",\n    \"comparison\": \"The text and formatting matches the image.  There are no formatting or text extraction issues.  The equations and section headers are correct.\",\n    \"overall\": 5,\n    \"text\": 5,\n    \"formatting\": 5,\n    \"section_headers\": 5,\n\t\"tables\": 0,\n\t\"forms\": 0,\n    \"equations\": 5,\n\t\"lists\": 0,\n\t\"images\": 0\n}\n```\n**Input**\n```markdown\n{{markdown}}\n```\n**Output**\n\"\"\"\n\ncomparison_keys = [\"comparison\"]\ndescription_keys = [\"image_description\", \"markdown_description\"]\ntext_keys = comparison_keys + description_keys\nscore_keys = [\"overall\", \"text\", \"formatting\", \"section_headers\", \"tables\", \"forms\", \"equations\",\n            \"lists\", \"images\"]\n\n", "n_tokens": 923, "byte_len": 4104, "file_sha1": "bbb6823828c3c5d8e1dcaee3617f601d8fb438ce", "start_line": 10, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py", "rel_path": "benchmarks/overall/scorers/llm.py", "module": "benchmarks.overall.scorers.llm", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "LLMScorer", "markdown", "class", "scale", "sample", "llm", "rater", "tempfile", "suffix", "self", "return", "render", "list", "block", "scores", "flush", "scorer", "pdfium", "pil", "with", "base", "close", "pdf", "document", "write", "seek", "bytes", "named", "temporary", "llm_rater", "llm_response_wrapper", "identified", "elements", "header", "compare", "based", "seconds", "text", "keys", "process", "section", "object", "small", "image", "make", "effectively", "project", "recognized", "full"], "ast_kind": "class_or_type", "text": "class LLMScorer(BaseScorer):\n    def __call__(self, sample, gt_markdown: List[str], markdown: str) -> BlockScores:\n        pdf_bytes = sample[\"pdf\"]\n        with tempfile.NamedTemporaryFile(suffix=\".pdf\") as f:\n            f.write(pdf_bytes)\n            f.flush()\n            f.seek(0)\n            doc = pdfium.PdfDocument(f.name)\n            img = doc[0].render(scale=96/72).to_pil()\n            doc.close()\n\n        return self.llm_rater(img, markdown)\n\n", "n_tokens": 114, "byte_len": 456, "file_sha1": "bbb6823828c3c5d8e1dcaee3617f601d8fb438ce", "start_line": 94, "end_line": 107}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py", "rel_path": "benchmarks/overall/scorers/llm.py", "module": "benchmarks.overall.scorers.llm", "ext": "py", "chunk_number": 4, "symbols": ["llm_rater", "image", "prompt", "integer", "markdown", "assert", "text", "keys", "response", "schema", "llm", "object", "rater", "else", "content", "type", "required", "self", "string", "properties", "return", "missing", "score", "block", "scores", "replace", "specific", "update", "rating", "overall", "__call__", "llm_response_wrapper", "LLMScorer", "identified", "elements", "header", "compare", "based", "seconds", "process", "section", "sample", "small", "make", "effectively", "project", "recognized", "full", "document", "scoring"], "ast_kind": "function_or_method", "text": "    def llm_rater(self, img: Image.Image, markdown: str) -> BlockScores:\n        if not markdown:\n            null_scores = {k: 1 for k in score_keys}\n            text_scores = {k: \"\" for k in text_keys}\n            null_scores.update(text_scores)\n            return {\n                \"score\": 1,\n                \"specific_scores\": null_scores\n            }\n        req_keys = text_keys + score_keys\n        properties = {}\n        for key in req_keys:\n            content_type = \"INTEGER\" if key in score_keys else \"STRING\"\n            properties[key] = {\"type\": content_type}\n\n        response_schema = {\n            \"required\": req_keys,\n            \"properties\": properties,\n            \"type\": \"OBJECT\"\n        }\n        prompt = rating_prompt.replace(\"{{markdown}}\", markdown)\n        response = self.llm_response_wrapper([img, prompt], response_schema)\n        assert all([k in response for k in req_keys]), f\"Missing keys in response: {response}\"\n        return {\n            \"score\": response[\"overall\"],\n            \"specific_scores\": response,\n        }\n", "n_tokens": 229, "byte_len": 1065, "file_sha1": "bbb6823828c3c5d8e1dcaee3617f601d8fb438ce", "start_line": 108, "end_line": 135}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/llm.py", "rel_path": "benchmarks/overall/scorers/llm.py", "module": "benchmarks.overall.scorers.llm", "ext": "py", "chunk_number": 5, "symbols": ["llm_response_wrapper", "client", "prompt", "verte", "location", "text", "response", "schema", "model", "gemini", "timeout", "llm", "content", "project", "self", "config", "responses", "generate", "temperature", "candidates", "print", "vertexai", "waiting", "return", "contents", "time", "except", "genai", "projec", "flash", "__call__", "llm_rater", "LLMScorer", "identified", "elements", "markdown", "header", "compare", "based", "seconds", "keys", "process", "section", "sample", "object", "small", "image", "make", "effectively", "recognized"], "ast_kind": "function_or_method", "text": "    def llm_response_wrapper(self, prompt, response_schema, depth=0):\n        client = genai.Client(\n            http_options={\"timeout\": 60000},\n            vertexai=True,\n            project=os.getenv(\"VERTEX_PROJECT_ID\"),\n            location=os.getenv(\"VERTEX_LOCATION\"),\n        )\n        try:\n            responses = client.models.generate_content(\n                model=\"gemini-2.0-flash-001\",\n                contents=prompt,\n                config={\n                    \"temperature\": 0,\n                    \"response_schema\": response_schema,\n                    \"response_mime_type\": \"application/json\",\n                },\n            )\n            output = responses.candidates[0].content.parts[0].text\n            return json.loads(output)\n        except APIError as e:\n            print(f\"Hit Gemini rate limit, waiting 120 seconds\")\n            time.sleep(120)\n            if depth > 2:\n                raise e\n            return self.llm_response_wrapper(prompt, response_schema, depth + 1)", "n_tokens": 196, "byte_len": 1006, "file_sha1": "bbb6823828c3c5d8e1dcaee3617f601d8fb438ce", "start_line": 136, "end_line": 160}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/schema.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/schema.py", "rel_path": "benchmarks/overall/scorers/schema.py", "module": "benchmarks.overall.scorers.schema", "ext": "py", "chunk_number": 1, "symbols": ["BlockScores", "import", "class", "list", "block", "scores", "from", "float", "specific", "typing", "score", "typed", "dict", "optional"], "ast_kind": "class_or_type", "text": "from typing import TypedDict, List, Optional, Dict\n\n\nclass BlockScores(TypedDict):\n    score: float\n    specific_scores: Dict[str, float | List[float]]\n", "n_tokens": 36, "byte_len": 152, "file_sha1": "18daa09dd51ba2ee010ad3b61322732a52c5cb10", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py", "rel_path": "benchmarks/overall/scorers/heuristic.py", "module": "benchmarks.overall.scorers.heuristic", "ext": "py", "chunk_number": 1, "symbols": ["HeuristicScorer", "scorers", "rapidfuzz", "import", "class", "list", "block", "scores", "schema", "benchmarks", "markdown", "cleaner", "from", "overall", "fuzz", "typing", "heuristic", "scorer", "base", "clean", "__call__", "kendall_tau", "find_fuzzy_alignments", "clean_input", "elif", "dest", "end", "start", "concordant", "discordant", "float", "scale", "sample", "range", "substrings", "order", "score", "find", "actual", "correct", "sign", "append", "self", "result", "standardize", "dict", "substr", "input", "return", "weight"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom rapidfuzz import fuzz\n\nfrom benchmarks.overall.scorers.clean import MarkdownCleaner\nfrom benchmarks.overall.scorers.schema import BlockScores\nfrom benchmarks.overall.scorers import BaseScorer\n\n\nclass HeuristicScorer(BaseScorer):", "n_tokens": 58, "byte_len": 258, "file_sha1": "195b8d80f4897b9744b6251119818e6958430493", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py", "rel_path": "benchmarks/overall/scorers/heuristic.py", "module": "benchmarks.overall.scorers.heuristic", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "markdown", "start", "sample", "range", "order", "score", "find", "actual", "self", "scores", "standardize", "overall", "clean", "input", "return", "weight", "sorted", "alignments", "fuzzy", "inputs", "length", "kendall", "tau", "list", "block", "specific", "weights", "alignment", "lambda", "kendall_tau", "find_fuzzy_alignments", "clean_input", "HeuristicScorer", "scorers", "elif", "dest", "end", "class", "concordant", "discordant", "float", "scale", "substrings", "correct", "sign", "append", "schema", "benchmarks", "result"], "ast_kind": "function_or_method", "text": "    def __call__(self, sample, gt_markdown: List[str], method_markdown: str) -> BlockScores:\n        if not method_markdown:\n            return {\n                \"score\": 0,\n                \"specific_scores\": {\n                    \"order\": 0,\n                    \"by_block\": [0] * len(gt_markdown)\n                }\n            }\n\n        # Standardize inputs\n        gt_markdown = [self.clean_input(block) for block in gt_markdown]\n        method_markdown = self.clean_input(method_markdown)\n\n        alignments = self.find_fuzzy_alignments(method_markdown, gt_markdown)\n        scores = [alignment[\"score\"] for alignment in alignments]\n\n        # Find order score\n        orders = [alignment[\"start\"] for alignment in alignments]\n        correct_order = list(range(len(gt_markdown)))\n        actual_order = sorted(range(len(gt_markdown)), key=lambda x: orders[x])\n        order_score = self.kendall_tau(correct_order, actual_order)\n\n        # Weight score by sequence length\n        gt_weights = [len(g) for g in gt_markdown]\n        weighted_scores = [score * weight for score, weight in zip(scores, gt_weights)]\n\n        # Weight the score by sequence length\n        overall_score = sum(weighted_scores) / max(1, sum(gt_weights))\n        overall_score = overall_score * 0.8 + order_score * 0.2\n        return {\n            \"score\": overall_score,\n            \"specific_scores\": {\n                \"order\": order_score,\n                \"by_block\": scores\n            },\n        }\n", "n_tokens": 326, "byte_len": 1482, "file_sha1": "195b8d80f4897b9744b6251119818e6958430493", "start_line": 11, "end_line": 48}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py", "rel_path": "benchmarks/overall/scorers/heuristic.py", "module": "benchmarks.overall.scorers.heuristic", "ext": "py", "chunk_number": 3, "symbols": ["kendall_tau", "concordant", "elif", "actual", "order", "kendall", "tau", "list", "correct", "sign", "discordant", "total", "pairs", "staticmethod", "float", "scale", "range", "return", "__call__", "find_fuzzy_alignments", "clean_input", "HeuristicScorer", "scorers", "markdown", "dest", "end", "class", "start", "sample", "substrings", "score", "find", "append", "schema", "benchmarks", "self", "result", "from", "standardize", "scores", "overall", "dict", "substr", "clean", "input", "weight", "sorted", "alignments", "rapidfuzz", "fuzzy"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def kendall_tau(correct_order: List[int], actual_order: List[int]) -> float:\n        n = len(correct_order)\n        concordant = 0\n        discordant = 0\n\n        if n <= 1:\n            return 100\n\n        for i in range(n):\n            for j in range(i + 1, n):\n                correct_sign = correct_order[i] - correct_order[j]\n                actual_sign = actual_order[i] - actual_order[j]\n\n                if (correct_sign > 0 and actual_sign > 0) or (correct_sign < 0 and actual_sign < 0):\n                    concordant += 1\n                elif (correct_sign < 0 and actual_sign > 0) or (correct_sign > 0 and actual_sign < 0):\n                    discordant += 1\n\n        total_pairs = (n * (n - 1)) // 2\n        tau = (concordant - discordant) / total_pairs\n        tau = (tau + 1) / 2 # 0-1 scale\n        return tau * 100 # 0-100 scale\n", "n_tokens": 240, "byte_len": 868, "file_sha1": "195b8d80f4897b9744b6251119818e6958430493", "start_line": 49, "end_line": 72}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/scorers/heuristic.py", "rel_path": "benchmarks/overall/scorers/heuristic.py", "module": "benchmarks.overall.scorers.heuristic", "ext": "py", "chunk_number": 4, "symbols": ["find_fuzzy_alignments", "clean_input", "dest", "end", "start", "substrings", "append", "result", "substr", "dict", "clean", "input", "return", "find", "fuzzy", "alignments", "list", "cleaner", "main", "string", "staticmethod", "enumerate", "partial", "ratio", "markdown", "score", "cutoff", "fuzz", "threshold", "__call__", "kendall_tau", "HeuristicScorer", "scorers", "elif", "class", "concordant", "discordant", "float", "scale", "sample", "range", "order", "actual", "correct", "sign", "schema", "benchmarks", "self", "from", "standardize"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def find_fuzzy_alignments(\n            main_string: str,\n            substrings: List[str],\n            threshold: int = 70\n    ) -> List[dict]:\n        alignments = []\n\n        for idx, substr in enumerate(substrings):\n            result = fuzz.partial_ratio_alignment(substr, main_string, score_cutoff=threshold)\n\n            score = 0\n            dest_start = 0\n            dest_end = 0\n            if result:\n                score = result.score\n                dest_start = result.dest_start\n                dest_end = result.dest_end\n\n            alignments.append({\n                \"string\": substr,\n                \"start\": dest_start,\n                \"end\": dest_end,\n                \"score\": score,\n                \"idx\": idx\n            })\n        return alignments\n\n\n    @staticmethod\n    def clean_input(md: str):\n        cleaner = MarkdownCleaner()\n        return cleaner(md)", "n_tokens": 183, "byte_len": 911, "file_sha1": "195b8d80f4897b9744b6251119818e6958430493", "start_line": 73, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mistral.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mistral.py", "rel_path": "benchmarks/overall/download/mistral.py", "module": "benchmarks.overall.download.mistral", "ext": "py", "chunk_number": 1, "symbols": ["get_html", "MistralDownloader", "download", "class", "start", "api", "key", "base", "rand", "name", "bytes", "get", "html", "benchmarks", "self", "from", "return", "mistral", "buff", "decode", "time", "downloader", "bytesio", "upload", "and", "import", "isinstance", "service", "pdf", "overall", "upload_and_process_file", "latest", "expiry", "markdown", "none", "file", "url", "response", "headers", "model", "https", "authorization", "purpose", "document", "content", "result", "signed", "bearer", "ocr", "files"], "ast_kind": "class_or_type", "text": "import io\nimport time\nimport requests\n\nfrom benchmarks.overall.download.base import Downloader\n\n\nclass MistralDownloader(Downloader):\n    service = \"mistral\"\n\n    def get_html(self, pdf_bytes):\n        rand_name = str(time.time()) + \".pdf\"\n        start = time.time()\n        buff = io.BytesIO(pdf_bytes)\n        md = upload_and_process_file(self.api_key, rand_name, buff)\n        end = time.time()\n        if isinstance(md, bytes):\n            md = md.decode(\"utf-8\")\n\n        return {\n            \"md\": md,\n            \"time\": end - start,\n        }\n\n", "n_tokens": 127, "byte_len": 553, "file_sha1": "fbdd54f42ac840cd4f7f371d4c86bdc0ca1ea6e9", "start_line": 1, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mistral.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mistral.py", "rel_path": "benchmarks/overall/download/mistral.py", "module": "benchmarks.overall.download.mistral", "ext": "py", "chunk_number": 2, "symbols": ["upload_and_process_file", "latest", "expiry", "markdown", "api", "key", "none", "file", "url", "response", "model", "headers", "https", "upload", "authorization", "purpose", "document", "content", "result", "return", "signed", "mistral", "bearer", "buff", "and", "ocr", "files", "copy", "fname", "type", "get_html", "MistralDownloader", "download", "class", "start", "base", "rand", "name", "bytes", "get", "html", "benchmarks", "self", "from", "decode", "time", "downloader", "bytesio", "json", "pages"], "ast_kind": "function_or_method", "text": "def upload_and_process_file(api_key: str, fname: str, buff):\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\"\n    }\n\n    upload_headers = headers.copy()\n    files = {\n        'file': (fname, buff, 'application/pdf'),\n        'purpose': (None, 'ocr')\n    }\n\n    upload_response = requests.post(\n        'https://api.mistral.ai/v1/files',\n        headers=upload_headers,\n        files=files\n    )\n    upload_response.raise_for_status()\n    file_id = upload_response.json()['id']\n\n    url_headers = headers.copy()\n    url_headers[\"Accept\"] = \"application/json\"\n\n    url_response = requests.get(\n        f'https://api.mistral.ai/v1/files/{file_id}/url?expiry=24',\n        headers=url_headers\n    )\n    url_response.raise_for_status()\n    signed_url = url_response.json()['url']\n\n    ocr_headers = headers.copy()\n    ocr_headers[\"Content-Type\"] = \"application/json\"\n\n    ocr_data = {\n        \"model\": \"mistral-ocr-latest\",\n        \"document\": {\n            \"type\": \"document_url\",\n            \"document_url\": signed_url\n        },\n        \"include_image_base64\": True\n    }\n    ocr_response = requests.post(\n        'https://api.mistral.ai/v1/ocr',\n        headers=ocr_headers,\n        json=ocr_data\n    )\n    ocr_response.raise_for_status()\n    result = ocr_response.json()\n    return result[\"pages\"][0][\"markdown\"]", "n_tokens": 325, "byte_len": 1323, "file_sha1": "fbdd54f42ac840cd4f7f371d4c86bdc0ca1ea6e9", "start_line": 26, "end_line": 73}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py", "rel_path": "benchmarks/overall/download/mathpix.py", "module": "benchmarks.overall.download.mathpix", "ext": "py", "chunk_number": 1, "symbols": ["get_html", "MathpixDownloader", "download", "class", "api", "key", "start", "base", "headers", "bytes", "else", "get", "html", "mathpix", "downloader", "status", "benchmarks", "self", "from", "error", "app", "request", "return", "decode", "time", "json", "pdf", "results", "import", "isinstance", "mathpix_request", "mathpix_status", "mathpix_results", "elif", "conversion", "https", "options", "break", "completed", "content", "buffer", "while", "resp", "max", "iters", "data", "out", "file", "status2", "dumps"], "ast_kind": "class_or_type", "text": "import json\nimport time\n\nimport requests\n\nfrom benchmarks.overall.download.base import Downloader\n\n\nclass MathpixDownloader(Downloader):\n    service = \"mathpix\"\n\n    def get_html(self, pdf_bytes):\n        headers = {\n            \"app_id\": self.app_id,\n            \"app_key\": self.api_key,\n        }\n        start = time.time()\n        pdf_id = mathpix_request(pdf_bytes, headers)\n        status = mathpix_status(pdf_id, headers)\n        if status in [\"processing\", \"error\"]:\n            md = \"\"\n        else:\n            md = mathpix_results(pdf_id, headers)\n        end = time.time()\n        if isinstance(md, bytes):\n            md = md.decode(\"utf-8\")\n\n        return {\n            \"md\": md,\n            \"time\": end - start\n        }\n", "n_tokens": 165, "byte_len": 737, "file_sha1": "feb5f9af68a054ec7daf093070099eecf478f75f", "start_line": 1, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py", "rel_path": "benchmarks/overall/download/mathpix.py", "module": "benchmarks.overall.download.mathpix", "ext": "py", "chunk_number": 2, "symbols": ["mathpix_request", "headers", "https", "options", "json", "html", "buffer", "mathpix", "request", "return", "data", "file", "dumps", "files", "pdf", "conversion", "formats", "post", "true", "requests", "response", "get_html", "mathpix_status", "mathpix_results", "MathpixDownloader", "download", "elif", "class", "status", "api", "key", "start", "base", "break", "completed", "content", "bytes", "else", "get", "downloader", "benchmarks", "self", "while", "from", "error", "resp", "app", "max", "iters", "decode"], "ast_kind": "function_or_method", "text": "def mathpix_request(buffer, headers):\n    response = requests.post(\"https://api.mathpix.com/v3/pdf\",\n        headers=headers,\n        data={\n            \"options_json\": json.dumps(\n                {\n                    \"conversion_formats\": {\n                        \"md\": True,\n                        \"html\": True\n                    }\n                }\n            )\n        },\n        files={\n            \"file\": buffer\n        }\n    )\n    data = response.json()\n    pdf_id = data[\"pdf_id\"]\n    return pdf_id\n", "n_tokens": 100, "byte_len": 513, "file_sha1": "feb5f9af68a054ec7daf093070099eecf478f75f", "start_line": 33, "end_line": 53}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py", "rel_path": "benchmarks/overall/download/mathpix.py", "module": "benchmarks.overall.download.mathpix", "ext": "py", "chunk_number": 3, "symbols": ["mathpix_status", "elif", "conversion", "status", "headers", "https", "break", "completed", "else", "html", "mathpix", "while", "error", "resp", "max", "iters", "return", "out", "time", "status2", "json", "pdf", "continue", "converter", "sleep", "processing", "requests", "response", "get_html", "mathpix_request", "mathpix_results", "MathpixDownloader", "download", "class", "api", "key", "start", "base", "options", "content", "bytes", "get", "downloader", "buffer", "benchmarks", "self", "from", "app", "request", "decode"], "ast_kind": "function_or_method", "text": "def mathpix_status(pdf_id, headers):\n    max_iters = 120\n    i = 0\n    status = \"processing\"\n    status2 = \"processing\"\n    while i < max_iters:\n        time.sleep(1)\n        response = requests.get(f\"https://api.mathpix.com/v3/converter/{pdf_id}\",\n            headers=headers\n        )\n        status_resp = response.json()\n        if \"conversion_status\" not in status_resp:\n            continue\n        status = status_resp[\"conversion_status\"][\"md\"][\"status\"]\n        status2 = status_resp[\"conversion_status\"][\"html\"][\"status\"]\n        if status == \"completed\" and status2 == \"completed\":\n            break\n        elif status == \"error\" or status2 == \"error\":\n            break\n    out_status = \"completed\" if status == \"completed\" and status2 == \"completed\" else \"error\"\n    return out_status\n", "n_tokens": 185, "byte_len": 799, "file_sha1": "feb5f9af68a054ec7daf093070099eecf478f75f", "start_line": 54, "end_line": 75}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/mathpix.py", "rel_path": "benchmarks/overall/download/mathpix.py", "module": "benchmarks.overall.download.mathpix", "ext": "py", "chunk_number": 4, "symbols": ["mathpix_results", "mathpix", "results", "converter", "content", "headers", "pdf", "https", "return", "requests", "response", "get_html", "mathpix_request", "mathpix_status", "MathpixDownloader", "download", "elif", "class", "conversion", "status", "api", "key", "start", "base", "options", "json", "break", "completed", "bytes", "else", "html", "get", "downloader", "buffer", "benchmarks", "self", "while", "from", "error", "resp", "app", "max", "iters", "request", "decode", "data", "out", "time", "file", "status2"], "ast_kind": "function_or_method", "text": "def mathpix_results(pdf_id, headers, ext=\"md\"):\n    response = requests.get(f\"https://api.mathpix.com/v3/converter/{pdf_id}.{ext}\",\n        headers=headers\n    )\n    return response.content\n", "n_tokens": 46, "byte_len": 190, "file_sha1": "feb5f9af68a054ec7daf093070099eecf478f75f", "start_line": 76, "end_line": 81}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/llamaparse.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/llamaparse.py", "rel_path": "benchmarks/overall/download/llamaparse.py", "module": "benchmarks.overall.download.llamaparse", "ext": "py", "chunk_number": 1, "symbols": ["get_html", "LlamaParseDownloader", "download", "class", "start", "api", "key", "base", "rand", "name", "bytes", "get", "html", "benchmarks", "self", "from", "llama", "parse", "upload", "and", "return", "decode", "buff", "time", "bytesio", "llamaparse", "import", "isinstance", "service", "pdf", "upload_and_parse_file", "results", "result", "response", "markdown", "success", "complete", "headers", "https", "llamaindex", "parsing", "range", "authorization", "attempts", "status", "cloud", "retry", "bearer", "timeout", "error"], "ast_kind": "class_or_type", "text": "import io\nimport time\n\nimport requests\n\nfrom benchmarks.overall.download.base import Downloader\n\n\nclass LlamaParseDownloader(Downloader):\n    service = \"llamaparse\"\n\n    def get_html(self, pdf_bytes):\n        rand_name = str(time.time()) + \".pdf\"\n        start = time.time()\n        buff = io.BytesIO(pdf_bytes)\n        md = upload_and_parse_file(self.api_key, rand_name, buff)\n        end = time.time()\n        if isinstance(md, bytes):\n            md = md.decode(\"utf-8\")\n\n        return {\n            \"md\": md,\n            \"time\": end - start,\n        }\n\n", "n_tokens": 130, "byte_len": 558, "file_sha1": "d6d9509d58d5c1e87b7703dfa9c5b8ce23ba357c", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/llamaparse.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/llamaparse.py", "rel_path": "benchmarks/overall/download/llamaparse.py", "module": "benchmarks.overall.download.llamaparse", "ext": "py", "chunk_number": 2, "symbols": ["upload_and_parse_file", "results", "result", "response", "markdown", "complete", "success", "api", "key", "headers", "https", "llamaindex", "range", "parsing", "authorization", "attempts", "status", "cloud", "retry", "upload", "and", "return", "bearer", "buff", "timeout", "error", "within", "delay", "file", "time", "get_html", "LlamaParseDownloader", "download", "class", "start", "base", "rand", "name", "bytes", "get", "html", "benchmarks", "self", "from", "llama", "parse", "decode", "maximum", "bytesio", "completion"], "ast_kind": "function_or_method", "text": "def upload_and_parse_file(api_key: str, fname: str, buff, max_retries: int = 180, delay: int = 1):\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Accept\": \"application/json\"\n    }\n\n    # Upload file\n    files = {\n        'file': (fname, buff, 'application/pdf')\n    }\n    response = requests.post(\n        'https://api.cloud.llamaindex.ai/api/v1/parsing/upload',\n        headers=headers,\n        files=files\n    )\n    response.raise_for_status()\n    job_id = response.json()['id']\n\n    # Poll for completion\n    for _ in range(max_retries):\n        status_response = requests.get(\n            f'https://api.cloud.llamaindex.ai/api/v1/parsing/job/{job_id}',\n            headers=headers\n        )\n        status_response.raise_for_status()\n        if status_response.json()['status'] == 'SUCCESS':\n            # Get results\n            result_response = requests.get(\n                f'https://api.cloud.llamaindex.ai/api/v1/parsing/job/{job_id}/result/markdown',\n                headers=headers\n            )\n            result_response.raise_for_status()\n            return result_response.json()['markdown']\n\n        time.sleep(delay)\n\n    raise TimeoutError(\"Job did not complete within the maximum retry attempts\")", "n_tokens": 277, "byte_len": 1241, "file_sha1": "d6d9509d58d5c1e87b7703dfa9c5b8ce23ba357c", "start_line": 27, "end_line": 63}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/main.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/main.py", "rel_path": "benchmarks/overall/download/main.py", "module": "benchmarks.overall.download.main", "ext": "py", "chunk_number": 1, "symbols": ["download", "import", "mathpix", "downloader", "mistral", "benchmarks", "click", "from", "overall", "llamaparse", "llama", "parse", "main", "services", "api", "key", "none", "argument", "default", "choice", "name", "app", "inference", "data", "max", "rows", "upload", "type", "service", "registry", "option", "generate", "command"], "ast_kind": "imports", "text": "import click\n\nfrom benchmarks.overall.download.llamaparse import LlamaParseDownloader\nfrom benchmarks.overall.download.mathpix import MathpixDownloader\nfrom benchmarks.overall.download.mistral import MistralDownloader\n\n", "n_tokens": 43, "byte_len": 219, "file_sha1": "1aee702c3b623184dc5dd7be592fc1b2919b9ac9", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/main.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/main.py", "rel_path": "benchmarks/overall/download/main.py", "module": "benchmarks.overall.download.main", "ext": "py", "chunk_number": 2, "symbols": ["main", "services", "api", "key", "none", "argument", "click", "download", "default", "mathpix", "downloader", "from", "choice", "name", "app", "inference", "llama", "parse", "mistral", "data", "llamaparse", "upload", "type", "command", "service", "registry", "option", "generate", "max", "rows", "benchmarks", "import", "overall"], "ast_kind": "function_or_method", "text": "@click.command(\"Download data from inference services\")\n@click.argument(\"service\", type=click.Choice([\"mathpix\", \"llamaparse\", \"mistral\"]))\n@click.option(\"--max_rows\", type=int, default=2200)\n@click.option(\"--api_key\", type=str, default=None)\n@click.option(\"--app_id\", type=str, default=None)\ndef main(service: str, max_rows: int, api_key: str, app_id: str):\n    registry = {\n        \"mathpix\": MathpixDownloader,\n        \"llamaparse\": LlamaParseDownloader,\n        \"mistral\": MistralDownloader,\n    }\n    downloader = registry[service](api_key, app_id, max_rows=max_rows)\n\n    # Generate data and upload to hub\n    downloader()\n\nif __name__ == \"__main__\":\n    main()\n", "n_tokens": 169, "byte_len": 668, "file_sha1": "1aee702c3b623184dc5dd7be592fc1b2919b9ac9", "start_line": 8, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py", "rel_path": "benchmarks/overall/download/base.py", "module": "benchmarks.overall.download.base", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "get_html", "Downloader", "split", "class", "cache", "path", "init", "api", "key", "datasets", "pathlib", "marker", "benchmark", "get", "html", "self", "from", "app", "exist", "not", "implemented", "json", "decode", "datalab", "mkdir", "load", "dataset", "raise", "import", "upload_ds", "generate_data", "__call__", "exception", "features", "results", "list", "desc", "float", "exists", "sample", "break", "out", "data", "private", "saving", "append", "print", "glob", "dump"], "ast_kind": "class_or_type", "text": "import json\nfrom json import JSONDecodeError\nfrom pathlib import Path\n\nimport datasets\nfrom tqdm import tqdm\n\n\nclass Downloader:\n    cache_path: Path = Path(\"cache\")\n    service: str\n\n    def __init__(self, api_key, app_id, max_rows: int = 2200):\n        self.cache_path.mkdir(exist_ok=True)\n        self.max_rows = max_rows\n        self.api_key = api_key\n        self.app_id = app_id\n        self.ds = datasets.load_dataset(\"datalab-to/marker_benchmark\", split=\"train\")\n\n    def get_html(self, pdf_bytes):\n        raise NotImplementedError\n", "n_tokens": 131, "byte_len": 541, "file_sha1": "934537a8117107d47f242a89a16ac5e8047e0a8f", "start_line": 1, "end_line": 22}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py", "rel_path": "benchmarks/overall/download/base.py", "module": "benchmarks.overall.download.base", "ext": "py", "chunk_number": 2, "symbols": ["upload_ds", "features", "cache", "path", "from", "list", "datasets", "float", "private", "out", "append", "marker", "benchmark", "self", "glob", "data", "upload", "file", "time", "datalab", "rows", "json", "open", "with", "value", "string", "service", "true", "load", "push", "__init__", "get_html", "generate_data", "__call__", "Downloader", "exception", "results", "split", "class", "init", "api", "key", "desc", "pathlib", "exists", "sample", "break", "get", "html", "saving"], "ast_kind": "function_or_method", "text": "    def upload_ds(self):\n        rows = []\n        for file in self.cache_path.glob(\"*.json\"):\n            with open(file, \"r\") as f:\n                data = json.load(f)\n            rows.append(data)\n\n        out_ds = datasets.Dataset.from_list(rows, features=datasets.Features({\n            \"md\": datasets.Value(\"string\"),\n            \"uuid\": datasets.Value(\"string\"),\n            \"time\": datasets.Value(\"float\"),\n        }))\n        out_ds.push_to_hub(f\"datalab-to/marker_benchmark_{self.service}\", private=True)\n", "n_tokens": 111, "byte_len": 515, "file_sha1": "934537a8117107d47f242a89a16ac5e8047e0a8f", "start_line": 23, "end_line": 36}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/download/base.py", "rel_path": "benchmarks/overall/download/base.py", "module": "benchmarks.overall.download.base", "ext": "py", "chunk_number": 3, "symbols": ["generate_data", "__call__", "exception", "results", "cache", "path", "desc", "exists", "sample", "break", "out", "data", "get", "html", "saving", "self", "print", "dump", "upload", "json", "decode", "except", "call", "single", "this", "enumerate", "error", "with", "open", "file", "__init__", "get_html", "upload_ds", "Downloader", "features", "split", "class", "init", "api", "key", "from", "list", "datasets", "float", "pathlib", "private", "marker", "benchmark", "append", "glob"], "ast_kind": "function_or_method", "text": "    def generate_data(self):\n        max_rows = self.max_rows\n        for idx, sample in tqdm(enumerate(self.ds), desc=f\"Saving {self.service} results\"):\n            cache_file = self.cache_path / f\"{idx}.json\"\n            if cache_file.exists():\n                continue\n\n            pdf_bytes = sample[\"pdf\"]  # This is a single page PDF\n            try:\n                out_data = self.get_html(pdf_bytes)\n            except JSONDecodeError as e:\n                print(f\"Error with sample {idx}: {e}\")\n                continue\n            except Exception as e:\n                print(f\"Error with sample {idx}: {e}\")\n                continue\n            out_data[\"uuid\"] = sample[\"uuid\"]\n\n            with cache_file.open(\"w\") as f:\n                json.dump(out_data, f)\n\n            if idx >= max_rows:\n                break\n\n    def __call__(self):\n        self.generate_data()\n        self.upload_ds()\n", "n_tokens": 192, "byte_len": 909, "file_sha1": "934537a8117107d47f242a89a16ac5e8047e0a8f", "start_line": 37, "end_line": 64}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/dataset.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/dataset.py", "rel_path": "benchmarks/overall/display/dataset.py", "module": "benchmarks.overall.display.dataset", "ext": "py", "chunk_number": 1, "symbols": ["import", "metho", "registry", "list", "schema", "benchmarks", "datasets", "from", "overall", "typing", "json", "tqdm", "full", "result", "build_dataset", "exception", "image", "classification", "markdown", "key", "error", "build", "dataset", "none", "desc", "sample", "break", "method", "cls", "happen", "append", "scores", "return", "building", "score", "types", "when", "except", "render", "missing", "detail", "language", "type", "dumps", "rows", "specific", "this", "enumerate", "img", "continue"], "ast_kind": "imports", "text": "import json\nfrom typing import List\n\nimport datasets\nfrom tqdm import tqdm\n\nfrom benchmarks.overall.registry import METHOD_REGISTRY\nfrom benchmarks.overall.schema import FullResult\n\n", "n_tokens": 34, "byte_len": 182, "file_sha1": "c3b3e13fe918619cb0affd6efb5ceeac249696b5", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/dataset.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/dataset.py", "rel_path": "benchmarks/overall/display/dataset.py", "module": "benchmarks.overall.display.dataset", "ext": "py", "chunk_number": 2, "symbols": ["build_dataset", "exception", "image", "classification", "markdown", "metho", "registry", "key", "error", "build", "dataset", "none", "datasets", "from", "list", "desc", "sample", "break", "method", "cls", "happen", "append", "result", "scores", "return", "building", "score", "types", "when", "except", "schema", "benchmarks", "render", "missing", "detail", "language", "type", "dumps", "rows", "specific", "this", "typing", "enumerate", "json", "full", "img", "continue", "import", "bench", "overall"], "ast_kind": "function_or_method", "text": "def build_dataset(bench_dataset: datasets.Dataset, result: FullResult, score_types: List[str], max_rows: int | None = None) -> datasets.Dataset:\n    rows = []\n    for idx, sample in tqdm(enumerate(bench_dataset), desc=\"Building dataset\"):\n        if idx not in result[\"markdown\"]:\n            continue\n\n        if max_rows is not None and idx >= max_rows:\n            break\n\n        row = {\n            \"uuid\": sample[\"uuid\"],\n            \"classification\": sample[\"classification\"],\n            \"language\": sample[\"language\"],\n            \"img\": sample[\"img\"],\n        }\n        for method in result[\"markdown\"][idx]:\n            if method == \"gt\":\n                continue\n\n            method_cls = METHOD_REGISTRY[method]()\n            md = result[\"markdown\"][idx][method]\n            try:\n                method_img = method_cls.render(result[\"markdown\"][idx][method])\n            except Exception as e:\n                # This can happen when the markdown is None\n                method_img = PIL.Image.new(\"RGB\", (200, 200))\n\n            row[f\"{method}_md\"] = md\n            row[f\"{method}_img\"] = method_img\n\n            for score_type in score_types:\n                try:\n                    row[f\"{method}_{score_type}\"] = result[\"scores\"][idx][method][score_type][\"score\"]\n                except KeyError:\n                    row[f\"{method}_{score_type}\"] = -1.0 # Missing score\n                try:\n                    row[f\"{method}_{score_type}_detail\"] = json.dumps(result[\"scores\"][idx][method][score_type][\"specific_scores\"])\n                except KeyError:\n                    row[f\"{method}_{score_type}_detail\"] = \"\" # Missing detail\n        rows.append(row)\n    ds = datasets.Dataset.from_list(rows)\n    return ds\n\n", "n_tokens": 363, "byte_len": 1734, "file_sha1": "c3b3e13fe918619cb0affd6efb5ceeac249696b5", "start_line": 11, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/table.py", "rel_path": "benchmarks/overall/display/table.py", "module": "benchmarks.overall.display.table", "ext": "py", "chunk_number": 1, "symbols": ["write_table", "write", "table", "headers", "pathlib", "tablefmt", "schema", "benchmarks", "print", "from", "filename", "github", "dict", "list", "out", "path", "rows", "typing", "tabulate", "open", "with", "full", "result", "import", "title", "overall", "encoding", "print_scores", "markdown", "based", "scores", "document", "types", "lst", "all", "raw", "sometimes", "predicted", "ground", "except", "block", "continue", "average", "times", "marker", "aligning", "averages", "type", "blocks", "default"], "ast_kind": "function_or_method", "text": "from pathlib import Path\nfrom typing import Dict, List\n\nimport tabulate\n\nfrom benchmarks.overall.schema import FullResult\n\ndef write_table(title: str, rows: list, headers: list, out_path: Path, filename: str):\n    table = tabulate.tabulate(rows, headers=headers, tablefmt=\"github\")\n    with open(out_path / filename, \"w\", encoding=\"utf-8\") as f:\n        f.write(f\"# {title}\\n\")\n        f.write(table)\n    print(title)\n    print(table)\n\n", "n_tokens": 109, "byte_len": 436, "file_sha1": "811ec36616f752253fe36a9bd550045fc95f18f8", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/table.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/benchmarks/overall/display/table.py", "rel_path": "benchmarks/overall/display/table.py", "module": "benchmarks.overall.display.table", "ext": "py", "chunk_number": 2, "symbols": ["print_scores", "block", "type", "computed", "markdown", "key", "error", "based", "write", "table", "headers", "print", "scores", "score", "document", "types", "blocks", "each", "doc", "methods", "append", "inference", "rows", "result", "possible", "method", "lst", "all", "raw", "sometimes", "write_table", "filename", "github", "predicted", "ground", "except", "open", "continue", "average", "times", "marker", "title", "aligning", "averages", "overall", "benchmarks", "dict", "default", "out", "path"], "ast_kind": "function_or_method", "text": "def print_scores(result: FullResult, out_path: Path, methods: List[str], score_types: List[str], default_score_type=\"heuristic\", default_method=\"marker\"):\n    document_types = list(result[\"averages_by_type\"][default_method][default_score_type].keys())\n    headers = [\"Document Type\"]\n    for method in methods:\n        for score_type in score_types:\n            headers.append(f\"{method} {score_type}\")\n\n    document_rows = [[k] for k in document_types]\n    for i, doc_type in enumerate(document_types):\n        for method in methods:\n            for score_type in score_types:\n                avg_score = sum(result[\"averages_by_type\"][method][score_type][doc_type]) / max(1, len(result[\"averages_by_type\"][method][score_type][doc_type]))\n                document_rows[i].append(avg_score)\n\n    write_table(\"Document Types\", document_rows, headers, out_path, \"document_types.md\")\n\n    headers = [\"Block Type\"]\n    block_types = list(result[\"averages_by_block_type\"][default_method][default_score_type].keys()) # all possible blocks\n    block_score_types = list(result[\"averages_by_block_type\"][default_method].keys())\n    for method in methods:\n        for score_type in block_score_types:\n            headers.append(f\"{method} {score_type}\")\n\n    block_rows = [[k] for k in block_types]\n    for i, block_type in enumerate(block_types):\n        for method in methods:\n            for score_type in block_score_types:\n                avg_score = sum(result[\"averages_by_block_type\"][method][score_type][block_type]) / max(1, len(result[\"averages_by_block_type\"][method][score_type][block_type]))\n                block_rows[i].append(avg_score)\n\n    write_table(\"Block types\", block_rows, headers, out_path, \"block_types.md\")\n\n    headers = [\"Method\",  \"Avg Time\"] + score_types\n    inference_rows = [[k] for k in methods]\n    all_raw_scores = [result[\"scores\"][i] for i in result[\"scores\"]]\n    for i, method in enumerate(methods):\n        avg_time = sum(result[\"average_times\"][method]) / max(1, len(result[\"average_times\"][method]))\n        inference_rows[i].append(avg_time)\n        for score_type in score_types:\n            scores_lst = []\n            for ar in all_raw_scores:\n                try:\n                    # Sometimes a few llm scores are missing\n                    scores_lst.append(ar[method][score_type][\"score\"])\n                except KeyError:\n                    continue\n            avg_score = sum(scores_lst) / max(1, len(scores_lst))\n            inference_rows[i].append(avg_score)\n\n    write_table(\"Overall Results\", inference_rows, headers, out_path, \"overall.md\")\n\n    print(\"Scores computed by aligning ground truth markdown blocks with predicted markdown for each method.  The scores are 0-100 based on edit distance.\")", "n_tokens": 608, "byte_len": 2754, "file_sha1": "811ec36616f752253fe36a9bd550045fc95f18f8", "start_line": 17, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/models.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/models.py", "rel_path": "marker/models.py", "module": "marker.models", "ext": "py", "chunk_number": 1, "symbols": ["supported", "foundation", "predictor", "isin", "ocr", "error", "recognition", "layout", "from", "pytorc", "enabl", "uses", "table", "rec", "surya", "transformers", "detection", "import", "which", "environ", "create_model_dict", "create", "model", "none", "device", "dict", "return", "attention", "implementation", "dtype"], "ast_kind": "imports", "text": "import os\n\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = (\n    \"1\"  # Transformers uses .isin for an op, which is not supported on MPS\n)\n\nfrom surya.foundation import FoundationPredictor\nfrom surya.detection import DetectionPredictor\nfrom surya.layout import LayoutPredictor\nfrom surya.ocr_error import OCRErrorPredictor\nfrom surya.recognition import RecognitionPredictor\nfrom surya.table_rec import TableRecPredictor\n\n", "n_tokens": 101, "byte_len": 417, "file_sha1": "7aecc0a083c0f139fad3463a3fdc75486781ffad", "start_line": 1, "end_line": 14}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/models.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/models.py", "rel_path": "marker/models.py", "module": "marker.models", "ext": "py", "chunk_number": 2, "symbols": ["create_model_dict", "create", "model", "foundation", "predictor", "table", "rec", "none", "layout", "ocr", "error", "recognition", "device", "dict", "return", "attention", "implementation", "detection", "dtype", "supported", "isin", "from", "pytorc", "enabl", "uses", "surya", "transformers", "import", "which", "environ"], "ast_kind": "function_or_method", "text": "def create_model_dict(\n    device=None, dtype=None, attention_implementation: str | None = None\n) -> dict:\n    foundation_predictor = FoundationPredictor(\n        device=device, dtype=dtype, attention_implementation=attention_implementation\n    )\n    return {\n        \"foundation_model\": foundation_predictor,\n        \"layout_model\": LayoutPredictor(device=device, dtype=dtype),\n        \"recognition_model\": RecognitionPredictor(foundation_predictor),\n        \"table_rec_model\": TableRecPredictor(device=device, dtype=dtype),\n        \"detection_model\": DetectionPredictor(device=device, dtype=dtype),\n        \"ocr_error_model\": OCRErrorPredictor(device=device, dtype=dtype),\n    }\n", "n_tokens": 147, "byte_len": 681, "file_sha1": "7aecc0a083c0f139fad3463a3fdc75486781ffad", "start_line": 15, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 1, "symbols": ["openin", "regex", "numpy", "closin", "import", "module", "small", "annotated", "pydantic", "schema", "settings", "importlib", "from", "superscript", "mapping", "tag", "bold", "mark", "inspect", "base", "model", "subscript", "list", "highlight", "math", "underline", "typing", "marker", "italic", "polygon", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists"], "ast_kind": "imports", "text": "import inspect\nimport os\nfrom importlib import import_module\nfrom typing import List, Annotated\nimport re\n\nimport numpy as np\nimport requests\nfrom pydantic import BaseModel\n\nfrom marker.schema.polygon import PolygonBox\nfrom marker.settings import settings\n\nOPENING_TAG_REGEX = re.compile(r\"<((?:math|i|b))(?:\\s+[^>]*)?>\")\nCLOSING_TAG_REGEX = re.compile(r\"</((?:math|i|b))>\")\nTAG_MAPPING = {\n    'i': 'italic',\n    'b': 'bold',\n    'math': 'math',\n    'mark': 'highlight',\n    'sub': 'subscript',\n    'sup': 'superscript',\n    'small': 'small',\n    'u': 'underline',\n    'code': 'code'\n}\n", "n_tokens": 168, "byte_len": 587, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 2, "symbols": ["strings_to_classes", "classes_to_strings", "class", "classes", "strings", "import", "module", "item", "append", "name", "return", "inspect", "isclass", "list", "getattr", "raise", "type", "value", "error", "rsplit", "items", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "small", "horizontally", "max", "config", "determines", "used", "dict", "range", "lst", "advanced", "escapes"], "ast_kind": "function_or_method", "text": "def strings_to_classes(items: List[str]) -> List[type]:\n    classes = []\n    for item in items:\n        module_name, class_name = item.rsplit('.', 1)\n        module = import_module(module_name)\n        classes.append(getattr(module, class_name))\n    return classes\n\n\ndef classes_to_strings(items: List[type]) -> List[str]:\n    for item in items:\n        if not inspect.isclass(item):\n            raise ValueError(f\"Item {item} is not a class\")\n\n    return [f\"{item.__module__}.{item.__name__}\" for item in items]\n\n", "n_tokens": 120, "byte_len": 514, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 28, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 3, "symbols": ["verify_config_keys", "annotation", "attr", "name", "assert", "configuration", "none", "annotated", "vals", "verify", "config", "annotations", "inspect", "getattr", "order", "class", "get", "type", "value", "isinstance", "items", "values", "must", "strings_to_classes", "classes_to_strings", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings", "classes", "small", "horizontally", "max", "determines", "used", "dict"], "ast_kind": "function_or_method", "text": "def verify_config_keys(obj):\n    annotations = inspect.get_annotations(obj.__class__)\n\n    none_vals = \"\"\n    for attr_name, annotation in annotations.items():\n        if isinstance(annotation, type(Annotated[str, \"\"])):\n            value = getattr(obj, attr_name)\n            if value is None:\n                none_vals += f\"{attr_name}, \"\n\n    assert len(none_vals) == 0, f\"In order to use {obj.__class__.__name__}, you must set the configuration values `{none_vals}`.\"\n\n", "n_tokens": 105, "byte_len": 473, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 45, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 4, "symbols": ["assign_config", "elif", "class", "assign", "config", "none", "specific", "else", "pydantic", "cls", "name", "dict", "removeprefix", "return", "split", "base", "model", "enables", "keys", "setattr", "raise", "continue", "isinstance", "value", "error", "using", "markdown", "renderer", "hasattr", "like", "strings_to_classes", "classes_to_strings", "verify_config_keys", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings"], "ast_kind": "function_or_method", "text": "def assign_config(cls, config: BaseModel | dict | None):\n    cls_name = cls.__class__.__name__\n    if config is None:\n        return\n    elif isinstance(config, BaseModel):\n        dict_config = config.dict()\n    elif isinstance(config, dict):\n        dict_config = config\n    else:\n        raise ValueError(\"config must be a dict or a pydantic BaseModel\")\n\n    for k in dict_config:\n        if hasattr(cls, k):\n            setattr(cls, k, dict_config[k])\n    for k in dict_config:\n        if cls_name not in k:\n            continue\n        # Enables using class-specific keys, like \"MarkdownRenderer_remove_blocks\"\n        split_k = k.removeprefix(cls_name + \"_\")\n\n        if hasattr(cls, split_k):\n            setattr(cls, split_k, dict_config[k])\n\n", "n_tokens": 166, "byte_len": 751, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 58, "end_line": 81}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 5, "symbols": ["parse_range_str", "else", "split", "list", "order", "append", "start", "parse", "range", "numbers", "str", "lst", "page", "sort", "return", "deduplicate", "sorted", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "whitespace", "matrix", "intersection", "exists", "strings", "classes", "small", "horizontally", "max", "config", "determines", "used", "dict", "advanced", "escapes", "bold", "mark", "inspect", "extracts"], "ast_kind": "function_or_method", "text": "def parse_range_str(range_str: str) -> List[int]:\n    range_lst = range_str.split(\",\")\n    page_lst = []\n    for i in range_lst:\n        if \"-\" in i:\n            start, end = i.split(\"-\")\n            page_lst += list(range(int(start), int(end) + 1))\n        else:\n            page_lst.append(int(i))\n    page_lst = sorted(list(set(page_lst)))  # Deduplicate page numbers and sort in order\n    return page_lst\n\n", "n_tokens": 100, "byte_len": 410, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 82, "end_line": 94}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 6, "symbols": ["matrix_intersection_area", "min", "float", "matrix", "intersection", "ndarray", "shape", "max", "height", "return", "zeros", "array", "list", "minimum", "boxes", "boxes1", "width", "newaxis", "boxes2", "maximum", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "exists", "strings", "classes", "small", "horizontally", "config", "determines", "used", "dict", "range", "lst", "advanced", "escapes", "bold"], "ast_kind": "function_or_method", "text": "def matrix_intersection_area(boxes1: List[List[float]], boxes2: List[List[float]]) -> np.ndarray:\n    if len(boxes1) == 0 or len(boxes2) == 0:\n        return np.zeros((len(boxes1), len(boxes2)))\n\n    boxes1 = np.array(boxes1)\n    boxes2 = np.array(boxes2)\n\n    boxes1 = boxes1[:, np.newaxis, :]  # Shape: (N, 1, 4)\n    boxes2 = boxes2[np.newaxis, :, :]  # Shape: (1, M, 4)\n\n    min_x = np.maximum(boxes1[..., 0], boxes2[..., 0])  # Shape: (N, M)\n    min_y = np.maximum(boxes1[..., 1], boxes2[..., 1])\n    max_x = np.minimum(boxes1[..., 2], boxes2[..., 2])\n    max_y = np.minimum(boxes1[..., 3], boxes2[..., 3])\n\n    width = np.maximum(0, max_x - min_x)\n    height = np.maximum(0, max_y - min_y)\n\n    return width * height  # Shape: (N, M)\n\n", "n_tokens": 252, "byte_len": 740, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 95, "end_line": 115}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 7, "symbols": ["matrix_distance", "axis", "array", "norm", "list", "newaxis", "boxes", "centers", "linalg", "float", "ndarray", "boxes2", "matrix", "distance", "shape", "distances", "boxes1", "return", "zeros", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "intersection", "exists", "strings", "classes", "small", "horizontally", "max", "config", "determines", "used", "dict", "range", "lst", "advanced", "escapes"], "ast_kind": "function_or_method", "text": "def matrix_distance(boxes1: List[List[float]], boxes2: List[List[float]]) -> np.ndarray:\n    if len(boxes2) == 0:\n        return np.zeros((len(boxes1), 0))\n    if len(boxes1) == 0:\n        return np.zeros((0, len(boxes2)))\n\n    boxes1 = np.array(boxes1)  # Shape: (N, 4)\n    boxes2 = np.array(boxes2)  # Shape: (M, 4)\n\n    boxes1_centers = (boxes1[:, :2] + boxes1[:, 2:]) / 2 # Shape: (M, 2)\n    boxes2_centers = (boxes2[:, :2] + boxes2[:, 2:]) / 2  # Shape: (M, 2)\n\n    boxes1_centers = boxes1_centers[:, np.newaxis, :]  # Shape: (N, 1, 2)\n    boxes2_centers = boxes2_centers[np.newaxis, :, :]  # Shape: (1, M, 2)\n\n    distances = np.linalg.norm(boxes1_centers - boxes2_centers, axis=2)  # Shape: (N, M)\n    return distances\n\n", "n_tokens": 255, "byte_len": 727, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 116, "end_line": 134}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 8, "symbols": ["sort_text_lines", "bbox", "into", "group", "key", "each", "sorted", "more", "horizontally", "append", "line", "used", "advanced", "vertical", "groups", "return", "reading", "flatten", "list", "order", "single", "tolerance", "should", "sort", "text", "lines", "point", "starting", "extend", "only", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings"], "ast_kind": "function_or_method", "text": "def sort_text_lines(lines: List[PolygonBox], tolerance=1.25):\n    # Sorts in reading order.  Not 100% accurate, this should only\n    # be used as a starting point for more advanced sorting.\n    vertical_groups = {}\n    for line in lines:\n        group_key = round(line.bbox[1] / tolerance) * tolerance\n        if group_key not in vertical_groups:\n            vertical_groups[group_key] = []\n        vertical_groups[group_key].append(line)\n\n    # Sort each group horizontally and flatten the groups into a single list\n    sorted_lines = []\n    for _, group in sorted(vertical_groups.items()):\n        sorted_group = sorted(group, key=lambda x: x.bbox[0])\n        sorted_lines.extend(sorted_group)\n\n    return sorted_lines\n", "n_tokens": 162, "byte_len": 721, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 135, "end_line": 152}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 9, "symbols": ["download_font", "download", "font", "exists", "path", "iter", "content", "fon", "settings", "exist", "artifac", "url", "chunk", "open", "with", "makedirs", "stream", "size", "write", "name", "dirname", "true", "raise", "for", "requests", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "strings", "classes", "small", "horizontally", "max", "config", "determines"], "ast_kind": "function_or_method", "text": "def download_font():\n    if not os.path.exists(settings.FONT_PATH):\n        os.makedirs(os.path.dirname(settings.FONT_PATH), exist_ok=True)\n        font_dl_path = f\"{settings.ARTIFACT_URL}/{settings.FONT_NAME}\"\n        with requests.get(font_dl_path, stream=True) as r, open(settings.FONT_PATH, 'wb') as f:\n            r.raise_for_status()\n            for chunk in r.iter_content(chunk_size=8192):\n                f.write(chunk)\n", "n_tokens": 95, "byte_len": 429, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 153, "end_line": 161}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 10, "symbols": ["get_opening_tag_type", "openin", "regex", "none", "get", "opening", "group", "determines", "mapping", "tag", "return", "match", "returns", "extracts", "analyze", "string", "type", "bool", "true", "args", "tuple", "false", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_closing_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings", "classes", "small", "horizontally", "max", "config", "used", "dict", "range"], "ast_kind": "function_or_method", "text": "def get_opening_tag_type(tag):\n    \"\"\"\n    Determines if a tag is an opening tag and extracts the tag type.\n    \n    Args:\n        tag (str): The tag string to analyze.\n\n    Returns:\n        tuple: (is_opening_tag (bool), tag_type (str or None))\n    \"\"\"\n    match = OPENING_TAG_REGEX.match(tag)\n    \n    if match:\n        tag_type = match.group(1)\n        if tag_type in TAG_MAPPING:\n            return True, TAG_MAPPING[tag_type]\n    \n    return False, None\n", "n_tokens": 111, "byte_len": 459, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 162, "end_line": 180}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 11, "symbols": ["get_closing_tag_type", "none", "group", "closin", "regex", "determines", "from", "mapping", "tag", "late", "escapes", "return", "match", "returns", "extracts", "surya", "recognition", "mat", "pattern", "math", "symbols", "analyze", "string", "type", "bool", "true", "compile", "args", "tuple", "false", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "normalize_latex_escapes", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings"], "ast_kind": "function_or_method", "text": "def get_closing_tag_type(tag):\n    \"\"\"\n    Determines if a tag is an opening tag and extracts the tag type.\n    \n    Args:\n        tag (str): The tag string to analyze.\n\n    Returns:\n        tuple: (is_opening_tag (bool), tag_type (str or None))\n    \"\"\"\n    match = CLOSING_TAG_REGEX.match(tag)\n    \n    if match:\n        tag_type = match.group(1)\n        if tag_type in TAG_MAPPING:\n            return True, TAG_MAPPING[tag_type]\n    \n    return False, None\n\n# Modification of unwrap_math from surya.recognition\nMATH_SYMBOLS = [\"^\", \"_\", \"\\\\\", \"{\", \"}\"]\nMATH_TAG_PATTERN = re.compile(r'<math\\b[^>]*>.*?</math>', re.DOTALL)\nLATEX_ESCAPES = {\n    r'\\%': '%',\n    r'\\$': '$',\n    r'\\_': '_',\n    r'\\&': '&',\n    r'\\#': '#',\n    r'\\': '',\n}", "n_tokens": 215, "byte_len": 743, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 181, "end_line": 210}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 12, "symbols": ["normalize_latex_escapes", "normalize", "latex", "replace", "items", "late", "escapes", "return", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "unwrap_math", "inner", "stripped", "start", "whitespace", "matrix", "intersection", "exists", "strings", "classes", "small", "horizontally", "max", "config", "determines", "used", "dict", "range", "lst", "advanced", "bold", "mark", "sorted", "inspect", "extracts", "norm", "getattr", "mat", "pattern", "symbols", "class"], "ast_kind": "function_or_method", "text": "def normalize_latex_escapes(s: str) -> str:\n    for k, v in LATEX_ESCAPES.items():\n        s = s.replace(k, v)\n    return s\n", "n_tokens": 40, "byte_len": 124, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 211, "end_line": 215}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py#13", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/util.py", "rel_path": "marker/util.py", "module": "marker.util", "ext": "py", "chunk_number": 13, "symbols": ["unwrap_math", "strip", "really", "inner", "stripped", "unwrapped", "remove", "text", "normalize", "whitespace", "otherwise", "trailing", "escapes", "match", "return", "unwrap", "math", "symbols", "list", "single", "leading", "remain", "fully", "flags", "mat", "surrounding", "tags", "plus", "latex", "block", "strings_to_classes", "classes_to_strings", "verify_config_keys", "assign_config", "parse_range_str", "matrix_intersection_area", "matrix_distance", "sort_text_lines", "download_font", "get_opening_tag_type", "get_closing_tag_type", "normalize_latex_escapes", "start", "matrix", "intersection", "exists", "strings", "classes", "small", "horizontally"], "ast_kind": "function_or_method", "text": "def unwrap_math(text: str, math_symbols: List[str] = MATH_SYMBOLS) -> str:\n    \"\"\"Unwrap a single <math>...</math> block if it's not really math.\"\"\"\n    if MATH_TAG_PATTERN.match(text):\n        # Remove tags\n        inner = re.sub(r'^\\s*<math\\b[^>]*>|</math>\\s*$', '', text, flags=re.DOTALL)\n\n        # Strip a single leading/trailing \\\\ plus surrounding whitespace\n        inner_stripped = re.sub(r'^\\s*\\\\\\\\\\s*|\\s*\\\\\\\\\\s*$', '', inner)\n\n        # Unwrap \\text{...}\n        unwrapped = re.sub(r'\\\\text[a-zA-Z]*\\s*\\{(.*?)\\}', r'\\1', inner_stripped)\n\n        # Normalize escapes\n        normalized = normalize_latex_escapes(unwrapped)\n\n        # If no math symbols remain  unwrap fully\n        if not any(symb in normalized for symb in math_symbols):\n            return normalized.strip()\n\n    # Otherwise, return as-is\n    return text", "n_tokens": 225, "byte_len": 836, "file_sha1": "e68de66738293970e2d27a021894909cbef05f19", "start_line": 216, "end_line": 236}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/logger.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/logger.py", "rel_path": "marker/logger.py", "module": "marker.logger", "ext": "py", "chunk_number": 1, "symbols": ["configure_logging", "get_logger", "levelname", "loglevels", "simplefilter", "get", "logger", "warnings", "add", "handler", "subset", "font", "tools", "set", "formatter", "error", "settings", "from", "action", "logging", "future", "return", "critical", "lib", "ttlib", "ignore", "level", "asctime", "handlers", "configure", "message", "import", "weasyprint", "marker", "loglevel", "category", "component", "stream", "warning", "setup", "name", "ttfont"], "ast_kind": "function_or_method", "text": "import logging\nimport warnings\n\nfrom marker.settings import settings\n\n\ndef configure_logging():\n    # Setup marker logger\n    logger = get_logger()\n\n    if not logger.handlers:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"\n        )\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n\n    logger.setLevel(settings.LOGLEVEL)\n\n    # Ignore future warnings\n    warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n    # Set component loglevels\n    logging.getLogger(\"PIL\").setLevel(logging.ERROR)\n    logging.getLogger(\"fontTools.subset\").setLevel(logging.ERROR)\n    logging.getLogger(\"fontTools.ttLib.ttFont\").setLevel(logging.ERROR)\n    logging.getLogger(\"weasyprint\").setLevel(logging.CRITICAL)\n\n\ndef get_logger():\n    return logging.getLogger(\"marker\")\n", "n_tokens": 178, "byte_len": 888, "file_sha1": "4438c0fc544f1ec6a477a4e5dd5b012478b71759", "start_line": 1, "end_line": 33}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py", "rel_path": "marker/settings.py", "module": "marker.settings", "ext": "py", "chunk_number": 1, "symbols": ["import", "dotenv", "pydantic", "torch", "from", "base", "settings", "typing", "find", "computed", "field", "optional", "TORCH_DEVICE_MODEL", "MODEL_DTYPE", "Settings", "Config", "fonts", "class", "regular", "artifacts", "noto", "current", "none", "text", "env", "file", "outpu", "encoding", "static", "default", "https", "jpeg", "mode", "dtype", "fon", "path", "else", "conversion", "results", "extra", "self", "device", "config", "dir", "debu", "dat", "general", "googl", "key", "does"], "ast_kind": "imports", "text": "from typing import Optional\n\nfrom dotenv import find_dotenv\nfrom pydantic import computed_field\nfrom pydantic_settings import BaseSettings\nimport torch\nimport os\n\n", "n_tokens": 35, "byte_len": 163, "file_sha1": "18416ddc8a25638ae27e17eccd779053a452a259", "start_line": 1, "end_line": 9}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py", "rel_path": "marker/settings.py", "module": "marker.settings", "ext": "py", "chunk_number": 2, "symbols": ["Settings", "fonts", "class", "regular", "artifacts", "noto", "current", "none", "text", "outpu", "encoding", "settings", "static", "default", "https", "jpeg", "fon", "path", "conversion", "results", "device", "dir", "debu", "dat", "general", "googl", "key", "work", "does", "debug", "TORCH_DEVICE_MODEL", "MODEL_DTYPE", "Config", "env", "file", "mode", "dtype", "else", "pydantic", "extra", "self", "config", "from", "torc", "devic", "data", "artifac", "url", "imag", "return"], "ast_kind": "class_or_type", "text": "class Settings(BaseSettings):\n    # Paths\n    BASE_DIR: str = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    OUTPUT_DIR: str = os.path.join(BASE_DIR, \"conversion_results\")\n    FONT_DIR: str = os.path.join(BASE_DIR, \"static\", \"fonts\")\n    DEBUG_DATA_FOLDER: str = os.path.join(BASE_DIR, \"debug_data\")\n    ARTIFACT_URL: str = \"https://models.datalab.to/artifacts\"\n    FONT_NAME: str = \"GoNotoCurrent-Regular.ttf\"\n    FONT_PATH: str = os.path.join(FONT_DIR, FONT_NAME)\n    LOGLEVEL: str = \"INFO\"\n\n    # General\n    OUTPUT_ENCODING: str = \"utf-8\"\n    OUTPUT_IMAGE_FORMAT: str = \"JPEG\"\n\n    # LLM\n    GOOGLE_API_KEY: Optional[str] = \"\"\n\n    # General models\n    TORCH_DEVICE: Optional[str] = (\n        None  # Note: MPS device does not work for text detection, and will default to CPU\n    )\n", "n_tokens": 215, "byte_len": 803, "file_sha1": "18416ddc8a25638ae27e17eccd779053a452a259", "start_line": 10, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/settings.py", "rel_path": "marker/settings.py", "module": "marker.settings", "ext": "py", "chunk_number": 3, "symbols": ["TORCH_DEVICE_MODEL", "MODEL_DTYPE", "Config", "class", "none", "env", "file", "settings", "mode", "dtype", "else", "extra", "self", "config", "torc", "devic", "return", "backends", "device", "property", "bfloat", "bfloat16", "ignore", "local", "available", "torch", "float", "float32", "cuda", "find", "Settings", "fonts", "regular", "artifacts", "noto", "current", "text", "outpu", "encoding", "static", "default", "https", "jpeg", "fon", "path", "conversion", "results", "pydantic", "from", "dir"], "ast_kind": "class_or_type", "text": "    @computed_field\n    @property\n    def TORCH_DEVICE_MODEL(self) -> str:\n        if self.TORCH_DEVICE is not None:\n            return self.TORCH_DEVICE\n\n        if torch.cuda.is_available():\n            return \"cuda\"\n\n        if torch.backends.mps.is_available():\n            return \"mps\"\n\n        return \"cpu\"\n\n    @computed_field\n    @property\n    def MODEL_DTYPE(self) -> torch.dtype:\n        if self.TORCH_DEVICE_MODEL == \"cuda\":\n            return torch.bfloat16\n        else:\n            return torch.float32\n\n    class Config:\n        env_file = find_dotenv(\"local.env\")\n        extra = \"ignore\"\n\n\nsettings = Settings()\n", "n_tokens": 143, "byte_len": 629, "file_sha1": "18416ddc8a25638ae27e17eccd779053a452a259", "start_line": 33, "end_line": 61}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 1, "symbols": ["unwrap_outer_tag", "image", "markdown", "unwrap", "outer", "html", "output", "parser", "blocks", "extraction", "json", "block", "soup", "pydantic", "schema", "settings", "from", "return", "contents", "base", "model", "ocr", "renderers", "import", "marker", "isinstance", "beautiful", "ocrjson", "list", "name", "json_to_html", "output_exists", "text_from_rendered", "convert_if_not_rgb", "save_output", "give", "exists", "child", "ids", "exclude", "content", "refs", "convert", "outpu", "imag", "decode", "file", "children", "getattr", "replace"], "ast_kind": "function_or_method", "text": "import json\nimport os\n\nfrom bs4 import BeautifulSoup, Tag\nfrom pydantic import BaseModel\nfrom PIL import Image\n\nfrom marker.renderers.extraction import ExtractionOutput\nfrom marker.renderers.html import HTMLOutput\nfrom marker.renderers.json import JSONOutput, JSONBlockOutput\nfrom marker.renderers.markdown import MarkdownOutput\nfrom marker.renderers.ocr_json import OCRJSONOutput\nfrom marker.schema.blocks import BlockOutput\nfrom marker.settings import settings\n\n\ndef unwrap_outer_tag(html: str):\n    soup = BeautifulSoup(html, \"html.parser\")\n    contents = list(soup.contents)\n    if len(contents) == 1 and isinstance(contents[0], Tag) and contents[0].name == \"p\":\n        # Unwrap the p tag\n        soup.p.unwrap()\n\n    return str(soup)\n\n", "n_tokens": 168, "byte_len": 741, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 2, "symbols": ["json_to_html", "none", "find", "all", "give", "child", "html", "parser", "take", "json", "block", "function", "soup", "content", "ids", "else", "output", "refs", "return", "children", "getattr", "replace", "with", "attrs", "index", "utility", "beautiful", "src", "unwrap_outer_tag", "output_exists", "text_from_rendered", "convert_if_not_rgb", "save_output", "markdown", "exists", "image", "exclude", "convert", "outpu", "imag", "decode", "file", "meta", "invalid", "open", "marker", "this", "isinstance", "indent", "true"], "ast_kind": "function_or_method", "text": "def json_to_html(block: JSONBlockOutput | BlockOutput):\n    # Utility function to take in json block output and give html for the block.\n    if not getattr(block, \"children\", None):\n        return block.html\n    else:\n        child_html = [json_to_html(child) for child in block.children]\n        child_ids = [child.id for child in block.children]\n\n        soup = BeautifulSoup(block.html, \"html.parser\")\n        content_refs = soup.find_all(\"content-ref\")\n        for ref in content_refs:\n            src_id = ref.attrs[\"src\"]\n            if src_id in child_ids:\n                child_soup = BeautifulSoup(\n                    child_html[child_ids.index(src_id)], \"html.parser\"\n                )\n                ref.replace_with(child_soup)\n        return str(soup)\n\n", "n_tokens": 158, "byte_len": 768, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 27, "end_line": 46}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 3, "symbols": ["output_exists", "html", "exts", "fname", "base", "true", "false", "output", "dir", "path", "exists", "json", "join", "return", "unwrap_outer_tag", "json_to_html", "text_from_rendered", "convert_if_not_rgb", "save_output", "markdown", "give", "child", "ids", "image", "block", "exclude", "content", "refs", "convert", "outpu", "imag", "decode", "file", "children", "getattr", "replace", "with", "meta", "invalid", "open", "attrs", "marker", "this", "isinstance", "utility", "indent", "rendered", "text", "unwrap", "outer"], "ast_kind": "function_or_method", "text": "def output_exists(output_dir: str, fname_base: str):\n    exts = [\"md\", \"html\", \"json\"]\n    for ext in exts:\n        if os.path.exists(os.path.join(output_dir, f\"{fname_base}.{ext}\")):\n            return True\n    return False\n\n", "n_tokens": 61, "byte_len": 226, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 47, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 4, "symbols": ["text_from_rendered", "elif", "markdown", "rendered", "html", "output", "model", "dump", "images", "else", "metadata", "exclude", "chunk", "from", "return", "base", "file", "json", "text", "invalid", "renderers", "raise", "extraction", "type", "import", "marker", "this", "isinstance", "value", "error", "unwrap_outer_tag", "json_to_html", "output_exists", "convert_if_not_rgb", "save_output", "give", "exists", "child", "ids", "image", "block", "content", "refs", "convert", "outpu", "imag", "decode", "children", "getattr", "replace"], "ast_kind": "function_or_method", "text": "def text_from_rendered(rendered: BaseModel):\n    from marker.renderers.chunk import ChunkOutput  # Has an import from this file\n\n    if isinstance(rendered, MarkdownOutput):\n        return rendered.markdown, \"md\", rendered.images\n    elif isinstance(rendered, HTMLOutput):\n        return rendered.html, \"html\", rendered.images\n    elif isinstance(rendered, JSONOutput):\n        return rendered.model_dump_json(exclude=[\"metadata\"], indent=2), \"json\", {}\n    elif isinstance(rendered, ChunkOutput):\n        return rendered.model_dump_json(exclude=[\"metadata\"], indent=2), \"json\", {}\n    elif isinstance(rendered, OCRJSONOutput):\n        return rendered.model_dump_json(exclude=[\"metadata\"], indent=2), \"json\", {}\n    elif isinstance(rendered, ExtractionOutput):\n        return rendered.document_json, \"json\", {}\n    else:\n        raise ValueError(\"Invalid output type\")\n\n", "n_tokens": 187, "byte_len": 870, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 55, "end_line": 73}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 5, "symbols": ["convert_if_not_rgb", "image", "convert", "not", "mode", "return", "unwrap_outer_tag", "json_to_html", "output_exists", "text_from_rendered", "save_output", "markdown", "give", "exists", "child", "ids", "block", "output", "exclude", "content", "refs", "outpu", "imag", "decode", "file", "children", "getattr", "replace", "with", "meta", "invalid", "open", "attrs", "marker", "this", "isinstance", "utility", "indent", "true", "rendered", "text", "unwrap", "outer", "find", "all", "html", "blocks", "extraction", "encoding", "soup"], "ast_kind": "function_or_method", "text": "def convert_if_not_rgb(image: Image.Image) -> Image.Image:\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    return image\n\n", "n_tokens": 34, "byte_len": 142, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 74, "end_line": 79}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/output.py", "rel_path": "marker/output.py", "module": "marker.output", "ext": "py", "chunk_number": 6, "symbols": ["save_output", "errors", "rendered", "text", "save", "outpu", "encoding", "images", "metadata", "fname", "base", "output", "settings", "path", "imag", "rgba", "decode", "encode", "model", "from", "dumps", "replace", "meta", "dir", "open", "json", "with", "write", "convert", "not", "unwrap_outer_tag", "json_to_html", "output_exists", "text_from_rendered", "convert_if_not_rgb", "markdown", "give", "exists", "child", "ids", "image", "block", "exclude", "content", "refs", "return", "file", "children", "getattr", "invalid"], "ast_kind": "function_or_method", "text": "def save_output(rendered: BaseModel, output_dir: str, fname_base: str):\n    text, ext, images = text_from_rendered(rendered)\n    text = text.encode(settings.OUTPUT_ENCODING, errors=\"replace\").decode(\n        settings.OUTPUT_ENCODING\n    )\n\n    with open(\n        os.path.join(output_dir, f\"{fname_base}.{ext}\"),\n        \"w+\",\n        encoding=settings.OUTPUT_ENCODING,\n    ) as f:\n        f.write(text)\n    with open(\n        os.path.join(output_dir, f\"{fname_base}_meta.json\"),\n        \"w+\",\n        encoding=settings.OUTPUT_ENCODING,\n    ) as f:\n        f.write(json.dumps(rendered.metadata, indent=2))\n\n    for img_name, img in images.items():\n        img = convert_if_not_rgb(img)  # RGBA images can't save as JPG\n        img.save(os.path.join(output_dir, img_name), settings.OUTPUT_IMAGE_FORMAT)\n", "n_tokens": 193, "byte_len": 801, "file_sha1": "59c66904e95fb33c70c11ed5bd296e605da7d25f", "start_line": 80, "end_line": 102}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py", "rel_path": "marker/renderers/ocr_json.py", "module": "marker.renderers.ocr_json", "ext": "py", "chunk_number": 1, "symbols": ["OCRJSONCharOutput", "OCRJSONLineOutput", "OCRJSONPageOutput", "OCRJSONOutput", "block", "type", "bbox", "ocrjson", "page", "class", "text", "none", "tuple", "float", "char", "line", "annotated", "metadata", "html", "pydantic", "document", "schema", "from", "dict", "base", "model", "children", "list", "typing", "types", "extract_json", "__call__", "OCRJSONRenderer", "formatted", "append", "equation", "renderer", "equations", "images", "else", "extract", "json", "self", "spans", "span", "chars", "return", "obj", "get", "lines"], "ast_kind": "class_or_type", "text": "from typing import Annotated, List, Tuple\n\nfrom pydantic import BaseModel\n\nfrom marker.renderers import BaseRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n\nclass OCRJSONCharOutput(BaseModel):\n    id: str\n    block_type: str\n    text: str\n    polygon: List[List[float]]\n    bbox: List[float]\n\n\nclass OCRJSONLineOutput(BaseModel):\n    id: str\n    block_type: str\n    html: str\n    polygon: List[List[float]]\n    bbox: List[float]\n    children: List[\"OCRJSONCharOutput\"] | None = None\n\n\nclass OCRJSONPageOutput(BaseModel):\n    id: str\n    block_type: str\n    polygon: List[List[float]]\n    bbox: List[float]\n    children: List[OCRJSONLineOutput] | None = None\n\n\nclass OCRJSONOutput(BaseModel):\n    children: List[OCRJSONPageOutput]\n    block_type: str = str(BlockTypes.Document)\n    metadata: dict | None = None\n\n", "n_tokens": 212, "byte_len": 854, "file_sha1": "74d49f2fcc7b466a03604cc512d7fdfe812fe361", "start_line": 1, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py", "rel_path": "marker/renderers/ocr_json.py", "module": "marker.renderers.ocr_json", "ext": "py", "chunk_number": 2, "symbols": ["OCRJSONRenderer", "class", "tuple", "renderer", "page", "images", "annotated", "types", "ocrjson", "figure", "blocks", "block", "picture", "pages", "output", "image", "list", "base", "consider", "json", "extract_json", "__call__", "OCRJSONCharOutput", "OCRJSONLineOutput", "OCRJSONPageOutput", "OCRJSONOutput", "type", "bbox", "formatted", "text", "append", "equation", "none", "float", "line", "char", "equations", "metadata", "else", "html", "pydantic", "document", "schema", "extract", "self", "spans", "span", "from", "chars", "dict"], "ast_kind": "class_or_type", "text": "class OCRJSONRenderer(BaseRenderer):\n    \"\"\"\n    A renderer for OCR JSON output.\n    \"\"\"\n\n    image_blocks: Annotated[\n        Tuple[BlockTypes],\n        \"The list of block types to consider as images.\",\n    ] = (BlockTypes.Picture, BlockTypes.Figure)\n    page_blocks: Annotated[\n        Tuple[BlockTypes],\n        \"The list of block types to consider as pages.\",\n    ] = (BlockTypes.Page,)\n", "n_tokens": 91, "byte_len": 391, "file_sha1": "74d49f2fcc7b466a03604cc512d7fdfe812fe361", "start_line": 41, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py", "rel_path": "marker/renderers/ocr_json.py", "module": "marker.renderers.ocr_json", "ext": "py", "chunk_number": 3, "symbols": ["extract_json", "block", "type", "bbox", "ocrjson", "page", "formatted", "text", "equation", "line", "char", "equations", "else", "html", "document", "extract", "json", "self", "span", "spans", "append", "chars", "return", "obj", "get", "lines", "children", "list", "structure", "types", "__call__", "OCRJSONCharOutput", "OCRJSONLineOutput", "OCRJSONPageOutput", "OCRJSONOutput", "OCRJSONRenderer", "class", "none", "tuple", "float", "renderer", "images", "annotated", "metadata", "pydantic", "schema", "from", "dict", "base", "model"], "ast_kind": "function_or_method", "text": "    def extract_json(self, document: Document) -> List[OCRJSONPageOutput]:\n        pages = []\n        for page in document.pages:\n            page_equations = [\n                b for b in page.children if b.block_type == BlockTypes.Equation\n                and not b.removed\n            ]\n            equation_lines = []\n            for equation in page_equations:\n                if not equation.structure:\n                    continue\n\n                equation_lines += [\n                    line\n                    for line in equation.structure\n                    if line.block_type == BlockTypes.Line\n                ]\n\n            page_lines = [\n                block\n                for block in page.children\n                if block.block_type == BlockTypes.Line\n                and block.id not in equation_lines\n                and not block.removed\n            ]\n\n            lines = []\n            for line in page_lines + page_equations:\n                line_obj = OCRJSONLineOutput(\n                    id=str(line.id),\n                    block_type=str(line.block_type),\n                    html=\"\",\n                    polygon=line.polygon.polygon,\n                    bbox=line.polygon.bbox,\n                )\n                if line in page_equations:\n                    line_obj.html = line.html\n                else:\n                    line_obj.html = line.formatted_text(document)\n                    spans = (\n                        [document.get_block(span_id) for span_id in line.structure]\n                        if line.structure\n                        else []\n                    )\n                    children = []\n                    for span in spans:\n                        if not span.structure:\n                            continue\n\n                        span_chars = [\n                            document.get_block(char_id) for char_id in span.structure\n                        ]\n                        children.extend(\n                            [\n                                OCRJSONCharOutput(\n                                    id=str(char.id),\n                                    block_type=str(char.block_type),\n                                    text=char.text,\n                                    polygon=char.polygon.polygon,\n                                    bbox=char.polygon.bbox,\n                                )\n                                for char in span_chars\n                            ]\n                        )\n                    line_obj.children = children\n                lines.append(line_obj)\n\n            page = OCRJSONPageOutput(\n                id=str(page.id),\n                block_type=str(page.block_type),\n                polygon=page.polygon.polygon,\n                bbox=page.polygon.bbox,\n                children=lines,\n            )\n            pages.append(page)\n\n        return pages\n", "n_tokens": 445, "byte_len": 2888, "file_sha1": "74d49f2fcc7b466a03604cc512d7fdfe812fe361", "start_line": 55, "end_line": 132}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/ocr_json.py", "rel_path": "marker/renderers/ocr_json.py", "module": "marker.renderers.ocr_json", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "metadata", "document", "children", "extract", "json", "self", "none", "ocrjson", "output", "return", "call", "extract_json", "OCRJSONCharOutput", "OCRJSONLineOutput", "OCRJSONPageOutput", "OCRJSONOutput", "OCRJSONRenderer", "block", "type", "bbox", "page", "formatted", "text", "class", "append", "equation", "tuple", "float", "line", "renderer", "char", "equations", "images", "annotated", "else", "html", "pydantic", "schema", "types", "spans", "span", "from", "chars", "dict", "obj", "get", "base", "model", "lines"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document) -> OCRJSONOutput:\n        return OCRJSONOutput(children=self.extract_json(document), metadata=None)\n", "n_tokens": 30, "byte_len": 143, "file_sha1": "74d49f2fcc7b466a03604cc512d7fdfe812fe361", "start_line": 133, "end_line": 135}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py", "rel_path": "marker/renderers/html.py", "module": "marker.renderers.html", "ext": "py", "chunk_number": 1, "symbols": ["HTMLOutput", "HTMLRenderer", "image", "textwrap", "class", "none", "tuple", "html", "output", "renderer", "blocks", "page", "warnings", "images", "annotated", "metadata", "decompression", "bomb", "pydantic", "filterwarnings", "schema", "suppress", "types", "settings", "from", "dict", "whether", "base", "model", "paginate", "extract_image", "insert_block_id", "extract_html", "__call__", "generate", "document", "block", "config", "break", "indentation", "found", "outermost", "tag", "content", "refs", "description", "outpu", "imag", "return", "insert"], "ast_kind": "class_or_type", "text": "import textwrap\n\nfrom PIL import Image\nfrom typing import Annotated, Tuple\n\nfrom bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\nfrom pydantic import BaseModel\n\nfrom marker.renderers import BaseRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import BlockId\nfrom marker.settings import settings\n\n# Ignore beautifulsoup warnings\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n\n# Suppress DecompressionBombError\nImage.MAX_IMAGE_PIXELS = None\n\n\nclass HTMLOutput(BaseModel):\n    html: str\n    images: dict\n    metadata: dict\n\n\nclass HTMLRenderer(BaseRenderer):\n    \"\"\"\n    A renderer for HTML output.\n    \"\"\"\n\n    page_blocks: Annotated[\n        Tuple[BlockTypes],\n        \"The block types to consider as pages.\",\n    ] = (BlockTypes.Page,)\n    paginate_output: Annotated[\n        bool,\n        \"Whether to paginate the output.\",\n    ] = False\n", "n_tokens": 200, "byte_len": 915, "file_sha1": "e62890961c1ba131f31cb234af88e6ac6f07a31a", "start_line": 1, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py", "rel_path": "marker/renderers/html.py", "module": "marker.renderers.html", "ext": "py", "chunk_number": 2, "symbols": ["extract_image", "image", "block", "document", "self", "get", "highres", "extraction", "cropped", "return", "extract", "insert_block_id", "extract_html", "__call__", "HTMLOutput", "HTMLRenderer", "generate", "config", "renderer", "break", "warnings", "indentation", "found", "outermost", "tag", "dict", "content", "refs", "description", "outpu", "imag", "insert", "children", "paginate", "markup", "resembles", "replace", "with", "pixels", "tags", "page", "output", "only", "bool", "marker", "span", "html", "call", "type", "textwrap"], "ast_kind": "function_or_method", "text": "    def extract_image(self, document, image_id):\n        image_block = document.get_block(image_id)\n        cropped = image_block.get_image(\n            document, highres=self.image_extraction_mode == \"highres\"\n        )\n        return cropped\n", "n_tokens": 49, "byte_len": 244, "file_sha1": "e62890961c1ba131f31cb234af88e6ac6f07a31a", "start_line": 43, "end_line": 49}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py", "rel_path": "marker/renderers/html.py", "module": "marker.renderers.html", "ext": "py", "chunk_number": 3, "symbols": ["insert_block_id", "block", "type", "elif", "add", "none", "text", "into", "hasattr", "outermost", "line", "navigable", "string", "soup", "break", "content", "insert", "find", "contains", "append", "found", "self", "first", "tag", "span", "new", "attribute", "return", "data", "contents", "extract_image", "extract_html", "__call__", "HTMLOutput", "HTMLRenderer", "generate", "document", "config", "renderer", "warnings", "image", "indentation", "dict", "refs", "description", "outpu", "imag", "children", "paginate", "markup"], "ast_kind": "function_or_method", "text": "    def insert_block_id(self, soup, block_id: BlockId):\n        \"\"\"\n        Insert a block ID into the soup as a data attribute.\n        \"\"\"\n        if block_id.block_type in [BlockTypes.Line, BlockTypes.Span]:\n            return soup\n\n        if self.add_block_ids:\n            # Find the outermost tag (first tag that isn't a NavigableString)\n            outermost_tag = None\n            for element in soup.contents:\n                if hasattr(element, \"name\") and element.name:\n                    outermost_tag = element\n                    break\n\n            # If we found an outermost tag, add the data-block-id attribute\n            if outermost_tag:\n                outermost_tag[\"data-block-id\"] = str(block_id)\n\n            # If soup only contains text or no tags, wrap in a span\n            elif soup.contents:\n                wrapper = soup.new_tag(\"span\")\n                wrapper[\"data-block-id\"] = str(block_id)\n\n                contents = list(soup.contents)\n                for content in contents:\n                    content.extract()\n                    wrapper.append(content)\n                soup.append(wrapper)\n        return soup\n", "n_tokens": 225, "byte_len": 1155, "file_sha1": "e62890961c1ba131f31cb234af88e6ac6f07a31a", "start_line": 50, "end_line": 80}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py", "rel_path": "marker/renderers/html.py", "module": "marker.renderers.html", "ext": "py", "chunk_number": 4, "symbols": ["extract_html", "block", "type", "consecutive", "elif", "textwrap", "class", "doctype", "merge", "none", "document", "output", "find", "all", "inline", "parser", "mode", "head", "soup", "content", "break", "extract", "images", "insert", "image", "else", "charset", "html", "self", "path", "extract_image", "insert_block_id", "__call__", "HTMLOutput", "HTMLRenderer", "generate", "config", "renderer", "warnings", "indentation", "found", "outermost", "tag", "dict", "refs", "description", "outpu", "imag", "return", "children"], "ast_kind": "function_or_method", "text": "    def extract_html(self, document, document_output, level=0):\n        soup = BeautifulSoup(document_output.html, \"html.parser\")\n\n        content_refs = soup.find_all(\"content-ref\")\n        ref_block_id = None\n        images = {}\n        for ref in content_refs:\n            src = ref.get(\"src\")\n            sub_images = {}\n            content = \"\"\n            for item in document_output.children:\n                if item.id == src:\n                    content, sub_images_ = self.extract_html(document, item, level + 1)\n                    sub_images.update(sub_images_)\n                    ref_block_id: BlockId = item.id\n                    break\n\n            if ref_block_id.block_type in self.image_blocks:\n                if self.extract_images:\n                    image = self.extract_image(document, ref_block_id)\n                    image_name = f\"{ref_block_id.to_path()}.{settings.OUTPUT_IMAGE_FORMAT.lower()}\"\n                    images[image_name] = image\n                    element = BeautifulSoup(\n                        f\"<p>{content}<img src='{image_name}'></p>\", \"html.parser\"\n                    )\n                    ref.replace_with(self.insert_block_id(element, ref_block_id))\n                else:\n                    # This will be the image description if using llm mode, or empty if not\n                    element = BeautifulSoup(f\"{content}\", \"html.parser\")\n                    ref.replace_with(self.insert_block_id(element, ref_block_id))\n            elif ref_block_id.block_type in self.page_blocks:\n                images.update(sub_images)\n                if self.paginate_output:\n                    content = f\"<div class='page' data-page-id='{ref_block_id.page_id}'>{content}</div>\"\n                element = BeautifulSoup(f\"{content}\", \"html.parser\")\n                ref.replace_with(self.insert_block_id(element, ref_block_id))\n            else:\n                images.update(sub_images)\n                element = BeautifulSoup(f\"{content}\", \"html.parser\")\n                ref.replace_with(self.insert_block_id(element, ref_block_id))\n\n        output = str(soup)\n        if level == 0:\n            output = self.merge_consecutive_tags(output, \"b\")\n            output = self.merge_consecutive_tags(output, \"i\")\n            output = self.merge_consecutive_math(\n                output\n            )  # Merge consecutive inline math tags\n            output = textwrap.dedent(f\"\"\"\n            <!DOCTYPE html>\n            <html>\n                <head>\n                    <meta charset=\"utf-8\" />\n                </head>\n                <body>\n                    {output}\n                </body>\n            </html>\n\"\"\")\n\n        return output, images\n", "n_tokens": 510, "byte_len": 2690, "file_sha1": "e62890961c1ba131f31cb234af88e6ac6f07a31a", "start_line": 81, "end_line": 142}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/html.py", "rel_path": "marker/renderers/html.py", "module": "marker.renderers.html", "ext": "py", "chunk_number": 5, "symbols": ["__call__", "generate", "document", "full", "html", "output", "parser", "block", "config", "soup", "images", "indentation", "metadata", "self", "prettify", "return", "render", "beautiful", "extract", "call", "extract_image", "insert_block_id", "extract_html", "HTMLOutput", "HTMLRenderer", "renderer", "break", "warnings", "image", "found", "outermost", "tag", "dict", "content", "refs", "description", "outpu", "imag", "insert", "children", "paginate", "markup", "resembles", "replace", "with", "pixels", "tags", "page", "only", "bool"], "ast_kind": "function_or_method", "text": "    def __call__(self, document) -> HTMLOutput:\n        document_output = document.render(self.block_config)\n        full_html, images = self.extract_html(document, document_output)\n        soup = BeautifulSoup(full_html, \"html.parser\")\n        full_html = soup.prettify()  # Add indentation to the HTML\n        return HTMLOutput(\n            html=full_html,\n            images=images,\n            metadata=self.generate_document_metadata(document, document_output),\n        )\n", "n_tokens": 100, "byte_len": 477, "file_sha1": "e62890961c1ba131f31cb234af88e6ac6f07a31a", "start_line": 143, "end_line": 153}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 1, "symbols": ["assign", "config", "tuple", "base", "blocks", "annotated", "base64", "pydantic", "block", "output", "schema", "document", "settings", "from", "collections", "model", "blockid", "typing", "types", "optional", "import", "marker", "util", "beautiful", "soup", "counter", "literal", "__init__", "__call__", "extract_image", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "generate_page_stats", "generate_document_metadata", "extract_block_html", "BaseRenderer", "generate", "header", "whitespace", "break", "page", "stats", "dump", "dict", "content", "refs", "format", "convert", "outpu"], "ast_kind": "imports", "text": "import base64\nimport io\nimport re\nfrom collections import Counter\nfrom typing import Annotated, Optional, Tuple, Literal\n\nfrom bs4 import BeautifulSoup\nfrom pydantic import BaseModel\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks.base import BlockId, BlockOutput\nfrom marker.schema.document import Document\nfrom marker.settings import settings\nfrom marker.util import assign_config\n\n", "n_tokens": 79, "byte_len": 400, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 2, "symbols": ["BaseRenderer", "extract", "class", "header", "add", "block", "highres", "tuple", "literal", "consider", "mode", "extracting", "images", "annotated", "lowres", "html", "document", "types", "from", "whether", "footer", "figure", "keep", "pageheader", "picture", "output", "bool", "image", "blocks", "false", "__init__", "__call__", "extract_image", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "generate_page_stats", "generate_document_metadata", "extract_block_html", "generate", "base", "whitespace", "config", "break", "page", "stats", "base64", "model", "dump", "dict"], "ast_kind": "class_or_type", "text": "class BaseRenderer:\n    image_blocks: Annotated[\n        Tuple[BlockTypes, ...], \"The block types to consider as images.\"\n    ] = (BlockTypes.Picture, BlockTypes.Figure)\n    extract_images: Annotated[bool, \"Extract images from the document.\"] = True\n    image_extraction_mode: Annotated[\n        Literal[\"lowres\", \"highres\"],\n        \"The mode to use for extracting images.\",\n    ] = \"highres\"\n    keep_pageheader_in_output: Annotated[\n        bool, \"Keep the page header in the output HTML.\"\n    ] = False\n    keep_pagefooter_in_output: Annotated[\n        bool, \"Keep the page footer in the output HTML.\"\n    ] = False\n    add_block_ids: Annotated[bool, \"Whether to add block IDs to the output HTML.\"] = (\n        False\n    )\n", "n_tokens": 180, "byte_len": 727, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 17, "end_line": 35}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "init", "assign", "config", "add", "block", "none", "document", "self", "dict", "children", "not", "implemented", "reading", "base", "model", "order", "keep", "pageheader", "optional", "raise", "pagefooter", "call", "extract_image", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "generate_page_stats", "generate_document_metadata", "extract_block_html", "BaseRenderer", "generate", "header", "whitespace", "break", "page", "stats", "base64", "output", "dump", "content", "refs", "format", "convert", "outpu", "imag", "return", "decode", "metadata"], "ast_kind": "function_or_method", "text": "    def __init__(self, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n\n        self.block_config = {\n            \"keep_pageheader_in_output\": self.keep_pageheader_in_output,\n            \"keep_pagefooter_in_output\": self.keep_pagefooter_in_output,\n            \"add_block_ids\": self.add_block_ids,\n        }\n\n    def __call__(self, document):\n        # Children are in reading order\n        raise NotImplementedError\n", "n_tokens": 96, "byte_len": 448, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 36, "end_line": 48}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 4, "symbols": ["extract_image", "highres", "save", "mode", "outpu", "encoding", "base", "base64", "document", "image", "self", "settings", "buffer", "format", "convert", "imag", "return", "rgba", "get", "block", "decode", "bytes", "bytesio", "cropped", "extract", "getvalue", "false", "encode", "b64encode", "extraction", "__init__", "__call__", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "generate_page_stats", "generate_document_metadata", "extract_block_html", "BaseRenderer", "generate", "header", "whitespace", "config", "break", "page", "stats", "output", "model", "dump", "dict"], "ast_kind": "function_or_method", "text": "    def extract_image(self, document: Document, image_id, to_base64=False):\n        image_block = document.get_block(image_id)\n        cropped = image_block.get_image(\n            document, highres=self.image_extraction_mode == \"highres\"\n        )\n\n        if to_base64:\n            image_buffer = io.BytesIO()\n            # RGBA to RGB\n            if not cropped.mode == \"RGB\":\n                cropped = cropped.convert(\"RGB\")\n\n            cropped.save(image_buffer, format=settings.OUTPUT_IMAGE_FORMAT)\n            cropped = base64.b64encode(image_buffer.getvalue()).decode(\n                settings.OUTPUT_ENCODING\n            )\n        return cropped\n", "n_tokens": 128, "byte_len": 655, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 49, "end_line": 66}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 5, "symbols": ["merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "else", "pattern", "html", "merge", "consecutive", "display", "math", "true", "while", "replace", "whitespace", "inline", "staticmethod", "new", "merged", "group", "match", "break", "return", "__init__", "__call__", "extract_image", "generate_page_stats", "generate_document_metadata", "extract_block_html", "BaseRenderer", "generate", "document", "header", "base", "block", "config", "page", "stats", "base64", "output", "model", "dump", "dict", "content", "refs", "format", "convert", "outpu", "imag", "decode", "children"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def merge_consecutive_math(html, tag=\"math\"):\n        if not html:\n            return html\n        pattern = rf\"-</{tag}>(\\s*)<{tag}>\"\n        html = re.sub(pattern, \" \", html)\n\n        pattern = rf'-</{tag}>(\\s*)<{tag} display=\"inline\">'\n        html = re.sub(pattern, \" \", html)\n        return html\n\n    @staticmethod\n    def merge_consecutive_tags(html, tag):\n        if not html:\n            return html\n\n        def replace_whitespace(match):\n            whitespace = match.group(1)\n            if len(whitespace) == 0:\n                return \"\"\n            else:\n                return \" \"\n\n        pattern = rf\"</{tag}>(\\s*)<{tag}>\"\n\n        while True:\n            new_merged = re.sub(pattern, replace_whitespace, html)\n            if new_merged == html:\n                break\n            html = new_merged\n\n        return html\n", "n_tokens": 199, "byte_len": 858, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 67, "end_line": 99}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 6, "symbols": ["generate_page_stats", "generate_document_metadata", "block", "type", "generate", "document", "none", "output", "table", "contents", "counts", "metadata", "page", "stats", "append", "self", "model", "dump", "return", "text", "extraction", "children", "debug", "data", "pages", "aggregate", "counter", "most", "common", "__init__", "__call__", "extract_image", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "extract_block_html", "BaseRenderer", "header", "base", "whitespace", "config", "break", "base64", "dict", "content", "refs", "format", "convert", "outpu", "imag"], "ast_kind": "function_or_method", "text": "    def generate_page_stats(self, document: Document, document_output):\n        page_stats = []\n        for page in document.pages:\n            block_counts = Counter(\n                [str(block.block_type) for block in page.children]\n            ).most_common()\n            block_metadata = page.aggregate_block_metadata()\n            page_stats.append(\n                {\n                    \"page_id\": page.page_id,\n                    \"text_extraction_method\": page.text_extraction_method,\n                    \"block_counts\": block_counts,\n                    \"block_metadata\": block_metadata.model_dump(),\n                }\n            )\n        return page_stats\n\n    def generate_document_metadata(self, document: Document, document_output):\n        metadata = {\n            \"table_of_contents\": document.table_of_contents,\n            \"page_stats\": self.generate_page_stats(document, document_output),\n        }\n        if document.debug_data_path is not None:\n            metadata[\"debug_data_path\"] = document.debug_data_path\n\n        return metadata\n", "n_tokens": 185, "byte_len": 1060, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 100, "end_line": 126}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/__init__.py", "rel_path": "marker/renderers/__init__.py", "module": "marker.renderers.__init__", "ext": "py", "chunk_number": 7, "symbols": ["extract_block_html", "block", "type", "none", "find", "all", "output", "parser", "soup", "content", "break", "base", "base64", "extract", "images", "else", "html", "document", "self", "refs", "return", "sub", "children", "replace", "with", "blockid", "image", "blocks", "ref", "beautiful", "__init__", "__call__", "extract_image", "merge_consecutive_math", "merge_consecutive_tags", "replace_whitespace", "generate_page_stats", "generate_document_metadata", "BaseRenderer", "generate", "header", "whitespace", "config", "page", "stats", "model", "dump", "dict", "format", "convert"], "ast_kind": "function_or_method", "text": "    def extract_block_html(self, document: Document, block_output: BlockOutput):\n        soup = BeautifulSoup(block_output.html, \"html.parser\")\n\n        content_refs = soup.find_all(\"content-ref\")\n        ref_block_id = None\n        images = {}\n        for ref in content_refs:\n            src = ref.get(\"src\")\n            sub_images = {}\n            for item in block_output.children:\n                if item.id == src:\n                    content, sub_images_ = self.extract_block_html(document, item)\n                    sub_images.update(sub_images_)\n                    ref_block_id: BlockId = item.id\n                    break\n\n            if ref_block_id.block_type in self.image_blocks and self.extract_images:\n                images[ref_block_id] = self.extract_image(\n                    document, ref_block_id, to_base64=True\n                )\n            else:\n                images.update(sub_images)\n                ref.replace_with(BeautifulSoup(content, \"html.parser\"))\n\n        if block_output.id.block_type in self.image_blocks and self.extract_images:\n            images[block_output.id] = self.extract_image(\n                document, block_output.id, to_base64=True\n            )\n\n        return str(soup), images\n", "n_tokens": 235, "byte_len": 1236, "file_sha1": "e4b5c561a5be152799d15e05705c7a98676ac493", "start_line": 127, "end_line": 157}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py", "rel_path": "marker/renderers/chunk.py", "module": "marker.renderers.chunk", "ext": "py", "chunk_number": 1, "symbols": ["collect_images", "FlatBlockOutput", "ChunkOutput", "block", "type", "bbox", "class", "none", "child", "float", "blocks", "json", "images", "else", "metadata", "html", "pydantic", "renderer", "schema", "document", "chunk", "output", "from", "flat", "dict", "page", "info", "return", "base", "model", "assemble_html_with_images", "json_to_chunks", "__call__", "ChunkRenderer", "generate", "config", "ids", "unescape", "extract", "content", "refs", "assemble", "children", "every", "getattr", "replace", "with", "attrs", "collect", "marker"], "ast_kind": "class_or_type", "text": "import html\nfrom typing import List, Dict\n\nfrom bs4 import BeautifulSoup\nfrom pydantic import BaseModel\n\nfrom marker.renderers.json import JSONRenderer, JSONBlockOutput\nfrom marker.schema.document import Document\n\n\nclass FlatBlockOutput(BaseModel):\n    id: str\n    block_type: str\n    html: str\n    page: int\n    polygon: List[List[float]]\n    bbox: List[float]\n    section_hierarchy: Dict[int, str] | None = None\n    images: dict | None = None\n\n\nclass ChunkOutput(BaseModel):\n    blocks: List[FlatBlockOutput]\n    page_info: Dict[int, dict]\n    metadata: dict\n\ndef collect_images(block: JSONBlockOutput) -> dict[str, str]:\n    if not getattr(block, \"children\", None):\n        return block.images or {}\n    else:\n        images = block.images or {}\n        for child_block in block.children:\n            images.update(collect_images(child_block))\n        return images\n", "n_tokens": 199, "byte_len": 869, "file_sha1": "fd7397f020e19ed24aedc1cd462342c45ac723d8", "start_line": 1, "end_line": 35}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py", "rel_path": "marker/renderers/chunk.py", "module": "marker.renderers.chunk", "ext": "py", "chunk_number": 2, "symbols": ["assemble_html_with_images", "block", "type", "none", "find", "all", "child", "html", "parser", "json", "soup", "content", "ids", "else", "unescape", "refs", "return", "assemble", "children", "getattr", "replace", "with", "attrs", "index", "image", "blocks", "beautiful", "src", "collect_images", "json_to_chunks", "__call__", "FlatBlockOutput", "ChunkOutput", "ChunkRenderer", "generate", "document", "config", "extract", "page", "info", "dict", "every", "collect", "images", "marker", "call", "chunk", "renderer", "split", "chunks"], "ast_kind": "function_or_method", "text": "def assemble_html_with_images(block: JSONBlockOutput, image_blocks: set[str]) -> str:\n    if not getattr(block, \"children\", None):\n        if block.block_type in image_blocks:\n            return f\"<p>{block.html}<img src='{block.id}'></p>\"\n        else:\n            return block.html\n\n    child_html = [assemble_html_with_images(child, image_blocks) for child in block.children]\n    child_ids = [child.id for child in block.children]\n\n    soup = BeautifulSoup(block.html, \"html.parser\")\n    content_refs = soup.find_all(\"content-ref\")\n    for ref in content_refs:\n        src_id = ref.attrs[\"src\"]\n        if src_id in child_ids:\n            ref.replace_with(child_html[child_ids.index(src_id)])\n\n    return html.unescape(str(soup))\n", "n_tokens": 166, "byte_len": 733, "file_sha1": "fd7397f020e19ed24aedc1cd462342c45ac723d8", "start_line": 36, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py", "rel_path": "marker/renderers/chunk.py", "module": "marker.renderers.chunk", "ext": "py", "chunk_number": 3, "symbols": ["json_to_chunks", "ChunkRenderer", "block", "type", "bbox", "split", "class", "json", "page", "images", "else", "html", "renderer", "flat", "return", "chunks", "assemble", "children", "list", "section", "hierarchy", "collect", "child", "polygon", "image", "blocks", "chunk", "collect_images", "assemble_html_with_images", "__call__", "FlatBlockOutput", "ChunkOutput", "generate", "document", "config", "ids", "unescape", "extract", "info", "dict", "content", "refs", "every", "getattr", "replace", "with", "attrs", "marker", "call", "find"], "ast_kind": "class_or_type", "text": "def json_to_chunks(\n    block: JSONBlockOutput, image_blocks: set[str], page_id: int=0) -> FlatBlockOutput | List[FlatBlockOutput]:\n    if block.block_type == \"Page\":\n        children = block.children\n        page_id = int(block.id.split(\"/\")[-1])\n        return [json_to_chunks(child, image_blocks, page_id=page_id) for child in children]\n    else:\n        return FlatBlockOutput(\n            id=block.id,\n            block_type=block.block_type,\n            html=assemble_html_with_images(block, image_blocks),\n            page=page_id,\n            polygon=block.polygon,\n            bbox=block.bbox,\n            section_hierarchy=block.section_hierarchy,\n            images=collect_images(block),\n        )\n\n\nclass ChunkRenderer(JSONRenderer):\n", "n_tokens": 163, "byte_len": 747, "file_sha1": "fd7397f020e19ed24aedc1cd462342c45ac723d8", "start_line": 55, "end_line": 75}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/chunk.py", "rel_path": "marker/renderers/chunk.py", "module": "marker.renderers.chunk", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "bbox", "chunks", "generate", "document", "output", "block", "config", "blocks", "metadata", "append", "self", "extract", "json", "chunk", "from", "page", "info", "return", "render", "children", "every", "this", "pages", "extend", "will", "polygon", "image", "item", "level", "collect_images", "assemble_html_with_images", "json_to_chunks", "FlatBlockOutput", "ChunkOutput", "ChunkRenderer", "child", "ids", "unescape", "dict", "content", "refs", "assemble", "html", "getattr", "replace", "with", "attrs", "collect", "images"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document) -> ChunkOutput:\n        document_output = document.render(self.block_config)\n        json_output = []\n        for page_output in document_output.children:\n            json_output.append(self.extract_json(document, page_output))\n\n        # This will get the top-level blocks from every page\n        chunk_output = []\n        for item in json_output:\n            chunks = json_to_chunks(item, set([str(block) for block in self.image_blocks]))\n            chunk_output.extend(chunks)\n\n        page_info = {\n            page.page_id: {\"bbox\": page.polygon.bbox, \"polygon\": page.polygon.polygon}\n            for page in document.pages\n        }\n\n        return ChunkOutput(\n            blocks=chunk_output,\n            page_info=page_info,\n            metadata=self.generate_document_metadata(document, document_output),\n        )\n", "n_tokens": 171, "byte_len": 869, "file_sha1": "fd7397f020e19ed24aedc1cd462342c45ac723d8", "start_line": 76, "end_line": 98}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/extraction.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/extraction.py", "rel_path": "marker/renderers/extraction.py", "module": "marker.renderers.extraction", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "ExtractionOutput", "ExtractionRenderer", "here", "class", "markdown", "soon", "analysis", "document", "extraction", "original", "more", "leave", "want", "complex", "pydantic", "self", "from", "return", "base", "model", "definitely", "stuff", "renderers", "output", "import", "extractors", "marker", "renderer", "json", "call"], "ast_kind": "class_or_type", "text": "from pydantic import BaseModel\n\nfrom marker.extractors.document import DocumentExtractionSchema\nfrom marker.renderers import BaseRenderer\n\n\nclass ExtractionOutput(BaseModel):\n    analysis: str\n    document_json: str\n    original_markdown: str\n\n\nclass ExtractionRenderer(BaseRenderer):\n    def __call__(\n        self, output: DocumentExtractionSchema, markdown: str\n    ) -> ExtractionOutput:\n        # We definitely want to do more complex stuff here soon, so leave it in\n        return ExtractionOutput(\n            analysis=output.analysis,\n            document_json=output.document_json,\n            original_markdown=markdown,\n        )\n", "n_tokens": 125, "byte_len": 641, "file_sha1": "02d2c19c135fe961a2392fdd76ab2341cee87be1", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 1, "symbols": ["escape_dollars", "cleanup_text", "markdown", "converter", "full", "text", "tuple", "navigable", "string", "get", "logger", "cleanup", "annotated", "html", "escape", "dollars", "pydantic", "document", "schema", "from", "collections", "renderer", "markdownify", "whitespace", "return", "base", "model", "replace", "strip", "typing", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "generate", "header", "content", "str", "row"], "ast_kind": "function_or_method", "text": "import re\nfrom collections import defaultdict\nfrom typing import Annotated, Tuple\n\nimport regex\nimport six\nfrom bs4 import NavigableString\nfrom markdownify import MarkdownConverter, re_whitespace\nfrom marker.logger import get_logger\nfrom pydantic import BaseModel\n\nfrom marker.renderers.html import HTMLRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\nlogger = get_logger()\n\n\ndef escape_dollars(text):\n    return text.replace(\"$\", r\"\\$\")\n\n\ndef cleanup_text(full_text):\n    full_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", full_text)\n    full_text = re.sub(r\"(\\n\\s){3,}\", \"\\n\\n\", full_text)\n    return full_text.strip()\n\n", "n_tokens": 154, "byte_len": 651, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 2, "symbols": ["get_formatted_table_text", "Markdownify", "elif", "markdown", "converter", "class", "full", "text", "none", "content", "str", "navigable", "string", "else", "escape", "dollars", "get", "formatted", "append", "return", "contents", "math", "strip", "enumerate", "continue", "isinstance", "markdownify", "element", "stripped", "name", "escape_dollars", "cleanup_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "process_text", "md_cls", "__call__", "MarkdownOutput", "MarkdownRenderer", "generate", "document", "header", "row", "cols"], "ast_kind": "class_or_type", "text": "def get_formatted_table_text(element):\n    text = []\n    for content in element.contents:\n        if content is None:\n            continue\n\n        if isinstance(content, NavigableString):\n            stripped = content.strip()\n            if stripped:\n                text.append(escape_dollars(stripped))\n        elif content.name == \"br\":\n            text.append(\"<br>\")\n        elif content.name == \"math\":\n            text.append(\"$\" + content.text + \"$\")\n        else:\n            content_str = escape_dollars(str(content))\n            text.append(content_str)\n\n    full_text = \"\"\n    for i, t in enumerate(text):\n        if t == \"<br>\":\n            full_text += t\n        elif i > 0 and text[i - 1] != \"<br>\":\n            full_text += \" \" + t\n        else:\n            full_text += t\n    return full_text\n\n\nclass Markdownify(MarkdownConverter):", "n_tokens": 189, "byte_len": 851, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 29, "end_line": 58}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "convert_div", "inline", "math", "init", "class", "has", "attr", "text", "else", "convert", "div", "self", "page", "separator", "kwargs", "return", "data", "pagination", "item", "super", "paginate", "output", "parent", "tags", "block", "escape_dollars", "cleanup_text", "get_formatted_table_text", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "escape", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "markdown", "generate", "document", "header", "content", "str", "row", "cols"], "ast_kind": "function_or_method", "text": "    def __init__(\n        self,\n        paginate_output,\n        page_separator,\n        inline_math_delimiters,\n        block_math_delimiters,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.paginate_output = paginate_output\n        self.page_separator = page_separator\n        self.inline_math_delimiters = inline_math_delimiters\n        self.block_math_delimiters = block_math_delimiters\n\n    def convert_div(self, el, text, parent_tags):\n        is_page = el.has_attr(\"class\") and el[\"class\"][0] == \"page\"\n        if self.paginate_output and is_page:\n            page_id = el[\"data-page-id\"]\n            pagination_item = (\n                \"\\n\\n\" + \"{\" + str(page_id) + \"}\" + self.page_separator + \"\\n\\n\"\n            )\n            return pagination_item + text\n        else:\n            return text\n", "n_tokens": 182, "byte_len": 828, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 59, "end_line": 83}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 4, "symbols": ["convert_p", "block", "type", "split", "class", "has", "attr", "text", "handle", "default", "convert", "else", "continuation", "hypenation", "self", "return", "list", "group", "parent", "tags", "types", "across", "pages", "regex", "inline", "compile", "hyphens", "dotall", "match", "behavior", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "escape", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "markdown", "generate", "document"], "ast_kind": "function_or_method", "text": "    def convert_p(self, el, text, parent_tags):\n        hyphens = r\"-\"\n        has_continuation = el.has_attr(\"class\") and \"has-continuation\" in el[\"class\"]\n        if has_continuation:\n            block_type = BlockTypes[el[\"block-type\"]]\n            if block_type in [BlockTypes.TextInlineMath, BlockTypes.Text]:\n                if regex.compile(\n                    rf\".*[\\p{{Ll}}|\\d][{hyphens}]\\s?$\", regex.DOTALL\n                ).match(text):  # handle hypenation across pages\n                    return regex.split(rf\"[{hyphens}]\\s?$\", text)[0]\n                return f\"{text} \"\n            if block_type == BlockTypes.ListGroup:\n                return f\"{text}\"\n        return f\"{text}\\n\\n\" if text else \"\"  # default convert_p behavior\n", "n_tokens": 189, "byte_len": 750, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 84, "end_line": 98}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 5, "symbols": ["convert_math", "else", "inline", "math", "block", "has", "attr", "display", "convert", "self", "text", "strip", "parent", "tags", "return", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_table", "add_header_line", "convert_a", "convert_span", "escape", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "markdown", "generate", "document", "header", "content", "str", "row", "cols", "whitespace", "config", "embedded", "dict", "page", "separator", "last", "correct", "sometimes", "list"], "ast_kind": "function_or_method", "text": "    def convert_math(self, el, text, parent_tags):\n        block = el.has_attr(\"display\") and el[\"display\"] == \"block\"\n        if block:\n            return (\n                \"\\n\"\n                + self.block_math_delimiters[0]\n                + text.strip()\n                + self.block_math_delimiters[1]\n                + \"\\n\"\n            )\n        else:\n            return (\n                \" \"\n                + self.inline_math_delimiters[0]\n                + text.strip()\n                + self.inline_math_delimiters[1]\n                + \" \"\n            )\n", "n_tokens": 114, "byte_len": 563, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 99, "end_line": 117}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 6, "symbols": ["convert_table", "overflow", "text", "total", "rows", "find", "all", "row", "cols", "none", "idx", "skip", "predictions", "range", "else", "col", "append", "get", "formatted", "self", "while", "fill", "grid", "correct", "cell", "sometimes", "empty", "filled", "except", "colspan", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "add_header_line", "convert_a", "convert_span", "escape", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "markdown", "generate", "document"], "ast_kind": "function_or_method", "text": "    def convert_table(self, el, text, parent_tags):\n        total_rows = len(el.find_all(\"tr\"))\n        colspans = []\n        rowspan_cols = defaultdict(int)\n        for i, row in enumerate(el.find_all(\"tr\")):\n            row_cols = rowspan_cols[i]\n            for cell in row.find_all([\"td\", \"th\"]):\n                colspan = int(cell.get(\"colspan\", 1))\n                row_cols += colspan\n                for r in range(int(cell.get(\"rowspan\", 1)) - 1):\n                    rowspan_cols[i + r] += (\n                        colspan  # Add the colspan to the next rows, so they get the correct number of columns\n                    )\n            colspans.append(row_cols)\n        total_cols = max(colspans) if colspans else 0\n\n        grid = [[None for _ in range(total_cols)] for _ in range(total_rows)]\n\n        for row_idx, tr in enumerate(el.find_all(\"tr\")):\n            col_idx = 0\n            for cell in tr.find_all([\"td\", \"th\"]):\n                # Skip filled positions\n                while col_idx < total_cols and grid[row_idx][col_idx] is not None:\n                    col_idx += 1\n\n                # Fill in grid\n                value = (\n                    get_formatted_table_text(cell)\n                    .replace(\"\\n\", \" \")\n                    .replace(\"|\", \" \")\n                    .strip()\n                )\n                rowspan = int(cell.get(\"rowspan\", 1))\n                colspan = int(cell.get(\"colspan\", 1))\n\n                if col_idx >= total_cols:\n                    # Skip this cell if we're out of bounds\n                    continue\n\n                for r in range(rowspan):\n                    for c in range(colspan):\n                        try:\n                            if r == 0 and c == 0:\n                                grid[row_idx][col_idx] = value\n                            else:\n                                grid[row_idx + r][col_idx + c] = (\n                                    \"\"  # Empty cell due to rowspan/colspan\n                                )\n                        except IndexError:\n                            # Sometimes the colspan/rowspan predictions can overflow\n                            logger.info(\n                                f\"Overflow in columns: {col_idx + c} >= {total_cols} or rows: {row_idx + r} >= {total_rows}\"\n                            )\n                            continue\n\n                col_idx += colspan\n\n        markdown_lines = []\n        col_widths = [0] * total_cols\n        for row in grid:\n            for col_idx, cell in enumerate(row):\n                if cell is not None:\n                    col_widths[col_idx] = max(col_widths[col_idx], len(str(cell)))\n", "n_tokens": 538, "byte_len": 2667, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 118, "end_line": 181}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 7, "symbols": ["add_header_line", "markdown", "header", "none", "tables", "total", "rows", "skip", "handle", "col", "idx", "append", "line", "grid", "return", "when", "adding", "padding", "leading", "lines", "enumerate", "added", "table", "blank", "add", "continue", "width", "widths", "empty", "false", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "convert_a", "convert_span", "escape", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "generate", "document", "content"], "ast_kind": "function_or_method", "text": "        def add_header_line():\n            markdown_lines.append(\n                \"|\" + \"|\".join(\"-\" * (width + 2) for width in col_widths) + \"|\"\n            )\n\n        # Generate markdown rows\n        added_header = False\n        for i, row in enumerate(grid):\n            is_empty_line = all(not cell for cell in row)\n            if is_empty_line and not added_header:\n                # Skip leading blank lines\n                continue\n\n            line = []\n            for col_idx, cell in enumerate(row):\n                if cell is None:\n                    cell = \"\"\n                padding = col_widths[col_idx] - len(str(cell))\n                line.append(f\" {cell}{' ' * padding} \")\n            markdown_lines.append(\"|\" + \"|\".join(line) + \"|\")\n\n            if not added_header:\n                # Skip empty lines when adding the header row\n                add_header_line()\n                added_header = True\n\n        # Handle one row tables\n        if total_rows == 1:\n            add_header_line()\n\n        table_md = \"\\n\".join(markdown_lines)\n        return \"\\n\\n\" + table_md + \"\\n\\n\"\n", "n_tokens": 233, "byte_len": 1100, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 182, "end_line": 214}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 8, "symbols": ["convert_a", "convert_span", "escape", "else", "brackets", "super", "dollars", "parentheses", "text", "self", "convert", "return", "none", "replace", "options", "parent", "tags", "span", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "process_text", "md_cls", "__call__", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "markdown", "generate", "document", "header", "content", "str", "row", "cols", "whitespace", "block", "config", "embedded", "dict", "page", "separator", "last", "correct"], "ast_kind": "function_or_method", "text": "    def convert_a(self, el, text, parent_tags):\n        text = self.escape(text)\n        # Escape brackets and parentheses in text\n        text = re.sub(r\"([\\[\\]()])\", r\"\\\\\\1\", text)\n        return super().convert_a(el, text, parent_tags)\n\n    def convert_span(self, el, text, parent_tags):\n        if el.get(\"id\"):\n            return f'<span id=\"{el[\"id\"]}\">{text}</span>'\n        else:\n            return text\n\n    def escape(self, text, parent_tags=None):\n        text = super().escape(text, parent_tags)\n        if self.options[\"escape_dollars\"]:\n            text = text.replace(\"$\", r\"\\$\")\n        return text\n", "n_tokens": 150, "byte_len": 615, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 215, "end_line": 232}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 9, "symbols": ["process_text", "MarkdownOutput", "remove", "class", "markdown", "find", "parent", "text", "none", "whitespace", "output", "characters", "next", "sibling", "true", "preformatted", "images", "metadata", "normalize", "self", "trailing", "embedded", "dict", "node", "following", "last", "return", "current", "base", "model", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "escape", "md_cls", "__call__", "Markdownify", "MarkdownRenderer", "generate", "document", "header", "content"], "ast_kind": "class_or_type", "text": "    def process_text(self, el, parent_tags=None):\n        text = six.text_type(el) or \"\"\n\n        # normalize whitespace if we're not inside a preformatted element\n        if not el.find_parent(\"pre\"):\n            text = re_whitespace.sub(\" \", text)\n\n        # escape special characters if we're not inside a preformatted or code element\n        if not el.find_parent([\"pre\", \"code\", \"kbd\", \"samp\", \"math\"]):\n            text = self.escape(text)\n\n        # remove trailing whitespaces if any of the following condition is true:\n        # - current text node is the last node in li\n        # - current text node is followed by an embedded list\n        if el.parent.name == \"li\" and (\n            not el.next_sibling or el.next_sibling.name in [\"ul\", \"ol\"]\n        ):\n            text = text.rstrip()\n\n        return text\n\n\nclass MarkdownOutput(BaseModel):\n    markdown: str\n    images: dict\n    metadata: dict\n\n", "n_tokens": 203, "byte_len": 910, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 233, "end_line": 260}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 10, "symbols": ["md_cls", "MarkdownRenderer", "inline", "math", "class", "bullets", "tuple", "between", "escape", "misc", "annotated", "asterisks", "dollars", "self", "page", "separator", "html", "renderer", "return", "heading", "style", "property", "paginate", "output", "sup", "symbol", "pages", "default", "cls", "underscores", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "process_text", "__call__", "Markdownify", "MarkdownOutput", "markdown", "generate", "document", "header", "content"], "ast_kind": "class_or_type", "text": "class MarkdownRenderer(HTMLRenderer):\n    page_separator: Annotated[\n        str, \"The separator to use between pages.\", \"Default is '-' * 48.\"\n    ] = \"-\" * 48\n    inline_math_delimiters: Annotated[\n        Tuple[str], \"The delimiters to use for inline math.\"\n    ] = (\"$\", \"$\")\n    block_math_delimiters: Annotated[\n        Tuple[str], \"The delimiters to use for block math.\"\n    ] = (\"$$\", \"$$\")\n\n    @property\n    def md_cls(self):\n        return Markdownify(\n            self.paginate_output,\n            self.page_separator,\n            heading_style=\"ATX\",\n            bullets=\"-\",\n            escape_misc=False,\n            escape_underscores=True,\n            escape_asterisks=True,\n            escape_dollars=True,\n            sub_symbol=\"<sub>\",\n            sup_symbol=\"<sup>\",\n            inline_math_delimiters=self.inline_math_delimiters,\n            block_math_delimiters=self.block_math_delimiters,\n        )\n", "n_tokens": 202, "byte_len": 925, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 261, "end_line": 288}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/markdown.py", "rel_path": "marker/renderers/markdown.py", "module": "marker.renderers.markdown", "ext": "py", "chunk_number": 11, "symbols": ["__call__", "markdown", "generate", "document", "full", "html", "output", "block", "config", "startswith", "pagination", "cleanup", "text", "images", "metadata", "self", "page", "separator", "correct", "convert", "return", "render", "ensure", "markers", "paginate", "cls", "endswith", "blanks", "extract", "call", "escape_dollars", "cleanup_text", "get_formatted_table_text", "__init__", "convert_div", "convert_p", "convert_math", "convert_table", "add_header_line", "convert_a", "convert_span", "escape", "process_text", "md_cls", "Markdownify", "MarkdownOutput", "MarkdownRenderer", "header", "content", "str"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document) -> MarkdownOutput:\n        document_output = document.render(self.block_config)\n        full_html, images = self.extract_html(document, document_output)\n        markdown = self.md_cls.convert(full_html)\n        markdown = cleanup_text(markdown)\n\n        # Ensure we set the correct blanks for pagination markers\n        if self.paginate_output:\n            if not markdown.startswith(\"\\n\\n\"):\n                markdown = \"\\n\\n\" + markdown\n            if markdown.endswith(self.page_separator):\n                markdown += \"\\n\\n\"\n\n        return MarkdownOutput(\n            markdown=markdown,\n            images=images,\n            metadata=self.generate_document_metadata(document, document_output),\n        )\n", "n_tokens": 138, "byte_len": 752, "file_sha1": "c541af79a9af5f8c7ddeaf2f6eb6279ebb5dcb34", "start_line": 289, "end_line": 307}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py", "rel_path": "marker/renderers/json.py", "module": "marker.renderers.json", "ext": "py", "chunk_number": 1, "symbols": ["reformat_section_hierarchy", "JSONBlockOutput", "JSONOutput", "block", "type", "bbox", "class", "none", "tuple", "float", "blocks", "json", "images", "annotated", "metadata", "html", "pydantic", "output", "schema", "document", "from", "dict", "reformat", "section", "return", "base", "model", "children", "list", "hierarchy", "extract_json", "__call__", "JSONRenderer", "generate", "renderer", "config", "page", "else", "types", "extract", "self", "append", "call", "render", "figure", "get", "typing", "child", "picture", "renderers"], "ast_kind": "class_or_type", "text": "from typing import Annotated, Dict, List, Tuple\n\nfrom pydantic import BaseModel\n\nfrom marker.renderers import BaseRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockOutput\nfrom marker.schema.document import Document\nfrom marker.schema.registry import get_block_class\n\n\nclass JSONBlockOutput(BaseModel):\n    id: str\n    block_type: str\n    html: str\n    polygon: List[List[float]]\n    bbox: List[float]\n    children: List[\"JSONBlockOutput\"] | None = None\n    section_hierarchy: Dict[int, str] | None = None\n    images: dict | None = None\n\n\nclass JSONOutput(BaseModel):\n    children: List[JSONBlockOutput]\n    block_type: str = str(BlockTypes.Document)\n    metadata: dict\n\n\ndef reformat_section_hierarchy(section_hierarchy):\n    new_section_hierarchy = {}\n    for key, value in section_hierarchy.items():\n        new_section_hierarchy[key] = str(value)\n    return new_section_hierarchy\n\n", "n_tokens": 204, "byte_len": 925, "file_sha1": "73aedf0cb6d29e0b643c9e7ed95a1dd30f47e7fa", "start_line": 1, "end_line": 35}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py", "rel_path": "marker/renderers/json.py", "module": "marker.renderers.json", "ext": "py", "chunk_number": 2, "symbols": ["JSONRenderer", "class", "tuple", "renderer", "page", "images", "annotated", "json", "types", "figure", "blocks", "block", "picture", "pages", "output", "image", "list", "base", "consider", "reformat_section_hierarchy", "extract_json", "__call__", "JSONBlockOutput", "JSONOutput", "type", "bbox", "generate", "document", "none", "float", "config", "metadata", "else", "html", "pydantic", "schema", "extract", "self", "from", "append", "dict", "reformat", "section", "return", "model", "children", "call", "hierarchy", "render", "get"], "ast_kind": "class_or_type", "text": "class JSONRenderer(BaseRenderer):\n    \"\"\"\n    A renderer for JSON output.\n    \"\"\"\n\n    image_blocks: Annotated[\n        Tuple[BlockTypes],\n        \"The list of block types to consider as images.\",\n    ] = (BlockTypes.Picture, BlockTypes.Figure)\n    page_blocks: Annotated[\n        Tuple[BlockTypes],\n        \"The list of block types to consider as pages.\",\n    ] = (BlockTypes.Page,)\n", "n_tokens": 89, "byte_len": 384, "file_sha1": "73aedf0cb6d29e0b643c9e7ed95a1dd30f47e7fa", "start_line": 36, "end_line": 49}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py", "rel_path": "marker/renderers/json.py", "module": "marker.renderers.json", "ext": "py", "chunk_number": 3, "symbols": ["extract_json", "block", "type", "bbox", "output", "base", "json", "images", "else", "html", "document", "extract", "self", "append", "reformat", "section", "return", "children", "hierarchy", "get", "child", "polygon", "reformat_section_hierarchy", "__call__", "JSONBlockOutput", "JSONOutput", "JSONRenderer", "class", "generate", "none", "tuple", "float", "renderer", "blocks", "config", "page", "annotated", "metadata", "pydantic", "schema", "types", "from", "dict", "model", "call", "list", "render", "figure", "typing", "picture"], "ast_kind": "function_or_method", "text": "    def extract_json(self, document: Document, block_output: BlockOutput):\n        cls = get_block_class(block_output.id.block_type)\n        if cls.__base__ == Block:\n            html, images = self.extract_block_html(document, block_output)\n            return JSONBlockOutput(\n                html=html,\n                polygon=block_output.polygon.polygon,\n                bbox=block_output.polygon.bbox,\n                id=str(block_output.id),\n                block_type=str(block_output.id.block_type),\n                images=images,\n                section_hierarchy=reformat_section_hierarchy(\n                    block_output.section_hierarchy\n                ),\n            )\n        else:\n            children = []\n            for child in block_output.children:\n                child_output = self.extract_json(document, child)\n                children.append(child_output)\n\n            return JSONBlockOutput(\n                html=block_output.html,\n                polygon=block_output.polygon.polygon,\n                bbox=block_output.polygon.bbox,\n                id=str(block_output.id),\n                block_type=str(block_output.id.block_type),\n                children=children,\n                section_hierarchy=reformat_section_hierarchy(\n                    block_output.section_hierarchy\n                ),\n            )\n", "n_tokens": 227, "byte_len": 1346, "file_sha1": "73aedf0cb6d29e0b643c9e7ed95a1dd30f47e7fa", "start_line": 50, "end_line": 82}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/renderers/json.py", "rel_path": "marker/renderers/json.py", "module": "marker.renderers.json", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "page", "output", "metadata", "document", "render", "children", "json", "generate", "append", "self", "extract", "block", "config", "return", "call", "reformat_section_hierarchy", "extract_json", "JSONBlockOutput", "JSONOutput", "JSONRenderer", "type", "bbox", "class", "none", "tuple", "float", "base", "renderer", "blocks", "images", "annotated", "else", "html", "pydantic", "schema", "types", "from", "dict", "reformat", "section", "model", "list", "hierarchy", "figure", "get", "typing", "child", "picture", "renderers"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document) -> JSONOutput:\n        document_output = document.render(self.block_config)\n        json_output = []\n        for page_output in document_output.children:\n            json_output.append(self.extract_json(document, page_output))\n        return JSONOutput(\n            children=json_output,\n            metadata=self.generate_document_metadata(document, document_output),\n        )\n", "n_tokens": 74, "byte_len": 422, "file_sha1": "73aedf0cb6d29e0b643c9e7ed95a1dd30f47e7fa", "start_line": 83, "end_line": 92}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 1, "symbols": ["layout", "box", "builders", "annotated", "predictor", "document", "schema", "settings", "providers", "from", "base", "builder", "surya", "list", "get", "block", "typing", "types", "import", "marker", "groups", "polygon", "registry", "page", "result", "pdf", "provider", "group", "__init__", "__call__", "get_batch_size", "forced_layout", "surya_layout", "expand_layout_blocks", "add_blocks_to_pages", "LayoutBuilder", "performing", "model", "force", "full", "cls", "config", "disable", "return", "rescale", "sorted", "children", "every", "expand", "bounds"], "ast_kind": "imports", "text": "from typing import Annotated, List\n\nfrom surya.layout import LayoutPredictor\nfrom surya.layout.schema import LayoutResult, LayoutBox\n\nfrom marker.builders import BaseBuilder\nfrom marker.providers.pdf import PdfProvider\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups.page import PageGroup\nfrom marker.schema.polygon import PolygonBox\nfrom marker.schema.registry import get_block_class\nfrom marker.settings import settings\n\n", "n_tokens": 91, "byte_len": 482, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 2, "symbols": ["LayoutBuilder", "results", "performing", "class", "bars", "disable", "tqdm", "none", "injected", "into", "model", "skip", "float", "force", "layout", "specific", "default", "annotated", "progress", "max", "expand", "merging", "fraction", "document", "types", "does", "size", "since", "base", "builder", "__init__", "__call__", "get_batch_size", "forced_layout", "surya_layout", "expand_layout_blocks", "add_blocks_to_pages", "result", "full", "block", "cls", "config", "return", "rescale", "sorted", "page", "children", "every", "bounds", "provider"], "ast_kind": "class_or_type", "text": "class LayoutBuilder(BaseBuilder):\n    \"\"\"\n    A builder for performing layout detection on PDF pages and merging the results into the document.\n    \"\"\"\n\n    layout_batch_size: Annotated[\n        int,\n        \"The batch size to use for the layout model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    force_layout_block: Annotated[\n        str,\n        \"Skip layout and force every page to be treated as a specific block type.\",\n    ] = None\n    disable_tqdm: Annotated[\n        bool,\n        \"Disable tqdm progress bars.\",\n    ] = False\n    expand_block_types: Annotated[\n        List[BlockTypes],\n        \"Block types whose bounds should be expanded to accomodate missing regions\",\n    ] = [\n        BlockTypes.Picture,\n        BlockTypes.Figure,\n        BlockTypes.ComplexRegion,\n    ]  # Does not include groups since they are only injected later\n    max_expand_frac: Annotated[\n        float, \"The maximum fraction to expand the layout box bounds by\"\n    ] = 0.05\n", "n_tokens": 228, "byte_len": 1021, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 16, "end_line": 45}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "get_batch_size", "elif", "init", "none", "layout", "model", "force", "surya", "content", "expand", "else", "predictor", "full", "document", "self", "config", "settings", "torc", "devic", "return", "batch", "add", "blocks", "super", "every", "single", "provider", "pages", "forced_layout", "surya_layout", "expand_layout_blocks", "add_blocks_to_pages", "LayoutBuilder", "performing", "result", "block", "cls", "disable", "rescale", "sorted", "page", "builder", "children", "bounds", "default", "whose", "only", "continue"], "ast_kind": "function_or_method", "text": "    def __init__(self, layout_model: LayoutPredictor, config=None):\n        self.layout_model = layout_model\n\n        super().__init__(config)\n\n    def __call__(self, document: Document, provider: PdfProvider):\n        if self.force_layout_block is not None:\n            # Assign the full content of every page to a single layout type\n            layout_results = self.forced_layout(document.pages)\n        else:\n            layout_results = self.surya_layout(document.pages)\n        self.add_blocks_to_pages(document.pages, layout_results)\n        self.expand_layout_blocks(document)\n\n    def get_batch_size(self):\n        if self.layout_batch_size is not None:\n            return self.layout_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 12\n        return 6\n", "n_tokens": 164, "byte_len": 796, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 46, "end_line": 66}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 4, "symbols": ["forced_layout", "surya_layout", "bbox", "layout", "box", "disable", "tqdm", "highres", "model", "force", "surya", "label", "append", "self", "position", "return", "list", "top", "pages", "get", "batch", "polygon", "image", "false", "results", "page", "bboxes", "result", "size", "sliced", "__init__", "__call__", "get_batch_size", "expand_layout_blocks", "add_blocks_to_pages", "LayoutBuilder", "performing", "full", "document", "block", "cls", "config", "rescale", "sorted", "builder", "children", "every", "expand", "bounds", "provider"], "ast_kind": "function_or_method", "text": "    def forced_layout(self, pages: List[PageGroup]) -> List[LayoutResult]:\n        layout_results = []\n        for page in pages:\n            layout_results.append(\n                LayoutResult(\n                    image_bbox=page.polygon.bbox,\n                    bboxes=[\n                        LayoutBox(\n                            label=self.force_layout_block,\n                            position=0,\n                            top_k={self.force_layout_block: 1},\n                            polygon=page.polygon.polygon,\n                        ),\n                    ],\n                    sliced=False,\n                )\n            )\n        return layout_results\n\n    def surya_layout(self, pages: List[PageGroup]) -> List[LayoutResult]:\n        self.layout_model.disable_tqdm = self.disable_tqdm\n        layout_results = self.layout_model(\n            [p.get_image(highres=False) for p in pages],\n            batch_size=int(self.get_batch_size()),\n        )\n        return layout_results\n", "n_tokens": 180, "byte_len": 1002, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 67, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 5, "symbols": ["expand_layout_blocks", "block", "type", "page", "size", "blocks", "expand", "layout", "access", "min", "gap", "else", "max", "document", "minimum", "self", "frac", "height", "get", "structure", "fit", "bounds", "pages", "easy", "continue", "width", "this", "polygon", "other", "box", "__init__", "__call__", "get_batch_size", "forced_layout", "surya_layout", "add_blocks_to_pages", "LayoutBuilder", "performing", "result", "model", "force", "full", "cls", "config", "disable", "return", "rescale", "sorted", "builder", "children"], "ast_kind": "function_or_method", "text": "    def expand_layout_blocks(self, document: Document):\n        for page in document.pages:\n            # Collect all blocks on this page as PolygonBox for easy access\n            page_blocks = [document.get_block(bid) for bid in page.structure]\n            page_size = page.polygon.size\n\n            for block_id in page.structure:\n                block = document.get_block(block_id)\n                if block.block_type in self.expand_block_types:\n                    other_blocks = [b for b in page_blocks if b != block]\n                    if not other_blocks:\n                        block.polygon = block.polygon.expand(\n                            self.max_expand_frac, self.max_expand_frac\n                        ).fit_to_bounds((0, 0, *page_size))\n                        continue\n\n                    min_gap = min(\n                        block.polygon.minimum_gap(other.polygon)\n                        for other in other_blocks\n                    )\n                    if min_gap <= 0:\n                        continue\n\n                    x_expand_frac = (\n                        min_gap / block.polygon.width if block.polygon.width > 0 else 0\n                    )\n                    y_expand_frac = (\n                        min_gap / block.polygon.height\n                        if block.polygon.height > 0\n                        else 0\n                    )\n\n                    block.polygon = block.polygon.expand(\n                        min(self.max_expand_frac, x_expand_frac),\n                        min(self.max_expand_frac, y_expand_frac),\n                    ).fit_to_bounds((0, 0, *page_size))\n", "n_tokens": 291, "byte_len": 1628, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 94, "end_line": 130}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/layout.py", "rel_path": "marker/builders/layout.py", "module": "marker.builders.layout", "ext": "py", "chunk_number": 6, "symbols": ["add_blocks_to_pages", "bbox", "layout", "sliced", "prob", "none", "result", "model", "indicates", "label", "block", "cls", "self", "from", "size", "position", "rescale", "sorted", "page", "add", "blocks", "children", "ensure", "list", "structure", "this", "get", "fit", "bounds", "types", "__init__", "__call__", "get_batch_size", "forced_layout", "surya_layout", "expand_layout_blocks", "LayoutBuilder", "performing", "force", "full", "document", "config", "disable", "return", "builder", "every", "expand", "provider", "default", "whose"], "ast_kind": "function_or_method", "text": "    def add_blocks_to_pages(\n        self, pages: List[PageGroup], layout_results: List[LayoutResult]\n    ):\n        for page, layout_result in zip(pages, layout_results):\n            layout_page_size = PolygonBox.from_bbox(layout_result.image_bbox).size\n            provider_page_size = page.polygon.size\n            page.layout_sliced = (\n                layout_result.sliced\n            )  # This indicates if the page was sliced by the layout model\n            for bbox in sorted(layout_result.bboxes, key=lambda x: x.position):\n                block_cls = get_block_class(BlockTypes[bbox.label])\n                layout_block = page.add_block(\n                    block_cls, PolygonBox(polygon=bbox.polygon)\n                )\n                layout_block.polygon = layout_block.polygon.rescale(\n                    layout_page_size, provider_page_size\n                ).fit_to_bounds((0, 0, *provider_page_size))\n                layout_block.top_k = {\n                    BlockTypes[label]: prob for (label, prob) in bbox.top_k.items()\n                }\n                page.add_structure(layout_block)\n\n            # Ensure page has non-empty structure\n            if page.structure is None:\n                page.structure = []\n\n            # Ensure page has non-empty children\n            if page.children is None:\n                page.children = []\n", "n_tokens": 262, "byte_len": 1356, "file_sha1": "39739268375cf7fe1a04563682d7059a583508e0", "start_line": 131, "end_line": 160}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 1, "symbols": ["image", "text", "tuple", "matrix", "intersection", "line", "provider", "page", "numpy", "builders", "ocr", "error", "annotated", "output", "document", "schema", "utils", "settings", "providers", "from", "base", "builder", "surya", "list", "detection", "predictor", "copy", "get", "block", "typing", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "result", "detections", "remove", "check", "disable", "individual"], "ast_kind": "imports", "text": "from copy import deepcopy\nfrom typing import Annotated, List, Tuple\n\nimport numpy as np\nfrom PIL import Image\nimport cv2\n\nfrom surya.detection import DetectionPredictor\nfrom surya.ocr_error import OCRErrorPredictor\n\nfrom marker.builders import BaseBuilder\nfrom marker.providers import ProviderOutput, ProviderPageLines\nfrom marker.providers.pdf import PdfProvider\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups.page import PageGroup\nfrom marker.schema.polygon import PolygonBox\nfrom marker.schema.registry import get_block_class\nfrom marker.schema.text.line import Line\nfrom marker.settings import settings\nfrom marker.util import matrix_intersection_area, sort_text_lines\nfrom marker.utils.image import is_blank_image\n\n", "n_tokens": 154, "byte_len": 780, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 2, "symbols": ["LineBuilder", "table", "group", "ocr", "remove", "disable", "individual", "document", "required", "exclude", "figure", "error", "layout", "coverage", "builder", "than", "less", "lines", "provider", "default", "keep", "chars", "only", "bool", "which", "this", "number", "pdf", "tqdm", "bars", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "detection", "result", "get", "page", "detections", "matrix", "intersection", "check", "line"], "ast_kind": "class_or_type", "text": "class LineBuilder(BaseBuilder):\n    \"\"\"\n    A builder for detecting text lines. Merges the detected lines with the lines from the provider\n    \"\"\"\n\n    detection_batch_size: Annotated[\n        int,\n        \"The batch size to use for the detection model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    ocr_error_batch_size: Annotated[\n        int,\n        \"The batch size to use for the ocr error detection model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    layout_coverage_min_lines: Annotated[\n        int,\n        \"The minimum number of PdfProvider lines that must be covered by the layout model\",\n        \"to consider the lines from the PdfProvider valid.\",\n    ] = 1\n    layout_coverage_threshold: Annotated[\n        float,\n        \"The minimum coverage ratio required for the layout model to consider\",\n        \"the lines from the PdfProvider valid.\",\n    ] = 0.25\n    min_document_ocr_threshold: Annotated[\n        float,\n        \"If less pages than this threshold are good, OCR will happen in the document.  Otherwise it will not.\",\n    ] = 0.85\n    provider_line_provider_line_min_overlap_pct: Annotated[\n        float,\n        \"The percentage of a provider line that has to be covered by a detected line\",\n    ] = 0.1\n    excluded_for_coverage: Annotated[\n        Tuple[BlockTypes],\n        \"A list of block types to exclude from the layout coverage check.\",\n    ] = (\n        BlockTypes.Figure,\n        BlockTypes.Picture,\n        BlockTypes.Table,\n        BlockTypes.FigureGroup,\n        BlockTypes.TableGroup,\n        BlockTypes.PictureGroup,\n    )\n    ocr_remove_blocks: Tuple[BlockTypes, ...] = (\n        BlockTypes.Table,\n        BlockTypes.Form,\n        BlockTypes.TableOfContents,\n        BlockTypes.Equation,\n    )\n    disable_tqdm: Annotated[\n        bool,\n        \"Disable tqdm progress bars.\",\n    ] = False\n    disable_ocr: Annotated[\n        bool,\n        \"Disable OCR for the document. This will only use the lines from the provider.\",\n    ] = False\n    keep_chars: Annotated[bool, \"Keep individual characters.\"] = False\n", "n_tokens": 491, "byte_len": 2154, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 25, "end_line": 84}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "get_detection_batch_size", "elif", "init", "none", "detect", "where", "detections", "inline", "model", "merge", "blocks", "ocr", "error", "document", "self", "config", "settings", "torc", "devic", "layout", "disable", "also", "return", "detection", "batch", "super", "predictor", "lines", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "result", "get", "page", "remove", "matrix", "intersection", "check", "line", "individual"], "ast_kind": "function_or_method", "text": "    def __init__(\n        self,\n        detection_model: DetectionPredictor,\n        ocr_error_model: OCRErrorPredictor,\n        config=None,\n    ):\n        super().__init__(config)\n\n        self.detection_model = detection_model\n        self.ocr_error_model = ocr_error_model\n\n    def __call__(self, document: Document, provider: PdfProvider):\n        # Disable inline detection for documents where layout model doesn't detect any equations\n        # Also disable if we won't use the inline detections (if we aren't using the LLM)\n        provider_lines, ocr_lines = self.get_all_lines(document, provider)\n        self.merge_blocks(document, provider_lines, ocr_lines)\n\n    def get_detection_batch_size(self):\n        if self.detection_batch_size is not None:\n            return self.detection_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 10\n        return 4\n", "n_tokens": 194, "byte_len": 897, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 85, "end_line": 108}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 4, "symbols": ["get_ocr_error_batch_size", "get_detection_results", "image", "elif", "assert", "disable", "tqdm", "none", "images", "page", "else", "append", "self", "ocr", "error", "settings", "get", "detection", "torc", "devic", "good", "return", "run", "list", "results", "bool", "model", "cuda", "batch", "size", "__init__", "__call__", "get_detection_batch_size", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "result", "detections", "remove", "matrix", "intersection", "check", "line", "individual"], "ast_kind": "function_or_method", "text": "    def get_ocr_error_batch_size(self):\n        if self.ocr_error_batch_size is not None:\n            return self.ocr_error_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 14\n        return 4\n\n    def get_detection_results(\n        self, page_images: List[Image.Image], run_detection: List[bool]\n    ):\n        self.detection_model.disable_tqdm = self.disable_tqdm\n        page_detection_results = self.detection_model(\n            images=page_images, batch_size=self.get_detection_batch_size()\n        )\n\n        assert len(page_detection_results) == sum(run_detection)\n        detection_results = []\n        idx = 0\n        for good in run_detection:\n            if good:\n                detection_results.append(page_detection_results[idx])\n                idx += 1\n            else:\n                detection_results.append(None)\n        assert idx == len(page_images)\n\n        assert len(run_detection) == len(detection_results)\n        return detection_results\n", "n_tokens": 204, "byte_len": 1001, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 109, "end_line": 137}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 5, "symbols": ["get_all_lines", "detection", "result", "get", "page", "ocr", "remove", "check", "line", "disable", "make", "full", "document", "labels", "blocks", "rescale", "return", "every", "error", "than", "class", "provider", "lines", "results", "sort", "text", "bool", "value", "image", "pdftext", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "detections", "matrix", "intersection", "individual", "small", "utils", "required"], "ast_kind": "function_or_method", "text": "    def get_all_lines(self, document: Document, provider: PdfProvider):\n        ocr_error_detection_results = self.ocr_error_detection(\n            document.pages, provider.page_lines\n        )\n\n        boxes_to_ocr = {page.page_id: [] for page in document.pages}\n        page_lines = {page.page_id: [] for page in document.pages}\n\n        LineClass: Line = get_block_class(BlockTypes.Line)\n\n        layout_good = []\n        for document_page, ocr_error_detection_label in zip(\n            document.pages, ocr_error_detection_results.labels\n        ):\n            document_page.ocr_errors_detected = ocr_error_detection_label == \"bad\"\n            provider_lines: List[ProviderOutput] = provider.page_lines.get(\n                document_page.page_id, []\n            )\n            provider_lines_good = all(\n                [\n                    bool(provider_lines),\n                    not document_page.ocr_errors_detected,\n                    self.check_layout_coverage(document_page, provider_lines),\n                    self.check_line_overlaps(\n                        document_page, provider_lines\n                    ),  # Ensure provider lines don't overflow the page or intersect\n                ]\n            )\n            if self.disable_ocr:\n                provider_lines_good = True\n\n            layout_good.append(provider_lines_good)\n\n        run_detection = [not good for good in layout_good]\n        page_images = [\n            page.get_image(highres=False, remove_blocks=self.ocr_remove_blocks)\n            for page, bad in zip(document.pages, run_detection)\n            if bad\n        ]\n\n        # Note: run_detection is longer than page_images, since it has a value for each page, not just good ones\n        # Detection results and inline detection results are for every page (we use run_detection to make the list full length)\n        detection_results = self.get_detection_results(page_images, run_detection)\n\n        assert len(detection_results) == len(layout_good) == len(document.pages)\n        for document_page, detection_result, provider_lines_good in zip(\n            document.pages, detection_results, layout_good\n        ):\n            provider_lines: List[ProviderOutput] = provider.page_lines.get(\n                document_page.page_id, []\n            )\n\n            # Setup detection results\n            detection_boxes = []\n            if detection_result:\n                detection_boxes = [\n                    PolygonBox(polygon=box.polygon) for box in detection_result.bboxes\n                ]\n\n            detection_boxes = sort_text_lines(detection_boxes)\n\n            if provider_lines_good:\n                document_page.text_extraction_method = \"pdftext\"\n\n                # Mark extraction method as pdftext, since all lines are good\n                for provider_line in provider_lines:\n                    provider_line.line.text_extraction_method = \"pdftext\"\n\n                page_lines[document_page.page_id] = provider_lines\n            else:\n                document_page.text_extraction_method = \"surya\"\n                boxes_to_ocr[document_page.page_id].extend(detection_boxes)\n\n        # Dummy lines to merge into the document - Contains no spans, will be filled in later by OCRBuilder\n        ocr_lines = {document_page.page_id: [] for document_page in document.pages}\n        for page_id, page_ocr_boxes in boxes_to_ocr.items():\n            page_size = provider.get_page_bbox(page_id).size\n            image_size = document.get_page(page_id).get_image(highres=False).size\n            for box_to_ocr in page_ocr_boxes:\n                line_polygon = PolygonBox(polygon=box_to_ocr.polygon).rescale(\n                    image_size, page_size\n                )\n                ocr_lines[page_id].append(\n                    ProviderOutput(\n                        line=LineClass(\n                            polygon=line_polygon,\n                            page_id=page_id,\n                            text_extraction_method=\"surya\",\n                        ),\n                        spans=[],\n                        chars=[],\n                    )\n                )\n\n        return page_lines, ocr_lines\n", "n_tokens": 775, "byte_len": 4161, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 138, "end_line": 233}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 6, "symbols": ["ocr_error_detection", "page", "text", "ocr", "error", "disable", "tqdm", "provider", "texts", "append", "self", "spans", "line", "get", "return", "list", "lines", "document", "pages", "batch", "size", "join", "group", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "detection", "result", "detections", "remove", "matrix", "intersection", "check", "individual", "small", "image", "make", "full", "utils", "required", "config"], "ast_kind": "function_or_method", "text": "    def ocr_error_detection(\n        self, pages: List[PageGroup], provider_page_lines: ProviderPageLines\n    ):\n        page_texts = []\n        for document_page in pages:\n            provider_lines = provider_page_lines.get(document_page.page_id, [])\n            page_text = \"\\n\".join(\n                \" \".join(s.text for s in line.spans) for line in provider_lines\n            )\n            page_texts.append(page_text)\n\n        self.ocr_error_model.disable_tqdm = self.disable_tqdm\n        ocr_error_detection_results = self.ocr_error_model(\n            page_texts, batch_size=int(self.get_ocr_error_batch_size())\n        )\n        return ocr_error_detection_results\n", "n_tokens": 145, "byte_len": 671, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 234, "end_line": 250}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 7, "symbols": ["check_line_overlaps", "bbox", "provider", "line", "intersection", "matrix", "check", "overflows", "small", "output", "there", "self", "return", "minor", "intersect", "counts", "list", "margin", "account", "itself", "lines", "document", "page", "should", "enumerate", "with", "bool", "polygon", "bboxes", "expand", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_layout_coverage", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "detection", "result", "get", "detections", "ocr", "remove", "disable"], "ast_kind": "function_or_method", "text": "    def check_line_overlaps(\n        self, document_page: PageGroup, provider_lines: List[ProviderOutput]\n    ) -> bool:\n        provider_bboxes = [line.line.polygon.bbox for line in provider_lines]\n        # Add a small margin to account for minor overflows\n        page_bbox = document_page.polygon.expand(5, 5).bbox\n\n        for bbox in provider_bboxes:\n            if bbox[0] < page_bbox[0]:\n                return False\n            if bbox[1] < page_bbox[1]:\n                return False\n            if bbox[2] > page_bbox[2]:\n                return False\n            if bbox[3] > page_bbox[3]:\n                return False\n\n        intersection_matrix = matrix_intersection_area(provider_bboxes, provider_bboxes)\n        for i, line in enumerate(provider_lines):\n            intersect_counts = np.sum(\n                intersection_matrix[i]\n                > self.provider_line_provider_line_min_overlap_pct\n            )\n\n            # There should be one intersection with itself\n            if intersect_counts > 2:\n                return False\n\n        return True\n", "n_tokens": 225, "byte_len": 1075, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 251, "end_line": 280}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 8, "symbols": ["check_layout_coverage", "block", "type", "bbox", "check", "layout", "coverage", "text", "okay", "matrix", "intersection", "ratio", "covered", "blocks", "total", "else", "provider", "output", "model", "self", "intersecting", "lines", "count", "nonzero", "line", "return", "get", "sometimes", "large", "when", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "filter_blank_lines", "merge_blocks", "LineBuilder", "table", "group", "detection", "result", "page", "detections", "ocr", "remove", "disable"], "ast_kind": "function_or_method", "text": "    def check_layout_coverage(\n        self,\n        document_page: PageGroup,\n        provider_lines: List[ProviderOutput],\n    ):\n        covered_blocks = 0\n        total_blocks = 0\n        large_text_blocks = 0\n\n        layout_blocks = [\n            document_page.get_block(block) for block in document_page.structure\n        ]\n        layout_blocks = [\n            b for b in layout_blocks if b.block_type not in self.excluded_for_coverage\n        ]\n\n        layout_bboxes = [block.polygon.bbox for block in layout_blocks]\n        provider_bboxes = [line.line.polygon.bbox for line in provider_lines]\n\n        if len(layout_bboxes) == 0:\n            return True\n\n        if len(provider_bboxes) == 0:\n            return False\n\n        intersection_matrix = matrix_intersection_area(layout_bboxes, provider_bboxes)\n\n        for idx, layout_block in enumerate(layout_blocks):\n            total_blocks += 1\n            intersecting_lines = np.count_nonzero(intersection_matrix[idx] > 0)\n\n            if intersecting_lines >= self.layout_coverage_min_lines:\n                covered_blocks += 1\n\n            if (\n                layout_block.polygon.intersection_pct(document_page.polygon) > 0.8\n                and layout_block.block_type == BlockTypes.Text\n            ):\n                large_text_blocks += 1\n\n        coverage_ratio = covered_blocks / total_blocks if total_blocks > 0 else 1\n        text_okay = coverage_ratio >= self.layout_coverage_threshold\n\n        # Model will sometimes say there is a single block of text on the page when it is blank\n        if not text_okay and (total_blocks == 1 and large_text_blocks == 1):\n            text_okay = True\n        return text_okay\n", "n_tokens": 360, "byte_len": 1692, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 281, "end_line": 328}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 9, "symbols": ["filter_blank_lines", "bbox", "page", "image", "size", "provider", "output", "filter", "blank", "append", "self", "line", "height", "rescale", "return", "list", "polygon", "fit", "bounds", "lines", "crop", "deepcopy", "good", "width", "get", "group", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "merge_blocks", "LineBuilder", "table", "detection", "result", "detections", "ocr", "remove", "matrix", "intersection", "check", "disable", "individual", "small", "make"], "ast_kind": "function_or_method", "text": "    def filter_blank_lines(self, page: PageGroup, lines: List[ProviderOutput]):\n        page_size = (page.polygon.width, page.polygon.height)\n        page_image = page.get_image()\n        image_size = page_image.size\n\n        good_lines = []\n        for line in lines:\n            line_polygon_rescaled = deepcopy(line.line.polygon).rescale(\n                page_size, image_size\n            )\n            line_bbox = line_polygon_rescaled.fit_to_bounds((0, 0, *image_size)).bbox\n\n            if not is_blank_image(page_image.crop(line_bbox)):\n                good_lines.append(line)\n\n        return good_lines\n", "n_tokens": 131, "byte_len": 611, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 329, "end_line": 345}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/line.py", "rel_path": "marker/builders/line.py", "module": "marker.builders.line", "ext": "py", "chunk_number": 10, "symbols": ["merge_blocks", "merge", "blocks", "text", "extraction", "provider", "page", "overridden", "merged", "lines", "else", "output", "filter", "blank", "document", "self", "invisible", "from", "only", "boxes", "ocr", "surya", "red", "ocred", "list", "have", "pages", "method", "keep", "chars", "__init__", "__call__", "get_detection_batch_size", "get_ocr_error_batch_size", "get_detection_results", "get_all_lines", "ocr_error_detection", "check_line_overlaps", "check_layout_coverage", "filter_blank_lines", "LineBuilder", "table", "group", "detection", "result", "get", "detections", "remove", "matrix", "intersection"], "ast_kind": "function_or_method", "text": "    def merge_blocks(\n        self,\n        document: Document,\n        page_provider_lines: ProviderPageLines,\n        page_ocr_lines: ProviderPageLines,\n    ):\n        for document_page in document.pages:\n            provider_lines: List[ProviderOutput] = page_provider_lines[\n                document_page.page_id\n            ]\n            ocr_lines: List[ProviderOutput] = page_ocr_lines[document_page.page_id]\n\n            # Only one or the other will have lines\n            # Filter out blank lines which come from bad provider boxes, or invisible text\n            merged_lines = self.filter_blank_lines(\n                document_page, provider_lines + ocr_lines\n            )\n\n            # Text extraction method is overridden later for OCRed documents\n            document_page.merge_blocks(\n                merged_lines,\n                text_extraction_method=\"pdftext\" if provider_lines else \"surya\",\n                keep_chars=self.keep_chars,\n            )\n", "n_tokens": 185, "byte_len": 970, "file_sha1": "272bfd81cd909230a10fb6bd4f3168d83d2f893e", "start_line": 346, "end_line": 370}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/__init__.py", "rel_path": "marker/builders/__init__.py", "module": "marker.builders.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__call__", "BaseBuilder", "args", "class", "init", "assign", "config", "none", "pydantic", "self", "from", "dict", "base", "builder", "kwargs", "not", "implemented", "data", "model", "typing", "optional", "raise", "import", "marker", "util", "call"], "ast_kind": "class_or_type", "text": "from typing import Optional\n\nfrom pydantic import BaseModel\n\nfrom marker.util import assign_config\n\n\nclass BaseBuilder:\n    def __init__(self, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n\n    def __call__(self, data, *args, **kwargs):\n        raise NotImplementedError\n", "n_tokens": 68, "byte_len": 305, "file_sha1": "9cdebb4bc635a636b14e4332db904f53a562fe8e", "start_line": 1, "end_line": 14}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 1, "symbols": ["image", "fix", "text", "base", "get", "opening", "ocr", "result", "common", "line", "blocks", "builders", "annotated", "recognition", "predictor", "document", "schema", "char", "settings", "providers", "from", "span", "builder", "surya", "list", "ftfy", "copy", "block", "blockid", "typing", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "page", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back"], "ast_kind": "imports", "text": "import copy\nfrom typing import Annotated, List\n\nfrom ftfy import fix_text\nfrom PIL import Image\nfrom surya.common.surya.schema import TaskNames\nfrom surya.recognition import RecognitionPredictor, OCRResult, TextChar\n\nfrom marker.builders import BaseBuilder\nfrom marker.providers.pdf import PdfProvider\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import BlockId\nfrom marker.schema.blocks.base import Block\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\nfrom marker.schema.registry import get_block_class\nfrom marker.schema.text.char import Char\nfrom marker.schema.text.line import Line\nfrom marker.schema.text.span import Span\nfrom marker.settings import settings\nfrom marker.schema.polygon import PolygonBox\nfrom marker.util import get_opening_tag_type, get_closing_tag_type\n\n", "n_tokens": 169, "byte_len": 835, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 2, "symbols": ["OcrBuilder", "performing", "footnote", "beta", "block", "mode", "drop", "repeated", "individual", "back", "sparingly", "section", "header", "ocr", "builder", "document", "disable", "used", "code", "within", "skip", "lines", "default", "keep", "chars", "bool", "which", "this", "text", "inline", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "get", "page", "renderer", "replace", "match", "span", "rescale", "might", "insert"], "ast_kind": "class_or_type", "text": "class OcrBuilder(BaseBuilder):\n    \"\"\"\n    A builder for performing OCR on PDF pages and merging the results into the document.\n    \"\"\"\n\n    recognition_batch_size: Annotated[\n        int,\n        \"The batch size to use for the recognition model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    disable_tqdm: Annotated[\n        bool,\n        \"Disable tqdm progress bars.\",\n    ] = False\n    # We can skip tables here, since the TableProcessor will re-OCR\n    skip_ocr_blocks: Annotated[\n        List[BlockTypes],\n        \"Blocktypes to skip OCRing by the model in this stage.\"\n        \"By default, this avoids recognizing lines inside equations/tables (handled later), figures, and pictures\",\n        \"Note that we **do not** have to skip group types, since they are not built by this point\"\n    ] = [\n        BlockTypes.Equation,\n        BlockTypes.Figure,\n        BlockTypes.Picture,\n        BlockTypes.Table,\n    ]\n    full_ocr_block_types: Annotated[\n        List[BlockTypes],\n        \"Blocktypes for which OCR is done at the **block level** instead of line-level.\"\n        \"This feature is still in beta, and should be used sparingly.\"\n    ] = [\n        BlockTypes.SectionHeader,\n        BlockTypes.ListItem,\n        BlockTypes.Footnote,\n        BlockTypes.Text,\n        BlockTypes.TextInlineMath,\n        BlockTypes.Code,\n        BlockTypes.Caption,\n    ]\n    ocr_task_name: Annotated[\n        str,\n        \"The OCR mode to use, see surya for details.  Set to 'ocr_without_boxes' for potentially better performance, at the expense of formatting.\",\n    ] = TaskNames.ocr_with_boxes\n    keep_chars: Annotated[bool, \"Keep individual characters.\"] = False\n    disable_ocr_math: Annotated[bool, \"Disable inline math recognition in OCR\"] = False\n    drop_repeated_text: Annotated[bool, \"Drop repeated text in OCR results.\"] = False\n    block_mode_intersection_thresh: Annotated[float, \"Max intersection before falling back to line mode\"] = 0.5\n    block_mode_max_lines: Annotated[int, \"Max lines within a block before falling back to line mode\"] = 15\n    block_mode_max_height_frac: Annotated[float, \"Max height of a block as a percentage of the page before falling back to line mode\"] = 0.5\n", "n_tokens": 524, "byte_len": 2244, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 25, "end_line": 74}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "get", "ocr", "init", "none", "block", "polygons", "recognition", "predictor", "original", "document", "self", "config", "model", "text", "extraction", "surya", "super", "pages", "provider", "page", "pdf", "call", "ids", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "match", "span", "rescale", "might", "insert", "default", "which", "caption"], "ast_kind": "function_or_method", "text": "    def __init__(self, recognition_model: RecognitionPredictor, config=None):\n        super().__init__(config)\n\n        self.recognition_model = recognition_model\n\n    def __call__(self, document: Document, provider: PdfProvider):\n        pages_to_ocr = [page for page in document.pages if page.text_extraction_method == 'surya']\n        ocr_page_images, block_polygons, block_ids, block_original_texts = (\n            self.get_ocr_images_polygons_ids(document, pages_to_ocr, provider)\n        )\n        self.ocr_extraction(\n            document,\n            pages_to_ocr,\n            ocr_page_images,\n            block_polygons,\n            block_ids,\n            block_original_texts,\n        )\n", "n_tokens": 148, "byte_len": 697, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 75, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 4, "symbols": ["get_recognition_batch_size", "select_ocr_blocks_by_mode", "block", "type", "elif", "none", "mode", "lines", "float", "line", "self", "settings", "torc", "devic", "return", "height", "select", "ocr", "recognition", "batch", "list", "page", "max", "polygon", "full", "cuda", "get", "group", "__init__", "__call__", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "match", "span", "rescale", "might", "insert"], "ast_kind": "function_or_method", "text": "    def get_recognition_batch_size(self):\n        if self.recognition_batch_size is not None:\n            return self.recognition_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 48\n        elif settings.TORCH_DEVICE_MODEL == \"mps\":\n            return 16\n        return 32\n\n    def select_ocr_blocks_by_mode(\n        self, page: PageGroup, block: Block, block_lines: List[Block], page_max_intersection_pct: float\n    ):\n        if any([\n            page_max_intersection_pct > self.block_mode_intersection_thresh,\n            block.block_type not in self.full_ocr_block_types,\n            len(block_lines) > self.block_mode_max_lines,\n            block.polygon.height >= self.block_mode_max_height_frac * page.polygon.height\n        ]):\n            # Line mode\n            return block_lines\n\n        # Block mode\n        return [block]\n", "n_tokens": 186, "byte_len": 870, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 94, "end_line": 117}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 5, "symbols": ["get_ocr_images_polygons_ids", "block", "type", "get", "ocr", "highres", "images", "blocks", "page", "size", "contained", "lines", "skip", "model", "line", "default", "create", "image", "original", "document", "append", "self", "since", "polygon", "rescale", "return", "might", "max", "intersection", "text", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "match", "span"], "ast_kind": "function_or_method", "text": "    def get_ocr_images_polygons_ids(\n        self, document: Document, pages: List[PageGroup], provider: PdfProvider\n    ):\n        highres_images, highres_polys, block_ids, block_original_texts = [], [], [], []\n        for document_page in pages:\n            page_highres_image = document_page.get_image(highres=True)\n            page_highres_polys = []\n            page_block_ids = []\n            page_block_original_texts = []\n\n            page_size = provider.get_page_bbox(document_page.page_id).size\n            image_size = page_highres_image.size\n            max_intersection_pct = document_page.compute_max_structure_block_intersection_pct()\n            for block in document_page.structure_blocks(document):\n                if block.block_type in self.skip_ocr_blocks:\n                    # Skip OCR\n                    continue\n\n                block_lines = block.contained_blocks(document, [BlockTypes.Line])\n                blocks_to_ocr = self.select_ocr_blocks_by_mode(document_page, block, block_lines, max_intersection_pct)\n\n                block.text_extraction_method = \"surya\"\n                for block in blocks_to_ocr:\n                    # Fit the polygon to image bounds since PIL image crop expands by default which might create bad images for the OCR model.\n                    block_polygon_rescaled = (\n                        copy.deepcopy(block.polygon)\n                        .rescale(page_size, image_size)\n                        .fit_to_bounds((0, 0, *image_size))\n                    )\n                    block_bbox_rescaled = block_polygon_rescaled.polygon\n                    block_bbox_rescaled = [\n                        [int(x) for x in point] for point in block_bbox_rescaled\n                    ]\n\n                    page_highres_polys.append(block_bbox_rescaled)\n                    page_block_ids.append(block.id)\n                    page_block_original_texts.append(\"\")\n\n            highres_images.append(page_highres_image)\n            highres_polys.append(page_highres_polys)\n            block_ids.append(page_block_ids)\n            block_original_texts.append(page_block_original_texts)\n\n        return highres_images, highres_polys, block_ids, block_original_texts\n", "n_tokens": 415, "byte_len": 2219, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 118, "end_line": 162}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 6, "symbols": ["ocr_extraction", "new", "line", "renderer", "replace", "drop", "repeated", "image", "input", "text", "document", "disable", "ocr", "todo", "return", "mismatch", "page", "block", "max", "sliding", "lines", "improve", "constructed", "task", "names", "continue", "this", "true", "type", "tqdm", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "get", "footnote", "beta", "back", "match", "span", "rescale", "might", "insert"], "ast_kind": "function_or_method", "text": "    def ocr_extraction(\n        self,\n        document: Document,\n        pages: List[PageGroup],\n        images: List[any],\n        block_polygons: List[List[List[List[int]]]],  # polygons\n        block_ids: List[List[BlockId]],\n        block_original_texts: List[List[str]],\n    ):\n        if sum(len(b) for b in block_polygons) == 0:\n            return\n\n        self.recognition_model.disable_tqdm = self.disable_tqdm\n        recognition_results: List[OCRResult] = self.recognition_model(\n            images=images,\n            task_names=[self.ocr_task_name] * len(images),\n            polygons=block_polygons,\n            input_text=block_original_texts,\n            recognition_batch_size=int(self.get_recognition_batch_size()),\n            sort_lines=False,\n            math_mode=not self.disable_ocr_math,\n            drop_repeated_text=self.drop_repeated_text,\n            max_sliding_window=2148,\n            max_tokens=2048\n        )\n\n        assert len(recognition_results) == len(images) == len(pages) == len(block_ids), (\n            f\"Mismatch in OCR lengths: {len(recognition_results)}, {len(images)}, {len(pages)}, {len(block_ids)}\"\n        )\n        for document_page, page_recognition_result, page_block_ids, image in zip(\n            pages, recognition_results, block_ids, images\n        ):\n            for block_id, block_ocr_result in zip(\n                page_block_ids, page_recognition_result.text_lines\n            ):\n                if block_ocr_result.original_text_good:\n                    continue\n                if not fix_text(block_ocr_result.text):\n                    continue\n                \n                block = document_page.get_block(block_id)\n                # This is a nested list of spans, so multiple lines are supported\n                all_line_spans = self.spans_from_html_chars(\n                    block_ocr_result.chars, document_page, image\n                )\n                if block.block_type == BlockTypes.Line:\n                    # flatten all spans across lines\n                    flat_spans = [s for line_spans in all_line_spans for s in line_spans]\n                    self.replace_line_spans(document, document_page, block, flat_spans)\n                else:\n                    # Clear out any old lines. Mark as removed for the json ocr renderer\n                    for line in block.contained_blocks(document_page, block_types=[BlockTypes.Line]):\n                        line.removed = True\n                    block.structure = []\n\n                    for line_spans in all_line_spans:\n                        # TODO Replace this polygon with the polygon for each line, constructed from the spans\n                        # This needs the OCR model bbox predictions to improve first\n                        new_line = Line(\n                            polygon=block.polygon,\n                            page_id=block.page_id,\n                            text_extraction_method=\"surya\"\n                        )\n                        document_page.add_full_block(new_line)\n                        block.add_structure(new_line)\n                        self.replace_line_spans(document, document_page, new_line, line_spans)\n", "n_tokens": 612, "byte_len": 3191, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 163, "end_line": 229}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 7, "symbols": ["link_and_break_span", "link", "and", "text", "none", "after", "span", "into", "characters", "before", "multiple", "self", "spans", "match", "todo", "return", "polygons", "when", "partition", "structure", "copy", "duplicate", "deepcopy", "avoid", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "replace_line_spans", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "get", "page", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "rescale", "might", "insert", "default", "which", "caption"], "ast_kind": "function_or_method", "text": "    # TODO Fix polygons when we cut the span into multiple spans\n    def link_and_break_span(self, span: Span, text: str, match_text, url: str):\n        before_text, _, after_text = text.partition(match_text)\n        before_span, after_span = None, None\n        if before_text:\n            before_span = copy.deepcopy(span)\n            before_span.structure = []  # Avoid duplicate characters\n            before_span.text = before_text\n        if after_text:\n            after_span = copy.deepcopy(span)\n            after_span.text = after_text\n            after_span.structure = []  # Avoid duplicate characters\n\n        match_span = copy.deepcopy(span)\n        match_span.text = match_text\n        match_span.url = url\n\n        return before_span, match_span, after_span\n", "n_tokens": 161, "byte_len": 773, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 230, "end_line": 248}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 8, "symbols": ["replace_line_spans", "add", "full", "cannot", "link", "and", "new", "spans", "text", "contained", "blocks", "into", "model", "ref", "repeat", "line", "these", "break", "more", "back", "appropriate", "else", "document", "append", "self", "prevent", "while", "from", "since", "span", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "assign_chars", "store_char", "spans_from_html_chars", "OcrBuilder", "get", "page", "footnote", "renderer", "replace", "beta", "drop", "repeated", "match"], "ast_kind": "function_or_method", "text": "    # Pull all refs from old spans and attempt to insert back into appropriate place in new spans\n    def replace_line_spans(\n        self, document: Document, page: PageGroup, line: Line, new_spans: List[Span]\n    ):\n        old_spans = line.contained_blocks(document, [BlockTypes.Span])\n        text_ref_matching = {span.text: span.url for span in old_spans if span.url}\n\n        # Insert refs into new spans, since the OCR model does not (cannot) generate these\n        final_new_spans = []\n        for span in new_spans:\n            # Use for copying attributes into new spans\n            original_span = copy.deepcopy(span)\n            remaining_text = span.text\n            while remaining_text:\n                matched = False\n                for match_text, url in text_ref_matching.items():\n                    if match_text in remaining_text:\n                        matched = True\n                        before, current, after = self.link_and_break_span(\n                            original_span, remaining_text, match_text, url\n                        )\n                        if before:\n                            final_new_spans.append(before)\n                        final_new_spans.append(current)\n                        if after:\n                            remaining_text = after.text\n                        else:\n                            remaining_text = \"\"  # No more text left\n                        # Prevent repeat matches\n                        del text_ref_matching[match_text]\n                        break\n                if not matched:\n                    remaining_span = copy.deepcopy(original_span)\n                    remaining_span.text = remaining_text\n                    final_new_spans.append(remaining_span)\n                    break\n\n        # Clear the old spans from the line\n        line.structure = []\n        for span in final_new_spans:\n            page.add_full_block(span)\n            line.structure.append(span.id)\n", "n_tokens": 349, "byte_len": 1975, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 249, "end_line": 291}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 9, "symbols": ["assign_chars", "store_char", "add", "full", "current", "chars", "list", "store", "char", "append", "self", "structure", "span", "page", "assign", "keep", "return", "group", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "spans_from_html_chars", "OcrBuilder", "get", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "match", "rescale", "might", "insert", "default", "which", "caption", "done", "pdf", "provider", "tqdm", "text", "new", "spans"], "ast_kind": "function_or_method", "text": "    def assign_chars(self, span: Span, current_chars: List[Char]):\n        if self.keep_chars:\n            span.structure = [c.id for c in current_chars]\n\n        return []\n\n    def store_char(self, char: Char, current_chars: List[Char], page: PageGroup):\n        if self.keep_chars:\n            current_chars.append(char)\n            page.add_full_block(char)\n", "n_tokens": 80, "byte_len": 361, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 292, "end_line": 302}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/ocr.py", "rel_path": "marker/builders/ocr.py", "module": "marker.builders.ocr", "ext": "py", "chunk_number": 10, "symbols": ["spans_from_html_chars", "exception", "minimum", "position", "assign", "chars", "image", "formats", "char", "last", "format", "rescale", "return", "except", "tags", "page", "continue", "skip", "useful", "get", "closing", "span", "text", "model", "class", "spans", "from", "all", "line", "boxes", "__init__", "__call__", "get_recognition_batch_size", "select_ocr_blocks_by_mode", "get_ocr_images_polygons_ids", "ocr_extraction", "link_and_break_span", "replace_line_spans", "assign_chars", "store_char", "OcrBuilder", "footnote", "renderer", "replace", "beta", "drop", "repeated", "back", "match", "might"], "ast_kind": "function_or_method", "text": "    def spans_from_html_chars(\n        self, chars: List[TextChar], page: PageGroup, image: Image.Image\n    ) -> List[List[Span]]:\n        # Turn input characters from surya into spans - also store the raw characters\n        SpanClass: Span = get_block_class(BlockTypes.Span)\n        CharClass: Char = get_block_class(BlockTypes.Char)\n\n        all_line_spans = []\n        current_line_spans = []\n        formats = {\"plain\"}\n        current_span = None\n        current_chars = []\n        image_size = image.size\n\n        for idx, char in enumerate(chars):\n            char_box = PolygonBox(polygon=char.polygon).rescale(\n                image_size, page.polygon.size\n            )\n            marker_char = CharClass(\n                text=char.text,\n                idx=idx,\n                page_id=page.page_id,\n                polygon=char_box,\n            )\n\n            if char.text == \"<br>\":\n                if current_span:\n                    current_chars = self.assign_chars(current_span, current_chars)\n                    current_line_spans.append(current_span)\n                    current_span = None\n                if current_line_spans:\n                    current_line_spans[-1].text += \"\\n\"\n                    all_line_spans.append(current_line_spans)\n                    current_line_spans = []\n                continue\n\n            is_opening_tag, format = get_opening_tag_type(char.text)\n            if is_opening_tag and format not in formats:\n                formats.add(format)\n                if current_span:\n                    current_chars = self.assign_chars(current_span, current_chars)\n                    current_line_spans.append(current_span)\n                    current_span = None\n\n                if format == \"math\":\n                    current_span = SpanClass(\n                        text=\"\",\n                        formats=list(formats),\n                        page_id=page.page_id,\n                        polygon=char_box,\n                        minimum_position=0,\n                        maximum_position=0,\n                        font=\"Unknown\",\n                        font_weight=0,\n                        font_size=0,\n                    )\n                    self.store_char(marker_char, current_chars, page)\n                continue\n\n            is_closing_tag, format = get_closing_tag_type(char.text)\n            if is_closing_tag:\n                # Useful since the OCR model sometimes returns closing tags without an opening tag\n                try:\n                    formats.remove(format)\n                except Exception:\n                    continue\n                if current_span:\n                    current_chars = self.assign_chars(current_span, current_chars)\n                    current_line_spans.append(current_span)\n                    current_span = None\n                continue\n\n            if not current_span:\n                current_span = SpanClass(\n                    text=fix_text(char.text),\n                    formats=list(formats),\n                    page_id=page.page_id,\n                    polygon=char_box,\n                    minimum_position=0,\n                    maximum_position=0,\n                    font=\"Unknown\",\n                    font_weight=0,\n                    font_size=0,\n                )\n                self.store_char(marker_char, current_chars, page)\n                continue\n\n            current_span.text = fix_text(current_span.text + char.text)\n            self.store_char(marker_char, current_chars, page)\n\n            # Tokens inside a math span don't have valid boxes, so we skip the merging\n            if \"math\" not in formats:\n                current_span.polygon = current_span.polygon.merge([char_box])\n\n        # Add the last span to the list\n        if current_span:\n            self.assign_chars(current_span, current_chars)\n            current_line_spans.append(current_span)\n\n        # flush last line\n        if current_line_spans:\n            current_line_spans[-1].text += \"\\n\"\n            all_line_spans.append(current_line_spans)\n\n        return all_line_spans\n", "n_tokens": 743, "byte_len": 4104, "file_sha1": "20ebfcdff03f72726deaad7943a2f49ac245b29a", "start_line": 303, "end_line": 408}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py", "rel_path": "marker/builders/document.py", "module": "marker.builders.document", "ext": "py", "chunk_number": 1, "symbols": ["DocumentBuilder", "highres", "image", "class", "line", "resolution", "document", "builder", "disable", "ocr", "builders", "images", "annotated", "high", "schema", "setting", "providers", "lowres", "from", "layout", "used", "detection", "base", "get", "block", "typing", "types", "given", "constructs", "import", "__call__", "build_document", "page", "group", "initial", "pages", "self", "return", "filepath", "refs", "provider", "build", "enumerate", "bool", "marker", "groups", "polygon", "false", "registry", "processing"], "ast_kind": "class_or_type", "text": "from typing import Annotated\n\nfrom marker.builders import BaseBuilder\nfrom marker.builders.layout import LayoutBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.providers.pdf import PdfProvider\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups.page import PageGroup\nfrom marker.schema.registry import get_block_class\n\n\nclass DocumentBuilder(BaseBuilder):\n    \"\"\"\n    Constructs a Document given a PdfProvider, LayoutBuilder, and OcrBuilder.\n    \"\"\"\n    lowres_image_dpi: Annotated[\n        int,\n        \"DPI setting for low-resolution page images used for Layout and Line Detection.\",\n    ] = 96\n    highres_image_dpi: Annotated[\n        int,\n        \"DPI setting for high-resolution page images used for OCR.\",\n    ] = 192\n    disable_ocr: Annotated[\n        bool,\n        \"Disable OCR processing.\",\n    ] = False\n", "n_tokens": 197, "byte_len": 930, "file_sha1": "334533cd4eea9538662b4e59a918f49f7fc33ae7", "start_line": 1, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py", "rel_path": "marker/builders/document.py", "module": "marker.builders.document", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "layout", "builder", "ocr", "document", "self", "disable", "build", "return", "line", "provider", "pdf", "call", "build_document", "DocumentBuilder", "highres", "image", "page", "group", "initial", "pages", "class", "get", "resolution", "builders", "images", "annotated", "high", "schema", "setting", "providers", "lowres", "from", "used", "detection", "base", "filepath", "block", "refs", "typing", "types", "given", "constructs", "enumerate", "import", "bool", "marker", "groups", "polygon", "false"], "ast_kind": "function_or_method", "text": "    def __call__(self, provider: PdfProvider, layout_builder: LayoutBuilder, line_builder: LineBuilder, ocr_builder: OcrBuilder):\n        document = self.build_document(provider)\n        layout_builder(document, provider)\n        line_builder(document, provider)\n        if not self.disable_ocr:\n            ocr_builder(document, provider)\n        return document\n", "n_tokens": 74, "byte_len": 364, "file_sha1": "334533cd4eea9538662b4e59a918f49f7fc33ae7", "start_line": 31, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/document.py", "rel_path": "marker/builders/document.py", "module": "marker.builders.document", "ext": "py", "chunk_number": 3, "symbols": ["build_document", "page", "group", "highres", "image", "initial", "pages", "get", "self", "lowres", "return", "images", "filepath", "block", "refs", "provider", "types", "build", "document", "enumerate", "class", "polygon", "range", "pdf", "__call__", "DocumentBuilder", "line", "resolution", "builder", "disable", "ocr", "builders", "annotated", "high", "schema", "setting", "providers", "from", "layout", "used", "detection", "base", "typing", "given", "constructs", "import", "bool", "marker", "groups", "false"], "ast_kind": "function_or_method", "text": "    def build_document(self, provider: PdfProvider):\n        PageGroupClass: PageGroup = get_block_class(BlockTypes.Page)\n        lowres_images = provider.get_images(provider.page_range, self.lowres_image_dpi)\n        highres_images = provider.get_images(provider.page_range, self.highres_image_dpi)\n        initial_pages = [\n            PageGroupClass(\n                page_id=p,\n                lowres_image=lowres_images[i],\n                highres_image=highres_images[i],\n                polygon=provider.get_page_bbox(p),\n                refs=provider.get_page_refs(p)\n            ) for i, p in enumerate(provider.page_range)\n        ]\n        DocumentClass: Document = get_block_class(BlockTypes.Document)\n        return DocumentClass(filepath=provider.filepath, pages=initial_pages)\n", "n_tokens": 159, "byte_len": 791, "file_sha1": "334533cd4eea9538662b4e59a918f49f7fc33ae7", "start_line": 39, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py", "rel_path": "marker/builders/structure.py", "module": "marker.builders.structure", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__call__", "StructureBuilder", "together", "class", "init", "based", "none", "float", "blocks", "group", "caption", "builders", "between", "annotated", "document", "schema", "self", "config", "gap", "threshold", "from", "base", "builder", "same", "list", "structure", "super", "call", "minimum", "group_caption_blocks", "group_lists", "unmark_lists", "footnote", "break", "merged", "insert", "static", "page", "new", "polygon", "types", "grouping", "prev", "block", "their", "continue", "marker", "part", "unmark"], "ast_kind": "class_or_type", "text": "from typing import Annotated\n\nfrom marker.builders import BaseBuilder\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Text\nfrom marker.schema.document import Document\nfrom marker.schema.groups import ListGroup\nfrom marker.schema.groups.page import PageGroup\nfrom marker.schema.registry import get_block_class\n\n\nclass StructureBuilder(BaseBuilder):\n    \"\"\"\n    A builder for grouping blocks together based on their structure.\n    \"\"\"\n    gap_threshold: Annotated[\n        float,\n        \"The minimum gap between blocks to consider them part of the same group.\",\n    ] = 0.05\n    list_gap_threshold: Annotated[\n        float,\n        \"The minimum gap between list items to consider them part of the same group.\",\n    ] = 0.1\n\n    def __init__(self, config=None):\n        super().__init__(config)\n\n    def __call__(self, document: Document):\n        for page in document.pages:\n            self.group_caption_blocks(page)\n            self.group_lists(page)\n            self.unmark_lists(page)\n", "n_tokens": 207, "byte_len": 1012, "file_sha1": "163139182b35663e57b6ec69d8fce86b156ba8c7", "start_line": 1, "end_line": 33}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py", "rel_path": "marker/builders/structure.py", "module": "marker.builders.structure", "ext": "py", "chunk_number": 2, "symbols": ["group_caption_blocks", "block", "type", "add", "group", "footnote", "reflect", "new", "caption", "merged", "next", "minimum", "gap", "append", "self", "threshold", "table", "height", "get", "insert", "remove", "structure", "static", "page", "copy", "figure", "enumerate", "types", "picture", "polygon", "__init__", "__call__", "group_lists", "unmark_lists", "StructureBuilder", "together", "based", "break", "document", "config", "same", "list", "builder", "grouping", "prev", "their", "continue", "marker", "part", "unmark"], "ast_kind": "function_or_method", "text": "    def group_caption_blocks(self, page: PageGroup):\n        gap_threshold_px = self.gap_threshold * page.polygon.height\n        static_page_structure = page.structure.copy()\n        remove_ids = list()\n\n        for i, block_id in enumerate(static_page_structure):\n            block = page.get_block(block_id)\n            if block.block_type not in [BlockTypes.Table, BlockTypes.Figure, BlockTypes.Picture]:\n                continue\n\n            if block.id in remove_ids:\n                continue\n\n            block_structure = [block_id]\n            selected_polygons = [block.polygon]\n            caption_types = [BlockTypes.Caption, BlockTypes.Footnote]\n\n            prev_block = page.get_prev_block(block)\n            next_block = page.get_next_block(block)\n\n            if prev_block and \\\n                prev_block.block_type in caption_types and \\\n                prev_block.polygon.minimum_gap(block.polygon) < gap_threshold_px and \\\n                    prev_block.id not in remove_ids:\n                block_structure.insert(0, prev_block.id)\n                selected_polygons.append(prev_block.polygon)\n\n            if next_block and \\\n                    next_block.block_type in caption_types and \\\n                    next_block.polygon.minimum_gap(block.polygon) < gap_threshold_px:\n                block_structure.append(next_block.id)\n                selected_polygons.append(next_block.polygon)\n\n            if len(block_structure) > 1:\n                # Create a merged block\n                new_block_cls = get_block_class(BlockTypes[block.block_type.name + \"Group\"])\n                new_polygon = block.polygon.merge(selected_polygons)\n                group_block = page.add_block(new_block_cls, new_polygon)\n                group_block.structure = block_structure\n\n                # Update the structure of the page to reflect the new block\n                page.update_structure_item(block_id, group_block.id)\n                remove_ids.extend(block_structure)\n        page.remove_structure_items(remove_ids)\n", "n_tokens": 375, "byte_len": 2032, "file_sha1": "163139182b35663e57b6ec69d8fce86b156ba8c7", "start_line": 34, "end_line": 78}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py", "rel_path": "marker/builders/structure.py", "module": "marker.builders.structure", "ext": "py", "chunk_number": 3, "symbols": ["group_lists", "block", "type", "add", "reflect", "group", "break", "next", "else", "minimum", "gap", "append", "self", "height", "get", "list", "remove", "structure", "static", "page", "copy", "item", "enumerate", "types", "new", "polygon", "extend", "update", "continue", "threshold", "__init__", "__call__", "group_caption_blocks", "unmark_lists", "StructureBuilder", "together", "based", "footnote", "caption", "merged", "document", "config", "same", "insert", "builder", "grouping", "prev", "their", "marker", "part"], "ast_kind": "function_or_method", "text": "    def group_lists(self, page: PageGroup):\n        gap_threshold_px = self.list_gap_threshold * page.polygon.height\n        static_page_structure = page.structure.copy()\n        remove_ids = list()\n        for i, block_id in enumerate(static_page_structure):\n            block = page.get_block(block_id)\n            if block.block_type not in [BlockTypes.ListItem]:\n                continue\n\n            if block.id in remove_ids:\n                continue\n\n            block_structure = [block_id]\n            selected_polygons = [block.polygon]\n\n            for j, next_block_id in enumerate(page.structure[i + 1:]):\n                next_block = page.get_block(next_block_id)\n                if all([\n                    next_block.block_type == BlockTypes.ListItem,\n                    next_block.polygon.minimum_gap(selected_polygons[-1]) < gap_threshold_px\n                ]):\n                    block_structure.append(next_block_id)\n                    selected_polygons.append(next_block.polygon)\n                else:\n                    break\n\n            if len(block_structure) > 1:\n                new_polygon = block.polygon.merge(selected_polygons)\n                group_block = page.add_block(ListGroup, new_polygon)\n                group_block.structure = block_structure\n\n                # Update the structure of the page to reflect the new block\n                page.update_structure_item(block_id, group_block.id)\n                remove_ids.extend(block_structure)\n\n        page.remove_structure_items(remove_ids)\n", "n_tokens": 279, "byte_len": 1535, "file_sha1": "163139182b35663e57b6ec69d8fce86b156ba8c7", "start_line": 79, "end_line": 115}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/builders/structure.py", "rel_path": "marker/builders/structure.py", "module": "marker.builders.structure", "ext": "py", "chunk_number": 4, "symbols": ["unmark_lists", "block", "type", "lists", "self", "grouped", "generated", "get", "text", "structure", "list", "item", "unmark", "types", "page", "aren", "polygon", "them", "items", "replace", "group", "__init__", "__call__", "group_caption_blocks", "group_lists", "StructureBuilder", "together", "based", "footnote", "caption", "break", "merged", "document", "config", "gap", "threshold", "same", "insert", "builder", "static", "new", "grouping", "prev", "their", "continue", "marker", "part", "create", "call", "blocks"], "ast_kind": "function_or_method", "text": "    def unmark_lists(self, page: PageGroup):\n        # If lists aren't grouped, unmark them as list items\n        for block_id in page.structure:\n            block = page.get_block(block_id)\n            if block.block_type == BlockTypes.ListItem:\n                generated_block = Text(\n                    polygon=block.polygon,\n                    page_id=block.page_id,\n                    structure=block.structure,\n                )\n                page.replace_block(block, generated_block)\n", "n_tokens": 93, "byte_len": 497, "file_sha1": "163139182b35663e57b6ec69d8fce86b156ba8c7", "start_line": 116, "end_line": 127}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "ConfigParser", "markdown", "class", "init", "parse", "range", "click", "classes", "strings", "get", "logger", "html", "converters", "json", "renderer", "self", "config", "settings", "from", "dict", "typing", "chunk", "renderers", "crawler", "cli", "options", "import", "pdf", "converter", "common_options", "generate_config_dict", "get_llm_service", "get_renderer", "get_processors", "get_converter_cls", "get_output_folder", "get_base_filename", "service", "cls", "exception", "defaults", "exists", "additional", "comma", "disable", "multiprocessing", "parsing", "pdftext", "workers"], "ast_kind": "class_or_type", "text": "import json\nimport os\nfrom typing import Dict\n\nimport click\n\nfrom marker.config.crawler import crawler\nfrom marker.converters.pdf import PdfConverter\nfrom marker.logger import get_logger\nfrom marker.renderers.chunk import ChunkRenderer\nfrom marker.renderers.html import HTMLRenderer\nfrom marker.renderers.json import JSONRenderer\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.settings import settings\nfrom marker.util import classes_to_strings, parse_range_str, strings_to_classes\n\nlogger = get_logger()\n\n\nclass ConfigParser:\n    def __init__(self, cli_options: dict):\n        self.cli_options = cli_options\n", "n_tokens": 126, "byte_len": 629, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 2, "symbols": ["common_options", "defaults", "markdown", "click", "exists", "additional", "comma", "disable", "multiprocessing", "parsing", "image", "full", "required", "choice", "convert", "format", "return", "file", "staticmethod", "processors", "options", "transformation", "output", "string", "directory", "converter", "marker", "page", "google", "gemini", "__init__", "generate_config_dict", "get_llm_service", "get_renderer", "get_processors", "get_converter_cls", "get_output_folder", "get_base_filename", "ConfigParser", "service", "cls", "exception", "strings", "classes", "pdftext", "workers", "converters", "debug", "json", "config"], "ast_kind": "class_or_type", "text": "    @staticmethod\n    def common_options(fn):\n        fn = click.option(\n            \"--output_dir\",\n            type=click.Path(exists=False),\n            required=False,\n            default=settings.OUTPUT_DIR,\n            help=\"Directory to save output.\",\n        )(fn)\n        fn = click.option(\"--debug\", \"-d\", is_flag=True, help=\"Enable debug mode.\")(fn)\n        fn = click.option(\n            \"--output_format\",\n            type=click.Choice([\"markdown\", \"json\", \"html\", \"chunks\"]),\n            default=\"markdown\",\n            help=\"Format to output results in.\",\n        )(fn)\n        fn = click.option(\n            \"--processors\",\n            type=str,\n            default=None,\n            help=\"Comma separated list of processors to use.  Must use full module path.\",\n        )(fn)\n        fn = click.option(\n            \"--config_json\",\n            type=str,\n            default=None,\n            help=\"Path to JSON file with additional configuration.\",\n        )(fn)\n        fn = click.option(\n            \"--disable_multiprocessing\",\n            is_flag=True,\n            default=False,\n            help=\"Disable multiprocessing.\",\n        )(fn)\n        fn = click.option(\n            \"--disable_image_extraction\",\n            is_flag=True,\n            default=False,\n            help=\"Disable image extraction.\",\n        )(fn)\n        # these are options that need a list transformation, i.e splitting/parsing a string\n        fn = click.option(\n            \"--page_range\",\n            type=str,\n            default=None,\n            help=\"Page range to convert, specify comma separated page numbers or ranges.  Example: 0,5-10,20\",\n        )(fn)\n\n        # we put common options here\n        fn = click.option(\n            \"--converter_cls\",\n            type=str,\n            default=None,\n            help=\"Converter class to use.  Defaults to PDF converter.\",\n        )(fn)\n        fn = click.option(\n            \"--llm_service\",\n            type=str,\n            default=None,\n            help=\"LLM service to use - should be full import path, like marker.services.gemini.GoogleGeminiService\",\n        )(fn)\n        return fn\n", "n_tokens": 431, "byte_len": 2145, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 24, "end_line": 86}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 3, "symbols": ["generate_config_dict", "debug", "pdf", "data", "parse", "range", "disable", "multiprocessing", "extract", "images", "pdftext", "workers", "generate", "config", "json", "self", "settings", "googl", "key", "gemini", "api", "google", "match", "return", "dict", "layout", "case", "attr", "set", "output", "__init__", "common_options", "get_llm_service", "get_renderer", "get_processors", "get_converter_cls", "get_output_folder", "get_base_filename", "ConfigParser", "service", "cls", "exception", "defaults", "markdown", "click", "exists", "strings", "classes", "additional", "comma"], "ast_kind": "function_or_method", "text": "    def generate_config_dict(self) -> Dict[str, any]:\n        config = {}\n        output_dir = self.cli_options.get(\"output_dir\", settings.OUTPUT_DIR)\n        for k, v in self.cli_options.items():\n            if not v:\n                continue\n\n            match k:\n                case \"debug\":\n                    config[\"debug_pdf_images\"] = True\n                    config[\"debug_layout_images\"] = True\n                    config[\"debug_json\"] = True\n                    config[\"debug_data_folder\"] = output_dir\n                case \"page_range\":\n                    config[\"page_range\"] = parse_range_str(v)\n                case \"config_json\":\n                    with open(v, \"r\", encoding=\"utf-8\") as f:\n                        config.update(json.load(f))\n                case \"disable_multiprocessing\":\n                    config[\"pdftext_workers\"] = 1\n                case \"disable_image_extraction\":\n                    config[\"extract_images\"] = False\n                case _:\n                    if k in crawler.attr_set:\n                        config[k] = v\n\n        # Backward compatibility for google_api_key\n        if settings.GOOGLE_API_KEY:\n            config[\"gemini_api_key\"] = settings.GOOGLE_API_KEY\n\n        return config\n", "n_tokens": 241, "byte_len": 1246, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 87, "end_line": 118}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 4, "symbols": ["get_llm_service", "get_renderer", "service", "cls", "services", "markdown", "chunks", "none", "classes", "strings", "llm", "output", "format", "html", "json", "renderer", "self", "only", "return", "get", "when", "case", "invalid", "raise", "cli", "options", "marker", "enabled", "value", "error", "__init__", "common_options", "generate_config_dict", "get_processors", "get_converter_cls", "get_output_folder", "get_base_filename", "ConfigParser", "exception", "defaults", "click", "exists", "additional", "comma", "disable", "multiprocessing", "parsing", "pdftext", "workers", "image"], "ast_kind": "function_or_method", "text": "    def get_llm_service(self):\n        # Only return an LLM service when use_llm is enabled\n        if not self.cli_options.get(\"use_llm\", False):\n            return None\n\n        service_cls = self.cli_options.get(\"llm_service\", None)\n        if service_cls is None:\n            service_cls = \"marker.services.gemini.GoogleGeminiService\"\n        return service_cls\n\n    def get_renderer(self):\n        match self.cli_options[\"output_format\"]:\n            case \"json\":\n                r = JSONRenderer\n            case \"markdown\":\n                r = MarkdownRenderer\n            case \"html\":\n                r = HTMLRenderer\n            case \"chunks\":\n                r = ChunkRenderer\n            case _:\n                raise ValueError(\"Invalid output format\")\n        return classes_to_strings([r])[0]\n", "n_tokens": 164, "byte_len": 807, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 119, "end_line": 142}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 5, "symbols": ["get_processors", "get_converter_cls", "exception", "split", "none", "strings", "classes", "converter", "cls", "get", "processors", "self", "error", "processor", "return", "loading", "except", "with", "logger", "raise", "cli", "options", "pdf", "__init__", "common_options", "generate_config_dict", "get_llm_service", "get_renderer", "get_output_folder", "get_base_filename", "ConfigParser", "service", "defaults", "markdown", "click", "exists", "additional", "comma", "disable", "multiprocessing", "parsing", "pdftext", "workers", "image", "full", "converters", "required", "debug", "json", "config"], "ast_kind": "function_or_method", "text": "    def get_processors(self):\n        processors = self.cli_options.get(\"processors\", None)\n        if processors is not None:\n            processors = processors.split(\",\")\n            for p in processors:\n                try:\n                    strings_to_classes([p])\n                except Exception as e:\n                    logger.error(f\"Error loading processor: {p} with error: {e}\")\n                    raise\n\n        return processors\n\n    def get_converter_cls(self):\n        converter_cls = self.cli_options.get(\"converter_cls\", None)\n        if converter_cls is not None:\n            try:\n                return strings_to_classes([converter_cls])[0]\n            except Exception as e:\n                logger.error(\n                    f\"Error loading converter: {converter_cls} with error: {e}\"\n                )\n                raise\n\n        return PdfConverter\n", "n_tokens": 158, "byte_len": 879, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 143, "end_line": 168}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/parser.py", "rel_path": "marker/config/parser.py", "module": "marker.config.parser", "ext": "py", "chunk_number": 6, "symbols": ["get_output_folder", "get_base_filename", "cli", "options", "splitext", "fname", "base", "self", "get", "output", "settings", "filepath", "outpu", "dir", "path", "join", "exist", "true", "makedirs", "return", "basename", "__init__", "common_options", "generate_config_dict", "get_llm_service", "get_renderer", "get_processors", "get_converter_cls", "ConfigParser", "service", "cls", "exception", "defaults", "markdown", "click", "exists", "strings", "classes", "additional", "comma", "disable", "multiprocessing", "parsing", "pdftext", "workers", "image", "full", "converters", "required", "debug"], "ast_kind": "function_or_method", "text": "    def get_output_folder(self, filepath: str):\n        output_dir = self.cli_options.get(\"output_dir\", settings.OUTPUT_DIR)\n        fname_base = os.path.splitext(os.path.basename(filepath))[0]\n        output_dir = os.path.join(output_dir, fname_base)\n        os.makedirs(output_dir, exist_ok=True)\n        return output_dir\n\n    def get_base_filename(self, filepath: str):\n        basename = os.path.basename(filepath)\n        return os.path.splitext(basename)[0]\n", "n_tokens": 99, "byte_len": 465, "file_sha1": "70a89affa289cd571b618077ba55ccbef972ac4e", "start_line": 169, "end_line": 179}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/printer.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/printer.py", "rel_path": "marker/config/printer.py", "module": "marker.config.printer", "ext": "py", "chunk_number": 1, "symbols": ["CustomClickPrinter", "import", "marker", "class", "config", "click", "from", "typing", "custom", "command", "crawler", "optional", "parse_args", "second", "exit", "name", "create", "base", "type", "here", "processors", "params", "options", "attrs", "verify", "their", "renderers", "bool", "along", "display", "help", "pass", "true", "flag", "echo", "classes", "default", "metadata", "shared", "only", "providers", "sets", "option", "this", "keep", "compatibility", "join", "info", "important", "args"], "ast_kind": "class_or_type", "text": "from typing import Optional\n\nimport click\n\nfrom marker.config.crawler import crawler\n\n\nclass CustomClickPrinter(click.Command):", "n_tokens": 23, "byte_len": 127, "file_sha1": "c3a01e6895f54def52fc795922c50cac00638569", "start_line": 1, "end_line": 8}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/printer.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/printer.py", "rel_path": "marker/config/printer.py", "module": "marker.config.printer", "ext": "py", "chunk_number": 2, "symbols": ["parse_args", "second", "exit", "class", "name", "click", "create", "base", "type", "config", "here", "processors", "params", "options", "attrs", "verify", "their", "renderers", "bool", "along", "display", "help", "pass", "true", "flag", "echo", "command", "classes", "default", "metadata", "CustomClickPrinter", "marker", "shared", "only", "providers", "sets", "option", "this", "crawler", "import", "keep", "compatibility", "join", "info", "important", "args", "attr", "types", "desc", "float"], "ast_kind": "function_or_method", "text": "    def parse_args(self, ctx, args):\n        display_help = \"config\" in args and \"--help\" in args\n        if display_help:\n            click.echo(\n                \"Here is a list of all the Builders, Processors, Converters, Providers and Renderers in Marker along with their attributes:\"\n            )\n\n        # Keep track of shared attributes and their types\n        shared_attrs = {}\n\n        # First pass: identify shared attributes and verify compatibility\n        for base_type, base_type_dict in crawler.class_config_map.items():\n            for class_name, class_map in base_type_dict.items():\n                for attr, (attr_type, formatted_type, default, metadata) in class_map[\n                    \"config\"\n                ].items():\n                    if attr not in shared_attrs:\n                        shared_attrs[attr] = {\n                            \"classes\": [],\n                            \"type\": attr_type,\n                            \"is_flag\": attr_type in [bool, Optional[bool]]\n                            and not default,\n                            \"metadata\": metadata,\n                            \"default\": default,\n                        }\n                    shared_attrs[attr][\"classes\"].append(class_name)\n\n        # These are the types of attrs that can be set from the command line\n        attr_types = [\n            str,\n            int,\n            float,\n            bool,\n            Optional[int],\n            Optional[float],\n            Optional[str],\n        ]\n\n        # Add shared attribute options first\n        for attr, info in shared_attrs.items():\n            if info[\"type\"] in attr_types:\n                ctx.command.params.append(\n                    click.Option(\n                        [\"--\" + attr],\n                        type=info[\"type\"],\n                        help=\" \".join(info[\"metadata\"])\n                        + f\" (Applies to: {', '.join(info['classes'])})\",\n                        default=None,  # This is important, or it sets all the default keys again in config\n                        is_flag=info[\"is_flag\"],\n                        flag_value=True if info[\"is_flag\"] else None,\n                    )\n                )\n\n        # Second pass: create class-specific options\n        for base_type, base_type_dict in crawler.class_config_map.items():\n            if display_help:\n                click.echo(f\"{base_type}s:\")\n            for class_name, class_map in base_type_dict.items():\n                if display_help and class_map[\"config\"]:\n                    click.echo(\n                        f\"\\n  {class_name}: {class_map['class_type'].__doc__ or ''}\"\n                    )\n                    click.echo(\" \" * 4 + \"Attributes:\")\n                for attr, (attr_type, formatted_type, default, metadata) in class_map[\n                    \"config\"\n                ].items():\n                    class_name_attr = class_name + \"_\" + attr\n\n                    if display_help:\n                        click.echo(\" \" * 8 + f\"{attr} ({formatted_type}):\")\n                        click.echo(\n                            \"\\n\".join([f\"{' ' * 12}\" + desc for desc in metadata])\n                        )\n\n                    if attr_type in attr_types:\n                        is_flag = attr_type in [bool, Optional[bool]] and not default\n\n                        # Only add class-specific options\n                        ctx.command.params.append(\n                            click.Option(\n                                [\"--\" + class_name_attr, class_name_attr],\n                                type=attr_type,\n                                help=\" \".join(metadata),\n                                is_flag=is_flag,\n                                default=None,  # This is important, or it sets all the default keys again in config\n                            )\n                        )\n\n        if display_help:\n            ctx.exit()\n\n        super().parse_args(ctx, args)\n", "n_tokens": 705, "byte_len": 3962, "file_sha1": "c3a01e6895f54def52fc795922c50cac00638569", "start_line": 9, "end_line": 101}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "ConfigCrawler", "services", "class", "base", "extractor", "init", "provider", "config", "crawl", "builders", "annotated", "converters", "self", "providers", "importlib", "from", "dict", "processor", "builder", "inspect", "crawler", "service", "get", "origin", "processors", "pkgutil", "typing", "type", "renderers", "_crawl_config", "_gather_super_annotations", "attr_counts", "attr_set", "_find_subclasses", "_format_type", "superclass", "overwrite", "reversed", "walk", "subclass", "same", "format", "return", "except", "getattr", "staticmethod", "name", "default", "string"], "ast_kind": "class_or_type", "text": "import importlib\nimport inspect\nimport pkgutil\nfrom functools import cached_property\nfrom typing import Annotated, Dict, Set, Type, get_args, get_origin\n\nfrom marker.builders import BaseBuilder\nfrom marker.converters import BaseConverter\nfrom marker.extractors import BaseExtractor\nfrom marker.processors import BaseProcessor\nfrom marker.providers import BaseProvider\nfrom marker.renderers import BaseRenderer\nfrom marker.services import BaseService\n\n\nclass ConfigCrawler:\n    def __init__(\n        self,\n        base_classes=(\n            BaseBuilder,\n            BaseProcessor,\n            BaseConverter,\n            BaseProvider,\n            BaseRenderer,\n            BaseService,\n            BaseExtractor,\n        ),\n    ):\n        self.base_classes = base_classes\n        self.class_config_map: Dict[str, dict] = {}\n\n        self._crawl_config()\n", "n_tokens": 162, "byte_len": 852, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 1, "end_line": 33}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 2, "symbols": ["_crawl_config", "attr", "base", "desc", "startswith", "default", "crawl", "config", "formatted", "type", "annotated", "metadata", "else", "format", "self", "name", "removeprefix", "get", "origin", "getattr", "find", "subclasses", "class", "gather", "super", "continue", "args", "items", "classes", "setdefault", "__init__", "_gather_super_annotations", "attr_counts", "attr_set", "_find_subclasses", "_format_type", "ConfigCrawler", "extractor", "provider", "superclass", "overwrite", "reversed", "walk", "converters", "subclass", "dict", "processor", "same", "return", "inspect"], "ast_kind": "function_or_method", "text": "    def _crawl_config(self):\n        for base in self.base_classes:\n            base_class_type = base.__name__.removeprefix(\"Base\")\n            self.class_config_map.setdefault(base_class_type, {})\n            for class_name, class_type in self._find_subclasses(base).items():\n                if class_name.startswith(\"Base\"):\n                    continue\n\n                self.class_config_map[base_class_type].setdefault(\n                    class_name, {\"class_type\": class_type, \"config\": {}}\n                )\n                for attr, attr_type in self._gather_super_annotations(\n                    class_type\n                ).items():\n                    default = getattr(class_type, attr)\n                    metadata = (f\"Default is {default}.\",)\n\n                    if get_origin(attr_type) is Annotated:\n                        if any(\"Default\" in desc for desc in attr_type.__metadata__):\n                            metadata = attr_type.__metadata__\n                        else:\n                            metadata = attr_type.__metadata__ + metadata\n                        attr_type = get_args(attr_type)[0]\n\n                    formatted_type = self._format_type(attr_type)\n                    self.class_config_map[base_class_type][class_name][\"config\"][\n                        attr\n                    ] = (attr_type, formatted_type, default, metadata)\n", "n_tokens": 247, "byte_len": 1379, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 34, "end_line": 62}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 3, "symbols": ["_gather_super_annotations", "annotation", "annotations", "superclass", "bottom", "overwrite", "base", "mro", "reversed", "walk", "subclass", "from", "annotated", "attribute", "same", "return", "dict", "staticmethod", "type", "with", "gather", "super", "continue", "superclasses", "object", "derived", "items", "hasattr", "collect", "attributes", "__init__", "_crawl_config", "attr_counts", "attr_set", "_find_subclasses", "_format_type", "ConfigCrawler", "extractor", "provider", "converters", "config", "processor", "format", "inspect", "except", "getattr", "processors", "class", "name", "pkgutil"], "ast_kind": "class_or_type", "text": "    @staticmethod\n    def _gather_super_annotations(cls: Type) -> Dict[str, Type]:\n        \"\"\"\n        Collect all annotated attributes from `cls` and its superclasses, bottom-up.\n        Subclass attributes overwrite superclass attributes with the same name.\n        \"\"\"\n        # We'll walk the MRO from base -> derived so subclass attributes overwrite\n        # the same attribute name from superclasses.\n        annotations = {}\n        for base in reversed(cls.__mro__):\n            if base is object:\n                continue\n            if hasattr(base, \"__annotations__\"):\n                for name, annotation in base.__annotations__.items():\n                    annotations[name] = annotation\n        return annotations\n", "n_tokens": 136, "byte_len": 729, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 63, "end_line": 79}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 4, "symbols": ["attr_counts", "attr_set", "attr", "counts", "values", "base", "type", "self", "config", "return", "class", "set", "name", "map", "items", "keys", "cached", "property", "dict", "__init__", "_crawl_config", "_gather_super_annotations", "_find_subclasses", "_format_type", "ConfigCrawler", "extractor", "provider", "superclass", "overwrite", "reversed", "walk", "converters", "subclass", "annotated", "processor", "same", "format", "inspect", "except", "getattr", "staticmethod", "processors", "pkgutil", "default", "string", "continue", "marker", "origins", "separately", "pass"], "ast_kind": "function_or_method", "text": "    @cached_property\n    def attr_counts(self) -> Dict[str, int]:\n        counts: Dict[str, int] = {}\n        for base_type_dict in self.class_config_map.values():\n            for class_map in base_type_dict.values():\n                for attr in class_map[\"config\"].keys():\n                    counts[attr] = counts.get(attr, 0) + 1\n        return counts\n\n    @cached_property\n    def attr_set(self) -> Set[str]:\n        attr_set: Set[str] = set()\n        for base_type_dict in self.class_config_map.values():\n            for class_name, class_map in base_type_dict.items():\n                for attr in class_map[\"config\"].keys():\n                    attr_set.add(attr)\n                    attr_set.add(f\"{class_name}_{attr}\")\n        return attr_set\n", "n_tokens": 163, "byte_len": 751, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 80, "end_line": 98}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 5, "symbols": ["_find_subclasses", "path", "base", "class", "subclasses", "import", "module", "self", "importlib", "error", "return", "inspect", "except", "isclass", "find", "walk", "packages", "pkgutil", "getmembers", "name", "pass", "package", "issubclass", "hasattr", "__init__", "_crawl_config", "_gather_super_annotations", "attr_counts", "attr_set", "_format_type", "ConfigCrawler", "extractor", "provider", "superclass", "overwrite", "reversed", "converters", "subclass", "config", "dict", "annotated", "processor", "same", "format", "getattr", "staticmethod", "processors", "default", "string", "continue"], "ast_kind": "function_or_method", "text": "    def _find_subclasses(self, base_class):\n        subclasses = {}\n        module_name = base_class.__module__\n        package = importlib.import_module(module_name)\n        if hasattr(package, \"__path__\"):\n            for _, module_name, _ in pkgutil.walk_packages(\n                package.__path__, module_name + \".\"\n            ):\n                try:\n                    module = importlib.import_module(module_name)\n                    for name, obj in inspect.getmembers(module, inspect.isclass):\n                        if issubclass(obj, base_class) and obj is not base_class:\n                            subclasses[name] = obj\n                except ImportError:\n                    pass\n        return subclasses\n", "n_tokens": 130, "byte_len": 724, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 99, "end_line": 115}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/config/crawler.py", "rel_path": "marker/config/crawler.py", "module": "marker.config.crawler", "ext": "py", "chunk_number": 6, "symbols": ["_format_type", "regular", "into", "handle", "readable", "else", "format", "type", "self", "types", "name", "removeprefix", "return", "config", "crawler", "get", "origin", "typing", "with", "optional", "string", "origins", "separately", "like", "__init__", "_crawl_config", "_gather_super_annotations", "attr_counts", "attr_set", "_find_subclasses", "ConfigCrawler", "base", "extractor", "provider", "superclass", "overwrite", "reversed", "walk", "converters", "subclass", "dict", "annotated", "processor", "same", "inspect", "except", "getattr", "staticmethod", "processors", "class"], "ast_kind": "function_or_method", "text": "    def _format_type(self, t: Type) -> str:\n        \"\"\"Format a typing type like Optional[int] into a readable string.\"\"\"\n\n        if get_origin(t):  # Handle Optional and types with origins separately\n            return f\"{t}\".removeprefix(\"typing.\")\n        else:  # Regular types like int, str\n            return t.__name__\n\n\ncrawler = ConfigCrawler()\n", "n_tokens": 81, "byte_len": 355, "file_sha1": "bedaf788fc7a6b9071437a04c0f7473e603ff3d9", "start_line": 116, "end_line": 126}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py", "rel_path": "marker/providers/spreadsheet.py", "module": "marker.providers.spreadsheet", "ext": "py", "chunk_number": 1, "symbols": ["SpreadSheetProvider", "spread", "sheet", "class", "break", "tempfile", "auto", "avoid", "providers", "from", "size", "margin", "padding", "inside", "solid", "table", "import", "width", "font", "marker", "border", "collapse", "landscape", "page", "pdf", "provider", "__init__", "__del__", "convert_xlsx_to_pdf", "_get_merged_cell_ranges", "_excel_to_html_table", "exception", "merge", "info", "failed", "get", "merged", "start", "exists", "temp", "config", "stylesheets", "convert", "cells", "return", "file", "except", "colspan", "bounds", "filepath"], "ast_kind": "class_or_type", "text": "import os\nimport tempfile\n\nfrom marker.providers.pdf import PdfProvider\n\ncss = '''\n@page {\n    size: A4 landscape;\n    margin: 1.5cm;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n    break-inside: auto;\n    font-size: 10pt;\n}\n\ntr {\n    break-inside: avoid;\n    page-break-inside: avoid;\n}\n\ntd {\n    border: 0.75pt solid #000;\n    padding: 6pt;\n}\n'''\n\n\nclass SpreadSheetProvider(PdfProvider):", "n_tokens": 117, "byte_len": 405, "file_sha1": "aaebd372cf8a5552998e4fda848632800c24d755", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py", "rel_path": "marker/providers/spreadsheet.py", "module": "marker.providers.spreadsheet", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "__del__", "exception", "remove", "init", "failed", "none", "temp", "pdf", "initialize", "exists", "tempfile", "convert", "xlsx", "del", "suffix", "self", "config", "path", "delete", "except", "super", "runtime", "error", "filepath", "provider", "with", "raise", "false", "named", "convert_xlsx_to_pdf", "_get_merged_cell_ranges", "_excel_to_html_table", "SpreadSheetProvider", "merge", "info", "get", "merged", "start", "break", "stylesheets", "font", "cells", "return", "file", "colspan", "bounds", "staticmethod", "invalid", "solid"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        temp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=f\".pdf\")\n        self.temp_pdf_path = temp_pdf.name\n        temp_pdf.close()\n\n        # Convert XLSX to PDF\n        try:\n            self.convert_xlsx_to_pdf(filepath)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to convert {filepath} to PDF: {e}\")\n\n        # Initialize the PDF provider with the temp pdf path\n        super().__init__(self.temp_pdf_path, config)\n\n    def __del__(self):\n        if os.path.exists(self.temp_pdf_path):\n            os.remove(self.temp_pdf_path)\n", "n_tokens": 138, "byte_len": 623, "file_sha1": "aaebd372cf8a5552998e4fda848632800c24d755", "start_line": 32, "end_line": 49}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py", "rel_path": "marker/providers/spreadsheet.py", "module": "marker.providers.spreadsheet", "ext": "py", "chunk_number": 3, "symbols": ["convert_xlsx_to_pdf", "sheet", "none", "into", "temp", "pdf", "else", "convert", "xlsx", "html", "load", "workbook", "self", "from", "stylesheets", "get", "font", "excel", "file", "filepath", "invalid", "openpyxl", "raise", "string", "import", "weasyprint", "value", "error", "sheetnames", "write", "__init__", "__del__", "_get_merged_cell_ranges", "_excel_to_html_table", "SpreadSheetProvider", "exception", "merge", "info", "failed", "merged", "start", "exists", "break", "config", "cells", "return", "except", "colspan", "bounds", "staticmethod"], "ast_kind": "function_or_method", "text": "    def convert_xlsx_to_pdf(self, filepath: str):\n        from weasyprint import CSS, HTML\n        from openpyxl import load_workbook\n\n        html = \"\"\n        workbook = load_workbook(filepath)\n        if workbook is not None:\n            for sheet_name in workbook.sheetnames:\n                sheet = workbook[sheet_name]\n                html += f'<div><h1>{sheet_name}</h1>' + self._excel_to_html_table(sheet) + '</div>'\n        else:\n            raise ValueError(\"Invalid XLSX file\")\n\n        # We convert the HTML into a PDF\n        HTML(string=html).write_pdf(\n            self.temp_pdf_path,\n            stylesheets=[CSS(string=css), self.get_font_css()]\n        )\n", "n_tokens": 152, "byte_len": 673, "file_sha1": "aaebd372cf8a5552998e4fda848632800c24d755", "start_line": 50, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py", "rel_path": "marker/providers/spreadsheet.py", "module": "marker.providers.spreadsheet", "ext": "py", "chunk_number": 4, "symbols": ["_get_merged_cell_ranges", "sheet", "get", "merged", "ranges", "cells", "colspan", "min", "row", "max", "col", "bounds", "return", "staticmethod", "range", "info", "rowspan", "__init__", "__del__", "convert_xlsx_to_pdf", "_excel_to_html_table", "SpreadSheetProvider", "exception", "merge", "failed", "start", "exists", "break", "temp", "pdf", "config", "stylesheets", "font", "convert", "file", "except", "filepath", "invalid", "provider", "solid", "string", "continue", "skip", "marker", "this", "value", "part", "landscape", "page", "named"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def _get_merged_cell_ranges(sheet):\n        merged_info = {}\n        for merged_range in sheet.merged_cells.ranges:\n            min_col, min_row, max_col, max_row = merged_range.bounds\n            merged_info[(min_row, min_col)] = {\n                'rowspan': max_row - min_row + 1,\n                'colspan': max_col - min_col + 1,\n                'range': merged_range\n            }\n        return merged_info\n", "n_tokens": 101, "byte_len": 434, "file_sha1": "aaebd372cf8a5552998e4fda848632800c24d755", "start_line": 69, "end_line": 80}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/spreadsheet.py", "rel_path": "marker/providers/spreadsheet.py", "module": "marker.providers.spreadsheet", "ext": "py", "chunk_number": 5, "symbols": ["_excel_to_html_table", "check", "sheet", "merge", "info", "regular", "get", "merged", "start", "none", "skip", "cells", "row", "idx", "range", "else", "html", "col", "self", "being", "return", "excel", "colspan", "rows", "should", "enumerate", "with", "table", "track", "continue", "__init__", "__del__", "convert_xlsx_to_pdf", "_get_merged_cell_ranges", "SpreadSheetProvider", "exception", "failed", "exists", "break", "temp", "pdf", "config", "stylesheets", "font", "convert", "file", "except", "bounds", "filepath", "staticmethod"], "ast_kind": "function_or_method", "text": "    def _excel_to_html_table(self, sheet):\n        merged_cells = self._get_merged_cell_ranges(sheet)\n\n        html = f'<table>'\n\n        # Track cells we should skip due to being part of a merge range\n        skip_cells = set()\n\n        for row_idx, row in enumerate(sheet.rows, 1):\n            html += '<tr>'\n            for col_idx, cell in enumerate(row, 1):\n                if (row_idx, col_idx) in skip_cells:\n                    continue\n\n                # Check if this cell is the start of a merged range\n                merge_info = merged_cells.get((row_idx, col_idx))\n                if merge_info:\n                    # Add cells to skip\n                    for r in range(row_idx, row_idx + merge_info['rowspan']):\n                        for c in range(col_idx, col_idx + merge_info['colspan']):\n                            if (r, c) != (row_idx, col_idx):\n                                skip_cells.add((r, c))\n\n                    # Add merged cell with rowspan/colspan\n                    value = cell.value if cell.value is not None else ''\n                    html += f'<td rowspan=\"{merge_info[\"rowspan\"]}\" colspan=\"{merge_info[\"colspan\"]}\">{value}'\n                else:\n                    # Regular cell\n                    value = cell.value if cell.value is not None else ''\n                    html += f'<td>{value}'\n\n                html += '</td>'\n            html += '</tr>'\n        html += '</table>'\n        return html\n", "n_tokens": 303, "byte_len": 1452, "file_sha1": "aaebd372cf8a5552998e4fda848632800c24d755", "start_line": 81, "end_line": 116}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py", "rel_path": "marker/providers/registry.py", "module": "marker.providers.registry", "ext": "py", "chunk_number": 1, "symbols": ["load_matchers", "load_extensions", "spread", "sheet", "docx", "file", "match", "power", "point", "archive", "image", "load", "extensions", "html", "document", "types", "provider", "providers", "from", "powerpoint", "return", "filetype", "doctyp", "matchers", "extension", "epub", "doctype", "import", "marker", "xlsx", "provider_from_ext", "provider_from_filepath", "exception", "check", "find", "none", "detect", "parser", "soup", "incorrectly", "except", "there", "filepath", "strip", "fallback", "open", "tags", "with", "bool", "type"], "ast_kind": "function_or_method", "text": "import filetype\nimport filetype.match as file_match\nfrom bs4 import BeautifulSoup\nfrom filetype.types import archive, document, IMAGE\n\nfrom marker.providers.document import DocumentProvider\nfrom marker.providers.epub import EpubProvider\nfrom marker.providers.html import HTMLProvider\nfrom marker.providers.image import ImageProvider\nfrom marker.providers.pdf import PdfProvider\nfrom marker.providers.powerpoint import PowerPointProvider\nfrom marker.providers.spreadsheet import SpreadSheetProvider\n\nDOCTYPE_MATCHERS = {\n    \"image\": IMAGE,\n    \"pdf\": [\n        archive.Pdf,\n    ],\n    \"epub\": [\n        archive.Epub,\n    ],\n    \"doc\": [document.Docx],\n    \"xls\": [document.Xlsx],\n    \"ppt\": [document.Pptx],\n}\n\n\ndef load_matchers(doctype: str):\n    return [cls() for cls in DOCTYPE_MATCHERS[doctype]]\n\n\ndef load_extensions(doctype: str):\n    return [cls.EXTENSION for cls in DOCTYPE_MATCHERS[doctype]]\n\n", "n_tokens": 203, "byte_len": 903, "file_sha1": "9bd1176664a86bc85ac3a6257d35e4a6862e2064", "start_line": 1, "end_line": 35}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py", "rel_path": "marker/providers/registry.py", "module": "marker.providers.registry", "ext": "py", "chunk_number": 2, "symbols": ["provider_from_ext", "image", "load", "extensions", "epub", "provider", "spread", "sheet", "html", "power", "point", "document", "filepath", "strip", "rsplit", "from", "pdf", "return", "load_matchers", "load_extensions", "provider_from_filepath", "exception", "check", "find", "docx", "none", "file", "match", "detect", "parser", "soup", "archive", "types", "providers", "incorrectly", "powerpoint", "filetype", "except", "doctyp", "matchers", "there", "fallback", "open", "tags", "with", "extension", "doctype", "import", "bool", "marker"], "ast_kind": "function_or_method", "text": "def provider_from_ext(filepath: str):\n    ext = filepath.rsplit(\".\", 1)[-1].strip()\n    if not ext:\n        return PdfProvider\n\n    if ext in load_extensions(\"image\"):\n        return ImageProvider\n    if ext in load_extensions(\"pdf\"):\n        return PdfProvider\n    if ext in load_extensions(\"doc\"):\n        return DocumentProvider\n    if ext in load_extensions(\"xls\"):\n        return SpreadSheetProvider\n    if ext in load_extensions(\"ppt\"):\n        return PowerPointProvider\n    if ext in load_extensions(\"epub\"):\n        return EpubProvider\n    if ext in [\"html\"]:\n        return HTMLProvider\n\n    return PdfProvider\n\n", "n_tokens": 136, "byte_len": 621, "file_sha1": "9bd1176664a86bc85ac3a6257d35e4a6862e2064", "start_line": 36, "end_line": 58}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/registry.py", "rel_path": "marker/providers/registry.py", "module": "marker.providers.registry", "ext": "py", "chunk_number": 3, "symbols": ["provider_from_filepath", "exception", "check", "spread", "sheet", "find", "none", "detect", "file", "match", "parser", "power", "point", "soup", "html", "image", "provider", "incorrectly", "from", "return", "filetype", "except", "document", "there", "filepath", "fallback", "open", "tags", "with", "epub", "load_matchers", "load_extensions", "provider_from_ext", "docx", "archive", "load", "extensions", "types", "providers", "powerpoint", "doctyp", "matchers", "strip", "extension", "doctype", "import", "bool", "marker", "xlsx", "type"], "ast_kind": "function_or_method", "text": "def provider_from_filepath(filepath: str):\n    if filetype.image_match(filepath) is not None:\n        return ImageProvider\n    if file_match(filepath, load_matchers(\"pdf\")) is not None:\n        return PdfProvider\n    if file_match(filepath, load_matchers(\"epub\")) is not None:\n        return EpubProvider\n    if file_match(filepath, load_matchers(\"doc\")) is not None:\n        return DocumentProvider\n    if file_match(filepath, load_matchers(\"xls\")) is not None:\n        return SpreadSheetProvider\n    if file_match(filepath, load_matchers(\"ppt\")) is not None:\n        return PowerPointProvider\n\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            soup = BeautifulSoup(f.read(), \"html.parser\")\n            # Check if there are any HTML tags\n            if bool(soup.find()):\n                return HTMLProvider\n    except Exception:\n        pass\n\n    # Fallback if we incorrectly detect the file type\n    return provider_from_ext(filepath)\n", "n_tokens": 211, "byte_len": 966, "file_sha1": "9bd1176664a86bc85ac3a6257d35e4a6862e2064", "start_line": 59, "end_line": 84}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/html.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/html.py", "rel_path": "marker/providers/html.py", "module": "marker.providers.html", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__del__", "HTMLProvider", "exception", "convert", "html", "remove", "class", "init", "failed", "none", "temp", "pdf", "initialize", "exists", "tempfile", "del", "suffix", "self", "config", "providers", "from", "path", "delete", "except", "super", "runtime", "error", "filepath", "provider", "convert_html_to_pdf", "font", "css", "stylesheets", "get", "filename", "with", "raise", "import", "weasyprint", "marker", "false", "named", "temporary", "write", "encoding", "close", "name"], "ast_kind": "class_or_type", "text": "import os\nimport tempfile\n\nfrom marker.providers.pdf import PdfProvider\n\n\nclass HTMLProvider(PdfProvider):\n    def __init__(self, filepath: str, config=None):\n        temp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n        self.temp_pdf_path = temp_pdf.name\n        temp_pdf.close()\n\n        # Convert HTML to PDF\n        try:\n            self.convert_html_to_pdf(filepath)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to convert {filepath} to PDF: {e}\")\n\n        # Initialize the PDF provider with the temp pdf path\n        super().__init__(self.temp_pdf_path, config)\n\n    def __del__(self):\n        if os.path.exists(self.temp_pdf_path):\n            os.remove(self.temp_pdf_path)\n", "n_tokens": 155, "byte_len": 729, "file_sha1": "90350f3bd56c7b5cef9560432782a93f4bf8a15f", "start_line": 1, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/html.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/html.py", "rel_path": "marker/providers/html.py", "module": "marker.providers.html", "ext": "py", "chunk_number": 2, "symbols": ["convert_html_to_pdf", "convert", "html", "import", "weasyprint", "write", "pdf", "self", "filepath", "from", "temp", "stylesheets", "font", "css", "get", "filename", "encoding", "__init__", "__del__", "HTMLProvider", "exception", "remove", "class", "init", "failed", "none", "initialize", "exists", "tempfile", "del", "suffix", "config", "providers", "path", "delete", "except", "super", "runtime", "error", "provider", "with", "raise", "marker", "false", "named", "temporary", "close", "name"], "ast_kind": "function_or_method", "text": "    def convert_html_to_pdf(self, filepath: str):\n        from weasyprint import HTML\n\n        font_css = self.get_font_css()\n        HTML(filename=filepath, encoding=\"utf-8\").write_pdf(\n            self.temp_pdf_path, stylesheets=[font_css]\n        )\n", "n_tokens": 58, "byte_len": 252, "file_sha1": "90350f3bd56c7b5cef9560432782a93f4bf8a15f", "start_line": 26, "end_line": 33}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py", "rel_path": "marker/providers/__init__.py", "module": "marker.providers.__init__", "ext": "py", "chunk_number": 1, "symbols": ["raw_text", "__hash__", "ProviderOutput", "image", "bbox", "class", "assign", "config", "text", "none", "line", "reference", "raw", "provider", "output", "pydantic", "schema", "char", "self", "settings", "spans", "from", "span", "return", "dict", "base", "model", "list", "property", "hash", "merge", "__init__", "__len__", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "__enter__", "get_font_css", "BaseProvider", "get", "page", "family", "new", "font", "images", "filepath", "staticmethod", "ligatures", "string"], "ast_kind": "class_or_type", "text": "from copy import deepcopy\nfrom typing import List, Optional, Dict\n\nfrom PIL import Image\nfrom pydantic import BaseModel\n\nfrom pdftext.schema import Reference\n\nfrom marker.logger import configure_logging\nfrom marker.schema.polygon import PolygonBox\nfrom marker.schema.text import Span\nfrom marker.schema.text.char import Char\nfrom marker.schema.text.line import Line\nfrom marker.settings import settings\nfrom marker.util import assign_config\n\nconfigure_logging()\n\n\nclass ProviderOutput(BaseModel):\n    line: Line\n    spans: List[Span]\n    chars: Optional[List[List[Char]]] = None\n\n    @property\n    def raw_text(self):\n        return \"\".join(span.text for span in self.spans)\n\n    def __hash__(self):\n        return hash(tuple(self.line.polygon.bbox))\n", "n_tokens": 161, "byte_len": 751, "file_sha1": "5743606d3c6c5be365330401a5d35ca3087a3e0b", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py", "rel_path": "marker/providers/__init__.py", "module": "marker.providers.__init__", "ext": "py", "chunk_number": 2, "symbols": ["merge", "__init__", "__len__", "get_images", "BaseProvider", "image", "elif", "class", "init", "base", "provider", "assign", "config", "none", "idxs", "page", "new", "output", "self", "spans", "line", "dict", "other", "copy", "return", "get", "images", "model", "list", "filepath", "raw_text", "__hash__", "get_page_bbox", "get_page_lines", "get_page_refs", "__enter__", "get_font_css", "ProviderOutput", "family", "raw", "text", "char", "font", "property", "staticmethod", "ligatures", "string", "marker", "util", "pass"], "ast_kind": "class_or_type", "text": "    def merge(self, other: \"ProviderOutput\"):\n        new_output = deepcopy(self)\n        other_copy = deepcopy(other)\n\n        new_output.spans.extend(other_copy.spans)\n        if new_output.chars is not None and other_copy.chars is not None:\n            new_output.chars.extend(other_copy.chars)\n        elif other_copy.chars is not None:\n            new_output.chars = other_copy.chars\n\n        new_output.line.polygon = new_output.line.polygon.merge(\n            [other_copy.line.polygon]\n        )\n        return new_output\n\n\nProviderPageLines = Dict[int, List[ProviderOutput]]\n\n\nclass BaseProvider:\n    def __init__(self, filepath: str, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n        self.filepath = filepath\n\n    def __len__(self):\n        pass\n\n    def get_images(self, idxs: List[int], dpi: int) -> List[Image.Image]:\n        pass\n", "n_tokens": 197, "byte_len": 881, "file_sha1": "5743606d3c6c5be365330401a5d35ca3087a3e0b", "start_line": 32, "end_line": 61}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py", "rel_path": "marker/providers/__init__.py", "module": "marker.providers.__init__", "ext": "py", "chunk_number": 3, "symbols": ["get_page_bbox", "get_page_lines", "get_page_refs", "__enter__", "reference", "enter", "list", "self", "pass", "get", "page", "none", "polygon", "box", "line", "return", "raw_text", "__hash__", "merge", "__init__", "__len__", "get_images", "get_font_css", "ProviderOutput", "BaseProvider", "base", "provider", "family", "raw", "text", "new", "output", "char", "config", "dict", "font", "images", "property", "filepath", "staticmethod", "ligatures", "string", "marker", "util", "pdftext", "span", "fonts", "split", "noto", "current"], "ast_kind": "function_or_method", "text": "    def get_page_bbox(self, idx: int) -> PolygonBox | None:\n        pass\n\n    def get_page_lines(self, idx: int) -> List[Line]:\n        pass\n\n    def get_page_refs(self, idx: int) -> List[Reference]:\n        pass\n\n    def __enter__(self):\n        return self\n", "n_tokens": 69, "byte_len": 259, "file_sha1": "5743606d3c6c5be365330401a5d35ca3087a3e0b", "start_line": 62, "end_line": 73}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/__init__.py", "rel_path": "marker/providers/__init__.py", "module": "marker.providers.__init__", "ext": "py", "chunk_number": 4, "symbols": ["get_font_css", "variant", "fonts", "split", "regular", "swap", "text", "noto", "current", "sans", "family", "fon", "path", "display", "rendering", "settings", "from", "liga", "get", "font", "face", "body", "return", "none", "optimize", "legibility", "staticmethod", "configuration", "ligatures", "config", "raw_text", "__hash__", "merge", "__init__", "__len__", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "__enter__", "ProviderOutput", "BaseProvider", "base", "provider", "page", "raw", "new", "output", "char", "dict"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def get_font_css():\n        from weasyprint import CSS\n        from weasyprint.text.fonts import FontConfiguration\n\n        font_config = FontConfiguration()\n        css = CSS(\n            string=f\"\"\"\n            @font-face {{\n                font-family: GoNotoCurrent-Regular;\n                src: url({settings.FONT_PATH});\n                font-display: swap;\n            }}\n            body {{\n                font-family: {settings.FONT_NAME.split(\".\")[0]}, sans-serif;\n                font-variant-ligatures: none;\n                font-feature-settings: \"liga\" 0;\n                text-rendering: optimizeLegibility;\n            }}\n            \"\"\",\n            font_config=font_config,\n        )\n        return css\n", "n_tokens": 145, "byte_len": 742, "file_sha1": "5743606d3c6c5be365330401a5d35ca3087a3e0b", "start_line": 74, "end_line": 97}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 1, "symbols": ["image", "fix", "text", "base", "provider", "line", "flatten", "pdf", "extraction", "about", "page", "form", "pypdfium", "pypdfium2", "annotated", "ctypes", "reference", "output", "pdfium", "dictionary", "utils", "schema", "error", "providers", "from", "get", "logger", "logging", "span", "contextlib", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "covering"], "ast_kind": "imports", "text": "import contextlib\nimport ctypes\nimport logging\nimport re\nfrom typing import Annotated, Dict, List, Optional, Set\n\nimport pypdfium2 as pdfium\nimport pypdfium2.raw as pdfium_c\nfrom ftfy import fix_text\nfrom pdftext.extraction import dictionary_output\nfrom pdftext.schema import Reference\nfrom pdftext.pdf.utils import flatten as flatten_pdf_page\n\nfrom PIL import Image\nfrom pypdfium2 import PdfiumError, PdfDocument\n\nfrom marker.providers import BaseProvider, ProviderOutput, Char, ProviderPageLines\nfrom marker.providers.utils import alphanum_ratio\nfrom marker.schema import BlockTypes\nfrom marker.schema.polygon import PolygonBox\nfrom marker.schema.registry import get_block_class\nfrom marker.schema.text.line import Line\nfrom marker.schema.text.span import Span\n\n# Ignore pypdfium2 warning about form flattening\nlogging.getLogger(\"pypdfium2\").setLevel(logging.ERROR)\n\n", "n_tokens": 201, "byte_len": 869, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 2, "symbols": ["PdfProvider", "alphanumeric", "class", "strip", "existing", "base", "provider", "none", "force", "ocr", "detect", "text", "character", "information", "process", "characters", "float", "image", "threshold", "skipping", "disable", "links", "range", "whole", "pdftext", "workers", "annotated", "spaces", "document", "from", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "breaking", "ideographic", "get", "page"], "ast_kind": "class_or_type", "text": "class PdfProvider(BaseProvider):\n    \"\"\"\n    A provider for PDF files.\n    \"\"\"\n\n    page_range: Annotated[\n        List[int],\n        \"The range of pages to process.\",\n        \"Default is None, which will process all pages.\",\n    ] = None\n    pdftext_workers: Annotated[\n        int,\n        \"The number of workers to use for pdftext.\",\n    ] = 4\n    flatten_pdf: Annotated[\n        bool,\n        \"Whether to flatten the PDF structure.\",\n    ] = True\n    force_ocr: Annotated[\n        bool,\n        \"Whether to force OCR on the whole document.\",\n    ] = False\n    ocr_invalid_chars: Annotated[\n        tuple,\n        \"The characters to consider invalid for OCR.\",\n    ] = (chr(0xFFFD), \"\")\n    ocr_space_threshold: Annotated[\n        float,\n        \"The minimum ratio of spaces to non-spaces to detect bad text.\",\n    ] = 0.7\n    ocr_newline_threshold: Annotated[\n        float,\n        \"The minimum ratio of newlines to non-newlines to detect bad text.\",\n    ] = 0.6\n    ocr_alphanum_threshold: Annotated[\n        float,\n        \"The minimum ratio of alphanumeric characters to non-alphanumeric characters to consider an alphanumeric character.\",\n    ] = 0.3\n    image_threshold: Annotated[\n        float,\n        \"The minimum coverage ratio of the image to the page to consider skipping the page.\",\n    ] = 0.65\n    strip_existing_ocr: Annotated[\n        bool,\n        \"Whether to strip existing OCR text from the PDF.\",\n    ] = False\n    disable_links: Annotated[\n        bool,\n        \"Whether to disable links.\",\n    ] = False\n    keep_chars: Annotated[\n        bool,\n        \"Whether to keep character-level information in the output.\",\n    ] = False\n", "n_tokens": 400, "byte_len": 1660, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 29, "end_line": 83}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "init", "assert", "none", "force", "ocr", "page", "bboxes", "provider", "range", "between", "else", "reference", "provided", "get", "doc", "self", "config", "from", "since", "refs", "assign", "dict", "super", "lines", "list", "bbox", "filepath", "invalid", "with", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "covering", "back"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        super().__init__(filepath, config)\n\n        self.filepath = filepath\n\n        with self.get_doc() as doc:\n            self.page_count = len(doc)\n            self.page_lines: ProviderPageLines = {i: [] for i in range(len(doc))}\n            self.page_refs: Dict[int, List[Reference]] = {\n                i: [] for i in range(len(doc))\n            }\n\n            if self.page_range is None:\n                self.page_range = range(len(doc))\n\n            assert max(self.page_range) < len(doc) and min(self.page_range) >= 0, (\n                f\"Invalid page range, values must be between 0 and {len(doc) - 1}.  Min of provided page range is {min(self.page_range)} and max is {max(self.page_range)}.\"\n            )\n\n            if self.force_ocr:\n                # Manually assign page bboxes, since we can't get them from pdftext\n                self.page_bboxes = {i: doc[i].get_bbox() for i in self.page_range}\n            else:\n                self.page_lines = self.pdftext_extraction(doc)\n", "n_tokens": 245, "byte_len": 1050, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 84, "end_line": 108}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 4, "symbols": ["get_doc", "__len__", "none", "parent", "get", "doc", "self", "called", "retrieving", "contextlib", "correctly", "return", "render", "must", "yield", "filepath", "pdfium", "pages", "len", "init", "forms", "pdf", "document", "finally", "flatten", "before", "page", "count", "contextmanager", "close", "__init__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "covering", "back", "utils"], "ast_kind": "function_or_method", "text": "    @contextlib.contextmanager\n    def get_doc(self):\n        doc = None\n        try:\n            doc = pdfium.PdfDocument(self.filepath)\n\n            # Must be called on the parent pdf, before retrieving pages to render correctly\n            if self.flatten_pdf:\n                doc.init_forms()\n\n            yield doc\n        finally:\n            if doc:\n                doc.close()\n\n    def __len__(self) -> int:\n        return self.page_count\n", "n_tokens": 92, "byte_len": 447, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 109, "end_line": 126}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 5, "symbols": ["font_flags_to_format", "serif", "elif", "none", "plain", "use", "extern", "italic", "else", "formats", "self", "flag", "name", "fixed", "pitch", "bold", "set", "flags", "return", "bit", "position", "symbolic", "small", "cap", "force", "optional", "map", "all", "script", "nonsymbolic", "__init__", "get_doc", "__len__", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "get", "page"], "ast_kind": "function_or_method", "text": "    def font_flags_to_format(self, flags: Optional[int]) -> Set[str]:\n        if flags is None:\n            return {\"plain\"}\n\n        flag_map = {\n            1: \"FixedPitch\",\n            2: \"Serif\",\n            3: \"Symbolic\",\n            4: \"Script\",\n            6: \"Nonsymbolic\",\n            7: \"Italic\",\n            17: \"AllCap\",\n            18: \"SmallCap\",\n            19: \"ForceBold\",\n            20: \"UseExternAttr\",\n        }\n        set_flags = set()\n        for bit_position, flag_name in flag_map.items():\n            if flags & (1 << (bit_position - 1)):\n                set_flags.add(flag_name)\n        if not set_flags:\n            set_flags.add(\"Plain\")\n\n        formats = set()\n        if set_flags == {\"Symbolic\", \"Italic\"} or set_flags == {\n            \"Symbolic\",\n            \"Italic\",\n            \"UseExternAttr\",\n        }:\n            formats.add(\"plain\")\n        elif set_flags == {\"UseExternAttr\"}:\n            formats.add(\"plain\")\n        elif set_flags == {\"Plain\"}:\n            formats.add(\"plain\")\n        else:\n            if set_flags & {\"Italic\"}:\n                formats.add(\"italic\")\n            if set_flags & {\"ForceBold\"}:\n                formats.add(\"bold\")\n            if set_flags & {\n                \"FixedPitch\",\n                \"Serif\",\n                \"Script\",\n                \"Nonsymbolic\",\n                \"AllCap\",\n                \"SmallCap\",\n                \"UseExternAttr\",\n            }:\n                formats.add(\"plain\")\n        return formats\n", "n_tokens": 336, "byte_len": 1497, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 127, "end_line": 177}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 6, "symbols": ["font_names_to_format", "normalize_spaces", "ital", "breaking", "u200b", "u2003", "ideographic", "none", "text", "space", "chars", "u00a0", "u3000", "formats", "self", "u2002", "font", "name", "bold", "lower", "normalize", "spaces", "return", "replace", "staticmethod", "names", "width", "italic", "zero", "__init__", "get_doc", "__len__", "font_flags_to_format", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "get", "page", "covering", "back", "utils", "logging"], "ast_kind": "function_or_method", "text": "    def font_names_to_format(self, font_name: str | None) -> Set[str]:\n        formats = set()\n        if font_name is None:\n            return formats\n\n        if \"bold\" in font_name.lower():\n            formats.add(\"bold\")\n        if \"ital\" in font_name.lower():\n            formats.add(\"italic\")\n        return formats\n\n    @staticmethod\n    def normalize_spaces(text):\n        space_chars = [\n            \"\\u2003\",  # em space\n            \"\\u2002\",  # en space\n            \"\\u00a0\",  # non-breaking space\n            \"\\u200b\",  # zero-width space\n            \"\\u3000\",  # ideographic space\n        ]\n        for space in space_chars:\n            text = text.replace(space, \" \")\n        return text\n", "n_tokens": 167, "byte_len": 702, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 178, "end_line": 201}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 7, "symbols": ["pdftext_extraction", "minimum", "position", "check", "line", "pdftext", "workers", "formats", "char", "page", "refs", "return", "mismatch", "filepath", "class", "lines", "keep", "chars", "font", "names", "pdf", "document", "union", "continue", "flatten", "span", "true", "extraction", "text", "blocks", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "get", "covering"], "ast_kind": "function_or_method", "text": "    def pdftext_extraction(self, doc: PdfDocument) -> ProviderPageLines:\n        page_lines: ProviderPageLines = {}\n        page_char_blocks = dictionary_output(\n            self.filepath,\n            page_range=self.page_range,\n            keep_chars=self.keep_chars,\n            workers=self.pdftext_workers,\n            flatten_pdf=self.flatten_pdf,\n            quote_loosebox=False,\n            disable_links=self.disable_links,\n        )\n        self.page_bboxes = {\n            i: [0, 0, page[\"width\"], page[\"height\"]]\n            for i, page in zip(self.page_range, page_char_blocks)\n        }\n\n        SpanClass: Span = get_block_class(BlockTypes.Span)\n        LineClass: Line = get_block_class(BlockTypes.Line)\n        CharClass: Char = get_block_class(BlockTypes.Char)\n\n        for page in page_char_blocks:\n            page_id = page[\"page\"]\n            lines: List[ProviderOutput] = []\n            if not self.check_page(page_id, doc):\n                continue\n\n            for block in page[\"blocks\"]:\n                for line in block[\"lines\"]:\n                    spans: List[Span] = []\n                    chars: List[List[Char]] = []\n                    for span in line[\"spans\"]:\n                        if not span[\"text\"]:\n                            continue\n                        font_formats = self.font_flags_to_format(\n                            span[\"font\"][\"flags\"]\n                        ).union(self.font_names_to_format(span[\"font\"][\"name\"]))\n                        font_name = span[\"font\"][\"name\"] or \"Unknown\"\n                        font_weight = span[\"font\"][\"weight\"] or 0\n                        font_size = span[\"font\"][\"size\"] or 0\n                        polygon = PolygonBox.from_bbox(\n                            span[\"bbox\"], ensure_nonzero_area=True\n                        )\n                        superscript = span.get(\"superscript\", False)\n                        subscript = span.get(\"subscript\", False)\n                        text = self.normalize_spaces(fix_text(span[\"text\"]))\n                        if superscript or superscript:\n                            text = text.strip()\n\n                        spans.append(\n                            SpanClass(\n                                polygon=polygon,\n                                text=text,\n                                font=font_name,\n                                font_weight=font_weight,\n                                font_size=font_size,\n                                minimum_position=span[\"char_start_idx\"],\n                                maximum_position=span[\"char_end_idx\"],\n                                formats=list(font_formats),\n                                page_id=page_id,\n                                text_extraction_method=\"pdftext\",\n                                url=span.get(\"url\"),\n                                has_superscript=superscript,\n                                has_subscript=subscript,\n                            )\n                        )\n\n                        if self.keep_chars:\n                            span_chars = [\n                                CharClass(\n                                    text=c[\"char\"],\n                                    polygon=PolygonBox.from_bbox(\n                                        c[\"bbox\"], ensure_nonzero_area=True\n                                    ),\n                                    idx=c[\"char_idx\"],\n                                )\n                                for c in span[\"chars\"]\n                            ]\n                            chars.append(span_chars)\n                        else:\n                            chars.append([])\n\n                    polygon = PolygonBox.from_bbox(\n                        line[\"bbox\"], ensure_nonzero_area=True\n                    )\n\n                    assert len(spans) == len(chars), (\n                        f\"Spans and chars length mismatch on page {page_id}: {len(spans)} spans, {len(chars)} chars\"\n                    )\n                    lines.append(\n                        ProviderOutput(\n                            line=LineClass(polygon=polygon, page_id=page_id),\n                            spans=spans,\n                            chars=chars,\n                        )\n                    )\n            if self.check_line_spans(lines):\n                page_lines[page_id] = lines\n\n            self.page_refs[page_id] = []\n            if page_refs := page.get(\"refs\", None):\n                self.page_refs[page_id] = page_refs\n\n        return page_lines\n", "n_tokens": 747, "byte_len": 4555, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 202, "end_line": 305}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 8, "symbols": ["check_line_spans", "bool", "provider", "output", "page", "lines", "detect", "bad", "list", "self", "text", "spans", "strip", "line", "false", "check", "span", "true", "return", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "get", "covering", "back", "utils", "logging", "assign", "bold", "fpd", "textrendermod", "invalid", "force", "default", "which"], "ast_kind": "function_or_method", "text": "    def check_line_spans(self, page_lines: List[ProviderOutput]) -> bool:\n        page_spans = [span for line in page_lines for span in line.spans]\n        if len(page_spans) == 0:\n            return False\n\n        text = \"\"\n        for span in page_spans:\n            text = text + \" \" + span.text\n            text = text + \"\\n\"\n        if len(text.strip()) == 0:\n            return False\n        if self.detect_bad_ocr(text):\n            return False\n        return True\n", "n_tokens": 115, "byte_len": 473, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 306, "end_line": 320}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 9, "symbols": ["check_page", "fonts", "strip", "existing", "glyphless", "objects", "text", "most", "large", "font", "map", "check", "mode", "fpd", "textrendermod", "non", "embedded", "get", "image", "threshold", "fpdf", "also", "empty", "page", "pypdfium", "pypdfium2", "back", "covering", "images", "pdfium", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "utils", "logging"], "ast_kind": "function_or_method", "text": "    def check_page(self, page_id: int, doc: PdfDocument) -> bool:\n        page = doc.get_page(page_id)\n        page_bbox = PolygonBox.from_bbox(page.get_bbox())\n        try:\n            page_objs = list(\n                page.get_objects(\n                    filter=[pdfium_c.FPDF_PAGEOBJ_TEXT, pdfium_c.FPDF_PAGEOBJ_IMAGE]\n                )\n            )\n        except PdfiumError:\n            # Happens when pdfium fails to get the number of page objects\n            return False\n\n        # if we do not see any text objects in the pdf, we can skip this page\n        if not any([obj.type == pdfium_c.FPDF_PAGEOBJ_TEXT for obj in page_objs]):\n            return False\n\n        if self.strip_existing_ocr:\n            # If any text objects on the page are in invisible render mode, skip this page\n            for text_obj in filter(\n                lambda obj: obj.type == pdfium_c.FPDF_PAGEOBJ_TEXT, page_objs\n            ):\n                if pdfium_c.FPDFTextObj_GetTextRenderMode(text_obj) in [\n                    pdfium_c.FPDF_TEXTRENDERMODE_INVISIBLE,\n                    pdfium_c.FPDF_TEXTRENDERMODE_UNKNOWN,\n                ]:\n                    return False\n\n            non_embedded_fonts = []\n            empty_fonts = []\n            font_map = {}\n            for text_obj in filter(\n                lambda obj: obj.type == pdfium_c.FPDF_PAGEOBJ_TEXT, page_objs\n            ):\n                font = pdfium_c.FPDFTextObj_GetFont(text_obj)\n                font_name = self._get_fontname(font)\n\n                # we also skip pages without embedded fonts and fonts without names\n                non_embedded_fonts.append(pdfium_c.FPDFFont_GetIsEmbedded(font) == 0)\n                empty_fonts.append(\n                    \"glyphless\" in font_name.lower()\n                )  # Add font name check back in when we bump pypdfium2\n                if font_name not in font_map:\n                    font_map[font_name or \"Unknown\"] = font\n\n            if all(non_embedded_fonts) or all(empty_fonts):\n                return False\n\n            # if we see very large images covering most of the page, we can skip this page\n            for img_obj in filter(\n                lambda obj: obj.type == pdfium_c.FPDF_PAGEOBJ_IMAGE, page_objs\n            ):\n                img_bbox = PolygonBox.from_bbox(img_obj.get_pos())\n                if page_bbox.intersection_pct(img_bbox) >= self.image_threshold:\n                    return False\n\n        return True\n", "n_tokens": 519, "byte_len": 2456, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 321, "end_line": 378}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 10, "symbols": ["detect_bad_ocr", "text", "assume", "detect", "bad", "findall", "alpha", "chars", "spaces", "invalid", "self", "newlines", "return", "non", "ocr", "newline", "have", "alphanum", "ratio", "garbled", "space", "false", "failed", "true", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "_render_image", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "get", "page", "covering", "back", "utils", "logging", "assign", "bold"], "ast_kind": "function_or_method", "text": "    def detect_bad_ocr(self, text):\n        if len(text) == 0:\n            # Assume OCR failed if we have no text\n            return True\n\n        spaces = len(re.findall(r\"\\s+\", text))\n        alpha_chars = len(re.sub(r\"\\s+\", \"\", text))\n        if spaces / (alpha_chars + spaces) > self.ocr_space_threshold:\n            return True\n\n        newlines = len(re.findall(r\"\\n+\", text))\n        non_newlines = len(re.sub(r\"\\n+\", \"\", text))\n        if newlines / (newlines + non_newlines) > self.ocr_newline_threshold:\n            return True\n\n        if alphanum_ratio(text) < self.ocr_alphanum_threshold:  # Garbled text\n            return True\n\n        invalid_chars = len([c for c in text if c in self.ocr_invalid_chars])\n        if invalid_chars > max(6.0, len(text) * 0.03):\n            return True\n\n        return False\n", "n_tokens": 209, "byte_len": 822, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 379, "end_line": 402}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 11, "symbols": ["_render_image", "get_images", "get_page_bbox", "render", "image", "bbox", "draw", "annots", "none", "get", "page", "bboxes", "scale", "flatten", "pdf", "idxs", "images", "doc", "self", "convert", "return", "list", "staticmethod", "pdfium", "pil", "with", "document", "bool", "polygon", "box", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "get_page_lines", "get_page_refs", "_get_fontname", "PdfProvider", "breaking", "ideographic", "covering", "back", "utils", "logging"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def _render_image(\n        pdf: pdfium.PdfDocument, idx: int, dpi: int, flatten_page: bool\n    ) -> Image.Image:\n        page = pdf[idx]\n        if flatten_page:\n            flatten_pdf_page(page)\n            page = pdf[idx]\n        image = page.render(scale=dpi / 72, draw_annots=False).to_pil()\n        image = image.convert(\"RGB\")\n        return image\n\n    def get_images(self, idxs: List[int], dpi: int) -> List[Image.Image]:\n        with self.get_doc() as doc:\n            images = [\n                self._render_image(doc, idx, dpi, self.flatten_pdf) for idx in idxs\n            ]\n        return images\n\n    def get_page_bbox(self, idx: int) -> PolygonBox | None:\n        bbox = self.page_bboxes.get(idx)\n        if bbox:\n            return PolygonBox.from_bbox(bbox)\n", "n_tokens": 195, "byte_len": 796, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 403, "end_line": 426}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/pdf.py", "rel_path": "marker/providers/pdf.py", "module": "marker.providers.pdf", "ext": "py", "chunk_number": 12, "symbols": ["get_page_lines", "get_page_refs", "_get_fontname", "exception", "fpdf", "font", "else", "reference", "ctypes", "provider", "output", "pdfium", "self", "get", "page", "refs", "name", "return", "decode", "lines", "length", "except", "list", "create", "string", "staticmethod", "value", "fontname", "pass", "buffer", "__init__", "get_doc", "__len__", "font_flags_to_format", "font_names_to_format", "normalize_spaces", "pdftext_extraction", "check_line_spans", "check_page", "detect_bad_ocr", "_render_image", "get_images", "get_page_bbox", "PdfProvider", "breaking", "ideographic", "covering", "back", "utils", "logging"], "ast_kind": "function_or_method", "text": "    def get_page_lines(self, idx: int) -> List[ProviderOutput]:\n        return self.page_lines[idx]\n\n    def get_page_refs(self, idx: int) -> List[Reference]:\n        return self.page_refs[idx]\n\n    @staticmethod\n    def _get_fontname(font) -> str:\n        font_name = \"\"\n        buffer_size = 256\n\n        try:\n            font_name_buffer = ctypes.create_string_buffer(buffer_size)\n            length = pdfium_c.FPDFFont_GetBaseFontName(\n                font, font_name_buffer, buffer_size\n            )\n            if length < buffer_size:\n                font_name = font_name_buffer.value.decode(\"utf-8\")\n            else:\n                font_name_buffer = ctypes.create_string_buffer(length)\n                pdfium_c.FPDFFont_GetBaseFontName(font, font_name_buffer, length)\n                font_name = font_name_buffer.value.decode(\"utf-8\")\n        except Exception:\n            pass\n\n        return font_name\n", "n_tokens": 197, "byte_len": 917, "file_sha1": "c5e0f7910304f6c7864bf97dbe7b694785084143", "start_line": 427, "end_line": 453}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 1, "symbols": ["PowerPointProvider", "class", "traceback", "get", "logger", "power", "point", "break", "contain", "tempfile", "include", "slide", "auto", "base", "base64", "avoid", "providers", "from", "size", "height", "margin", "padding", "inside", "solid", "table", "import", "width", "font", "marker", "bool", "__init__", "__del__", "convert_pptx_to_pdf", "_handle_group", "_handle_text", "_handle_image", "_handle_table", "_escape_html", "exception", "find", "cannot", "enum", "start", "shape", "nsmap", "exists", "placeholder", "bullet", "num", "temp"], "ast_kind": "class_or_type", "text": "import base64\nimport os\nimport tempfile\nimport traceback\n\nfrom marker.logger import get_logger\nfrom marker.providers.pdf import PdfProvider\n\nlogger = get_logger()\n\ncss = \"\"\"\n@page {\n    size: A4 landscape;\n    margin: 1.5cm;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n    break-inside: auto;\n    font-size: 10pt;\n}\n\ntr {\n    break-inside: avoid;\n    page-break-inside: avoid;\n}\n\ntd {\n    border: 0.75pt solid #000;\n    padding: 6pt;\n}\n\nimg {\n    max-width: 100%;\n    height: auto;\n    object-fit: contain;\n}\n\"\"\"\n\n\nclass PowerPointProvider(PdfProvider):\n    include_slide_number: bool = False\n", "n_tokens": 164, "byte_len": 608, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 1, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "__del__", "exception", "remove", "convert", "pptx", "init", "none", "traceback", "temp", "pdf", "exists", "format", "exc", "tempfile", "del", "suffix", "self", "config", "print", "path", "delete", "except", "super", "initalize", "filepath", "error", "provider", "with", "raise", "convert_pptx_to_pdf", "_handle_group", "_handle_text", "_handle_image", "_handle_table", "_escape_html", "PowerPointProvider", "find", "cannot", "enum", "start", "shape", "nsmap", "placeholder", "break", "bullet", "num", "image", "include", "slide"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        temp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n        self.temp_pdf_path = temp_pdf.name\n        temp_pdf.close()\n\n        # Convert PPTX to PDF\n        try:\n            self.convert_pptx_to_pdf(filepath)\n        except Exception as e:\n            print(traceback.format_exc())\n            raise ValueError(f\"Error converting PPTX to PDF: {e}\")\n\n        # Initalize the PDF provider with the temp pdf path\n        super().__init__(self.temp_pdf_path, config)\n\n    def __del__(self):\n        if os.path.exists(self.temp_pdf_path):\n            os.remove(self.temp_pdf_path)\n", "n_tokens": 145, "byte_len": 654, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 45, "end_line": 63}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 3, "symbols": ["convert_pptx_to_pdf", "convert", "pptx", "presentation", "slide", "enum", "text", "none", "into", "shape", "temp", "pdf", "handle", "placeholders", "group", "shapes", "slides", "include", "else", "html", "append", "process", "self", "type", "from", "grouped", "stylesheets", "table", "distinguish", "get", "__init__", "__del__", "_handle_group", "_handle_text", "_handle_image", "_handle_table", "_escape_html", "PowerPointProvider", "exception", "find", "cannot", "start", "traceback", "nsmap", "exists", "placeholder", "break", "bullet", "num", "image"], "ast_kind": "function_or_method", "text": "    def convert_pptx_to_pdf(self, filepath):\n        from weasyprint import CSS, HTML\n        from pptx import Presentation\n        from pptx.enum.shapes import MSO_SHAPE_TYPE\n\n        pptx = Presentation(filepath)\n\n        html_parts = []\n\n        for slide_index, slide in enumerate(pptx.slides):\n            html_parts.append(\"<section>\")\n            if self.include_slide_number:\n                html_parts.append(f\"<h2>Slide {slide_index + 1}</h2>\")\n\n            # Process shapes in the slide\n            for shape in slide.shapes:\n                # If shape is a group shape, we recursively handle all grouped shapes\n                if shape.shape_type == MSO_SHAPE_TYPE.GROUP:\n                    html_parts.append(self._handle_group(shape))\n                    continue\n\n                # If shape is a table\n                if shape.has_table:\n                    html_parts.append(self._handle_table(shape))\n                    continue\n\n                # If shape is a picture\n                if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n                    html_parts.append(self._handle_image(shape))\n                    continue\n\n                # If shape has text\n                if hasattr(shape, \"text\") and shape.text is not None:\n                    if shape.has_text_frame:\n                        # Distinguish placeholders (title, subtitle, etc.)\n                        html_parts.append(self._handle_text(shape))\n                    else:\n                        html_parts.append(f\"<p>{self._escape_html(shape.text)}</p>\")\n\n            html_parts.append(\"</section>\")\n\n        html = \"\\n\".join(html_parts)\n\n        # We convert the HTML into a PDF\n        HTML(string=html).write_pdf(\n            self.temp_pdf_path, stylesheets=[CSS(string=css), self.get_font_css()]\n        )\n", "n_tokens": 349, "byte_len": 1806, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 64, "end_line": 111}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 4, "symbols": ["_handle_group", "enum", "text", "shape", "handle", "group", "shapes", "else", "html", "type", "append", "self", "from", "table", "return", "returns", "image", "picture", "entire", "escape", "pptx", "parts", "has", "string", "import", "continue", "shap", "join", "hasattr", "recursively", "__init__", "__del__", "convert_pptx_to_pdf", "_handle_text", "_handle_image", "_handle_table", "_escape_html", "PowerPointProvider", "exception", "find", "cannot", "start", "traceback", "nsmap", "exists", "placeholder", "break", "bullet", "num", "temp"], "ast_kind": "function_or_method", "text": "    def _handle_group(self, group_shape) -> str:\n        \"\"\"\n        Recursively handle shapes in a group. Returns HTML string for the entire group.\n        \"\"\"\n        from pptx.enum.shapes import MSO_SHAPE_TYPE\n\n        group_parts = []\n        for shape in group_shape.shapes:\n            if shape.shape_type == MSO_SHAPE_TYPE.GROUP:\n                group_parts.append(self._handle_group(shape))\n                continue\n\n            if shape.has_table:\n                group_parts.append(self._handle_table(shape))\n                continue\n\n            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n                group_parts.append(self._handle_image(shape))\n                continue\n\n            if hasattr(shape, \"text\"):\n                if shape.has_text_frame:\n                    group_parts.append(self._handle_text(shape))\n                else:\n                    group_parts.append(f\"<p>{self._escape_html(shape.text)}</p>\")\n\n        return \"\".join(group_parts)\n", "n_tokens": 183, "byte_len": 978, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 112, "end_line": 139}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 5, "symbols": ["_handle_text", "find", "enum", "start", "shape", "nsmap", "placeholder", "bullet", "num", "namespaces", "return", "pptx", "open", "were", "frame", "continue", "text", "still", "title", "normal", "subtitle", "just", "true", "numbered", "check", "paragraph", "list", "type", "format", "build", "__init__", "__del__", "convert_pptx_to_pdf", "_handle_group", "_handle_image", "_handle_table", "_escape_html", "PowerPointProvider", "exception", "cannot", "traceback", "exists", "break", "temp", "pdf", "image", "include", "slide", "quot", "base"], "ast_kind": "function_or_method", "text": "    def _handle_text(self, shape) -> str:\n        \"\"\"\n        Processes shape text, including bullet/numbered list detection and placeholders\n        (title, subtitle, etc.). Returns HTML for the text block(s).\n        \"\"\"\n        from pptx.enum.shapes import PP_PLACEHOLDER\n\n        # Distinguish placeholders to see if it's a title or subtitle\n        label_html_tag = \"p\"\n        if shape.is_placeholder:\n            placeholder_type = shape.placeholder_format.type\n            if placeholder_type in [PP_PLACEHOLDER.TITLE, PP_PLACEHOLDER.CENTER_TITLE]:\n                label_html_tag = \"h3\"\n            elif placeholder_type == PP_PLACEHOLDER.SUBTITLE:\n                label_html_tag = \"h4\"\n\n        # Keep track of whether we are currently in a <ul> or <ol>\n        html_parts = []\n        list_open = False\n        list_type = None  # \"ul\" or \"ol\"\n\n        for paragraph in shape.text_frame.paragraphs:\n            p_el = paragraph._element\n            # Check bullet\n            bullet_char = p_el.find(\".//a:buChar\", namespaces=p_el.nsmap)\n            bullet_num = p_el.find(\".//a:buAutoNum\", namespaces=p_el.nsmap)\n\n            is_bullet = (bullet_char is not None) or (paragraph.level > 0)\n            is_numbered = bullet_num is not None\n\n            # If the paragraph is bullet or numbered\n            if is_bullet or is_numbered:\n                # Decide if we need to start a new list or continue an existing one\n                current_list_type = \"ol\" if is_numbered else \"ul\"\n                if not list_open:\n                    # Start new\n                    list_open = True\n                    list_type = current_list_type\n                    html_parts.append(f\"<{list_type}>\")\n\n                elif list_open and list_type != current_list_type:\n                    # Close old list, start new\n                    html_parts.append(f\"</{list_type}>\")\n                    list_type = current_list_type\n                    html_parts.append(f\"<{list_type}>\")\n\n                # Build the bullet (li) text from all runs in the paragraph\n                p_text = \"\".join(run.text for run in paragraph.runs)\n                if p_text:\n                    html_parts.append(f\"<li>{self._escape_html(p_text)}</li>\")\n\n            else:\n                # If we were in a list, we need to close it\n                if list_open:\n                    html_parts.append(f\"</{list_type}>\")\n                    list_open = False\n                    list_type = None\n\n                # Now it's just a normal paragraph\n                # Gather the paragraph text from runs\n                p_text = \"\".join(run.text for run in paragraph.runs)\n                if p_text:\n                    # If we know it's a slide title, we can use <h3> or so\n                    html_parts.append(\n                        f\"<{label_html_tag}>{self._escape_html(p_text)}</{label_html_tag}>\"\n                    )\n\n        # If the text frame ended and we still have an open list, close it\n        if list_open:\n            html_parts.append(f\"</{list_type}>\")\n\n        return \"\".join(html_parts)\n", "n_tokens": 649, "byte_len": 3088, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 140, "end_line": 212}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 6, "symbols": ["_handle_image", "exception", "cannot", "shape", "image", "content", "type", "base", "base64", "html", "self", "warning", "return", "handle", "decode", "data", "img", "str", "except", "bytes", "pillow", "logger", "embeds", "loaded", "encode", "b64encode", "blob", "__init__", "__del__", "convert_pptx_to_pdf", "_handle_group", "_handle_text", "_handle_table", "_escape_html", "PowerPointProvider", "find", "enum", "start", "traceback", "nsmap", "exists", "placeholder", "break", "bullet", "num", "temp", "pdf", "include", "slide", "quot"], "ast_kind": "function_or_method", "text": "    def _handle_image(self, shape) -> str:\n        \"\"\"\n        Embeds the image as a base64 <img> in HTML.\n        \"\"\"\n        image = shape.image\n        image_bytes = image.blob\n\n        try:\n            img_str = base64.b64encode(image_bytes).decode(\"utf-8\")\n            return f\"<img src='data:{image.content_type};base64,{img_str}' />\"\n        except Exception as e:\n            logger.warning(f\"Warning: image cannot be loaded by Pillow: {e}\")\n            return \"\"\n", "n_tokens": 112, "byte_len": 472, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 213, "end_line": 226}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/powerpoint.py", "rel_path": "marker/providers/powerpoint.py", "module": "marker.providers.powerpoint", "ext": "py", "chunk_number": 7, "symbols": ["_handle_table", "_escape_html", "table", "html", "text", "shape", "characters", "minimal", "quot", "append", "self", "handle", "cells", "return", "escape", "rows", "replace", "escaping", "renders", "special", "border", "join", "row", "cell", "__init__", "__del__", "convert_pptx_to_pdf", "_handle_group", "_handle_text", "_handle_image", "PowerPointProvider", "exception", "find", "cannot", "enum", "start", "traceback", "nsmap", "exists", "placeholder", "break", "bullet", "num", "temp", "pdf", "image", "include", "slide", "base", "base64"], "ast_kind": "function_or_method", "text": "    def _handle_table(self, shape) -> str:\n        \"\"\"\n        Renders a shape's table as an HTML <table>.\n        \"\"\"\n        table_html = []\n        table_html.append(\"<table border='1'>\")\n\n        for row in shape.table.rows:\n            row_html = [\"<tr>\"]\n            for cell in row.cells:\n                row_html.append(f\"<td>{self._escape_html(cell.text)}</td>\")\n            row_html.append(\"</tr>\")\n            table_html.append(\"\".join(row_html))\n\n        table_html.append(\"</table>\")\n        return \"\".join(table_html)\n\n    def _escape_html(self, text: str) -> str:\n        \"\"\"\n        Minimal escaping for HTML special characters.\n        \"\"\"\n        return (\n            text.replace(\"&\", \"&amp;\")\n            .replace(\"<\", \"&lt;\")\n            .replace(\">\", \"&gt;\")\n            .replace('\"', \"&quot;\")\n            .replace(\"'\", \"&#39;\")\n        )\n", "n_tokens": 186, "byte_len": 862, "file_sha1": "a5ace918e6dc54818722bc3205ffa9191a3ef292", "start_line": 227, "end_line": 255}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/utils.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/utils.py", "rel_path": "marker/providers/utils.py", "module": "marker.providers.utils", "ext": "py", "chunk_number": 1, "symbols": ["alphanum_ratio", "text", "replace", "ratio", "isalnum", "alphanum", "return", "alphanumeric", "count"], "ast_kind": "function_or_method", "text": "def alphanum_ratio(text):\n    text = text.replace(\" \", \"\")\n    text = text.replace(\"\\n\", \"\")\n    alphanumeric_count = sum([1 for c in text if c.isalnum()])\n\n    if len(text) == 0:\n        return 1\n\n    ratio = alphanumeric_count / len(text)\n    return ratio\n", "n_tokens": 68, "byte_len": 258, "file_sha1": "bd8c072c669073843736ff99fc8c248da118e2c8", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py", "rel_path": "marker/providers/document.py", "module": "marker.providers.document", "ext": "py", "chunk_number": 1, "symbols": ["DocumentProvider", "image", "class", "get", "logger", "contain", "break", "tempfile", "auto", "base", "base64", "avoid", "providers", "from", "size", "height", "margin", "bytes", "bytesio", "padding", "inside", "document", "provider", "word", "solid", "table", "import", "width", "font", "marker", "__init__", "__del__", "convert_docx_to_pdf", "_preprocess_base64_images", "convert_image", "exception", "failed", "process", "exists", "temp", "pdf", "config", "result", "stylesheets", "error", "convert", "format", "return", "decode", "except"], "ast_kind": "class_or_type", "text": "import base64\nimport os\nimport re\nimport tempfile\nfrom io import BytesIO\n\nfrom PIL import Image\nfrom marker.logger import get_logger\n\nfrom marker.providers.pdf import PdfProvider\n\nlogger = get_logger()\n\ncss = \"\"\"\n@page {\n    size: A4;\n    margin: 2cm;\n}\n\nimg {\n    max-width: 100%;\n    max-height: 25cm;\n    object-fit: contain;\n    margin: 12pt auto;\n}\n\ndiv, p {\n    max-width: 100%;\n    word-break: break-word;\n    font-size: 10pt;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n    break-inside: auto;\n    font-size: 10pt;\n}\n\ntr {\n    break-inside: avoid;\n    page-break-inside: avoid;\n}\n\ntd {\n    border: 0.75pt solid #000;\n    padding: 6pt;\n}\n\"\"\"\n\n\nclass DocumentProvider(PdfProvider):", "n_tokens": 201, "byte_len": 702, "file_sha1": "d3a5366497d4a51d91faf6d8c29264c0516fbefe", "start_line": 1, "end_line": 52}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py", "rel_path": "marker/providers/document.py", "module": "marker.providers.document", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "__del__", "convert_docx_to_pdf", "exception", "remove", "init", "failed", "none", "temp", "pdf", "initialize", "exists", "tempfile", "del", "html", "suffix", "self", "config", "from", "path", "delete", "convert", "docx", "except", "super", "runtime", "error", "filepath", "provider", "with", "_preprocess_base64_images", "convert_image", "DocumentProvider", "process", "break", "image", "base", "base64", "result", "stylesheets", "get", "font", "format", "return", "decode", "breaks", "document", "staticmethod", "open", "solid"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        temp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n        self.temp_pdf_path = temp_pdf.name\n        temp_pdf.close()\n\n        # Convert DOCX to PDF\n        try:\n            self.convert_docx_to_pdf(filepath)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to convert {filepath} to PDF: {e}\")\n\n        # Initialize the PDF provider with the temp pdf path\n        super().__init__(self.temp_pdf_path, config)\n\n    def __del__(self):\n        if os.path.exists(self.temp_pdf_path):\n            os.remove(self.temp_pdf_path)\n\n    def convert_docx_to_pdf(self, filepath: str):\n        from weasyprint import CSS, HTML", "n_tokens": 158, "byte_len": 713, "file_sha1": "d3a5366497d4a51d91faf6d8c29264c0516fbefe", "start_line": 53, "end_line": 72}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py", "rel_path": "marker/providers/document.py", "module": "marker.providers.document", "ext": "py", "chunk_number": 3, "symbols": ["_preprocess_base64_images", "into", "temp", "pdf", "preprocess", "base", "pattern", "html", "base64", "self", "result", "stylesheets", "get", "font", "convert", "content", "data", "filepath", "staticmethod", "docx", "file", "open", "with", "string", "import", "value", "mammoth", "write", "__init__", "__del__", "convert_docx_to_pdf", "convert_image", "DocumentProvider", "exception", "failed", "process", "exists", "break", "image", "config", "error", "format", "return", "decode", "except", "breaks", "document", "provider", "solid", "output"], "ast_kind": "function_or_method", "text": "        import mammoth\n\n        with open(filepath, \"rb\") as docx_file:\n            # we convert the docx to HTML\n            result = mammoth.convert_to_html(docx_file)\n            html = result.value\n\n            # We convert the HTML into a PDF\n            HTML(string=self._preprocess_base64_images(html)).write_pdf(\n                self.temp_pdf_path, stylesheets=[CSS(string=css), self.get_font_css()]\n            )\n\n    @staticmethod\n    def _preprocess_base64_images(html_content):\n        pattern = r'data:([^;]+);base64,([^\"\\'>\\s]+)'\n", "n_tokens": 128, "byte_len": 544, "file_sha1": "d3a5366497d4a51d91faf6d8c29264c0516fbefe", "start_line": 73, "end_line": 88}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/document.py", "rel_path": "marker/providers/document.py", "module": "marker.providers.document", "ext": "py", "chunk_number": 4, "symbols": ["convert_image", "exception", "image", "failed", "save", "process", "group", "images", "pattern", "base", "base64", "new", "line", "error", "down", "format", "ditch", "return", "html", "content", "decode", "data", "except", "breaks", "convert", "bytes", "bytesio", "creation", "open", "with", "__init__", "__del__", "convert_docx_to_pdf", "_preprocess_base64_images", "DocumentProvider", "exists", "break", "temp", "pdf", "config", "result", "stylesheets", "get", "font", "document", "provider", "filepath", "staticmethod", "solid", "output"], "ast_kind": "function_or_method", "text": "        def convert_image(match):\n            try:\n                img_data = base64.b64decode(match.group(2))\n\n                with BytesIO(img_data) as bio:\n                    with Image.open(bio) as img:\n                        output = BytesIO()\n                        img.save(output, format=img.format)\n                        new_base64 = base64.b64encode(output.getvalue()).decode()\n                        return f\"data:{match.group(1)};base64,{new_base64}\"\n\n            except Exception as e:\n                logger.error(f\"Failed to process image: {e}\")\n                return \"\"  # we ditch broken images as that breaks the PDF creation down the line\n\n        return re.sub(pattern, convert_image, html_content)\n", "n_tokens": 141, "byte_len": 726, "file_sha1": "d3a5366497d4a51d91faf6d8c29264c0516fbefe", "start_line": 89, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py", "rel_path": "marker/providers/epub.py", "module": "marker.providers.epub", "ext": "py", "chunk_number": 1, "symbols": ["EpubProvider", "class", "break", "contain", "tempfile", "auto", "base", "base64", "avoid", "providers", "from", "size", "height", "margin", "padding", "inside", "word", "solid", "table", "import", "width", "font", "marker", "border", "beautiful", "soup", "object", "collapse", "page", "pdf", "__init__", "__del__", "convert_epub_to_pdf", "exception", "failed", "exists", "temp", "image", "xlink", "media", "type", "full", "style", "config", "stylesheets", "get", "convert", "file", "name", "decode"], "ast_kind": "class_or_type", "text": "import base64\nimport os\nimport tempfile\n\nfrom bs4 import BeautifulSoup\n\nfrom marker.providers.pdf import PdfProvider\n\ncss = '''\n@page {\n    size: A4;\n    margin: 2cm;\n}\n\nimg {\n    max-width: 100%;\n    max-height: 25cm;\n    object-fit: contain;\n    margin: 12pt auto;\n}\n\ndiv, p {\n    max-width: 100%;\n    word-break: break-word;\n    font-size: 10pt;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n    break-inside: auto;\n    font-size: 10pt;\n}\n\ntr {\n    break-inside: avoid;\n    page-break-inside: avoid;\n}\n\ntd {\n    border: 0.75pt solid #000;\n    padding: 6pt;\n}\n'''\n\n\nclass EpubProvider(PdfProvider):", "n_tokens": 183, "byte_len": 613, "file_sha1": "3ce3d14ef578c3137f7d702c916d796541badb7c", "start_line": 1, "end_line": 47}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py", "rel_path": "marker/providers/epub.py", "module": "marker.providers.epub", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "__del__", "convert_epub_to_pdf", "exception", "remove", "init", "failed", "none", "temp", "pdf", "initialize", "exists", "tempfile", "del", "html", "suffix", "self", "config", "from", "path", "delete", "convert", "except", "super", "runtime", "error", "epub", "filepath", "provider", "with", "EpubProvider", "break", "image", "xlink", "base", "base64", "media", "type", "full", "style", "stylesheets", "get", "font", "file", "name", "decode", "href", "url", "replace", "solid"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        temp_pdf = tempfile.NamedTemporaryFile(delete=False, suffix=f\".pdf\")\n        self.temp_pdf_path = temp_pdf.name\n        temp_pdf.close()\n\n        # Convert Epub to PDF\n        try:\n            self.convert_epub_to_pdf(filepath)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to convert {filepath} to PDF: {e}\")\n\n        # Initialize the PDF provider with the temp pdf path\n        super().__init__(self.temp_pdf_path, config)\n\n    def __del__(self):\n        if os.path.exists(self.temp_pdf_path):\n            os.remove(self.temp_pdf_path)\n\n    def convert_epub_to_pdf(self, filepath):\n        from weasyprint import CSS, HTML\n        from ebooklib import epub", "n_tokens": 164, "byte_len": 743, "file_sha1": "3ce3d14ef578c3137f7d702c916d796541badb7c", "start_line": 48, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/epub.py", "rel_path": "marker/providers/epub.py", "module": "marker.providers.epub", "ext": "py", "chunk_number": 3, "symbols": ["elif", "ite", "image", "find", "all", "parser", "temp", "pdf", "get", "items", "soup", "xlink", "html", "img", "tags", "base", "base64", "media", "type", "append", "full", "style", "self", "stylesheets", "font", "convert", "file", "name", "content", "decode", "__init__", "__del__", "convert_epub_to_pdf", "EpubProvider", "exception", "failed", "exists", "break", "config", "href", "url", "except", "replace", "filepath", "provider", "solid", "epub", "string", "marker", "page"], "ast_kind": "imports", "text": "        import ebooklib\n\n        ebook = epub.read_epub(filepath)\n\n        styles = []\n        html_content = \"\"\n        img_tags = {}\n\n        for item in ebook.get_items():\n            if item.get_type() == ebooklib.ITEM_IMAGE:\n                img_data = base64.b64encode(item.get_content()).decode(\"utf-8\")\n                img_tags[item.file_name] = f'data:{item.media_type};base64,{img_data}'\n            elif item.get_type() == ebooklib.ITEM_STYLE:\n                styles.append(item.get_content().decode('utf-8'))\n\n        for item in ebook.get_items():\n            if item.get_type() == ebooklib.ITEM_DOCUMENT:\n                html_content += item.get_content().decode(\"utf-8\")\n\n        soup = BeautifulSoup(html_content, 'html.parser')\n        for img in soup.find_all('img'):\n            src = img.get('src')\n            if src:\n                normalized_src = src.replace('../', '')\n                if normalized_src in img_tags:\n                    img['src'] = img_tags[normalized_src]\n\n        for image in soup.find_all('image'):\n            src = image.get('xlink:href')\n            if src:\n                normalized_src = src.replace('../', '')\n                if normalized_src in img_tags:\n                    image['xlink:href'] = img_tags[normalized_src]\n\n        html_content = str(soup)\n        full_style = ''.join([css])  # + styles)\n\n        # we convert the epub to HTML\n        HTML(string=html_content, base_url=filepath).write_pdf(\n            self.temp_pdf_path,\n            stylesheets=[CSS(string=full_style), self.get_font_css()]\n        )\n", "n_tokens": 336, "byte_len": 1575, "file_sha1": "3ce3d14ef578c3137f7d702c916d796541badb7c", "start_line": 69, "end_line": 111}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py", "rel_path": "marker/providers/image.py", "module": "marker.providers.image", "ext": "py", "chunk_number": 1, "symbols": ["ImageProvider", "image", "class", "base", "provider", "text", "none", "process", "line", "page", "range", "annotated", "reference", "schema", "providers", "from", "list", "count", "typing", "pages", "default", "import", "will", "marker", "which", "polygon", "box", "pdftext", "__init__", "__len__", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "bbox", "init", "assert", "get", "bboxes", "idxs", "between", "images", "provided", "self", "config", "size", "return", "super", "lines", "filepath"], "ast_kind": "class_or_type", "text": "from typing import List, Annotated\nfrom PIL import Image\n\nfrom marker.providers import ProviderPageLines, BaseProvider\nfrom marker.schema.polygon import PolygonBox\nfrom marker.schema.text import Line\nfrom pdftext.schema import Reference\n\n\nclass ImageProvider(BaseProvider):\n    page_range: Annotated[\n        List[int],\n        \"The range of pages to process.\",\n        \"Default is None, which will process all pages.\",\n    ] = None\n\n    image_count: int = 1\n", "n_tokens": 100, "byte_len": 459, "file_sha1": "ad6122e4a62f78eb0aa14aec709de158251b49c1", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py", "rel_path": "marker/providers/image.py", "module": "marker.providers.image", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "__len__", "image", "init", "assert", "none", "page", "bboxes", "provider", "range", "between", "images", "provided", "self", "config", "size", "return", "super", "lines", "count", "filepath", "invalid", "open", "len", "values", "must", "get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "ImageProvider", "bbox", "class", "base", "text", "get", "process", "line", "idxs", "annotated", "reference", "schema", "providers", "from", "list", "typing", "pages", "default", "import", "will"], "ast_kind": "function_or_method", "text": "    def __init__(self, filepath: str, config=None):\n        super().__init__(filepath, config)\n\n        self.images = [Image.open(filepath)]\n        self.page_lines: ProviderPageLines = {i: [] for i in range(self.image_count)}\n\n        if self.page_range is None:\n            self.page_range = range(self.image_count)\n\n        assert max(self.page_range) < self.image_count and min(self.page_range) >= 0, (\n            f\"Invalid page range, values must be between 0 and {len(self.doc) - 1}.  Min of provided page range is {min(self.page_range)} and max is {max(self.page_range)}.\"\n        )\n\n        self.page_bboxes = {\n            i: [0, 0, self.images[i].size[0], self.images[i].size[1]]\n            for i in self.page_range\n        }\n\n    def __len__(self):\n        return self.image_count\n", "n_tokens": 196, "byte_len": 794, "file_sha1": "ad6122e4a62f78eb0aa14aec709de158251b49c1", "start_line": 19, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/providers/image.py", "rel_path": "marker/providers/image.py", "module": "marker.providers.image", "ext": "py", "chunk_number": 3, "symbols": ["get_images", "get_page_bbox", "get_page_lines", "get_page_refs", "images", "image", "bbox", "reference", "page", "lines", "list", "self", "get", "polygon", "box", "none", "bboxes", "line", "idxs", "return", "from", "__init__", "__len__", "ImageProvider", "class", "init", "base", "provider", "assert", "text", "process", "range", "between", "annotated", "provided", "schema", "config", "providers", "size", "super", "count", "filepath", "typing", "invalid", "open", "pages", "default", "len", "import", "will"], "ast_kind": "function_or_method", "text": "    def get_images(self, idxs: List[int], dpi: int) -> List[Image.Image]:\n        return [self.images[i] for i in idxs]\n\n    def get_page_bbox(self, idx: int) -> PolygonBox | None:\n        bbox = self.page_bboxes[idx]\n        if bbox:\n            return PolygonBox.from_bbox(bbox)\n\n    def get_page_lines(self, idx: int) -> List[Line]:\n        return self.page_lines[idx]\n\n    def get_page_refs(self, idx: int) -> List[Reference]:\n        return []\n", "n_tokens": 115, "byte_len": 449, "file_sha1": "ad6122e4a62f78eb0aa14aec709de158251b49c1", "start_line": 40, "end_line": 53}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py", "rel_path": "marker/converters/__init__.py", "module": "marker.converters.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__call__", "BaseConverter", "args", "class", "init", "assign", "config", "none", "download", "font", "base", "llm", "some", "service", "pydantic", "self", "providers", "from", "dict", "processor", "kwargs", "not", "implemented", "meta", "inspect", "model", "render", "list", "processors", "resolve_dependencies", "initialize_processors", "elif", "parameter", "resolved", "resolve", "cls", "default", "else", "dependencies", "append", "lst", "simple", "initialize", "param", "name", "return", "insert", "parameters", "artifact"], "ast_kind": "class_or_type", "text": "import inspect\nfrom typing import Optional, List, Type\n\nfrom pydantic import BaseModel\n\nfrom marker.processors import BaseProcessor\nfrom marker.processors.llm import BaseLLMSimpleBlockProcessor\nfrom marker.processors.llm.llm_meta import LLMSimpleBlockMetaProcessor\nfrom marker.util import assign_config, download_font\n\n\nclass BaseConverter:\n    def __init__(self, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n        self.config = config\n        self.llm_service = None\n\n        # Download render font, needed for some providers\n        download_font()\n\n    def __call__(self, *args, **kwargs):\n        raise NotImplementedError\n", "n_tokens": 144, "byte_len": 664, "file_sha1": "f7918a82b8962f83455ee4323d3e157100e33302", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py", "rel_path": "marker/converters/__init__.py", "module": "marker.converters.__init__", "ext": "py", "chunk_number": 2, "symbols": ["resolve_dependencies", "elif", "init", "parameter", "resolved", "kwargs", "resolve", "default", "else", "dependencies", "self", "config", "param", "name", "return", "inspect", "parameters", "artifact", "dict", "signature", "raise", "continue", "value", "error", "empty", "cannot", "items", "dependency", "__init__", "__call__", "initialize_processors", "BaseConverter", "args", "class", "assign", "none", "download", "font", "processor", "cls", "base", "llm", "some", "service", "pydantic", "append", "lst", "providers", "simple", "from"], "ast_kind": "function_or_method", "text": "    def resolve_dependencies(self, cls):\n        init_signature = inspect.signature(cls.__init__)\n        parameters = init_signature.parameters\n\n        resolved_kwargs = {}\n        for param_name, param in parameters.items():\n            if param_name == 'self':\n                continue\n            elif param_name == 'config':\n                resolved_kwargs[param_name] = self.config\n            elif param.name in self.artifact_dict:\n                resolved_kwargs[param_name] = self.artifact_dict[param_name]\n            elif param.default != inspect.Parameter.empty:\n                resolved_kwargs[param_name] = param.default\n            else:\n                raise ValueError(f\"Cannot resolve dependency for parameter: {param_name}\")\n\n        return cls(**resolved_kwargs)\n", "n_tokens": 137, "byte_len": 784, "file_sha1": "f7918a82b8962f83455ee4323d3e157100e33302", "start_line": 24, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/__init__.py", "rel_path": "marker/converters/__init__.py", "module": "marker.converters.__init__", "ext": "py", "chunk_number": 3, "symbols": ["initialize_processors", "processor", "cls", "base", "llm", "service", "resolve", "dependencies", "append", "self", "lst", "config", "simple", "initialize", "processors", "return", "insert", "meta", "list", "other", "type", "enumerate", "position", "issubclass", "positions", "__init__", "__call__", "resolve_dependencies", "BaseConverter", "args", "elif", "class", "init", "parameter", "assign", "none", "resolved", "kwargs", "download", "font", "some", "default", "else", "pydantic", "providers", "from", "dict", "not", "implemented", "param"], "ast_kind": "function_or_method", "text": "    def initialize_processors(self, processor_cls_lst: List[Type[BaseProcessor]]) -> List[BaseProcessor]:\n        processors = []\n        for processor_cls in processor_cls_lst:\n            processors.append(self.resolve_dependencies(processor_cls))\n\n        simple_llm_processors = [p for p in processors if issubclass(type(p), BaseLLMSimpleBlockProcessor)]\n        other_processors = [p for p in processors if not issubclass(type(p), BaseLLMSimpleBlockProcessor)]\n\n        if not simple_llm_processors:\n            return processors\n\n        llm_positions = [i for i, p in enumerate(processors) if issubclass(type(p), BaseLLMSimpleBlockProcessor)]\n        insert_position = max(0, llm_positions[-1] - len(simple_llm_processors) + 1)\n\n        meta_processor = LLMSimpleBlockMetaProcessor(\n            processor_lst=simple_llm_processors,\n            llm_service=self.llm_service,\n            config=self.config,\n        )\n        other_processors.insert(insert_position, meta_processor)\n        return other_processors", "n_tokens": 212, "byte_len": 1019, "file_sha1": "f7918a82b8962f83455ee4323d3e157100e33302", "start_line": 43, "end_line": 63}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 1, "symbols": ["tokenizers", "tuple", "annotated", "document", "schema", "from", "collections", "contextlib", "dict", "list", "union", "typing", "type", "optional", "import", "disables", "marker", "warning", "defaultdict", "tokenizer", "parallelism", "environ", "contextmanager", "false", "__init__", "filepath_to_str", "build_document", "__call__", "PdfConverter", "mapping", "markdown", "enum", "ignoretext", "structure", "builder", "renderer", "exists", "toc", "llm", "form", "strings", "classes", "formats", "ocr", "converters", "file", "input", "footnote", "processor", "config"], "ast_kind": "imports", "text": "import os\n\nfrom marker.schema.document import Document\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # disables a tokenizers warning\n\nfrom collections import defaultdict\nfrom typing import Annotated, Any, Dict, List, Optional, Type, Tuple, Union\nimport io\nfrom contextlib import contextmanager", "n_tokens": 66, "byte_len": 296, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 2, "symbols": ["markdown", "ignoretext", "document", "toc", "llm", "form", "strings", "classes", "builder", "ocr", "converters", "footnote", "processor", "mathblock", "block", "relabel", "section", "base", "table", "structure", "register", "processors", "order", "blockquote", "marker", "util", "google", "gemini", "converter", "debug", "__init__", "filepath_to_str", "build_document", "__call__", "PdfConverter", "mapping", "tokenizers", "enum", "renderer", "exists", "formats", "file", "input", "config", "return", "layout", "override", "filepath", "files", "provider"], "ast_kind": "imports", "text": "import tempfile\n\nfrom marker.processors import BaseProcessor\nfrom marker.services import BaseService\nfrom marker.processors.llm.llm_table_merge import LLMTableMergeProcessor\nfrom marker.providers.registry import provider_from_filepath\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.layout import LayoutBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.builders.structure import StructureBuilder\nfrom marker.converters import BaseConverter\nfrom marker.processors.blockquote import BlockquoteProcessor\nfrom marker.processors.code import CodeProcessor\nfrom marker.processors.debug import DebugProcessor\nfrom marker.processors.document_toc import DocumentTOCProcessor\nfrom marker.processors.equation import EquationProcessor\nfrom marker.processors.footnote import FootnoteProcessor\nfrom marker.processors.ignoretext import IgnoreTextProcessor\nfrom marker.processors.line_numbers import LineNumbersProcessor\nfrom marker.processors.list import ListProcessor\nfrom marker.processors.llm.llm_complex import LLMComplexRegionProcessor\nfrom marker.processors.llm.llm_form import LLMFormProcessor\nfrom marker.processors.llm.llm_image_description import LLMImageDescriptionProcessor\nfrom marker.processors.llm.llm_table import LLMTableProcessor\nfrom marker.processors.page_header import PageHeaderProcessor\nfrom marker.processors.reference import ReferenceProcessor\nfrom marker.processors.sectionheader import SectionHeaderProcessor\nfrom marker.processors.table import TableProcessor\nfrom marker.processors.text import TextProcessor\nfrom marker.processors.block_relabel import BlockRelabelProcessor\nfrom marker.processors.blank_page import BlankPageProcessor\nfrom marker.processors.llm.llm_equation import LLMEquationProcessor\nfrom marker.renderers.markdown import MarkdownRenderer\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.schema.registry import register_block_class\nfrom marker.util import strings_to_classes\nfrom marker.processors.llm.llm_handwriting import LLMHandwritingProcessor\nfrom marker.processors.order import OrderProcessor\nfrom marker.services.gemini import GoogleGeminiService\nfrom marker.processors.line_merge import LineMergeProcessor\nfrom marker.processors.llm.llm_mathblock import LLMMathBlockProcessor\nfrom marker.processors.llm.llm_page_correction import LLMPageCorrectionProcessor\nfrom marker.processors.llm.llm_sectionheader import LLMSectionHeaderProcessor\n\n", "n_tokens": 482, "byte_len": 2498, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 11, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 3, "symbols": ["PdfConverter", "mapping", "enum", "document", "toc", "formats", "footnote", "processor", "llm", "section", "block", "relabel", "base", "table", "files", "order", "representing", "bool", "blockquote", "converter", "defaultdict", "llms", "higher", "processing", "google", "gemini", "form", "debug", "line", "merge", "__init__", "filepath_to_str", "build_document", "__call__", "markdown", "tokenizers", "ignoretext", "structure", "builder", "renderer", "exists", "strings", "classes", "ocr", "converters", "file", "input", "config", "mathblock", "return"], "ast_kind": "class_or_type", "text": "class PdfConverter(BaseConverter):\n    \"\"\"\n    A converter for processing and rendering PDF files into Markdown, JSON, HTML and other formats.\n    \"\"\"\n\n    override_map: Annotated[\n        Dict[BlockTypes, Type[Block]],\n        \"A mapping to override the default block classes for specific block types.\",\n        \"The keys are `BlockTypes` enum values, representing the types of blocks,\",\n        \"and the values are corresponding `Block` class implementations to use\",\n        \"instead of the defaults.\",\n    ] = defaultdict()\n    use_llm: Annotated[\n        bool,\n        \"Enable higher quality processing with LLMs.\",\n    ] = False\n    default_processors: Tuple[BaseProcessor, ...] = (\n        OrderProcessor,\n        BlockRelabelProcessor,\n        LineMergeProcessor,\n        BlockquoteProcessor,\n        CodeProcessor,\n        DocumentTOCProcessor,\n        EquationProcessor,\n        FootnoteProcessor,\n        IgnoreTextProcessor,\n        LineNumbersProcessor,\n        ListProcessor,\n        PageHeaderProcessor,\n        SectionHeaderProcessor,\n        TableProcessor,\n        LLMTableProcessor,\n        LLMTableMergeProcessor,\n        LLMFormProcessor,\n        TextProcessor,\n        LLMComplexRegionProcessor,\n        LLMImageDescriptionProcessor,\n        LLMEquationProcessor,\n        LLMHandwritingProcessor,\n        LLMMathBlockProcessor,\n        LLMSectionHeaderProcessor,\n        LLMPageCorrectionProcessor,\n        ReferenceProcessor,\n        BlankPageProcessor,\n        DebugProcessor,\n    )\n    default_llm_service: BaseService = GoogleGeminiService\n", "n_tokens": 314, "byte_len": 1566, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 58, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 4, "symbols": ["__init__", "block", "type", "default", "processors", "elif", "here", "init", "picked", "none", "into", "renderer", "llm", "service", "strings", "classes", "else", "access", "resolve", "dependencies", "self", "config", "converted", "initialize", "inject", "dict", "layout", "builder", "super", "list", "filepath_to_str", "build_document", "__call__", "PdfConverter", "mapping", "markdown", "tokenizers", "enum", "ignoretext", "structure", "exists", "document", "toc", "form", "formats", "ocr", "converters", "file", "input", "footnote"], "ast_kind": "class_or_type", "text": "    def __init__(\n        self,\n        artifact_dict: Dict[str, Any],\n        processor_list: Optional[List[str]] = None,\n        renderer: str | None = None,\n        llm_service: str | None = None,\n        config=None,\n    ):\n        super().__init__(config)\n\n        if config is None:\n            config = {}\n\n        for block_type, override_block_type in self.override_map.items():\n            register_block_class(block_type, override_block_type)\n\n        if processor_list is not None:\n            processor_list = strings_to_classes(processor_list)\n        else:\n            processor_list = self.default_processors\n\n        if renderer:\n            renderer = strings_to_classes([renderer])[0]\n        else:\n            renderer = MarkdownRenderer\n\n        # Put here so that resolve_dependencies can access it\n        self.artifact_dict = artifact_dict\n\n        if llm_service:\n            llm_service_cls = strings_to_classes([llm_service])[0]\n            llm_service = self.resolve_dependencies(llm_service_cls)\n        elif config.get(\"use_llm\", False):\n            llm_service = self.resolve_dependencies(self.default_llm_service)\n\n        # Inject llm service into artifact_dict so it can be picked up by processors, etc.\n        self.artifact_dict[\"llm_service\"] = llm_service\n        self.llm_service = llm_service\n\n        self.renderer = renderer\n\n        processor_list = self.initialize_processors(processor_list)\n        self.processor_list = processor_list\n\n        self.layout_builder_class = LayoutBuilder\n        self.page_count = None  # Track how many pages were converted\n", "n_tokens": 325, "byte_len": 1602, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 106, "end_line": 152}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 5, "symbols": ["filepath_to_str", "filepath", "str", "none", "exists", "type", "error", "expected", "else", "tempfile", "suffix", "file", "input", "self", "path", "delete", "temp", "yield", "bytes", "bytesio", "unlink", "union", "with", "raise", "write", "getvalue", "finally", "seek", "isinstance", "false", "__init__", "build_document", "__call__", "PdfConverter", "mapping", "markdown", "tokenizers", "enum", "ignoretext", "structure", "builder", "renderer", "document", "toc", "llm", "form", "strings", "classes", "formats", "ocr"], "ast_kind": "function_or_method", "text": "    @contextmanager\n    def filepath_to_str(self, file_input: Union[str, io.BytesIO]):\n        temp_file = None\n        try:\n            if isinstance(file_input, str):\n                yield file_input\n            else:\n                with tempfile.NamedTemporaryFile(\n                    delete=False, suffix=\".pdf\"\n                ) as temp_file:\n                    if isinstance(file_input, io.BytesIO):\n                        file_input.seek(0)\n                        temp_file.write(file_input.getvalue())\n                    else:\n                        raise TypeError(\n                            f\"Expected str or BytesIO, got {type(file_input)}\"\n                        )\n\n                yield temp_file.name\n        finally:\n            if temp_file is not None and os.path.exists(temp_file.name):\n                os.unlink(temp_file.name)\n", "n_tokens": 148, "byte_len": 857, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 153, "end_line": 175}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/pdf.py", "rel_path": "marker/converters/pdf.py", "module": "marker.converters.pdf", "ext": "py", "chunk_number": 6, "symbols": ["build_document", "__call__", "rendered", "filepath", "str", "renderer", "document", "builder", "resolve", "dependencies", "ocr", "self", "config", "processor", "provider", "cls", "return", "layout", "temp", "path", "structure", "call", "bytes", "bytesio", "line", "build", "from", "with", "pages", "page", "__init__", "filepath_to_str", "PdfConverter", "mapping", "markdown", "tokenizers", "enum", "ignoretext", "exists", "toc", "llm", "form", "strings", "classes", "formats", "converters", "file", "input", "footnote", "mathblock"], "ast_kind": "function_or_method", "text": "    def build_document(self, filepath: str) -> Document:\n        provider_cls = provider_from_filepath(filepath)\n        layout_builder = self.resolve_dependencies(self.layout_builder_class)\n        line_builder = self.resolve_dependencies(LineBuilder)\n        ocr_builder = self.resolve_dependencies(OcrBuilder)\n        provider = provider_cls(filepath, self.config)\n        document = DocumentBuilder(self.config)(\n            provider, layout_builder, line_builder, ocr_builder\n        )\n        structure_builder_cls = self.resolve_dependencies(StructureBuilder)\n        structure_builder_cls(document)\n\n        for processor in self.processor_list:\n            processor(document)\n\n        return document\n\n    def __call__(self, filepath: str | io.BytesIO):\n        with self.filepath_to_str(filepath) as temp_path:\n            document = self.build_document(temp_path)\n            self.page_count = len(document.pages)\n            renderer = self.resolve_dependencies(self.renderer)\n            rendered = renderer(document)\n        return rendered\n", "n_tokens": 188, "byte_len": 1056, "file_sha1": "0d833d550c62173c7eeeb69e2a6b2a9af3e49cb1", "start_line": 176, "end_line": 200}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/ocr.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/ocr.py", "rel_path": "marker/converters/ocr.py", "module": "marker.converters.ocr", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "OCRConverter", "default", "processors", "args", "class", "init", "equation", "force", "ocr", "processor", "tuple", "renderer", "converter", "document", "builder", "builders", "converters", "self", "config", "providers", "from", "line", "base", "kwargs", "ocrjson", "json", "super", "typing", "provider", "build_document", "__call__", "resolve", "dependencies", "cls", "return", "layout", "filepath", "build", "renderers", "pages", "import", "pdf", "marker", "page", "count", "registry", "list", "true", "call"], "ast_kind": "class_or_type", "text": "from typing import Tuple\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.converters.pdf import PdfConverter\nfrom marker.processors import BaseProcessor\nfrom marker.processors.equation import EquationProcessor\nfrom marker.providers.registry import provider_from_filepath\nfrom marker.renderers.ocr_json import OCRJSONRenderer\n\n\nclass OCRConverter(PdfConverter):\n    default_processors: Tuple[BaseProcessor, ...] = (EquationProcessor,)\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        if not self.config:\n            self.config = {}\n\n        self.config[\"force_ocr\"] = True\n        self.renderer = OCRJSONRenderer\n", "n_tokens": 157, "byte_len": 762, "file_sha1": "3d030c66e1039a5858d0b6bff3e84aa6cf7134d4", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/ocr.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/ocr.py", "rel_path": "marker/converters/ocr.py", "module": "marker.converters.ocr", "ext": "py", "chunk_number": 2, "symbols": ["build_document", "__call__", "document", "builder", "renderer", "resolve", "dependencies", "ocr", "self", "config", "processor", "provider", "cls", "return", "layout", "filepath", "line", "build", "from", "pages", "page", "count", "list", "call", "__init__", "OCRConverter", "default", "processors", "args", "class", "init", "equation", "force", "tuple", "converter", "builders", "converters", "providers", "base", "kwargs", "ocrjson", "json", "super", "typing", "renderers", "import", "pdf", "marker", "registry", "true"], "ast_kind": "function_or_method", "text": "    def build_document(self, filepath: str):\n        provider_cls = provider_from_filepath(filepath)\n        layout_builder = self.resolve_dependencies(self.layout_builder_class)\n        line_builder = self.resolve_dependencies(LineBuilder)\n        ocr_builder = self.resolve_dependencies(OcrBuilder)\n        document_builder = DocumentBuilder(self.config)\n\n        provider = provider_cls(filepath, self.config)\n        document = document_builder(provider, layout_builder, line_builder, ocr_builder)\n\n        for processor in self.processor_list:\n            processor(document)\n\n        return document\n\n    def __call__(self, filepath: str):\n        document = self.build_document(filepath)\n        self.page_count = len(document.pages)\n        renderer = self.resolve_dependencies(self.renderer)\n        return renderer(document)\n", "n_tokens": 147, "byte_len": 835, "file_sha1": "3d030c66e1039a5858d0b6bff3e84aa6cf7134d4", "start_line": 25, "end_line": 45}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py", "rel_path": "marker/converters/extraction.py", "module": "marker.converters.extraction", "ext": "py", "chunk_number": 1, "symbols": ["ExtractionConverter", "already", "markdown", "class", "none", "extraction", "get", "logger", "existing", "document", "builder", "builders", "annotated", "pattern", "page", "extractor", "ocr", "converters", "providers", "from", "line", "converted", "converter", "structure", "typing", "provider", "renderers", "output", "that", "import", "build_document", "__call__", "renderer", "merged", "config", "return", "parallel", "layout", "filepath", "marker", "this", "true", "call", "split", "inference", "llm", "service", "resolve", "dependencies", "pages"], "ast_kind": "class_or_type", "text": "import re\nfrom typing import Annotated\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.builders.structure import StructureBuilder\nfrom marker.converters.pdf import PdfConverter\nfrom marker.extractors.document import DocumentExtractor\nfrom marker.extractors.page import PageExtractor\nfrom marker.providers.registry import provider_from_filepath\n\nfrom marker.renderers.extraction import ExtractionRenderer, ExtractionOutput\nfrom marker.renderers.markdown import MarkdownRenderer\n\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n\nclass ExtractionConverter(PdfConverter):\n    pattern: str = r\"{\\d+\\}-{48}\\n\\n\"\n    existing_markdown: Annotated[\n        str, \"Markdown that was already converted for extraction.\"\n    ] = None\n", "n_tokens": 162, "byte_len": 839, "file_sha1": "654e993d36210b77d26c36cb88ac90ea36fd4c3a", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py", "rel_path": "marker/converters/extraction.py", "module": "marker.converters.extraction", "ext": "py", "chunk_number": 2, "symbols": ["build_document", "document", "builder", "resolve", "dependencies", "ocr", "self", "config", "processor", "provider", "cls", "return", "layout", "structure", "filepath", "line", "build", "from", "list", "__call__", "ExtractionConverter", "markdown", "renderer", "merged", "converters", "extractor", "parallel", "output", "marker", "this", "page", "true", "call", "split", "inference", "extraction", "get", "logger", "llm", "service", "pattern", "pages", "converted", "properly", "sets", "paginate", "import", "pdf", "converter", "registry"], "ast_kind": "function_or_method", "text": "    def build_document(self, filepath: str):\n        provider_cls = provider_from_filepath(filepath)\n        layout_builder = self.resolve_dependencies(self.layout_builder_class)\n        line_builder = self.resolve_dependencies(LineBuilder)\n        ocr_builder = self.resolve_dependencies(OcrBuilder)\n        provider = provider_cls(filepath, self.config)\n        document = DocumentBuilder(self.config)(\n            provider, layout_builder, line_builder, ocr_builder\n        )\n        structure_builder_cls = self.resolve_dependencies(StructureBuilder)\n        structure_builder_cls(document)\n\n        for processor in self.processor_list:\n            processor(document)\n\n        return document, provider\n", "n_tokens": 122, "byte_len": 709, "file_sha1": "654e993d36210b77d26c36cb88ac90ea36fd4c3a", "start_line": 27, "end_line": 43}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/extraction.py", "rel_path": "marker/converters/extraction.py", "module": "marker.converters.extraction", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "split", "markdown", "none", "inference", "document", "output", "into", "renderer", "extraction", "llm", "service", "existing", "format", "merged", "pattern", "resolve", "dependencies", "notes", "page", "extractor", "pages", "self", "config", "needs", "return", "properly", "call", "ensure", "parallel", "build_document", "ExtractionConverter", "builder", "ocr", "converters", "structure", "layout", "filepath", "provider", "marker", "this", "true", "line", "get", "logger", "converted", "sets", "paginate", "import", "pdf"], "ast_kind": "function_or_method", "text": "    def __call__(self, filepath: str) -> ExtractionOutput:\n        self.config[\"paginate_output\"] = True  # Ensure we can split the output properly\n        self.config[\"output_format\"] = (\n            \"markdown\"  # Output must be markdown for extraction\n        )\n        markdown = self.existing_markdown\n\n        if not markdown:\n            document, provider = self.build_document(filepath)\n            self.page_count = len(document.pages)\n            renderer = self.resolve_dependencies(MarkdownRenderer)\n            output = renderer(document)\n            markdown = output.markdown\n\n        output_pages = re.split(self.pattern, markdown)[1:]  # Split output into pages\n\n        # This needs an LLM service for extraction, this sets it in the extractor\n        if self.artifact_dict.get(\"llm_service\") is None:\n            self.artifact_dict[\"llm_service\"] = self.resolve_dependencies(\n                self.default_llm_service\n            )\n\n        page_extractor = self.resolve_dependencies(PageExtractor)\n        document_extractor = self.resolve_dependencies(DocumentExtractor)\n        renderer = self.resolve_dependencies(ExtractionRenderer)\n\n        # Inference in parallel\n        notes = page_extractor(output_pages)\n        document_output = document_extractor(notes)\n\n        merged = renderer(document_output, markdown)\n        return merged\n", "n_tokens": 260, "byte_len": 1362, "file_sha1": "654e993d36210b77d26c36cb88ac90ea36fd4c3a", "start_line": 44, "end_line": 76}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py", "rel_path": "marker/converters/table.py", "module": "marker.converters.table", "ext": "py", "chunk_number": 1, "symbols": ["llm", "table", "tuple", "processor", "form", "document", "builder", "builders", "ocr", "converters", "schema", "providers", "from", "line", "base", "list", "complex", "processors", "typing", "block", "types", "provider", "import", "pdf", "converter", "marker", "registry", "build_document", "__call__", "TableConverter", "type", "default", "class", "renderer", "disable", "resolve", "dependencies", "self", "config", "cls", "return", "contents", "layout", "call", "filepath", "structure", "build", "pages", "page", "count"], "ast_kind": "imports", "text": "from typing import Tuple, List\n\nfrom marker.builders.document import DocumentBuilder\nfrom marker.builders.line import LineBuilder\nfrom marker.builders.ocr import OcrBuilder\nfrom marker.converters.pdf import PdfConverter\nfrom marker.processors import BaseProcessor\nfrom marker.processors.llm.llm_complex import LLMComplexRegionProcessor\nfrom marker.processors.llm.llm_form import LLMFormProcessor\nfrom marker.processors.llm.llm_table import LLMTableProcessor\nfrom marker.processors.llm.llm_table_merge import LLMTableMergeProcessor\nfrom marker.processors.table import TableProcessor\nfrom marker.providers.registry import provider_from_filepath\nfrom marker.schema import BlockTypes\n\n", "n_tokens": 138, "byte_len": 681, "file_sha1": "ec6e20509718538f1d740fc1f2ed950f2bfaf10c", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py", "rel_path": "marker/converters/table.py", "module": "marker.converters.table", "ext": "py", "chunk_number": 2, "symbols": ["TableConverter", "default", "processors", "pdf", "converter", "class", "list", "form", "llm", "complex", "block", "table", "tuple", "processor", "base", "types", "contents", "build_document", "__call__", "type", "document", "builder", "renderer", "disable", "ocr", "builders", "resolve", "dependencies", "converters", "schema", "self", "config", "providers", "from", "line", "provider", "cls", "return", "layout", "call", "filepath", "structure", "typing", "build", "pages", "import", "marker", "page", "count", "registry"], "ast_kind": "class_or_type", "text": "class TableConverter(PdfConverter):\n    default_processors: Tuple[BaseProcessor, ...] = (\n        TableProcessor,\n        LLMTableProcessor,\n        LLMTableMergeProcessor,\n        LLMFormProcessor,\n        LLMComplexRegionProcessor,\n    )\n    converter_block_types: List[BlockTypes] = (\n        BlockTypes.Table,\n        BlockTypes.Form,\n        BlockTypes.TableOfContents,\n    )\n", "n_tokens": 83, "byte_len": 381, "file_sha1": "ec6e20509718538f1d740fc1f2ed950f2bfaf10c", "start_line": 17, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/converters/table.py", "rel_path": "marker/converters/table.py", "module": "marker.converters.table", "ext": "py", "chunk_number": 3, "symbols": ["build_document", "__call__", "block", "type", "document", "builder", "renderer", "disable", "ocr", "resolve", "dependencies", "self", "config", "processor", "provider", "cls", "return", "layout", "converter", "filepath", "structure", "line", "build", "from", "pages", "page", "count", "list", "true", "call", "TableConverter", "default", "processors", "class", "llm", "table", "tuple", "form", "builders", "converters", "schema", "providers", "base", "contents", "complex", "typing", "types", "import", "pdf", "marker"], "ast_kind": "function_or_method", "text": "    def build_document(self, filepath: str):\n        provider_cls = provider_from_filepath(filepath)\n        layout_builder = self.resolve_dependencies(self.layout_builder_class)\n        line_builder = self.resolve_dependencies(LineBuilder)\n        ocr_builder = self.resolve_dependencies(OcrBuilder)\n        document_builder = DocumentBuilder(self.config)\n        document_builder.disable_ocr = True\n\n        provider = provider_cls(filepath, self.config)\n        document = document_builder(provider, layout_builder, line_builder, ocr_builder)\n\n        for page in document.pages:\n            page.structure = [\n                p for p in page.structure if p.block_type in self.converter_block_types\n            ]\n\n        for processor in self.processor_list:\n            processor(document)\n\n        return document\n\n    def __call__(self, filepath: str):\n        document = self.build_document(filepath)\n        self.page_count = len(document.pages)\n\n        renderer = self.resolve_dependencies(self.renderer)\n        return renderer(document)\n", "n_tokens": 187, "byte_len": 1050, "file_sha1": "ec6e20509718538f1d740fc1f2ed950f2bfaf10c", "start_line": 31, "end_line": 58}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/batch.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/batch.py", "rel_path": "marker/utils/batch.py", "module": "marker.utils.batch", "ext": "py", "chunk_number": 1, "symbols": ["get_batch_sizes_worker_counts", "gpu", "manager", "equation", "batch", "utils", "ocr", "error", "table", "rec", "from", "workers", "return", "vram", "layout", "detection", "recognition", "peak", "worker", "get", "import", "marker", "detector", "postprocessing"], "ast_kind": "function_or_method", "text": "from marker.utils.gpu import GPUManager\n\n\ndef get_batch_sizes_worker_counts(gpu_manager: GPUManager, peak_worker_vram: int):\n    vram = gpu_manager.get_gpu_vram()\n\n    workers = max(1, vram // peak_worker_vram)\n    if workers == 1:\n        return {}, workers\n\n    return {\n        \"layout_batch_size\": 12,\n        \"detection_batch_size\": 8,\n        \"table_rec_batch_size\": 12,\n        \"ocr_error_batch_size\": 12,\n        \"recognition_batch_size\": 64,\n        \"equation_batch_size\": 16,\n        \"detector_postprocessing_cpu_workers\": 2,\n    }, workers\n", "n_tokens": 143, "byte_len": 551, "file_sha1": "443a02bf8805ae095f3bdd3faa7893f3efd79621", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py", "rel_path": "marker/utils/gpu.py", "module": "marker.utils.gpu", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__enter__", "__exit__", "using_cuda", "GPUManager", "cleanup", "enter", "class", "init", "subprocess", "none", "mps", "server", "get", "logger", "default", "gpu", "manager", "device", "idx", "exc", "type", "self", "settings", "from", "torc", "devic", "return", "val", "using", "check_cuda_available", "get_gpu_vram", "start_mps_server", "stop_mps_server", "exception", "popen", "failed", "start", "result", "stop", "format", "except", "control", "staticmethod", "started", "bool", "stdout", "marker", "vram", "total"], "ast_kind": "class_or_type", "text": "import os\nimport subprocess\nimport torch\n\nfrom marker.logger import get_logger\nfrom marker.settings import settings\n\nlogger = get_logger()\n\n\nclass GPUManager:\n    default_gpu_vram: int = 8\n\n    def __init__(self, device_idx: int):\n        self.device_idx = device_idx\n        self.original_compute_mode = None\n        self.mps_server_process = None\n\n    def __enter__(self):\n        if self.using_cuda():\n            self.start_mps_server()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self.using_cuda():\n            self.cleanup()\n\n    @staticmethod\n    def using_cuda():\n        return \"cuda\" in settings.TORCH_DEVICE_MODEL\n", "n_tokens": 153, "byte_len": 664, "file_sha1": "010706ee7ceeb7b486a41683a2e21f38449ce1b6", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py", "rel_path": "marker/utils/gpu.py", "module": "marker.utils.gpu", "ext": "py", "chunk_number": 2, "symbols": ["check_cuda_available", "get_gpu_vram", "query", "subprocess", "text", "check", "default", "gpu", "version", "device", "idx", "capture", "output", "self", "result", "format", "vram", "return", "called", "process", "cuda", "except", "using", "strip", "get", "file", "not", "nounits", "bool", "stdout", "__init__", "__enter__", "__exit__", "using_cuda", "start_mps_server", "stop_mps_server", "cleanup", "GPUManager", "exception", "popen", "failed", "start", "stop", "control", "staticmethod", "started", "mps", "marker", "total", "available"], "ast_kind": "function_or_method", "text": "    def check_cuda_available(self) -> bool:\n        if not torch.cuda.is_available():\n            return False\n        try:\n            subprocess.run([\"nvidia-smi\", \"--version\"], capture_output=True, check=True)\n            return True\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            return False\n\n    def get_gpu_vram(self):\n        if not self.using_cuda():\n            return self.default_gpu_vram\n\n        try:\n            result = subprocess.run(\n                [\n                    \"nvidia-smi\",\n                    \"--query-gpu=memory.total\",\n                    \"--format=csv,noheader,nounits\",\n                    \"-i\",\n                    str(self.device_idx),\n                ],\n                capture_output=True,\n                text=True,\n                check=True,\n            )\n\n            vram_mb = int(result.stdout.strip())\n            vram_gb = int(vram_mb / 1024)\n            return vram_gb\n\n        except (subprocess.CalledProcessError, ValueError, FileNotFoundError):\n            return self.default_gpu_vram\n", "n_tokens": 205, "byte_len": 1070, "file_sha1": "010706ee7ceeb7b486a41683a2e21f38449ce1b6", "start_line": 32, "end_line": 65}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py", "rel_path": "marker/utils/gpu.py", "module": "marker.utils.gpu", "ext": "py", "chunk_number": 3, "symbols": ["start_mps_server", "cud", "pip", "popen", "failed", "subprocess", "start", "mps", "server", "specific", "device", "idx", "stderr", "pipe", "log", "dir", "self", "exist", "directory", "return", "called", "process", "info", "check", "cuda", "except", "daemon", "control", "copy", "directories", "__init__", "__enter__", "__exit__", "using_cuda", "check_cuda_available", "get_gpu_vram", "stop_mps_server", "cleanup", "GPUManager", "exception", "result", "stop", "format", "staticmethod", "started", "bool", "stdout", "marker", "vram", "total"], "ast_kind": "function_or_method", "text": "    def start_mps_server(self) -> bool:\n        if not self.check_cuda_available():\n            return False\n\n        try:\n            # Set MPS environment with chunk-specific directories\n            env = os.environ.copy()\n            pipe_dir = f\"/tmp/nvidia-mps-{self.device_idx}\"\n            log_dir = f\"/tmp/nvidia-log-{self.device_idx}\"\n            env[\"CUDA_MPS_PIPE_DIRECTORY\"] = pipe_dir\n            env[\"CUDA_MPS_LOG_DIRECTORY\"] = log_dir\n\n            # Create directories\n            os.makedirs(pipe_dir, exist_ok=True)\n            os.makedirs(log_dir, exist_ok=True)\n\n            # Start MPS control daemon\n            self.mps_server_process = subprocess.Popen(\n                [\"nvidia-cuda-mps-control\", \"-d\"],\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n\n            logger.info(f\"Started NVIDIA MPS server for chunk {self.device_idx}\")\n            return True\n        except (subprocess.CalledProcessError, FileNotFoundError) as e:\n            logger.warning(\n                f\"Failed to start MPS server for chunk {self.device_idx}: {e}\"\n            )\n            return False\n", "n_tokens": 235, "byte_len": 1172, "file_sha1": "010706ee7ceeb7b486a41683a2e21f38449ce1b6", "start_line": 66, "end_line": 97}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py", "rel_path": "marker/utils/gpu.py", "module": "marker.utils.gpu", "ext": "py", "chunk_number": 4, "symbols": ["stop_mps_server", "cud", "pip", "input", "exception", "failed", "subprocess", "none", "text", "stop", "mps", "server", "timeout", "device", "idx", "kill", "self", "directory", "info", "except", "control", "copy", "nvidia", "quit", "chunk", "terminate", "logger", "wait", "warning", "stopped", "__init__", "__enter__", "__exit__", "using_cuda", "check_cuda_available", "get_gpu_vram", "start_mps_server", "cleanup", "GPUManager", "popen", "start", "result", "format", "return", "staticmethod", "started", "bool", "stdout", "marker", "vram"], "ast_kind": "function_or_method", "text": "    def stop_mps_server(self) -> None:\n        try:\n            # Stop MPS server\n            env = os.environ.copy()\n            env[\"CUDA_MPS_PIPE_DIRECTORY\"] = f\"/tmp/nvidia-mps-{self.device_idx}\"\n            env[\"CUDA_MPS_LOG_DIRECTORY\"] = f\"/tmp/nvidia-log-{self.device_idx}\"\n\n            subprocess.run(\n                [\"nvidia-cuda-mps-control\"],\n                input=\"quit\\n\",\n                text=True,\n                env=env,\n                timeout=10,\n            )\n\n            if self.mps_server_process:\n                self.mps_server_process.terminate()\n                try:\n                    self.mps_server_process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    self.mps_server_process.kill()\n                self.mps_server_process = None\n\n            logger.info(f\"Stopped NVIDIA MPS server for chunk {self.device_idx}\")\n        except Exception as e:\n            logger.warning(\n                f\"Failed to stop MPS server for chunk {self.device_idx}: {e}\"\n            )\n", "n_tokens": 205, "byte_len": 1037, "file_sha1": "010706ee7ceeb7b486a41683a2e21f38449ce1b6", "start_line": 98, "end_line": 126}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/gpu.py", "rel_path": "marker/utils/gpu.py", "module": "marker.utils.gpu", "ext": "py", "chunk_number": 5, "symbols": ["cleanup", "self", "none", "stop", "mps", "__init__", "__enter__", "__exit__", "using_cuda", "check_cuda_available", "get_gpu_vram", "start_mps_server", "stop_mps_server", "GPUManager", "exception", "popen", "failed", "start", "device", "idx", "result", "format", "return", "except", "control", "staticmethod", "started", "bool", "stdout", "marker", "vram", "total", "available", "torch", "environ", "create", "true", "pipe", "dir", "enter", "subprocess", "text", "get", "logger", "timeout", "server", "cud", "directory", "called", "process"], "ast_kind": "function_or_method", "text": "    def cleanup(self) -> None:\n        self.stop_mps_server()\n", "n_tokens": 15, "byte_len": 62, "file_sha1": "010706ee7ceeb7b486a41683a2e21f38449ce1b6", "start_line": 127, "end_line": 129}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/image.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/image.py", "rel_path": "marker/utils/image.py", "module": "marker.utils.image", "ext": "py", "chunk_number": 1, "symbols": ["image", "import", "list", "from", "typing", "numpy", "optional", "is_blank_image", "none", "text", "iterations", "shape", "background", "handle", "kernel", "adaptive", "connectivity", "range", "inverse", "uint", "uint8", "zeros", "like", "labels", "asarray", "size", "cleaned", "stats", "return", "cvt", "color", "corner", "colo", "gray", "threshold", "case", "connected", "components", "binarized", "thres", "binar", "blank", "gaussian", "blur", "white", "bool", "skip", "num", "dilated", "polygon"], "ast_kind": "imports", "text": "from PIL import Image\nimport numpy as np\nimport cv2\nfrom typing import List, Optional\n", "n_tokens": 21, "byte_len": 86, "file_sha1": "f527c6cf8cda42dbcad582a08cabbaca582c26a8", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/image.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/utils/image.py", "rel_path": "marker/utils/image.py", "module": "marker.utils.image", "ext": "py", "chunk_number": 2, "symbols": ["is_blank_image", "image", "none", "text", "iterations", "shape", "background", "handle", "kernel", "uint", "uint8", "adaptive", "connectivity", "range", "inverse", "zeros", "like", "labels", "asarray", "size", "cleaned", "stats", "return", "cvt", "color", "corner", "colo", "gray", "threshold", "list", "numpy", "from", "case", "typing", "connected", "components", "binarized", "thres", "binar", "optional", "blank", "gaussian", "blur", "white", "import", "bool", "skip", "num", "dilated", "polygon"], "ast_kind": "function_or_method", "text": "def is_blank_image(image: Image.Image, polygon: Optional[List[List[int]]] = None) -> bool:\n    image = np.asarray(image)\n    if (\n        image is None\n        or image.size == 0\n        or image.shape[0] == 0\n        or image.shape[1] == 0\n    ):\n        # Handle empty image case\n        return True\n\n    if polygon is not None:\n        rounded_polys = [[int(corner[0]), int(corner[1])] for corner in polygon]\n        if rounded_polys[0] == rounded_polys[1] and rounded_polys[2] == rounded_polys[3]:\n            return True\n\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n\n    # Adaptive threshold (inverse for text as white)\n    binarized = cv2.adaptiveThreshold(\n        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 15\n    )\n\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        binarized, connectivity=8\n    )\n    cleaned = np.zeros_like(binarized)\n    for i in range(1, num_labels):  # skip background\n        cleaned[labels == i] = 255\n\n    kernel = np.ones((1, 5), np.uint8)\n    dilated = cv2.dilate(cleaned, kernel, iterations=3)\n    b = dilated / 255\n    return bool(b.sum() == 0)", "n_tokens": 349, "byte_len": 1188, "file_sha1": "f527c6cf8cda42dbcad582a08cabbaca582c26a8", "start_line": 6, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/registry.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/registry.py", "rel_path": "marker/schema/registry.py", "module": "marker.schema.registry", "ext": "py", "chunk_number": 1, "symbols": ["register_block_class", "block", "type", "table", "group", "text", "footnote", "line", "blocks", "picture", "import", "module", "reference", "section", "header", "bloc", "registry", "document", "schema", "char", "cls", "importlib", "from", "figure", "span", "code", "name", "handwriting", "dict", "inline", "get_block_class", "assert", "page", "default", "return", "math", "contents", "list", "getattr", "form", "equation", "register", "get", "item", "class", "typing", "types", "path", "model", "fields"], "ast_kind": "function_or_method", "text": "from typing import Dict, Type\nfrom importlib import import_module\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import (\n    Block,\n    Caption,\n    Code,\n    Equation,\n    Figure,\n    Footnote,\n    Form,\n    Handwriting,\n    InlineMath,\n    ListItem,\n    PageFooter,\n    PageHeader,\n    Picture,\n    SectionHeader,\n    Table,\n    TableOfContents,\n    Text,\n    ComplexRegion,\n    TableCell,\n    Reference,\n)\nfrom marker.schema.document import Document\nfrom marker.schema.groups import (\n    FigureGroup,\n    ListGroup,\n    PageGroup,\n    PictureGroup,\n    TableGroup,\n)\nfrom marker.schema.text import Line, Span\nfrom marker.schema.text.char import Char\n\nBLOCK_REGISTRY: Dict[BlockTypes, str] = {}\n\n\ndef register_block_class(block_type: BlockTypes, block_cls: Type[Block]):\n    BLOCK_REGISTRY[block_type] = f\"{block_cls.__module__}.{block_cls.__name__}\"\n\n", "n_tokens": 198, "byte_len": 873, "file_sha1": "c0df54a8663cff00deaf0301edbbe61d8e7fb1f0", "start_line": 1, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/registry.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/registry.py", "rel_path": "marker/schema/registry.py", "module": "marker.schema.registry", "ext": "py", "chunk_number": 2, "symbols": ["get_block_class", "block", "type", "table", "group", "assert", "footnote", "line", "page", "default", "import", "module", "reference", "section", "header", "bloc", "registry", "span", "figure", "code", "char", "return", "handwriting", "inline", "math", "contents", "list", "getattr", "register", "form", "register_block_class", "text", "blocks", "picture", "document", "schema", "cls", "importlib", "from", "name", "dict", "equation", "get", "item", "class", "typing", "types", "path", "model", "fields"], "ast_kind": "function_or_method", "text": "def get_block_class(block_type: BlockTypes) -> Type[Block]:\n    class_path = BLOCK_REGISTRY[block_type]\n    module_name, class_name = class_path.rsplit(\".\", 1)\n    module = import_module(module_name)\n    return getattr(module, class_name)\n\n\nregister_block_class(BlockTypes.Line, Line)\nregister_block_class(BlockTypes.Span, Span)\nregister_block_class(BlockTypes.Char, Char)\nregister_block_class(BlockTypes.FigureGroup, FigureGroup)\nregister_block_class(BlockTypes.TableGroup, TableGroup)\nregister_block_class(BlockTypes.ListGroup, ListGroup)\nregister_block_class(BlockTypes.PictureGroup, PictureGroup)\nregister_block_class(BlockTypes.Page, PageGroup)\nregister_block_class(BlockTypes.Caption, Caption)\nregister_block_class(BlockTypes.Code, Code)\nregister_block_class(BlockTypes.Figure, Figure)\nregister_block_class(BlockTypes.Footnote, Footnote)\nregister_block_class(BlockTypes.Form, Form)\nregister_block_class(BlockTypes.Equation, Equation)\nregister_block_class(BlockTypes.Handwriting, Handwriting)\nregister_block_class(BlockTypes.TextInlineMath, InlineMath)\nregister_block_class(BlockTypes.ListItem, ListItem)\nregister_block_class(BlockTypes.PageFooter, PageFooter)\nregister_block_class(BlockTypes.PageHeader, PageHeader)\nregister_block_class(BlockTypes.Picture, Picture)\nregister_block_class(BlockTypes.SectionHeader, SectionHeader)\nregister_block_class(BlockTypes.Table, Table)\nregister_block_class(BlockTypes.Text, Text)\nregister_block_class(BlockTypes.TableOfContents, TableOfContents)\nregister_block_class(BlockTypes.ComplexRegion, ComplexRegion)\nregister_block_class(BlockTypes.TableCell, TableCell)\nregister_block_class(BlockTypes.Reference, Reference)\nregister_block_class(BlockTypes.Document, Document)\n\nassert len(BLOCK_REGISTRY) == len(BlockTypes)\nassert all(\n    [\n        get_block_class(k).model_fields[\"block_type\"].default == k\n        for k, _ in BLOCK_REGISTRY.items()\n    ]\n)\n", "n_tokens": 390, "byte_len": 1895, "file_sha1": "c0df54a8663cff00deaf0301edbbe61d8e7fb1f0", "start_line": 45, "end_line": 88}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 1, "symbols": ["PolygonBox", "import", "base", "model", "class", "list", "pydantic", "future", "polygon", "box", "computed", "field", "from", "copy", "float", "typing", "numpy", "validator", "annotations", "check_elements", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "elements", "coords", "new", "corners", "max"], "ast_kind": "class_or_type", "text": "from __future__ import annotations\nimport copy\nfrom typing import List\n\nimport numpy as np\nfrom pydantic import BaseModel, field_validator, computed_field\n\n\nclass PolygonBox(BaseModel):\n    polygon: List[List[float]]\n", "n_tokens": 46, "byte_len": 217, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 2, "symbols": ["check_elements", "elements", "min", "assert", "bottom", "float", "field", "validator", "corner", "error", "greater", "from", "left", "return", "ensure", "list", "check", "than", "classmethod", "have", "should", "raise", "corners", "clockwise", "value", "polygon", "right", "must", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area"], "ast_kind": "function_or_method", "text": "    @field_validator('polygon')\n    @classmethod\n    def check_elements(cls, v: List[List[float]]) -> List[List[float]]:\n        if len(v) != 4:\n            raise ValueError('corner must have 4 elements')\n\n        for corner in v:\n            if len(corner) != 2:\n                raise ValueError('corner must have 2 elements')\n\n        min_x = min([corner[0] for corner in v])\n        min_y = min([corner[1] for corner in v])\n\n        # Ensure corners are clockwise from top left\n        corner_error = f\" .Corners are {v}\"\n        assert v[2][1] >= min_y, f'bottom right corner should have a greater y value than top right corner' + corner_error\n        assert v[3][1] >= min_y, 'bottom left corner should have a greater y value than top left corner' + corner_error\n        assert v[1][0] >= min_x, 'top right corner should have a greater x value than top left corner' + corner_error\n        assert v[2][0] >= min_x, 'bottom right corner should have a greater x value than bottom left corner' + corner_error\n        return v\n", "n_tokens": 257, "byte_len": 1027, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 12, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 3, "symbols": ["height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "end", "bbox", "start", "property", "self", "return", "check_elements", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "new", "corners", "max", "others", "format", "corner", "scaler", "bounds", "than", "polygon", "intersection", "pct", "value", "right", "weight", "old"], "ast_kind": "function_or_method", "text": "    @property\n    def height(self):\n        return self.bbox[3] - self.bbox[1]\n\n    @property\n    def width(self):\n        return self.bbox[2] - self.bbox[0]\n\n    @property\n    def area(self):\n        return self.width * self.height\n\n    @property\n    def center(self):\n        return [(self.bbox[0] + self.bbox[2]) / 2, (self.bbox[1] + self.bbox[3]) / 2]\n\n    @property\n    def size(self):\n        return [self.width, self.height]\n\n    @property\n    def x_start(self):\n        return self.bbox[0]\n\n    @property\n    def y_start(self):\n        return self.bbox[1]\n\n    @property\n    def x_end(self):\n        return self.bbox[2]\n\n    @property\n    def y_end(self):\n        return self.bbox[3]\n", "n_tokens": 202, "byte_len": 692, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 33, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 4, "symbols": ["bbox", "corner", "min", "list", "polygon", "property", "self", "max", "return", "float", "computed", "field", "check_elements", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "new", "corners", "others", "format", "scaler", "bounds", "than", "intersection", "pct", "value"], "ast_kind": "function_or_method", "text": "    @computed_field\n    @property\n    def bbox(self) -> List[float]:\n        min_x = min([corner[0] for corner in self.polygon])\n        min_y = min([corner[1] for corner in self.polygon])\n        max_x = max([corner[0] for corner in self.polygon])\n        max_y = max([corner[1] for corner in self.polygon])\n        return [min_x, min_y, max_x, max_y]\n", "n_tokens": 101, "byte_len": 353, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 69, "end_line": 77}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 5, "symbols": ["expand", "elif", "width", "margin", "polygon", "append", "self", "box", "return", "float", "poly", "enumerate", "new", "height", "check_elements", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than", "intersection"], "ast_kind": "function_or_method", "text": "    def expand(self, x_margin: float, y_margin: float) -> PolygonBox:\n        new_polygon = []\n        x_margin = x_margin * self.width\n        y_margin = y_margin * self.height\n        for idx, poly in enumerate(self.polygon):\n            if idx == 0:\n                new_polygon.append([poly[0] - x_margin, poly[1] - y_margin])\n            elif idx == 1:\n                new_polygon.append([poly[0] + x_margin, poly[1] - y_margin])\n            elif idx == 2:\n                new_polygon.append([poly[0] + x_margin, poly[1] + y_margin])\n            elif idx == 3:\n                new_polygon.append([poly[0] - x_margin, poly[1] + y_margin])\n        return PolygonBox(polygon=new_polygon)\n", "n_tokens": 176, "byte_len": 689, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 78, "end_line": 92}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 6, "symbols": ["expand_y2", "else", "elif", "margin", "polygon", "append", "self", "box", "return", "float", "poly", "enumerate", "new", "expand", "height", "check_elements", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than"], "ast_kind": "function_or_method", "text": "    def expand_y2(self, y_margin: float) -> PolygonBox:\n        new_polygon = []\n        y_margin = y_margin * self.height\n        for idx, poly in enumerate(self.polygon):\n            if idx == 2:\n                new_polygon.append([poly[0], poly[1] + y_margin])\n            elif idx == 3:\n                new_polygon.append([poly[0], poly[1] + y_margin])\n            else:\n                new_polygon.append(poly)\n        return PolygonBox(polygon=new_polygon)\n", "n_tokens": 108, "byte_len": 463, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 93, "end_line": 104}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 7, "symbols": ["expand_y1", "minimum_gap", "else", "elif", "margin", "polygon", "append", "minimum", "gap", "self", "box", "return", "float", "expand", "poly", "other", "enumerate", "new", "intersection", "pct", "height", "check_elements", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand_y2", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "corners", "max", "others", "format"], "ast_kind": "function_or_method", "text": "    def expand_y1(self, y_margin: float) -> PolygonBox:\n        new_polygon = []\n        y_margin = y_margin * self.height\n        for idx, poly in enumerate(self.polygon):\n            if idx == 0:\n                new_polygon.append([poly[0], poly[1] - y_margin])\n            elif idx == 1:\n                new_polygon.append([poly[0], poly[1] - y_margin])\n            else:\n                new_polygon.append(poly)\n        return PolygonBox(polygon=new_polygon)\n\n    def minimum_gap(self, other: PolygonBox):\n        if self.intersection_pct(other) > 0:\n            return 0\n", "n_tokens": 135, "byte_len": 576, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 105, "end_line": 120}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 8, "symbols": ["dist", "bbox", "elif", "else", "bottom", "self", "right", "other", "left", "return", "check_elements", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "expand", "expand_y2", "expand_y1", "minimum_gap", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "new", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than", "polygon", "intersection", "pct"], "ast_kind": "function_or_method", "text": "        def dist(p1, p2):\n            return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5\n\n        left = other.bbox[2] < self.bbox[0]\n        right = self.bbox[2] < other.bbox[0]\n        bottom = other.bbox[3] < self.bbox[1]\n        top = self.bbox[3] < other.bbox[1]\n        if top and left:\n            return dist((self.bbox[0], self.bbox[3]), (other.bbox[2], other.bbox[1]))\n        elif left and bottom:\n            return dist((self.bbox[0], self.bbox[1]), (other.bbox[2], other.bbox[3]))\n        elif bottom and right:\n            return dist((self.bbox[2], self.bbox[1]), (other.bbox[0], other.bbox[3]))\n        elif right and top:\n            return dist((self.bbox[2], self.bbox[3]), (other.bbox[0], other.bbox[1]))\n        elif left:\n            return self.bbox[0] - other.bbox[2]\n        elif right:\n            return other.bbox[0] - self.bbox[2]\n        elif bottom:\n            return self.bbox[1] - other.bbox[3]\n        elif top:\n            return other.bbox[1] - self.bbox[3]\n        else:\n            return 0\n", "n_tokens": 337, "byte_len": 1040, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 121, "end_line": 146}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 9, "symbols": ["center_distance", "tl_distance", "else", "bbox", "center", "absolute", "self", "polygon", "box", "distance", "false", "float", "weight", "other", "return", "check_elements", "height", "width", "area", "size", "x_start", "y_start", "x_end", "y_end", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "new", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than"], "ast_kind": "function_or_method", "text": "    def center_distance(self, other: PolygonBox, x_weight: float = 1, y_weight: float = 1, absolute=False):\n        if not absolute:\n            return ((self.center[0] - other.center[0]) ** 2 * x_weight + (self.center[1] - other.center[1]) ** 2 * y_weight) ** 0.5\n        else:\n            return abs(self.center[0] - other.center[0]) * x_weight + abs(self.center[1] - other.center[1]) * y_weight\n\n    def tl_distance(self, other: PolygonBox):\n        return ((self.bbox[0] - other.bbox[0]) ** 2 + (self.bbox[1] - other.bbox[1]) ** 2) ** 0.5\n", "n_tokens": 173, "byte_len": 543, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 147, "end_line": 155}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 10, "symbols": ["rescale", "fit_to_bounds", "img", "width", "new", "corners", "old", "size", "self", "point", "format", "return", "corner", "scaler", "bounds", "copy", "fit", "height", "deepcopy", "page", "polygon", "box", "check_elements", "area", "center", "x_start", "y_start", "x_end", "y_end", "bbox", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "from_bbox", "PolygonBox", "elements", "coords", "max", "others", "property", "than"], "ast_kind": "function_or_method", "text": "    def rescale(self, old_size, new_size):\n        # Point is in x, y format\n        page_width, page_height = old_size\n        img_width, img_height = new_size\n\n        width_scaler = img_width / page_width\n        height_scaler = img_height / page_height\n\n        new_corners = copy.deepcopy(self.polygon)\n        for corner in new_corners:\n            corner[0] = corner[0] * width_scaler\n            corner[1] = corner[1] * height_scaler\n        return PolygonBox(polygon=new_corners)\n\n    def fit_to_bounds(self, bounds):\n        new_corners = copy.deepcopy(self.polygon)\n        for corner in new_corners:\n            corner[0] = max(min(corner[0], bounds[2]), bounds[0])\n            corner[1] = max(min(corner[1], bounds[3]), bounds[1])\n        return PolygonBox(polygon=new_corners)\n", "n_tokens": 197, "byte_len": 791, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 156, "end_line": 176}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 11, "symbols": ["overlap_x", "overlap_y", "intersection_area", "intersection_pct", "bbox", "area", "overlap", "self", "polygon", "box", "intersection", "other", "pct", "return", "check_elements", "height", "width", "center", "size", "x_start", "y_start", "x_end", "y_end", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "merge", "from_bbox", "PolygonBox", "elements", "coords", "new", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than", "value", "right", "weight"], "ast_kind": "function_or_method", "text": "    def overlap_x(self, other: PolygonBox):\n        return max(0, min(self.bbox[2], other.bbox[2]) - max(self.bbox[0], other.bbox[0]))\n\n    def overlap_y(self, other: PolygonBox):\n        return max(0, min(self.bbox[3], other.bbox[3]) - max(self.bbox[1], other.bbox[1]))\n\n    def intersection_area(self, other: PolygonBox):\n        return self.overlap_x(other) * self.overlap_y(other)\n\n    def intersection_pct(self, other: PolygonBox):\n        if self.area == 0:\n            return 0\n\n        intersection = self.intersection_area(other)\n        return intersection / self.area\n", "n_tokens": 153, "byte_len": 579, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 177, "end_line": 192}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 12, "symbols": ["merge", "elif", "min", "coords", "list", "polygon", "others", "self", "box", "max", "append", "return", "other", "range", "corners", "check_elements", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "bbox", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "from_bbox", "PolygonBox", "elements", "new", "format", "corner", "scaler", "property", "bounds", "than", "intersection"], "ast_kind": "function_or_method", "text": "    def merge(self, others: List[PolygonBox]) -> PolygonBox:\n        corners = []\n        for i in range(len(self.polygon)):\n            x_coords = [self.polygon[i][0]] + [other.polygon[i][0] for other in others]\n            y_coords = [self.polygon[i][1]] + [other.polygon[i][1] for other in others]\n            min_x = min(x_coords)\n            min_y = min(y_coords)\n            max_x = max(x_coords)\n            max_y = max(y_coords)\n\n            if i == 0:\n                corners.append([min_x, min_y])\n            elif i == 1:\n                corners.append([max_x, min_y])\n            elif i == 2:\n                corners.append([max_x, max_y])\n            elif i == 3:\n                corners.append([min_x, max_y])\n        return PolygonBox(polygon=corners)\n", "n_tokens": 191, "byte_len": 767, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 193, "end_line": 212}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py#13", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/polygon.py", "rel_path": "marker/schema/polygon.py", "module": "marker.schema.polygon", "ext": "py", "chunk_number": 13, "symbols": ["from_bbox", "bbox", "list", "polygon", "ensure", "nonzero", "false", "float", "classmethod", "return", "from", "check_elements", "height", "width", "area", "center", "size", "x_start", "y_start", "x_end", "y_end", "expand", "expand_y2", "expand_y1", "minimum_gap", "dist", "center_distance", "tl_distance", "rescale", "fit_to_bounds", "overlap_x", "overlap_y", "intersection_area", "intersection_pct", "merge", "PolygonBox", "elements", "coords", "new", "corners", "max", "others", "format", "corner", "scaler", "property", "bounds", "than", "intersection", "pct"], "ast_kind": "function_or_method", "text": "    @classmethod\n    def from_bbox(cls, bbox: List[float], ensure_nonzero_area=False):\n        if ensure_nonzero_area:\n            bbox = list(bbox)\n            bbox[2] = max(bbox[2], bbox[0] + 1)\n            bbox[3] = max(bbox[3], bbox[1] + 1)\n        return cls(polygon=[[bbox[0], bbox[1]], [bbox[2], bbox[1]], [bbox[2], bbox[3]], [bbox[0], bbox[3]]])\n", "n_tokens": 114, "byte_len": 354, "file_sha1": "455daf7ff021d577383525c706a5f37d1c653707", "start_line": 213, "end_line": 220}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/__init__.py", "rel_path": "marker/schema/__init__.py", "module": "marker.schema.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__str__", "BlockTypes", "table", "group", "class", "enum", "footnote", "line", "page", "reference", "section", "header", "auto", "self", "from", "span", "figure", "code", "char", "return", "handwriting", "contents", "list", "form", "equation", "text", "item", "block", "types", "picture", "str", "import", "inline", "document", "caption", "complex", "region", "cell", "footer", "name"], "ast_kind": "class_or_type", "text": "from enum import auto, Enum\n\n\nclass BlockTypes(str, Enum):\n    Line = auto()\n    Span = auto()\n    Char = auto()\n    FigureGroup = auto()\n    TableGroup = auto()\n    ListGroup = auto()\n    PictureGroup = auto()\n    Page = auto()\n    Caption = auto()\n    Code = auto()\n    Figure = auto()\n    Footnote = auto()\n    Form = auto()\n    Equation = auto()\n    Handwriting = auto()\n    TextInlineMath = auto()\n    ListItem = auto()\n    PageFooter = auto()\n    PageHeader = auto()\n    Picture = auto()\n    SectionHeader = auto()\n    Table = auto()\n    Text = auto()\n    TableOfContents = auto()\n    Document = auto()\n    ComplexRegion = auto()\n    TableCell = auto()\n    Reference = auto()\n\n    def __str__(self):\n        return self.name\n", "n_tokens": 180, "byte_len": 731, "file_sha1": "ef129ffb6ebc619a0d6829cc56e99ba11e07b68d", "start_line": 1, "end_line": 36}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py", "rel_path": "marker/schema/document.py", "module": "marker.schema.document", "ext": "py", "chunk_number": 1, "symbols": ["DocumentOutput", "TocItem", "Document", "block", "type", "class", "none", "float", "table", "contents", "blocks", "html", "pydantic", "saved", "future", "schema", "output", "from", "annotations", "data", "sequence", "base", "model", "document", "children", "list", "filepath", "blockid", "typing", "debug", "get_block", "get_page", "get_next_block", "get_next_page", "get_prev_block", "get_prev_page", "assemble_html", "render", "contained_blocks", "find", "config", "found", "search", "dict", "return", "page", "prev", "next", "marker", "title"], "ast_kind": "class_or_type", "text": "from __future__ import annotations\n\nfrom typing import List, Sequence, Optional\n\nfrom pydantic import BaseModel\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockId, BlockOutput\nfrom marker.schema.groups.page import PageGroup\n\n\nclass DocumentOutput(BaseModel):\n    children: List[BlockOutput]\n    html: str\n    block_type: BlockTypes = BlockTypes.Document\n\n\nclass TocItem(BaseModel):\n    title: str\n    heading_level: int\n    page_id: int\n    polygon: List[List[float]]\n\n\nclass Document(BaseModel):\n    filepath: str\n    pages: List[PageGroup]\n    block_type: BlockTypes = BlockTypes.Document\n    table_of_contents: List[TocItem] | None = None\n    debug_data_path: str | None = None  # Path that debug data was saved to\n", "n_tokens": 178, "byte_len": 753, "file_sha1": "ac0f37cbb1fd94f7f5df79d524022c2318ab0a8b", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py", "rel_path": "marker/schema/document.py", "module": "marker.schema.document", "ext": "py", "chunk_number": 2, "symbols": ["get_block", "get_page", "self", "block", "none", "return", "blockid", "page", "pages", "get", "get_next_block", "get_next_page", "get_prev_block", "get_prev_page", "assemble_html", "render", "contained_blocks", "DocumentOutput", "TocItem", "Document", "find", "config", "saved", "output", "found", "search", "dict", "children", "filepath", "prev", "next", "marker", "title", "type", "rendered", "blocks", "annotations", "structure", "copy", "template", "debug", "data", "index", "import", "toc", "item", "document", "subsequent", "polygon", "child"], "ast_kind": "function_or_method", "text": "    def get_block(self, block_id: BlockId):\n        page = self.get_page(block_id.page_id)\n        block = page.get_block(block_id)\n        if block:\n            return block\n        return None\n\n    def get_page(self, page_id):\n        for page in self.pages:\n            if page.page_id == page_id:\n                return page\n        return None\n", "n_tokens": 77, "byte_len": 349, "file_sha1": "ac0f37cbb1fd94f7f5df79d524022c2318ab0a8b", "start_line": 32, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py", "rel_path": "marker/schema/document.py", "module": "marker.schema.document", "ext": "py", "chunk_number": 3, "symbols": ["get_next_block", "get_next_page", "find", "none", "page", "idx", "get", "next", "block", "found", "self", "search", "return", "current", "list", "types", "pages", "index", "ignored", "subsequent", "group", "get_block", "get_page", "get_prev_block", "get_prev_page", "assemble_html", "render", "contained_blocks", "DocumentOutput", "TocItem", "Document", "config", "saved", "output", "dict", "children", "filepath", "prev", "marker", "title", "type", "rendered", "blocks", "annotations", "structure", "copy", "template", "blockid", "debug", "data"], "ast_kind": "function_or_method", "text": "    def get_next_block(\n        self, block: Block, ignored_block_types: List[BlockTypes] = None\n    ):\n        if ignored_block_types is None:\n            ignored_block_types = []\n        next_block = None\n\n        # Try to find the next block in the current page\n        page = self.get_page(block.page_id)\n        next_block = page.get_next_block(block, ignored_block_types)\n        if next_block:\n            return next_block\n\n        # If no block found, search subsequent pages\n        for page in self.pages[self.pages.index(page) + 1 :]:\n            next_block = page.get_next_block(None, ignored_block_types)\n            if next_block:\n                return next_block\n        return None\n\n    def get_next_page(self, page: PageGroup):\n        page_idx = self.pages.index(page)\n        if page_idx + 1 < len(self.pages):\n            return self.pages[page_idx + 1]\n        return None\n", "n_tokens": 197, "byte_len": 896, "file_sha1": "ac0f37cbb1fd94f7f5df79d524022c2318ab0a8b", "start_line": 45, "end_line": 70}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py", "rel_path": "marker/schema/document.py", "module": "marker.schema.document", "ext": "py", "chunk_number": 4, "symbols": ["get_prev_block", "get_prev_page", "assemble_html", "none", "page", "idx", "block", "config", "content", "get", "self", "dict", "prev", "return", "list", "structure", "template", "pages", "index", "optional", "assemble", "html", "child", "blocks", "group", "get_block", "get_page", "get_next_block", "get_next_page", "render", "contained_blocks", "DocumentOutput", "TocItem", "Document", "find", "saved", "output", "found", "search", "children", "filepath", "next", "marker", "title", "type", "rendered", "annotations", "copy", "blockid", "debug"], "ast_kind": "function_or_method", "text": "    def get_prev_block(self, block: Block):\n        page = self.get_page(block.page_id)\n        prev_block = page.get_prev_block(block)\n        if prev_block:\n            return prev_block\n        prev_page = self.get_prev_page(page)\n        if not prev_page:\n            return None\n        return prev_page.get_block(prev_page.structure[-1])\n\n    def get_prev_page(self, page: PageGroup):\n        page_idx = self.pages.index(page)\n        if page_idx > 0:\n            return self.pages[page_idx - 1]\n        return None\n\n    def assemble_html(\n        self, child_blocks: List[Block], block_config: Optional[dict] = None\n    ):\n        template = \"\"\n        for c in child_blocks:\n            template += f\"<content-ref src='{c.id}'></content-ref>\"\n        return template\n", "n_tokens": 175, "byte_len": 775, "file_sha1": "ac0f37cbb1fd94f7f5df79d524022c2318ab0a8b", "start_line": 71, "end_line": 94}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/document.py", "rel_path": "marker/schema/document.py", "module": "marker.schema.document", "ext": "py", "chunk_number": 5, "symbols": ["render", "contained_blocks", "child", "content", "rendered", "none", "contained", "blocks", "block", "config", "html", "append", "self", "dict", "return", "sequence", "document", "output", "children", "section", "hierarchy", "list", "types", "copy", "pages", "optional", "assemble", "page", "get_block", "get_page", "get_next_block", "get_next_page", "get_prev_block", "get_prev_page", "assemble_html", "DocumentOutput", "TocItem", "Document", "find", "saved", "found", "search", "filepath", "prev", "next", "marker", "title", "type", "annotations", "structure"], "ast_kind": "function_or_method", "text": "    def render(self, block_config: Optional[dict] = None):\n        child_content = []\n        section_hierarchy = None\n        for page in self.pages:\n            rendered = page.render(self, None, section_hierarchy, block_config)\n            section_hierarchy = rendered.section_hierarchy.copy()\n            child_content.append(rendered)\n\n        return DocumentOutput(\n            children=child_content,\n            html=self.assemble_html(child_content, block_config),\n        )\n\n    def contained_blocks(self, block_types: Sequence[BlockTypes] = None) -> List[Block]:\n        blocks = []\n        for page in self.pages:\n            blocks += page.contained_blocks(self, block_types)\n        return blocks\n", "n_tokens": 138, "byte_len": 711, "file_sha1": "ac0f37cbb1fd94f7f5df79d524022c2318ab0a8b", "start_line": 95, "end_line": 113}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/footnote.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/footnote.py", "rel_path": "marker/schema/blocks/footnote.py", "module": "marker.schema.blocks.footnote", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Footnote", "block", "type", "concept", "replace", "output", "class", "description", "none", "term", "footnote", "config", "blocks", "html", "document", "schema", "self", "from", "parent", "structure", "return", "super", "handle", "types", "explains", "that", "import", "bool", "assemble", "marker", "child", "true"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Footnote(Block):\n    block_type: BlockTypes = BlockTypes.Footnote\n    block_description: str = (\n        \"A footnote that explains a term or concept in the document.\"\n    )\n    replace_output_newlines: bool = True\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        return super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n", "n_tokens": 144, "byte_len": 701, "file_sha1": "6f45a8d3231b894914d84de3eb03496174833f81", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/toc.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/toc.py", "rel_path": "marker/schema/blocks/toc.py", "module": "marker.schema.blocks.toc", "ext": "py", "chunk_number": 1, "symbols": ["TableOfContents", "block", "type", "import", "contents", "marker", "basetable", "class", "base", "table", "schema", "description", "from", "blocks", "types"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks.basetable import BaseTable\n\n\nclass TableOfContents(BaseTable):\n    block_type: str = BlockTypes.TableOfContents\n    block_description: str = \"A table of contents.\"\n", "n_tokens": 49, "byte_len": 227, "file_sha1": "5940a12129466542e721964e2f72b7545c7b6102", "start_line": 1, "end_line": 8}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py", "rel_path": "marker/schema/blocks/listitem.py", "module": "marker.schema.blocks.listitem", "ext": "py", "chunk_number": 1, "symbols": ["replace_bullets", "block", "type", "replace", "bullets", "none", "characters", "line", "blocks", "html", "schema", "while", "from", "children", "first", "types", "with", "import", "marker", "bullet", "child", "pattern", "assemble_html", "ListItem", "class", "remove", "description", "character", "config", "document", "self", "attr", "used", "parent", "structure", "return", "super", "list", "indent", "represent", "single", "handle", "strip", "this", "item", "template", "that", "assemble", "part"], "ast_kind": "function_or_method", "text": "import re\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\ndef replace_bullets(child_blocks):\n    # Replace bullet characters with a -\n    first_block = None\n    while len(child_blocks) > 0:\n        first_block = child_blocks[0]\n        child_blocks = first_block.children\n\n    if first_block is not None and first_block.id.block_type == BlockTypes.Line:\n        bullet_pattern = r\"(^|[\\n ]|<[^>]*>)[ -]( )\"\n        first_block.html = re.sub(bullet_pattern, r\"\\1\\2\", first_block.html)\n\n", "n_tokens": 144, "byte_len": 549, "file_sha1": "77f8afd35529ae0f9d0819ffbbd9a9a3dfc246c9", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py", "rel_path": "marker/schema/blocks/listitem.py", "module": "marker.schema.blocks.listitem", "ext": "py", "chunk_number": 2, "symbols": ["ListItem", "block", "type", "class", "list", "indent", "represent", "single", "part", "description", "item", "html", "none", "this", "used", "types", "that", "replace_bullets", "assemble_html", "remove", "replace", "bullets", "character", "characters", "line", "config", "blocks", "document", "schema", "self", "first", "while", "from", "attr", "parent", "structure", "return", "super", "children", "handle", "strip", "template", "with", "import", "assemble", "marker", "bullet", "child", "pattern"], "ast_kind": "class_or_type", "text": "class ListItem(Block):\n    block_type: BlockTypes = BlockTypes.ListItem\n    list_indent_level: int = 0\n    block_description: str = \"A list item that is part of a list.  This block is used to represent a single item in a list.\"\n    html: str | None = None\n", "n_tokens": 66, "byte_len": 256, "file_sha1": "77f8afd35529ae0f9d0819ffbbd9a9a3dfc246c9", "start_line": 19, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/listitem.py", "rel_path": "marker/schema/blocks/listitem.py", "module": "marker.schema.blocks.listitem", "ext": "py", "chunk_number": 3, "symbols": ["assemble_html", "block", "type", "class", "remove", "none", "character", "replace", "bullets", "config", "html", "document", "self", "first", "attr", "parent", "structure", "return", "super", "handle", "list", "indent", "strip", "template", "assemble", "bullet", "child", "blocks", "replace_bullets", "ListItem", "description", "characters", "line", "schema", "while", "from", "used", "children", "represent", "single", "this", "item", "types", "with", "that", "import", "marker", "part", "pattern"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        template = template.replace(\"\\n\", \" \")\n        # Remove the first bullet character\n        replace_bullets(child_blocks)\n\n        if self.html:\n            template = (\n                super()\n                .handle_html_output(\n                    document, child_blocks, parent_structure, block_config\n                )\n                .strip()\n            )\n            template = template.replace(\"<li>\", \"\").replace(\"</li>\", \"\")\n\n        el_attr = f\" block-type='{self.block_type}'\"\n        if self.list_indent_level:\n            return f\"<ul><li{el_attr} class='list-indent-{self.list_indent_level}'>{template}</li></ul>\"\n        return f\"<li{el_attr}>{template}</li>\"\n", "n_tokens": 183, "byte_len": 907, "file_sha1": "77f8afd35529ae0f9d0819ffbbd9a9a3dfc246c9", "start_line": 25, "end_line": 49}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/handwriting.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/handwriting.py", "rel_path": "marker/schema/blocks/handwriting.py", "module": "marker.schema.blocks.handwriting", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Handwriting", "block", "type", "replace", "output", "class", "description", "none", "config", "blocks", "else", "html", "contains", "document", "schema", "self", "from", "parent", "structure", "return", "handwriting", "super", "types", "that", "import", "bool", "assemble", "marker", "child", "true", "region"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Handwriting(Block):\n    block_type: BlockTypes = BlockTypes.Handwriting\n    block_description: str = \"A region that contains handwriting.\"\n    html: str | None = None\n    replace_output_newlines: bool = True\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return self.html\n        else:\n            return super().assemble_html(\n                document, child_blocks, parent_structure, block_config\n            )\n", "n_tokens": 119, "byte_len": 589, "file_sha1": "a02551cbf603c580064ed9e9b38a18e1f2ea51da", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/inlinemath.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/inlinemath.py", "rel_path": "marker/schema/blocks/inlinemath.py", "module": "marker.schema.blocks.inlinemath", "ext": "py", "chunk_number": 1, "symbols": ["InlineMath", "block", "type", "class", "description", "text", "none", "inline", "blocks", "has", "continuation", "html", "contains", "schema", "from", "used", "blockquote", "math", "references", "this", "types", "that", "only", "import", "bool", "marker", "italic", "false", "level", "assemble_html", "config", "ignore", "for", "indentation", "else", "document", "self", "levels", "suffix", "attr", "parent", "structure", "return", "prefix", "super", "handle", "replace", "template", "assemble", "child"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass InlineMath(Block):\n    block_type: BlockTypes = BlockTypes.TextInlineMath\n    has_continuation: bool = False\n    blockquote: bool = False\n    blockquote_level: int = 0\n    block_description: str = \"A text block that contains inline math.  This is not used for italic text or references - only for text that contains math.\"\n    html: str | None = None\n", "n_tokens": 101, "byte_len": 435, "file_sha1": "4a449eb8ae96bf51fee7dc2b8ec99ce5aba8be3b", "start_line": 1, "end_line": 12}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/inlinemath.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/inlinemath.py", "rel_path": "marker/schema/blocks/inlinemath.py", "module": "marker.schema.blocks.inlinemath", "ext": "py", "chunk_number": 2, "symbols": ["assemble_html", "block", "type", "class", "none", "config", "ignore", "for", "indentation", "else", "has", "continuation", "html", "document", "blockquote", "suffix", "self", "levels", "attr", "parent", "structure", "return", "prefix", "super", "handle", "replace", "template", "assemble", "level", "child", "InlineMath", "description", "text", "inline", "blocks", "contains", "schema", "from", "used", "math", "references", "this", "types", "that", "only", "import", "bool", "marker", "italic", "false"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.ignore_for_output:\n            return \"\"\n\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        template = template.replace(\"\\n\", \" \")\n\n        el_attr = f\" block-type='{self.block_type}'\"\n        if self.has_continuation:\n            el_attr += \" class='has-continuation'\"\n\n        if self.blockquote:\n            # Add indentation for blockquote levels\n            blockquote_prefix = \"<blockquote>\" * self.blockquote_level\n            blockquote_suffix = \"</blockquote>\" * self.blockquote_level\n            return f\"{blockquote_prefix}<p{el_attr}>{template}</p>{blockquote_suffix}\"\n        else:\n            return f\"<p{el_attr}>{template}</p>\"\n", "n_tokens": 203, "byte_len": 996, "file_sha1": "4a449eb8ae96bf51fee7dc2b8ec99ce5aba8be3b", "start_line": 13, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/picture.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/picture.py", "rel_path": "marker/schema/blocks/picture.py", "module": "marker.schema.blocks.picture", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Picture", "block", "type", "image", "class", "none", "description", "config", "blocks", "reference", "html", "document", "schema", "self", "from", "picture", "parent", "structure", "return", "data", "super", "handle", "original", "represents", "types", "role", "that", "import", "child", "ref", "assemble", "marker"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Picture(Block):\n    block_type: BlockTypes = BlockTypes.Picture\n    description: str | None = None\n    block_description: str = \"An image block that represents a picture.\"\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        child_ref_blocks = [\n            block\n            for block in child_blocks\n            if block.id.block_type == BlockTypes.Reference\n        ]\n        html = super().assemble_html(\n            document, child_ref_blocks, parent_structure, block_config\n        )\n\n        if self.description:\n            return (\n                html\n                + f\"<p role='img' data-original-image-id='{self.id}'>Image {self.id} description: {self.description}</p>\"\n            )\n        return html\n", "n_tokens": 212, "byte_len": 1045, "file_sha1": "74d02273ac4e2097878ae15cac9560f442de5496", "start_line": 1, "end_line": 34}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py", "rel_path": "marker/schema/blocks/basetable.py", "module": "marker.schema.blocks.basetable", "ext": "py", "chunk_number": 1, "symbols": ["BaseTable", "block", "type", "import", "marker", "class", "list", "html", "schema", "output", "tablecell", "base", "table", "none", "from", "cell", "typing", "blocks", "types", "format_cells", "assemble_html", "elif", "row", "col", "text", "config", "format", "cells", "reference", "else", "document", "self", "spans", "dict", "processor", "twice", "parent", "structure", "return", "get", "sorted", "super", "filter", "render", "staticmethod", "they", "template", "child", "lines", "default"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockOutput\nfrom marker.schema.blocks.tablecell import TableCell\n\n\nclass BaseTable(Block):\n    block_type: BlockTypes | None = None\n    html: str | None = None\n", "n_tokens": 56, "byte_len": 262, "file_sha1": "b31ced07265161bb7d02cb01e7e0bbfee8124683", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py", "rel_path": "marker/schema/blocks/basetable.py", "module": "marker.schema.blocks.basetable", "ext": "py", "chunk_number": 2, "symbols": ["format_cells", "block", "type", "col", "row", "none", "config", "format", "cells", "document", "return", "get", "sorted", "list", "staticmethod", "types", "table", "child", "assemble", "html", "tbody", "lambda", "unique", "rows", "blocks", "cell", "repr", "assemble_html", "BaseTable", "elif", "class", "text", "reference", "else", "output", "schema", "self", "spans", "from", "dict", "processor", "twice", "parent", "structure", "super", "filter", "render", "base", "tablecell", "they"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def format_cells(\n        document, child_blocks, block_config, child_cells: List[TableCell] | None = None\n    ):\n        if child_cells is None:\n            child_cells: List[TableCell] = [\n                document.get_block(c.id)\n                for c in child_blocks\n                if c.id.block_type == BlockTypes.TableCell\n            ]\n\n        unique_rows = sorted(list(set([c.row_id for c in child_cells])))\n        html_repr = \"<table><tbody>\"\n        for row_id in unique_rows:\n            row_cells = sorted(\n                [c for c in child_cells if c.row_id == row_id], key=lambda x: x.col_id\n            )\n            html_repr += \"<tr>\"\n            for cell in row_cells:\n                html_repr += cell.assemble_html(\n                    document, child_blocks, None, block_config\n                )\n            html_repr += \"</tr>\"\n        html_repr += \"</tbody></table>\"\n        return html_repr\n", "n_tokens": 200, "byte_len": 939, "file_sha1": "b31ced07265161bb7d02cb01e7e0bbfee8124683", "start_line": 12, "end_line": 37}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/basetable.py", "rel_path": "marker/schema/blocks/basetable.py", "module": "marker.schema.blocks.basetable", "ext": "py", "chunk_number": 3, "symbols": ["assemble_html", "block", "type", "elif", "none", "text", "config", "format", "cells", "reference", "else", "html", "document", "output", "self", "spans", "table", "dict", "processor", "twice", "parent", "structure", "return", "super", "filter", "render", "list", "they", "template", "child", "format_cells", "BaseTable", "class", "row", "col", "blocks", "schema", "from", "get", "sorted", "base", "tablecell", "staticmethod", "typing", "types", "lines", "default", "import", "ref", "assemble"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self,\n        document,\n        child_blocks: List[BlockOutput],\n        parent_structure=None,\n        block_config: dict | None = None,\n    ):\n        # Filter out the table cells, so they don't render twice\n        child_ref_blocks = [\n            block\n            for block in child_blocks\n            if block.id.block_type == BlockTypes.Reference\n        ]\n        template = super().assemble_html(\n            document, child_ref_blocks, parent_structure, block_config\n        )\n\n        child_block_types = set([c.id.block_type for c in child_blocks])\n        if self.html:\n            # LLM processor\n            return template + self.html\n        elif len(child_blocks) > 0 and BlockTypes.TableCell in child_block_types:\n            # Table processor\n            return template + self.format_cells(document, child_blocks, block_config)\n        else:\n            # Default text lines and spans\n            return f\"<p>{template}</p>\"\n", "n_tokens": 199, "byte_len": 977, "file_sha1": "b31ced07265161bb7d02cb01e7e0bbfee8124683", "start_line": 38, "end_line": 65}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/equation.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/equation.py", "rel_path": "marker/schema/blocks/equation.py", "module": "marker.schema.blocks.equation", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Equation", "block", "type", "class", "equation", "none", "description", "config", "blocks", "else", "reference", "html", "document", "schema", "self", "out", "from", "parent", "structure", "return", "super", "math", "template", "types", "import", "child", "ref", "assemble", "marker"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Equation(Block):\n    block_type: BlockTypes = BlockTypes.Equation\n    html: str | None = None\n    block_description: str = \"A block math equation.\"\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure=None, block_config=None\n    ):\n        if self.html:\n            child_ref_blocks = [\n                block\n                for block in child_blocks\n                if block.id.block_type == BlockTypes.Reference\n            ]\n            html_out = super().assemble_html(\n                document, child_ref_blocks, parent_structure, block_config\n            )\n            html_out += f\"\"\"<p block-type='{self.block_type}'>{self.html}</p>\"\"\"\n            return html_out\n        else:\n            template = super().assemble_html(\n                document, child_blocks, parent_structure, block_config\n            )\n            return f\"<p block-type='{self.block_type}'>{template}</p>\"\n", "n_tokens": 202, "byte_len": 998, "file_sha1": "e2ac99635f456933850963e35793545496fe111c", "start_line": 1, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/code.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/code.py", "rel_path": "marker/schema/blocks/code.py", "module": "marker.schema.blocks.code", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Code", "block", "type", "class", "none", "description", "config", "blocks", "html", "document", "schema", "self", "from", "code", "parent", "structure", "return", "escape", "types", "programming", "import", "assemble", "marker", "child"], "ast_kind": "class_or_type", "text": "import html\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Code(Block):\n    block_type: BlockTypes = BlockTypes.Code\n    code: str | None = None\n    html: str | None = None\n    block_description: str = \"A programming code block.\"\n\n    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if self.html:\n            return self.html\n        code = self.code or \"\"\n        return f\"<pre>{html.escape(code)}</pre>\"\n", "n_tokens": 108, "byte_len": 485, "file_sha1": "fb7235fd3a84d214b837f584462cc8d69e9c1e7b", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/figure.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/figure.py", "rel_path": "marker/schema/blocks/figure.py", "module": "marker.schema.blocks.figure", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Figure", "block", "type", "image", "class", "none", "description", "config", "blocks", "reference", "html", "contains", "document", "schema", "self", "from", "parent", "structure", "return", "data", "super", "handle", "chart", "original", "figure", "types", "role", "that", "import", "child", "ref", "assemble", "marker", "other"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Figure(Block):\n    block_type: BlockTypes = BlockTypes.Figure\n    description: str | None = None\n    html: str | None = None\n    block_description: str = \"A chart or other image that contains data.\"\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        child_ref_blocks = [\n            block\n            for block in child_blocks\n            if block.id.block_type == BlockTypes.Reference\n        ]\n        html = super().assemble_html(\n            document, child_ref_blocks, parent_structure, block_config\n        )\n        if self.description:\n            html += f\"<p role='img' data-original-image-id='{self.id}'>Image {self.id} description: {self.description}</p>\"\n        return html\n", "n_tokens": 206, "byte_len": 989, "file_sha1": "b538cb3ec9c63ee2851c28a57b4ec73c0c0c7aca", "start_line": 1, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/__init__.py", "rel_path": "marker/schema/blocks/__init__.py", "module": "marker.schema.blocks.__init__", "ext": "py", "chunk_number": 1, "symbols": ["listitem", "equation", "text", "base", "footnote", "blocks", "form", "inlinemath", "sectionheader", "reference", "section", "header", "future", "schema", "block", "output", "from", "table", "code", "caption", "picture", "annotations", "handwriting", "inline", "math", "contents", "complexregion", "tablecell", "figure", "list", "item", "blockid", "import", "marker", "pageheader", "complex", "region", "cell", "page", "footer", "pagefooter"], "ast_kind": "imports", "text": "from __future__ import annotations\n\nfrom marker.schema.blocks.base import Block, BlockId, BlockOutput\nfrom marker.schema.blocks.caption import Caption\nfrom marker.schema.blocks.code import Code\nfrom marker.schema.blocks.figure import Figure\nfrom marker.schema.blocks.footnote import Footnote\nfrom marker.schema.blocks.form import Form\nfrom marker.schema.blocks.equation import Equation\nfrom marker.schema.blocks.handwriting import Handwriting\nfrom marker.schema.blocks.inlinemath import InlineMath\nfrom marker.schema.blocks.listitem import ListItem\nfrom marker.schema.blocks.pagefooter import PageFooter\nfrom marker.schema.blocks.pageheader import PageHeader\nfrom marker.schema.blocks.picture import Picture\nfrom marker.schema.blocks.sectionheader import SectionHeader\nfrom marker.schema.blocks.table import Table\nfrom marker.schema.blocks.text import Text\nfrom marker.schema.blocks.toc import TableOfContents\nfrom marker.schema.blocks.complexregion import ComplexRegion\nfrom marker.schema.blocks.tablecell import TableCell\nfrom marker.schema.blocks.reference import Reference\n", "n_tokens": 197, "byte_len": 1077, "file_sha1": "0e152653f3fac8b52d5ade9aafbf227a0f1a51d6", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/pageheader.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/pageheader.py", "rel_path": "marker/schema/blocks/pageheader.py", "module": "marker.schema.blocks.pageheader", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "PageHeader", "block", "type", "replace", "output", "class", "description", "none", "config", "blocks", "ignore", "for", "html", "document", "schema", "self", "from", "parent", "structure", "return", "super", "appears", "text", "keep", "pageheader", "types", "that", "import", "bool", "assemble", "marker", "title", "false", "child", "page", "header", "true", "like"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass PageHeader(Block):\n    block_type: BlockTypes = BlockTypes.PageHeader\n    block_description: str = (\n        \"Text that appears at the top of a page, like a page title.\"\n    )\n    replace_output_newlines: bool = True\n    ignore_for_output: bool = True\n    html: str | None = None\n\n    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if block_config and block_config.get(\"keep_pageheader_in_output\"):\n            self.ignore_for_output = False\n\n        if self.html and not self.ignore_for_output:\n            return self.html\n\n        return super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n", "n_tokens": 162, "byte_len": 767, "file_sha1": "2be88fbba0024f5bcd30f6f4438c0f97e72b91ff", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/caption.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/caption.py", "rel_path": "marker/schema/blocks/caption.py", "module": "marker.schema.blocks.caption", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Caption", "block", "type", "replace", "output", "class", "description", "text", "none", "config", "blocks", "image", "html", "document", "schema", "self", "from", "only", "used", "describing", "caption", "parent", "structure", "return", "super", "handle", "directly", "types", "table", "below", "that", "import", "bool", "assemble", "marker", "above", "child", "true"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Caption(Block):\n    block_type: BlockTypes = BlockTypes.Caption\n    block_description: str = \"A text caption that is directly above or below an image or table. Only used for text describing the image or table.  \"\n    replace_output_newlines: bool = True\n    html: str | None = None\n\n    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        return super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n", "n_tokens": 146, "byte_len": 722, "file_sha1": "a68e8430f15e9fcbc75a0a9fdd8c27fb300f6dec", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/form.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/form.py", "rel_path": "marker/schema/blocks/form.py", "module": "marker.schema.blocks.form", "ext": "py", "chunk_number": 1, "symbols": ["Form", "block", "type", "basetable", "class", "description", "most", "blocks", "such", "form", "contains", "schema", "labels", "from", "likely", "list", "base", "table", "structure", "have", "typing", "types", "that", "import", "marker", "fields", "doesn"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks.basetable import BaseTable\n\n\nclass Form(BaseTable):\n    block_type: BlockTypes = BlockTypes.Form\n    block_description: str = \"A form, such as a tax form, that contains fields and labels.  It most likely doesn't have a table structure.\"\n", "n_tokens": 72, "byte_len": 325, "file_sha1": "1cd42aa175ef6daf91115143727c5571b8d2ddd7", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/text.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/text.py", "rel_path": "marker/schema/blocks/text.py", "module": "marker.schema.blocks.text", "ext": "py", "chunk_number": 1, "symbols": ["Text", "block", "type", "paragraph", "class", "none", "description", "text", "blocks", "has", "continuation", "html", "schema", "from", "line", "blockquote", "types", "import", "bool", "marker", "false", "level", "assemble_html", "config", "ignore", "for", "else", "document", "self", "suffix", "happens", "used", "attr", "processor", "parent", "structure", "return", "prefix", "when", "super", "handle", "replace", "this", "template", "assemble", "child"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Text(Block):\n    block_type: BlockTypes = BlockTypes.Text\n    has_continuation: bool = False\n    blockquote: bool = False\n    blockquote_level: int = 0\n    html: str | None = None\n    block_description: str = \"A paragraph or line of text.\"\n", "n_tokens": 79, "byte_len": 324, "file_sha1": "be3dc59c95429abe03a4ad053f16d2263567a903", "start_line": 1, "end_line": 12}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/text.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/text.py", "rel_path": "marker/schema/blocks/text.py", "module": "marker.schema.blocks.text", "ext": "py", "chunk_number": 2, "symbols": ["assemble_html", "block", "type", "class", "none", "config", "ignore", "for", "else", "has", "continuation", "html", "document", "blockquote", "suffix", "self", "attr", "happens", "used", "processor", "parent", "structure", "return", "prefix", "when", "super", "handle", "replace", "this", "template", "Text", "paragraph", "description", "text", "blocks", "schema", "from", "line", "types", "import", "bool", "assemble", "marker", "false", "level", "child"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.ignore_for_output:\n            return \"\"\n\n        # This happens when we used an llm processor\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        template = template.replace(\"\\n\", \" \")\n\n        el_attr = f\" block-type='{self.block_type}'\"\n        if self.has_continuation:\n            el_attr += \" class='has-continuation'\"\n\n        if self.blockquote:\n            blockquote_prefix = \"<blockquote>\" * self.blockquote_level\n            blockquote_suffix = \"</blockquote>\" * self.blockquote_level\n            return f\"{blockquote_prefix}<p{el_attr}>{template}</p>{blockquote_suffix}\"\n        else:\n            return f\"<p{el_attr}>{template}</p>\"\n", "n_tokens": 206, "byte_len": 997, "file_sha1": "be3dc59c95429abe03a4ad053f16d2263567a903", "start_line": 13, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/reference.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/reference.py", "rel_path": "marker/schema/blocks/reference.py", "module": "marker.schema.blocks.reference", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "Reference", "block", "type", "class", "description", "none", "another", "config", "blocks", "reference", "document", "schema", "self", "from", "parent", "structure", "return", "super", "template", "types", "import", "assemble", "html", "marker", "this", "child", "span"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Reference(Block):\n    block_type: BlockTypes = BlockTypes.Reference\n    ref: str\n    block_description: str = \"A reference to this block from another block.\"\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure=None, block_config=None\n    ):\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        return f\"<span id='{self.ref}'>{template}</span>\"\n", "n_tokens": 110, "byte_len": 529, "file_sha1": "c673e1d3d926adc729ea04cee641b56f7e107ffb", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/complexregion.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/complexregion.py", "rel_path": "marker/schema/blocks/complexregion.py", "module": "marker.schema.blocks.complexregion", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "ComplexRegion", "block", "type", "class", "chosen", "none", "description", "config", "blocks", "images", "else", "reference", "complex", "html", "mixed", "document", "schema", "multiple", "types", "self", "from", "parent", "structure", "return", "when", "super", "different", "consist", "single", "this", "template", "with", "that", "import", "categorize", "assemble", "marker", "child", "ref", "difficult", "region"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass ComplexRegion(Block):\n    block_type: BlockTypes = BlockTypes.ComplexRegion\n    html: str | None = None\n    block_description: str = \"A complex region that can consist of multiple different types of blocks mixed with images. This block is chosen when it is difficult to categorize the region as a single block type.\"\n\n    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if self.html:\n            child_ref_blocks = [\n                block\n                for block in child_blocks\n                if block.id.block_type == BlockTypes.Reference\n            ]\n            html = super().assemble_html(\n                document, child_ref_blocks, parent_structure, block_config\n            )\n            return html + self.html\n        else:\n            template = super().assemble_html(\n                document, child_blocks, parent_structure, block_config\n            )\n            return f\"<p>{template}</p>\"\n", "n_tokens": 199, "byte_len": 1035, "file_sha1": "2e15a3005e5330ad6338b8e44dc53caf5e8fa8bc", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/tablecell.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/tablecell.py", "rel_path": "marker/schema/blocks/tablecell.py", "module": "marker.schema.blocks.tablecell", "ext": "py", "chunk_number": 1, "symbols": ["text", "TableCell", "block", "type", "class", "row", "col", "none", "description", "blocks", "schema", "lines", "self", "from", "cell", "return", "list", "colspan", "property", "header", "typing", "types", "table", "import", "bool", "marker", "join", "rowspan", "assemble_html", "add", "config", "else", "document", "parent", "structure", "data", "tag", "cls", "assemble", "html", "false", "child"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass TableCell(Block):\n    block_type: BlockTypes = BlockTypes.TableCell\n    rowspan: int\n    colspan: int\n    row_id: int\n    col_id: int\n    is_header: bool\n    text_lines: List[str] | None = None\n    block_description: str = \"A cell in a table.\"\n\n    @property\n    def text(self):\n        return \"\\n\".join(self.text_lines)\n", "n_tokens": 107, "byte_len": 430, "file_sha1": "b3264827ac504f8801ad598f548c09073f535185", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/tablecell.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/tablecell.py", "rel_path": "marker/schema/blocks/tablecell.py", "module": "marker.schema.blocks.tablecell", "ext": "py", "chunk_number": 2, "symbols": ["assemble_html", "add", "block", "none", "text", "config", "else", "document", "lines", "self", "parent", "structure", "return", "data", "colspan", "cell", "header", "tag", "cls", "assemble", "html", "false", "child", "blocks", "join", "rowspan", "TableCell", "type", "class", "row", "col", "description", "schema", "from", "list", "property", "typing", "types", "table", "import", "bool", "marker"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self, document, child_blocks, parent_structure=None, block_config=None\n    ):\n        add_cell_id = block_config and block_config.get(\"add_block_ids\", False)\n\n        tag_cls = \"th\" if self.is_header else \"td\"\n        tag = f\"<{tag_cls}\"\n        if self.rowspan > 1:\n            tag += f\" rowspan={self.rowspan}\"\n        if self.colspan > 1:\n            tag += f\" colspan={self.colspan}\"\n        if add_cell_id:\n            tag += f' data-block-id=\"{self.id}\"'\n        if self.text_lines is None:\n            self.text_lines = []\n        text = \"<br>\".join(self.text_lines)\n        return f\"{tag}>{text}</{tag_cls}>\"\n", "n_tokens": 162, "byte_len": 648, "file_sha1": "b3264827ac504f8801ad598f548c09073f535185", "start_line": 21, "end_line": 38}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/table.py", "rel_path": "marker/schema/blocks/table.py", "module": "marker.schema.blocks.table", "ext": "py", "chunk_number": 1, "symbols": ["Table", "block", "type", "results", "basetable", "class", "description", "blocks", "schema", "from", "table", "format", "data", "base", "tabular", "types", "import", "will", "marker", "like"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks.basetable import BaseTable\n\n\nclass Table(BaseTable):\n    block_type: BlockTypes = BlockTypes.Table\n    block_description: str = \"A table of data, like a results table.  It will be in a tabular format.\"\n", "n_tokens": 61, "byte_len": 265, "file_sha1": "68d98815d32c5b78df183c0ed72cadf3c289fd8d", "start_line": 1, "end_line": 8}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/pagefooter.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/pagefooter.py", "rel_path": "marker/schema/blocks/pagefooter.py", "module": "marker.schema.blocks.pagefooter", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "PageFooter", "block", "type", "replace", "output", "class", "bottom", "description", "none", "config", "blocks", "ignore", "for", "html", "document", "schema", "self", "from", "parent", "structure", "return", "super", "appears", "text", "types", "that", "import", "bool", "assemble", "marker", "number", "false", "keep", "pagefooter", "child", "page", "true", "footer", "like"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass PageFooter(Block):\n    block_type: str = BlockTypes.PageFooter\n    block_description: str = (\n        \"Text that appears at the bottom of a page, like a page number.\"\n    )\n    replace_output_newlines: bool = True\n    ignore_for_output: bool = True\n    html: str | None = None\n\n    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if block_config and block_config.get(\"keep_pagefooter_in_output\"):\n            self.ignore_for_output = False\n\n        if self.html and not self.ignore_for_output:\n            return self.html\n\n        return super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n", "n_tokens": 161, "byte_len": 764, "file_sha1": "ec92945341c4e9b398c93a495467973d792922c3", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 1, "symbols": ["merge", "BlockMetadata", "typ", "checking", "image", "class", "llm", "error", "previous", "order", "tuple", "field", "validator", "pydantic", "future", "schema", "document", "self", "tokens", "from", "return", "dict", "annotations", "sequence", "base", "model", "list", "getattr", "typing", "block", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy"], "ast_kind": "class_or_type", "text": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Dict, List, Literal, Optional, Sequence, Tuple\n\nfrom pydantic import BaseModel, ConfigDict, field_validator\nfrom PIL import Image\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.polygon import PolygonBox\n\nif TYPE_CHECKING:\n    from marker.schema.document import Document\n    from marker.schema.groups.page import PageGroup\n\n\nclass BlockMetadata(BaseModel):\n    llm_request_count: int = 0\n    llm_error_count: int = 0\n    llm_tokens_used: int = 0\n    previous_text: str = \"\"\n    previous_type: str = \"\"\n    previous_order: int = 0\n\n    def merge(self, model2):\n        return self.__class__(\n            **{\n                field: getattr(self, field) + getattr(model2, field)\n                for field in self.model_fields\n            }\n        )\n\n", "n_tokens": 189, "byte_len": 827, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 1, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 2, "symbols": ["__str__", "__hash__", "__repr__", "BlockOutput", "BlockId", "block", "type", "class", "none", "html", "output", "self", "return", "repr", "dict", "base", "model", "children", "list", "section", "hierarchy", "hash", "blockid", "types", "str", "page", "optional", "polygon", "box", "name", "merge", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block"], "ast_kind": "class_or_type", "text": "class BlockOutput(BaseModel):\n    html: str\n    polygon: PolygonBox\n    id: BlockId\n    children: List[BlockOutput] | None = None\n    section_hierarchy: Dict[int, BlockId] | None = None\n\n\nclass BlockId(BaseModel):\n    page_id: int\n    block_id: Optional[int] = None\n    block_type: BlockTypes | None = None\n\n    def __str__(self):\n        if self.block_type is None or self.block_id is None:\n            return f\"/page/{self.page_id}\"\n        return f\"/page/{self.page_id}/{self.block_type.name}/{self.block_id}\"\n\n    def __hash__(self):\n        return hash(str(self))\n\n    def __repr__(self):\n        return str(self)\n", "n_tokens": 159, "byte_len": 619, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 33, "end_line": 56}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 3, "symbols": ["__eq__", "validate_block_type", "to_path", "block", "type", "field", "validator", "else", "schema", "self", "path", "from", "not", "implemented", "return", "validate", "replace", "classmethod", "blockid", "invalid", "types", "page", "raise", "import", "marker", "isinstance", "value", "error", "other", "merge", "__str__", "__hash__", "__repr__", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render"], "ast_kind": "function_or_method", "text": "    def __eq__(self, other):\n        if not isinstance(other, (BlockId, str)):\n            return NotImplemented\n\n        if isinstance(other, str):\n            return str(self) == other\n        else:\n            return (\n                self.page_id == other.page_id\n                and self.block_id == other.block_id\n                and self.block_type == other.block_type\n            )\n\n    @field_validator(\"block_type\")\n    @classmethod\n    def validate_block_type(cls, v):\n        from marker.schema import BlockTypes\n\n        if v not in BlockTypes:\n            raise ValueError(f\"Invalid block type: {v}\")\n        return v\n\n    def to_path(self):\n        return str(self).replace(\"/\", \"_\")\n\n", "n_tokens": 145, "byte_len": 700, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 57, "end_line": 82}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 4, "symbols": ["Block", "block", "type", "image", "replace", "output", "class", "description", "none", "float", "ignore", "for", "metadata", "spaces", "ignored", "heuristics", "lowres", "layout", "whether", "dict", "processor", "replaced", "newlines", "text", "extraction", "base", "model", "surya", "list", "order", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html"], "ast_kind": "class_or_type", "text": "class Block(BaseModel):\n    polygon: PolygonBox\n    block_description: str\n    block_type: Optional[BlockTypes] = None\n    block_id: Optional[int] = None\n    page_id: Optional[int] = None\n    text_extraction_method: Optional[Literal[\"pdftext\", \"surya\", \"gemini\"]] = None\n    structure: List[BlockId] | None = (\n        None  # The top-level page structure, which is the block ids in order\n    )\n    ignore_for_output: bool = False  # Whether this block should be ignored in output\n    replace_output_newlines: bool = (\n        False  # Whether to replace newlines with spaces in output\n    )\n    source: Literal[\"layout\", \"heuristics\", \"processor\"] = \"layout\"\n    top_k: Optional[Dict[BlockTypes, float]] = None\n    metadata: BlockMetadata | None = None\n    lowres_image: Image.Image | None = None\n    highres_image: Image.Image | None = None\n    removed: bool = False  # Has block been replaced by new block?\n    _metadata: Optional[dict] = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n", "n_tokens": 258, "byte_len": 1008, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 83, "end_line": 106}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 5, "symbols": ["id", "from_block", "set_internal_metadata", "get_internal_metadata", "block", "type", "attrs", "none", "self", "exclude", "model", "dump", "return", "data", "metadata", "property", "classmethod", "from", "blockid", "page", "get", "internal", "set", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata", "BlockOutput", "BlockId", "Block"], "ast_kind": "function_or_method", "text": "    @property\n    def id(self) -> BlockId:\n        return BlockId(\n            page_id=self.page_id, block_id=self.block_id, block_type=self.block_type\n        )\n\n    @classmethod\n    def from_block(cls, block: Block) -> Block:\n        block_attrs = block.model_dump(exclude=[\"id\", \"block_id\", \"block_type\"])\n        return cls(**block_attrs)\n\n    def set_internal_metadata(self, key, data):\n        if self._metadata is None:\n            self._metadata = {}\n        self._metadata[key] = data\n\n    def get_internal_metadata(self, key):\n        if self._metadata is None:\n            return None\n        return self._metadata.get(key)\n", "n_tokens": 146, "byte_len": 635, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 107, "end_line": 127}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 6, "symbols": ["get_image", "image", "bbox", "page", "none", "highres", "tuple", "float", "get", "else", "document", "self", "remove", "blocks", "lowres", "scale", "size", "rescale", "height", "return", "sequence", "crop", "block", "types", "bool", "width", "polygon", "expand", "false", "expansion", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy"], "ast_kind": "function_or_method", "text": "    def get_image(\n        self,\n        document: Document,\n        highres: bool = False,\n        expansion: Tuple[float, float] | None = None,\n        remove_blocks: Sequence[BlockTypes] | None = None,\n    ) -> Image.Image | None:\n        image = self.highres_image if highres else self.lowres_image\n        if image is None:\n            page = document.get_page(self.page_id)\n            page_image = page.get_image(highres=highres, remove_blocks=remove_blocks)\n\n            # Scale to the image size\n            bbox = self.polygon.rescale(\n                (page.polygon.width, page.polygon.height), page_image.size\n            )\n            if expansion:\n                bbox = bbox.expand(*expansion)\n            bbox = bbox.bbox\n            image = page_image.crop(bbox)\n        return image\n", "n_tokens": 174, "byte_len": 800, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 128, "end_line": 149}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 7, "symbols": ["structure_blocks", "get_prev_block", "block", "type", "none", "reversed", "self", "return", "get", "list", "structure", "idx", "document", "page", "types", "index", "optional", "prev", "ignored", "blocks", "group", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata", "BlockOutput", "BlockId", "Block"], "ast_kind": "function_or_method", "text": "    def structure_blocks(self, document_page: Document | PageGroup) -> List[Block]:\n        if self.structure is None:\n            return []\n        return [document_page.get_block(block_id) for block_id in self.structure]\n\n    def get_prev_block(\n        self,\n        document_page: Document | PageGroup,\n        block: Block,\n        ignored_block_types: Optional[List[BlockTypes]] = None,\n    ):\n        if ignored_block_types is None:\n            ignored_block_types = []\n\n        structure_idx = self.structure.index(block.id)\n        if structure_idx == 0:\n            return None\n\n        for prev_block_id in reversed(self.structure[:structure_idx]):\n            if prev_block_id.block_type not in ignored_block_types:\n                return document_page.get_block(prev_block_id)\n", "n_tokens": 157, "byte_len": 790, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 150, "end_line": 171}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 8, "symbols": ["get_next_block", "add_structure", "block", "type", "none", "else", "append", "found", "self", "valid", "return", "get", "next", "list", "structure", "idx", "document", "page", "types", "index", "optional", "ignored", "add", "group", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata"], "ast_kind": "function_or_method", "text": "    def get_next_block(\n        self,\n        document_page: Document | PageGroup,\n        block: Optional[Block] = None,\n        ignored_block_types: Optional[List[BlockTypes]] = None,\n    ):\n        if ignored_block_types is None:\n            ignored_block_types = []\n\n        structure_idx = 0\n        if block is not None:\n            structure_idx = self.structure.index(block.id) + 1\n\n        for next_block_id in self.structure[structure_idx:]:\n            if next_block_id.block_type not in ignored_block_types:\n                return document_page.get_block(next_block_id)\n\n        return None  # No valid next block found\n\n    def add_structure(self, block: Block):\n        if self.structure is None:\n            self.structure = [block.id]\n        else:\n            self.structure.append(block.id)\n", "n_tokens": 167, "byte_len": 809, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 172, "end_line": 196}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 9, "symbols": ["update_structure_item", "remove_structure_items", "remove", "structure", "block", "ids", "list", "self", "none", "item", "new", "blockid", "enumerate", "old", "break", "update", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata", "BlockOutput", "BlockId", "Block", "config", "reversed", "image", "raw", "text"], "ast_kind": "function_or_method", "text": "    def update_structure_item(self, old_id: BlockId, new_id: BlockId):\n        if self.structure is not None:\n            for i, item in enumerate(self.structure):\n                if item == old_id:\n                    self.structure[i] = new_id\n                    break\n\n    def remove_structure_items(self, block_ids: List[BlockId]):\n        if self.structure is not None:\n            self.structure = [item for item in self.structure if item not in block_ids]\n", "n_tokens": 97, "byte_len": 464, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 197, "end_line": 207}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 10, "symbols": ["raw_text", "text", "none", "line", "blocks", "else", "raw", "document", "schema", "self", "from", "span", "return", "get", "block", "tablecell", "structure", "endswith", "import", "marker", "isinstance", "table", "cell", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata"], "ast_kind": "function_or_method", "text": "    def raw_text(self, document: Document) -> str:\n        from marker.schema.text.line import Line\n        from marker.schema.text.span import Span\n        from marker.schema.blocks.tablecell import TableCell\n\n        if self.structure is None:\n            if isinstance(self, (Span, TableCell)):\n                return self.text\n            else:\n                return \"\"\n\n        text = \"\"\n        for block_id in self.structure:\n            block = document.get_block(block_id)\n            text += block.raw_text(document)\n            if isinstance(block, Line) and not text.endswith(\"\\n\"):\n                text += \"\\n\"\n        return text\n", "n_tokens": 122, "byte_len": 645, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 208, "end_line": 226}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 11, "symbols": ["assemble_html", "assign_section_hierarchy", "block", "type", "replace", "output", "none", "config", "content", "ignore", "for", "section", "header", "assign", "document", "self", "levels", "dict", "parent", "structure", "return", "list", "hierarchy", "template", "types", "keys", "optional", "heading", "level", "assemble", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "contained_blocks"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self,\n        document: Document,\n        child_blocks: List[BlockOutput],\n        parent_structure: Optional[List[str]] = None,\n        block_config: Optional[dict] = None,\n    ) -> str:\n        if self.ignore_for_output:\n            return \"\"\n\n        template = \"\"\n        for c in child_blocks:\n            template += f\"<content-ref src='{c.id}'></content-ref>\"\n\n        if self.replace_output_newlines:\n            template = template.replace(\"\\n\", \" \")\n            template = \"<p>\" + template + \"</p>\"\n\n        return template\n\n    def assign_section_hierarchy(self, section_hierarchy):\n        if self.block_type == BlockTypes.SectionHeader and self.heading_level:\n            levels = list(section_hierarchy.keys())\n            for level in levels:\n                if level >= self.heading_level:\n                    del section_hierarchy[level]\n            section_hierarchy[self.heading_level] = self.id\n\n        return section_hierarchy\n", "n_tokens": 191, "byte_len": 980, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 227, "end_line": 256}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 12, "symbols": ["contained_blocks", "replace_block", "block", "type", "none", "contained", "blocks", "break", "document", "append", "self", "new", "return", "get", "sequence", "list", "types", "structure", "enumerate", "removed", "continue", "item", "replace", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "render", "line_height", "update_metadata", "handle_html_output", "BlockMetadata", "BlockOutput"], "ast_kind": "function_or_method", "text": "    def contained_blocks(\n        self, document: Document, block_types: Sequence[BlockTypes] = None\n    ) -> List[Block]:\n        if self.structure is None:\n            return []\n\n        blocks = []\n        for block_id in self.structure:\n            block = document.get_block(block_id)\n            if block.removed:\n                continue\n            if (\n                block_types is None or block.block_type in block_types\n            ) and not block.removed:\n                blocks.append(block)\n            blocks += block.contained_blocks(document, block_types)\n        return blocks\n\n    def replace_block(self, block: Block, new_block: Block):\n        if self.structure is not None:\n            for i, item in enumerate(self.structure):\n                if item == block.id:\n                    self.structure[i] = new_block.id\n                    break\n", "n_tokens": 168, "byte_len": 868, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 257, "end_line": 281}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#13", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 13, "symbols": ["render", "child", "content", "rendered", "none", "block", "config", "blocks", "assign", "section", "peer", "html", "document", "output", "self", "append", "from", "hierarchy", "dict", "parent", "structure", "return", "get", "children", "list", "copy", "optional", "assemble", "polygon", "update", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html"], "ast_kind": "function_or_method", "text": "    def render(\n        self,\n        document: Document,\n        parent_structure: Optional[List[str]] = None,\n        section_hierarchy: dict | None = None,\n        block_config: Optional[dict] = None,\n    ) -> BlockOutput:\n        if block_config is None:\n            block_config = {}\n\n        child_content = []\n        if section_hierarchy is None:\n            section_hierarchy = {}\n        section_hierarchy = self.assign_section_hierarchy(section_hierarchy)\n\n        if self.structure is not None and len(self.structure) > 0:\n            for block_id in self.structure:\n                block = document.get_block(block_id)\n                rendered = block.render(\n                    document, self.structure, section_hierarchy, block_config\n                )\n                section_hierarchy = (\n                    rendered.section_hierarchy.copy()\n                )  # Update the section hierarchy from the peer blocks\n                child_content.append(rendered)\n\n        return BlockOutput(\n            html=self.assemble_html(\n                document, child_content, parent_structure, block_config\n            ),\n            polygon=self.polygon,\n            id=self.id,\n            children=child_content,\n            section_hierarchy=section_hierarchy,\n        )\n", "n_tokens": 226, "byte_len": 1285, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 282, "end_line": 317}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#14", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 14, "symbols": ["line_height", "update_metadata", "metadata", "elif", "attr", "none", "contained", "blocks", "float", "line", "else", "document", "self", "attribute", "kwargs", "height", "return", "getattr", "lines", "block", "types", "setattr", "raise", "integer", "value", "polygon", "isinstance", "error", "items", "update", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html"], "ast_kind": "function_or_method", "text": "    def line_height(self, document: Document) -> float:\n        lines = self.contained_blocks(document, (BlockTypes.Line,))\n        if len(lines) == 0:\n            return 0\n        return self.polygon.height / len(lines)\n\n    def update_metadata(self, **kwargs):\n        if self.metadata is None:\n            self.metadata = BlockMetadata()\n\n        for key, value in kwargs.items():\n            metadata_attr = getattr(self.metadata, key)\n            if isinstance(metadata_attr, int) and isinstance(value, int):\n                setattr(self.metadata, key, metadata_attr + value)\n            elif isinstance(metadata_attr, str) and isinstance(value, str):\n                setattr(self.metadata, key, value)\n            else:\n                raise ValueError(f\"Metadata attribute {key} is not an integer\")\n", "n_tokens": 160, "byte_len": 806, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 318, "end_line": 336}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py#15", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/base.py", "rel_path": "marker/schema/blocks/base.py", "module": "marker.schema.blocks.base", "ext": "py", "chunk_number": 15, "symbols": ["handle_html_output", "block", "type", "reference", "child", "ref", "handle", "html", "assemble", "document", "self", "none", "config", "blocks", "types", "parent", "structure", "return", "merge", "__str__", "__hash__", "__repr__", "__eq__", "validate_block_type", "to_path", "id", "from_block", "set_internal_metadata", "get_internal_metadata", "get_image", "structure_blocks", "get_prev_block", "get_next_block", "add_structure", "update_structure_item", "remove_structure_items", "raw_text", "assemble_html", "assign_section_hierarchy", "contained_blocks", "replace_block", "render", "line_height", "update_metadata", "BlockMetadata", "BlockOutput", "BlockId", "Block", "break", "reversed"], "ast_kind": "function_or_method", "text": "    def handle_html_output(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if block_config is None:\n            block_config = {}\n\n        child_ref_blocks = [\n            block\n            for block in child_blocks\n            if block.id.block_type == BlockTypes.Reference\n        ]\n        html = Block.assemble_html(\n            self, document, child_ref_blocks, parent_structure, block_config\n        )\n        return html + self.html\n", "n_tokens": 96, "byte_len": 482, "file_sha1": "452207b88b7a32fc99bce02ea851be48980a34c0", "start_line": 337, "end_line": 352}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/sectionheader.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/blocks/sectionheader.py", "rel_path": "marker/schema/blocks/sectionheader.py", "module": "marker.schema.blocks.sectionheader", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "SectionHeader", "block", "type", "class", "header", "none", "description", "text", "config", "blocks", "ignore", "for", "else", "section", "html", "document", "schema", "self", "from", "parent", "structure", "return", "super", "handle", "replace", "template", "typing", "types", "optional", "heading", "level", "import", "assemble", "marker", "other", "child"], "ast_kind": "class_or_type", "text": "from typing import Optional\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass SectionHeader(Block):\n    block_type: BlockTypes = BlockTypes.SectionHeader\n    heading_level: Optional[int] = None\n    block_description: str = \"The header of a section of text or other blocks.\"\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.ignore_for_output:\n            return \"\"\n\n        if self.html:\n            return super().handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        template = template.replace(\"\\n\", \" \")\n        tag = f\"h{self.heading_level}\" if self.heading_level else \"h2\"\n        return f\"<{tag}>{template}</{tag}>\"\n", "n_tokens": 196, "byte_len": 936, "file_sha1": "f5258e5947f70597f569ed9ca6203bf95cd9ec47", "start_line": 1, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/list.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/list.py", "rel_path": "marker/schema/groups/list.py", "module": "marker.schema.groups.list", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "ListGroup", "block", "type", "together", "class", "group", "rendered", "description", "none", "base", "config", "has", "continuation", "html", "document", "schema", "self", "from", "attr", "parent", "structure", "return", "list", "handle", "super", "should", "template", "types", "that", "import", "bool", "assemble", "marker", "groups", "false", "child", "blocks", "items"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.groups.base import Group\n\n\nclass ListGroup(Group):\n    block_type: BlockTypes = BlockTypes.ListGroup\n    has_continuation: bool = False\n    block_description: str = \"A group of list items that should be rendered together.\"\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return self.handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        template = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n\n        el_attr = f\" block-type='{self.block_type}'\"\n        if self.has_continuation:\n            el_attr += \" class='has-continuation'\"\n        return f\"<p{el_attr}><ul>{template}</ul></p>\"\n", "n_tokens": 188, "byte_len": 876, "file_sha1": "16953ee2d3db5c89a7895945bf8ef6129b9e0cc2", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/picture.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/picture.py", "rel_path": "marker/schema/groups/picture.py", "module": "marker.schema.groups.picture", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "PictureGroup", "block", "type", "associated", "captions", "class", "group", "description", "none", "base", "child", "html", "config", "document", "schema", "self", "from", "picture", "parent", "structure", "return", "super", "types", "with", "import", "assemble", "marker", "groups", "along", "blocks"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.groups.base import Group\n\n\nclass PictureGroup(Group):\n    block_type: BlockTypes = BlockTypes.PictureGroup\n    block_description: str = \"A picture along with associated captions.\"\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return self.html\n\n        child_html = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        return child_html\n", "n_tokens": 116, "byte_len": 568, "file_sha1": "ee4aa4ed821ef5decdf5e58a912945d9f92958ff", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/figure.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/figure.py", "rel_path": "marker/schema/groups/figure.py", "module": "marker.schema.groups.figure", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "FigureGroup", "block", "type", "associated", "captions", "class", "group", "description", "none", "base", "child", "html", "config", "contains", "document", "schema", "self", "from", "figure", "parent", "structure", "return", "super", "types", "that", "import", "assemble", "marker", "groups", "blocks"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.groups.base import Group\n\n\nclass FigureGroup(Group):\n    block_type: BlockTypes = BlockTypes.FigureGroup\n    block_description: str = \"A group that contains a figure and associated captions.\"\n    html: str | None = None\n\n    def assemble_html(\n        self, document, child_blocks, parent_structure, block_config=None\n    ):\n        if self.html:\n            return self.html\n\n        child_html = super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n        return child_html\n", "n_tokens": 119, "byte_len": 580, "file_sha1": "0799d5149d6529d50363874ed39350e03adec612", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/__init__.py", "rel_path": "marker/schema/groups/__init__.py", "module": "marker.schema.groups.__init__", "ext": "py", "chunk_number": 1, "symbols": ["picture", "table", "group", "import", "list", "marker", "groups", "figure", "page", "block", "schema", "base", "from", "blocks"], "ast_kind": "imports", "text": "from marker.schema.blocks.base import Block\nfrom marker.schema.groups.figure import FigureGroup\nfrom marker.schema.groups.table import TableGroup\nfrom marker.schema.groups.list import ListGroup\nfrom marker.schema.groups.picture import PictureGroup\nfrom marker.schema.groups.page import PageGroup\n", "n_tokens": 53, "byte_len": 296, "file_sha1": "bf4ec5675b427a3978bd42cb3bf2af61ac7a83fb", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 1, "symbols": ["image", "group", "tuple", "base", "matrix", "intersection", "blocks", "numpy", "reference", "provider", "output", "pydantic", "schema", "providers", "from", "draw", "collections", "dict", "sequence", "list", "text", "lin", "mappin", "union", "block", "blockid", "typing", "sort", "types", "optional", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements"], "ast_kind": "imports", "text": "from collections import defaultdict\nfrom typing import Any, Dict, List, Optional, Sequence, Tuple, Union\nimport numpy as np\n\nfrom PIL import Image, ImageDraw\n\nfrom pdftext.schema import Reference\nfrom pydantic import computed_field\n\nfrom marker.providers import ProviderOutput\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockId, Text\nfrom marker.schema.blocks.base import BlockMetadata\nfrom marker.schema.groups.base import Group\nfrom marker.schema.polygon import PolygonBox\nfrom marker.util import matrix_intersection_area, sort_text_lines\n\nLINE_MAPPING_TYPE = List[Tuple[int, ProviderOutput]]\n\n", "n_tokens": 127, "byte_len": 630, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 2, "symbols": ["incr_block_id", "PageGroup", "block", "type", "image", "class", "layout", "sliced", "group", "none", "description", "model", "serialized", "float", "line", "page", "bytes", "else", "reference", "document", "self", "lowres", "whether", "span", "incr", "pixels", "sequence", "children", "maximum", "assignment", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "elements", "provider", "output"], "ast_kind": "class_or_type", "text": "class PageGroup(Group):\n    block_type: BlockTypes = BlockTypes.Page\n    # This is bytes if it is serialized\n    lowres_image: Image.Image | None | bytes = None\n    highres_image: Image.Image | None | bytes = None\n    children: List[Union[Any, Block]] | None = None\n    layout_sliced: bool = (\n        False  # Whether the layout model had to slice the image (order may be wrong)\n    )\n    excluded_block_types: Sequence[BlockTypes] = (\n        BlockTypes.Line,\n        BlockTypes.Span,\n    )\n    maximum_assignment_distance: float = 20  # pixels\n    block_description: str = \"A single page in the document.\"\n    refs: List[Reference] | None = None\n    ocr_errors_detected: bool = False\n\n    def incr_block_id(self):\n        if self.block_id is None:\n            self.block_id = 0\n        else:\n            self.block_id += 1\n", "n_tokens": 205, "byte_len": 826, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 21, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 3, "symbols": ["add_child", "else", "children", "block", "append", "self", "add", "child", "none", "incr_block_id", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "matrix", "intersection", "draw", "config", "replace", "fill", "diagonal", "assigned", "line", "image", "raw", "text", "min", "dist", "document", "found", "cls"], "ast_kind": "function_or_method", "text": "    def add_child(self, block: Block):\n        if self.children is None:\n            self.children = [block]\n        else:\n            self.children.append(block)\n", "n_tokens": 33, "byte_len": 163, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 45, "end_line": 50}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 4, "symbols": ["get_image", "block", "type", "check", "args", "image", "elements", "certain", "none", "highres", "draw", "mode", "else", "double", "self", "remove", "blocks", "lowres", "size", "bad", "convert", "kwargs", "rescale", "return", "current", "children", "sequence", "fill", "copy", "poly", "incr_block_id", "add_child", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "provider", "output"], "ast_kind": "function_or_method", "text": "    def get_image(\n        self,\n        *args,\n        highres: bool = False,\n        remove_blocks: Sequence[BlockTypes] | None = None,\n        **kwargs,\n    ):\n        image = self.highres_image if highres else self.lowres_image\n\n        # Check if RGB, convert if needed\n        if isinstance(image, Image.Image) and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        # Avoid double OCR for certain elements\n        if remove_blocks:\n            image = image.copy()\n            draw = ImageDraw.Draw(image)\n            bad_blocks = [\n                block\n                for block in self.current_children\n                if block.block_type in remove_blocks\n            ]\n            for bad_block in bad_blocks:\n                poly = bad_block.polygon.rescale(self.polygon.size, image.size).polygon\n                poly = [(int(p[0]), int(p[1])) for p in poly]\n                draw.polygon(poly, fill=\"white\")\n\n        return image\n", "n_tokens": 204, "byte_len": 961, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 51, "end_line": 79}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 5, "symbols": ["current_children", "get_next_block", "block", "type", "iterate", "none", "blocks", "found", "self", "following", "valid", "over", "return", "next", "current", "children", "get", "list", "property", "structure", "idx", "given", "types", "index", "optional", "ignored", "removed", "child", "computed", "field", "incr_block_id", "add_child", "get_image", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output"], "ast_kind": "function_or_method", "text": "    @computed_field\n    @property\n    def current_children(self) -> List[Block]:\n        return [child for child in self.children if not child.removed]\n\n    def get_next_block(\n        self,\n        block: Optional[Block] = None,\n        ignored_block_types: Optional[List[BlockTypes]] = None,\n    ):\n        if ignored_block_types is None:\n            ignored_block_types = []\n\n        structure_idx = 0\n        if block is not None:\n            structure_idx = self.structure.index(block.id) + 1\n\n        # Iterate over blocks following the given block\n        for next_block_id in self.structure[structure_idx:]:\n            if next_block_id.block_type not in ignored_block_types:\n                return self.get_block(next_block_id)\n\n        return None  # No valid next block found\n", "n_tokens": 167, "byte_len": 787, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 80, "end_line": 103}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 6, "symbols": ["get_prev_block", "add_block", "add_full_block", "get_block", "add", "full", "assert", "none", "block", "cls", "self", "idx", "incr", "return", "get", "children", "child", "structure", "blockid", "page", "index", "prev", "type", "polygon", "box", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "matrix", "intersection", "draw", "config"], "ast_kind": "function_or_method", "text": "    def get_prev_block(self, block: Block):\n        block_idx = self.structure.index(block.id)\n        if block_idx > 0:\n            return self.get_block(self.structure[block_idx - 1])\n        return None\n\n    def add_block(self, block_cls: type[Block], polygon: PolygonBox) -> Block:\n        self.incr_block_id()\n        block = block_cls(\n            polygon=polygon,\n            block_id=self.block_id,\n            page_id=self.page_id,\n        )\n        self.add_child(block)\n        return block\n\n    def add_full_block(self, block: Block) -> Block:\n        self.incr_block_id()\n        block.block_id = self.block_id\n        self.add_child(block)\n        return block\n\n    def get_block(self, block_id: BlockId) -> Block | None:\n        block: Block = self.children[block_id.block_id]\n        assert block.block_id == block_id.block_id\n        return block\n", "n_tokens": 195, "byte_len": 864, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 104, "end_line": 130}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 7, "symbols": ["assemble_html", "assemble", "html", "document", "self", "none", "content", "block", "config", "child", "blocks", "template", "parent", "structure", "return", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "matrix", "intersection", "draw", "replace", "fill", "diagonal", "assigned", "line", "image", "raw", "text"], "ast_kind": "function_or_method", "text": "    def assemble_html(\n        self, document, child_blocks, parent_structure=None, block_config=None\n    ):\n        template = \"\"\n        for c in child_blocks:\n            template += f\"<content-ref src='{c.id}'></content-ref>\"\n        return template\n", "n_tokens": 54, "byte_len": 254, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 131, "end_line": 138}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 8, "symbols": ["compute_line_block_intersections", "bbox", "provider", "output", "matrix", "intersection", "block", "bboxes", "blocks", "self", "line", "max", "return", "idx", "list", "argmax", "outputs", "enumerate", "continue", "polygon", "intersections", "compute", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "iterate", "base", "serialized", "draw", "config", "replace", "fill", "diagonal", "assigned"], "ast_kind": "function_or_method", "text": "    def compute_line_block_intersections(\n        self, blocks: List[Block], provider_outputs: List[ProviderOutput]\n    ):\n        max_intersections = {}\n\n        block_bboxes = [block.polygon.bbox for block in blocks]\n        line_bboxes = [\n            provider_output.line.polygon.bbox for provider_output in provider_outputs\n        ]\n\n        intersection_matrix = matrix_intersection_area(line_bboxes, block_bboxes)\n\n        for line_idx, line in enumerate(provider_outputs):\n            intersection_line = intersection_matrix[line_idx]\n            if intersection_line.sum() == 0:\n                continue\n\n            max_intersection = intersection_line.argmax()\n            max_intersections[line_idx] = (\n                intersection_matrix[line_idx, max_intersection],\n                blocks[max_intersection].id,\n            )\n        return max_intersections\n", "n_tokens": 161, "byte_len": 874, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 139, "end_line": 162}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 9, "symbols": ["compute_max_structure_block_intersection_pct", "bbox", "matrix", "intersection", "fill", "diagonal", "strucure", "block", "self", "idx", "return", "get", "max", "area", "intersections", "structure", "enumerate", "ignore", "blocks", "compute", "polygon", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "draw", "config", "replace", "assigned", "line"], "ast_kind": "function_or_method", "text": "    def compute_max_structure_block_intersection_pct(self):\n        structure_blocks = [self.get_block(block_id) for block_id in self.structure]\n        strucure_block_bboxes = [b.polygon.bbox for b in structure_blocks]\n\n        intersection_matrix = matrix_intersection_area(strucure_block_bboxes, strucure_block_bboxes)\n        np.fill_diagonal(intersection_matrix, 0)    # Ignore self-intersections\n\n        max_intersection_pct = 0\n        for block_idx, block in enumerate(structure_blocks):\n            max_intersection_pct = max(max_intersection_pct, np.max(intersection_matrix[block_idx]) / block.polygon.area)\n\n        return max_intersection_pct\n", "n_tokens": 138, "byte_len": 656, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 163, "end_line": 175}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 10, "symbols": ["replace_block", "add", "full", "child", "super", "children", "block", "handles", "self", "mark", "structure", "incrementing", "new", "replace", "true", "removed", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "matrix", "intersection", "draw", "config", "fill", "diagonal", "assigned", "line", "image", "raw"], "ast_kind": "function_or_method", "text": "    def replace_block(self, block: Block, new_block: Block):\n        # Handles incrementing the id\n        self.add_full_block(new_block)\n\n        # Replace block id in structure\n        super().replace_block(block, new_block)\n\n        # Replace block in structure of children\n        for child in self.children:\n            child.replace_block(block, new_block)\n\n        # Mark block as removed\n        block.removed = True\n", "n_tokens": 88, "byte_len": 425, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 176, "end_line": 189}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 11, "symbols": ["identify_missing_blocks", "elif", "none", "unassociated", "center", "distance", "assigned", "line", "else", "raw", "text", "provider", "output", "append", "self", "new", "blocks", "block", "return", "minimal", "maximum", "assignment", "idx", "list", "area", "outputs", "with", "continue", "skip", "identify", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "iterate"], "ast_kind": "function_or_method", "text": "    def identify_missing_blocks(\n        self,\n        provider_line_idxs: List[int],\n        provider_outputs: List[ProviderOutput],\n        assigned_line_idxs: set[int],\n    ):\n        new_blocks = []\n        new_block = None\n        for line_idx in provider_line_idxs:\n            if line_idx in assigned_line_idxs:\n                continue\n\n            # if the unassociated line is a new line with minimal area, we can skip it\n            if (\n                provider_outputs[line_idx].line.polygon.area <= 1\n                and provider_outputs[line_idx].raw_text == \"\\n\"\n            ):\n                continue\n\n            if new_block is None:\n                new_block = [(line_idx, provider_outputs[line_idx])]\n            elif all(\n                [\n                    new_block[-1][0] + 1 == line_idx,\n                    provider_outputs[line_idx].line.polygon.center_distance(\n                        new_block[-1][1].line.polygon\n                    )\n                    < self.maximum_assignment_distance,\n                ]\n            ):\n                new_block.append((line_idx, provider_outputs[line_idx]))\n            else:\n                new_blocks.append(new_block)\n                new_block = [(line_idx, provider_outputs[line_idx])]\n            assigned_line_idxs.add(line_idx)\n        if new_block:\n            new_blocks.append(new_block)\n\n        return new_blocks\n", "n_tokens": 262, "byte_len": 1399, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 190, "end_line": 229}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 12, "symbols": ["create_missing_blocks", "block", "type", "absolute", "none", "lines", "min", "dist", "center", "distance", "weight", "blocks", "existing", "want", "else", "heuristics", "append", "self", "new", "line", "assign", "get", "dict", "insert", "list", "create", "missing", "excluded", "text", "lin", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "add_initial_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "provider"], "ast_kind": "function_or_method", "text": "    def create_missing_blocks(\n        self,\n        new_blocks: List[LINE_MAPPING_TYPE],\n        block_lines: Dict[BlockId, LINE_MAPPING_TYPE],\n    ):\n        for new_block in new_blocks:\n            block = self.add_block(Text, new_block[0][1].line.polygon)\n            block.source = \"heuristics\"\n            block_lines[block.id] = new_block\n\n            min_dist_idx = None\n            min_dist = None\n            for existing_block_id in self.structure:\n                existing_block = self.get_block(existing_block_id)\n                if existing_block.block_type in self.excluded_block_types:\n                    continue\n                # We want to assign to blocks closer in y than x\n                dist = block.polygon.center_distance(\n                    existing_block.polygon, x_weight=5, absolute=True\n                )\n                if dist > 0 and min_dist_idx is None or dist < min_dist:\n                    min_dist = dist\n                    min_dist_idx = existing_block.id\n\n            if min_dist_idx is not None:\n                existing_idx = self.structure.index(min_dist_idx)\n                self.structure.insert(existing_idx + 1, block.id)\n            else:\n                self.structure.append(block.id)\n", "n_tokens": 244, "byte_len": 1240, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 230, "end_line": 259}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#13", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 13, "symbols": ["add_initial_blocks", "add", "full", "associated", "provider", "output", "argsort", "through", "block", "lines", "characters", "blocks", "line", "polygons", "else", "self", "char", "spans", "proper", "sorted", "get", "extraction", "dict", "text", "order", "lin", "mappin", "have", "blockid", "sort", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "merge_blocks", "aggregate_block_metadata", "PageGroup", "elements", "iterate"], "ast_kind": "function_or_method", "text": "    def add_initial_blocks(\n        self,\n        block_lines: Dict[BlockId, LINE_MAPPING_TYPE],\n        text_extraction_method: str,\n        keep_chars: bool = False,\n    ):\n        # Add lines to the proper blocks, sorted in order\n        for block_id, lines in block_lines.items():\n            line_extraction_methods = set(\n                [line[1].line.text_extraction_method for line in lines]\n            )\n            if len(line_extraction_methods) == 1:\n                lines = sorted(lines, key=lambda x: x[0])\n                lines = [line for _, line in lines]\n            else:\n                lines = [line for _, line in lines]\n                line_polygons = [line.line.polygon for line in lines]\n                sorted_line_polygons = sort_text_lines(line_polygons)\n                argsort = [line_polygons.index(p) for p in sorted_line_polygons]\n                lines = [lines[i] for i in argsort]\n\n            block = self.get_block(block_id)\n            for provider_output in lines:\n                line = provider_output.line\n                spans = provider_output.spans\n                self.add_full_block(line)\n                block.add_structure(line)\n                block.polygon = block.polygon.merge([line.polygon])\n                block.text_extraction_method = text_extraction_method\n                for span_idx, span in enumerate(spans):\n                    self.add_full_block(span)\n                    line.add_structure(span)\n\n                    if not keep_chars:\n                        continue\n\n                    # Provider doesn't have chars\n                    if len(provider_output.chars) == 0:\n                        continue\n\n                    # Loop through characters associated with the span\n                    for char in provider_output.chars[span_idx]:\n                        char.page_id = self.page_id\n                        self.add_full_block(char)\n                        span.add_structure(char)\n", "n_tokens": 363, "byte_len": 1965, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 260, "end_line": 305}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#14", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 14, "symbols": ["merge_blocks", "block", "type", "provider", "output", "merge", "blocks", "none", "hold", "lines", "intersection", "min", "dist", "center", "distance", "weight", "ensure", "haven", "assigned", "line", "anything", "range", "want", "append", "self", "new", "assign", "replaced", "current", "children", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "aggregate_block_metadata", "PageGroup", "elements", "iterate"], "ast_kind": "function_or_method", "text": "    def merge_blocks(\n        self,\n        provider_outputs: List[ProviderOutput],\n        text_extraction_method: str,\n        keep_chars: bool = False,\n    ):\n        provider_line_idxs = list(range(len(provider_outputs)))\n        valid_blocks = [\n            block\n            for block in self.current_children  # ensure we only look at children that haven't been replaced\n            if block.block_type not in self.excluded_block_types\n        ]\n\n        max_intersections = self.compute_line_block_intersections(\n            valid_blocks, provider_outputs\n        )\n\n        # Try to assign lines by intersection\n        assigned_line_idxs = set()\n        block_lines = defaultdict(list)\n        for line_idx, provider_output in enumerate(provider_outputs):\n            if line_idx in max_intersections:\n                block_id = max_intersections[line_idx][1]\n                block_lines[block_id].append((line_idx, provider_output))\n                assigned_line_idxs.add(line_idx)\n\n        # If no intersection, assign by distance\n        for line_idx in set(provider_line_idxs).difference(assigned_line_idxs):\n            min_dist = None\n            min_dist_idx = None\n            provider_output: ProviderOutput = provider_outputs[line_idx]\n            line = provider_output.line\n            for block in valid_blocks:\n                # We want to assign to blocks closer in y than x\n                dist = line.polygon.center_distance(block.polygon, x_weight=5)\n                if min_dist_idx is None or dist < min_dist:\n                    min_dist = dist\n                    min_dist_idx = block.id\n\n            if min_dist_idx is not None and min_dist < self.maximum_assignment_distance:\n                block_lines[min_dist_idx].append((line_idx, provider_output))\n                assigned_line_idxs.add(line_idx)\n\n        # This creates new blocks to hold anything too far away\n        new_blocks = self.identify_missing_blocks(\n            provider_line_idxs, provider_outputs, assigned_line_idxs\n        )\n        self.create_missing_blocks(new_blocks, block_lines)\n\n        # Add blocks to the page\n        self.add_initial_blocks(block_lines, text_extraction_method, keep_chars)\n", "n_tokens": 422, "byte_len": 2206, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 306, "end_line": 357}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py#15", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/page.py", "rel_path": "marker/schema/groups/page.py", "module": "marker.schema.groups.page", "ext": "py", "chunk_number": 15, "symbols": ["aggregate_block_metadata", "metadata", "aggregate", "block", "self", "none", "merge", "return", "current", "children", "incr_block_id", "add_child", "get_image", "current_children", "get_next_block", "get_prev_block", "add_block", "add_full_block", "get_block", "assemble_html", "compute_line_block_intersections", "compute_max_structure_block_intersection_pct", "replace_block", "identify_missing_blocks", "create_missing_blocks", "add_initial_blocks", "merge_blocks", "PageGroup", "elements", "provider", "output", "iterate", "base", "serialized", "matrix", "intersection", "draw", "config", "replace", "fill", "diagonal", "assigned", "line", "image", "raw", "text", "min", "dist", "document", "found"], "ast_kind": "function_or_method", "text": "    def aggregate_block_metadata(self) -> BlockMetadata:\n        if self.metadata is None:\n            self.metadata = BlockMetadata()\n\n        for block in self.current_children:\n            if block.metadata is not None:\n                self.metadata = self.metadata.merge(block.metadata)\n        return self.metadata\n", "n_tokens": 56, "byte_len": 320, "file_sha1": "8f18ebf23e0e29f9f66d6af3a9c357f05b7ed083", "start_line": 358, "end_line": 366}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/table.py", "rel_path": "marker/schema/groups/table.py", "module": "marker.schema.groups.table", "ext": "py", "chunk_number": 1, "symbols": ["assemble_html", "TableGroup", "block", "type", "table", "group", "associated", "captions", "class", "description", "none", "base", "config", "blocks", "html", "output", "schema", "self", "document", "from", "dict", "parent", "structure", "return", "handle", "super", "list", "typing", "types", "with", "import", "assemble", "marker", "groups", "along", "child"], "ast_kind": "class_or_type", "text": "from typing import List\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import BlockOutput\nfrom marker.schema.groups.base import Group\n\n\nclass TableGroup(Group):\n    block_type: BlockTypes = BlockTypes.TableGroup\n    block_description: str = \"A table along with associated captions.\"\n    html: str | None = None\n\n    def assemble_html(\n        self,\n        document,\n        child_blocks: List[BlockOutput],\n        parent_structure=None,\n        block_config: dict | None = None,\n    ):\n        if self.html:\n            return self.handle_html_output(\n                document, child_blocks, parent_structure, block_config\n            )\n\n        return super().assemble_html(\n            document, child_blocks, parent_structure, block_config\n        )\n", "n_tokens": 152, "byte_len": 772, "file_sha1": "7483b1a373af0cbac7da36b72d95d655cc8cadc2", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/base.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/groups/base.py", "rel_path": "marker/schema/groups/base.py", "module": "marker.schema.groups.base", "ext": "py", "chunk_number": 1, "symbols": ["Group", "import", "marker", "class", "group", "block", "schema", "pass", "from", "blocks"], "ast_kind": "class_or_type", "text": "from marker.schema.blocks import Block\n\n\nclass Group(Block):\n    pass", "n_tokens": 13, "byte_len": 69, "file_sha1": "51284c66aece4f4b293bec80377ffb4d08ac58de", "start_line": 1, "end_line": 5}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 1, "symbols": ["remove_tags", "replace_last", "start", "text", "blocks", "html", "block", "output", "schema", "finditer", "from", "return", "list", "typing", "types", "remove", "tags", "regex", "string", "matches", "import", "hyphens", "marker", "last", "match", "replace", "literal", "strip_trailing_hyphens", "ocr_input_text", "formatted_text", "assemble_html", "render", "merge", "Line", "whitespace", "config", "formats", "raw", "document", "lowercase", "letters", "bold", "format", "sometimes", "href", "next", "line", "children", "this", "dotall"], "ast_kind": "function_or_method", "text": "import html\nimport re\nfrom typing import Literal, List\n\nimport regex\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockOutput\n\nHYPHENS = r\"-\"\n\n\ndef remove_tags(text):\n    return re.sub(r\"<[^>]+>\", \"\", text)\n\n\ndef replace_last(string, old, new):\n    matches = list(re.finditer(old, string))\n    if not matches:\n        return string\n    last_match = matches[-1]\n    return string[: last_match.start()] + new + string[last_match.end() :]\n\n", "n_tokens": 116, "byte_len": 475, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 2, "symbols": ["strip_trailing_hyphens", "Line", "block", "type", "class", "strip", "trailing", "description", "text", "none", "line", "hyphen", "regex", "want", "formats", "lowercase", "letters", "format", "return", "match", "sometimes", "next", "html", "list", "math", "types", "hyphens", "compile", "dotall", "span", "remove_tags", "replace_last", "ocr_input_text", "formatted_text", "assemble_html", "render", "merge", "start", "whitespace", "config", "raw", "output", "document", "bold", "last", "href", "children", "remove", "tags", "string"], "ast_kind": "class_or_type", "text": "def strip_trailing_hyphens(line_text, next_line_text, line_html) -> str:\n    lowercase_letters = r\"\\p{Ll}\"\n\n    hyphen_regex = regex.compile(rf\".*[{HYPHENS}]\\s?$\", regex.DOTALL)\n    next_line_starts_lowercase = regex.match(\n        rf\"^\\s?[{lowercase_letters}]\", next_line_text\n    )\n\n    if hyphen_regex.match(line_text) and next_line_starts_lowercase:\n        line_html = replace_last(line_html, rf\"[{HYPHENS}]\", \"\")\n\n    return line_html\n\n\nclass Line(Block):\n    block_type: BlockTypes = BlockTypes.Line\n    block_description: str = \"A line of text.\"\n    formats: List[Literal[\"math\"]] | None = (\n        None  # Sometimes we want to set math format at the line level, not span\n    )\n", "n_tokens": 185, "byte_len": 687, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 25, "end_line": 45}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 3, "symbols": ["ocr_input_text", "elif", "text", "contained", "blocks", "block", "else", "document", "self", "stage", "since", "span", "ocr", "input", "bold", "return", "superscripts", "subscripts", "math", "strip", "they", "unreliable", "types", "this", "include", "italic", "remove_tags", "replace_last", "strip_trailing_hyphens", "formatted_text", "assemble_html", "render", "merge", "Line", "start", "whitespace", "config", "formats", "raw", "output", "lowercase", "letters", "format", "last", "sometimes", "href", "next", "line", "html", "children"], "ast_kind": "function_or_method", "text": "    def ocr_input_text(self, document):\n        text = \"\"\n        for block in self.contained_blocks(document, (BlockTypes.Span,)):\n            # We don't include superscripts/subscripts and math since they can be unreliable at this stage\n            block_text = block.text\n            if block.italic:\n                text += f\"<i>{block_text}</i>\"\n            elif block.bold:\n                text += f\"<b>{block_text}</b>\"\n            else:\n                text += block_text\n\n        return text.strip()\n", "n_tokens": 107, "byte_len": 509, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 46, "end_line": 59}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 4, "symbols": ["formatted_text", "skip", "urls", "formatted", "text", "elif", "contained", "blocks", "block", "inline", "else", "has", "superscript", "html", "document", "display", "self", "span", "bold", "return", "href", "escape", "math", "types", "italic", "false", "remove_tags", "replace_last", "strip_trailing_hyphens", "ocr_input_text", "assemble_html", "render", "merge", "Line", "start", "whitespace", "config", "formats", "raw", "output", "lowercase", "letters", "format", "last", "sometimes", "next", "line", "children", "remove", "tags"], "ast_kind": "function_or_method", "text": "    def formatted_text(self, document, skip_urls=False):\n        text = \"\"\n        for block in self.contained_blocks(document, (BlockTypes.Span,)):\n            block_text = html.escape(block.text)\n\n            if block.has_superscript:\n                block_text = re.sub(r\"^([0-9\\W]+)(.*)\", r\"<sup>\\1</sup>\\2\", block_text)\n                if \"<sup>\" not in block_text:\n                    block_text = f\"<sup>{block_text}</sup>\"\n\n            if block.url and not skip_urls:\n                block_text = f\"<a href='{block.url}'>{block_text}</a>\"\n\n            if block.italic:\n                text += f\"<i>{block_text}</i>\"\n            elif block.bold:\n                text += f\"<b>{block_text}</b>\"\n            elif block.math:\n                text += f\"<math display='inline'>{block_text}</math>\"\n            else:\n                text += block_text\n\n        return text\n", "n_tokens": 200, "byte_len": 873, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 60, "end_line": 83}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 5, "symbols": ["assemble_html", "next", "line", "strip", "trailing", "whitespace", "block", "config", "else", "raw", "text", "html", "document", "self", "from", "last", "parent", "structure", "return", "get", "idx", "template", "remove", "tags", "index", "assemble", "child", "blocks", "remove_tags", "replace_last", "strip_trailing_hyphens", "ocr_input_text", "formatted_text", "render", "merge", "Line", "start", "formats", "output", "lowercase", "letters", "bold", "format", "sometimes", "href", "children", "string", "marker", "match", "this"], "ast_kind": "function_or_method", "text": "    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        template = \"\"\n        for c in child_blocks:\n            template += c.html\n\n        raw_text = remove_tags(template).strip()\n        structure_idx = parent_structure.index(self.id)\n        if structure_idx < len(parent_structure) - 1:\n            next_block_id = parent_structure[structure_idx + 1]\n            next_line = document.get_block(next_block_id)\n            next_line_raw_text = next_line.raw_text(document)\n            template = strip_trailing_hyphens(raw_text, next_line_raw_text, template)\n        else:\n            template = template.strip(\n                \" \"\n            )  # strip any trailing whitespace from the last line\n        return template\n", "n_tokens": 153, "byte_len": 762, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 84, "end_line": 101}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 6, "symbols": ["render", "child", "content", "none", "block", "config", "html", "document", "append", "self", "output", "parent", "structure", "return", "get", "children", "section", "hierarchy", "assemble", "polygon", "remove_tags", "replace_last", "strip_trailing_hyphens", "ocr_input_text", "formatted_text", "assemble_html", "merge", "Line", "start", "whitespace", "formats", "raw", "text", "lowercase", "letters", "bold", "format", "last", "sometimes", "href", "next", "line", "remove", "tags", "string", "marker", "match", "this", "dotall", "span"], "ast_kind": "function_or_method", "text": "    def render(\n        self, document, parent_structure, section_hierarchy=None, block_config=None\n    ):\n        child_content = []\n        if self.structure is not None and len(self.structure) > 0:\n            for block_id in self.structure:\n                block = document.get_block(block_id)\n                child_content.append(\n                    block.render(\n                        document, parent_structure, section_hierarchy, block_config\n                    )\n                )\n\n        return BlockOutput(\n            html=self.assemble_html(\n                document, child_content, parent_structure, block_config\n            ),\n            polygon=self.polygon,\n            id=self.id,\n            children=[],\n            section_hierarchy=section_hierarchy,\n        )\n", "n_tokens": 135, "byte_len": 789, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 102, "end_line": 124}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/line.py", "rel_path": "marker/schema/text/line.py", "module": "marker.schema.text.line", "ext": "py", "chunk_number": 7, "symbols": ["merge", "elif", "formats", "merging", "polygon", "self", "none", "structure", "line", "other", "handle", "with", "list", "nones", "remove_tags", "replace_last", "strip_trailing_hyphens", "ocr_input_text", "formatted_text", "assemble_html", "render", "Line", "start", "whitespace", "block", "config", "raw", "text", "output", "document", "lowercase", "letters", "bold", "format", "last", "return", "sometimes", "href", "next", "html", "children", "remove", "tags", "string", "marker", "match", "this", "dotall", "span", "literal"], "ast_kind": "function_or_method", "text": "    def merge(self, other: \"Line\"):\n        self.polygon = self.polygon.merge([other.polygon])\n\n        # Handle merging structure with Nones\n        if self.structure is None:\n            self.structure = other.structure\n        elif other.structure is not None:\n            self.structure = self.structure + other.structure\n\n        # Merge formats with Nones\n        if self.formats is None:\n            self.formats = other.formats\n        elif other.formats is not None:\n            self.formats = list(set(self.formats + other.formats))\n", "n_tokens": 114, "byte_len": 543, "file_sha1": "8a13d120a186e3652cecd3695f7e47fff4617ab3", "start_line": 125, "end_line": 139}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/char.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/char.py", "rel_path": "marker/schema/text/char.py", "module": "marker.schema.text.char", "ext": "py", "chunk_number": 1, "symbols": ["Char", "block", "type", "import", "marker", "class", "single", "schema", "description", "character", "inside", "text", "from", "blocks", "types", "span", "char"], "ast_kind": "class_or_type", "text": "from marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\n\n\nclass Char(Block):\n    block_type: BlockTypes = BlockTypes.Char\n    block_description: str = \"A single character inside a span.\"\n\n    text: str\n    idx: int\n", "n_tokens": 53, "byte_len": 235, "file_sha1": "fdbb63aa51c2c55a4a3d9ddea3b63928900521e2", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/__init__.py", "rel_path": "marker/schema/text/__init__.py", "module": "marker.schema.text.__init__", "ext": "py", "chunk_number": 1, "symbols": ["import", "marker", "schema", "text", "from", "line", "span"], "ast_kind": "imports", "text": "from marker.schema.text.line import Line\nfrom marker.schema.text.span import Span\n", "n_tokens": 16, "byte_len": 82, "file_sha1": "8606a7425864be40fe5a355ca807f414cc5210d2", "start_line": 1, "end_line": 3}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py", "rel_path": "marker/schema/text/span.py", "module": "marker.schema.text.span", "ext": "py", "chunk_number": 1, "symbols": ["cleanup_text", "breaking", "full", "text", "blocks", "replace", "cleanup", "spaces", "html", "schema", "from", "return", "list", "typing", "block", "types", "optional", "import", "marker", "util", "literal", "unwrap", "math", "bold", "italic", "highlight", "superscript", "subscript", "small", "code", "underline", "assemble_html", "Span", "minimum", "position", "config", "chemical", "formats", "middle", "document", "gather", "multline", "todo", "mark", "href", "breaks", "property", "bool", "span", "true"], "ast_kind": "function_or_method", "text": "import html\nimport re\nfrom typing import List, Literal, Optional\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.util import unwrap_math\n\n\ndef cleanup_text(full_text):\n    full_text = re.sub(r\"(\\n\\s){3,}\", \"\\n\\n\", full_text)\n    full_text = full_text.replace(\"\\xa0\", \" \")  # Replace non-breaking spaces\n    return full_text\n\n", "n_tokens": 89, "byte_len": 366, "file_sha1": "4beb85f4a797308635ce01dbd9255ad10b0b65b9", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py", "rel_path": "marker/schema/text/span.py", "module": "marker.schema.text.span", "ext": "py", "chunk_number": 2, "symbols": ["bold", "italic", "math", "Span", "block", "type", "class", "description", "text", "minimum", "position", "none", "float", "chemical", "small", "font", "size", "formats", "has", "superscript", "html", "self", "subscript", "line", "maximum", "span", "return", "list", "highlight", "property", "cleanup_text", "code", "underline", "assemble_html", "breaking", "config", "replace", "middle", "full", "document", "gather", "multline", "todo", "mark", "href", "breaks", "bool", "marker", "util", "true"], "ast_kind": "class_or_type", "text": "class Span(Block):\n    block_type: BlockTypes = BlockTypes.Span\n    block_description: str = \"A span of text inside a line.\"\n\n    text: str\n    font: str\n    font_weight: float\n    font_size: float\n    minimum_position: int\n    maximum_position: int\n    formats: List[\n        Literal[\n            \"plain\",\n            \"math\",\n            \"chemical\",\n            \"bold\",\n            \"italic\",\n            \"highlight\",\n            \"subscript\",\n            \"superscript\",\n            \"small\",\n            \"code\",\n            \"underline\",\n        ]\n    ]\n    has_superscript: bool = False\n    has_subscript: bool = False\n    url: Optional[str] = None\n    html: Optional[str] = None\n\n    @property\n    def bold(self):\n        return \"bold\" in self.formats\n\n    @property\n    def italic(self):\n        return \"italic\" in self.formats\n\n    @property\n    def math(self):\n        return \"math\" in self.formats\n", "n_tokens": 217, "byte_len": 902, "file_sha1": "4beb85f4a797308635ce01dbd9255ad10b0b65b9", "start_line": 16, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py", "rel_path": "marker/schema/text/span.py", "module": "marker.schema.text.span", "ext": "py", "chunk_number": 3, "symbols": ["highlight", "superscript", "subscript", "small", "code", "underline", "formats", "property", "self", "return", "cleanup_text", "bold", "italic", "math", "assemble_html", "Span", "breaking", "minimum", "position", "block", "config", "replace", "chemical", "middle", "full", "document", "gather", "multline", "todo", "mark", "href", "breaks", "bool", "marker", "util", "span", "true", "literal", "type", "split", "text", "blocks", "cleanup", "has", "parent", "structure", "newlines", "escape", "inside", "import"], "ast_kind": "function_or_method", "text": "    @property\n    def highlight(self):\n        return \"highlight\" in self.formats\n\n    @property\n    def superscript(self):\n        return \"superscript\" in self.formats\n\n    @property\n    def subscript(self):\n        return \"subscript\" in self.formats\n\n    @property\n    def small(self):\n        return \"small\" in self.formats\n\n    @property\n    def code(self):\n        return \"code\" in self.formats\n\n    @property\n    def underline(self):\n        return \"underline\" in self.formats\n", "n_tokens": 118, "byte_len": 483, "file_sha1": "4beb85f4a797308635ce01dbd9255ad10b0b65b9", "start_line": 58, "end_line": 81}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/schema/text/span.py", "rel_path": "marker/schema/text/span.py", "module": "marker.schema.text.span", "ext": "py", "chunk_number": 4, "symbols": ["assemble_html", "elif", "split", "block", "envs", "remove", "text", "inline", "config", "handle", "cleanup", "ignore", "for", "small", "else", "formats", "has", "superscript", "html", "middle", "full", "document", "multiple", "self", "begin", "trailing", "while", "gather", "line", "from", "cleanup_text", "bold", "italic", "math", "highlight", "subscript", "code", "underline", "Span", "breaking", "minimum", "position", "replace", "chemical", "multline", "todo", "return", "mark", "href", "breaks"], "ast_kind": "function_or_method", "text": "    def assemble_html(self, document, child_blocks, parent_structure, block_config):\n        if self.ignore_for_output:\n            return \"\"\n\n        if self.html:\n            return self.html\n\n        text = self.text\n\n        # Remove trailing newlines\n        replaced_newline = False\n        while len(text) > 0 and text[-1] in [\"\\n\", \"\\r\"]:\n            text = text[:-1]\n            replaced_newline = True\n\n        # Remove leading newlines\n        while len(text) > 0 and text[0] in [\"\\n\", \"\\r\"]:\n            text = text[1:]\n\n        if replaced_newline and not text.endswith(\"-\"):\n            text += \" \"\n\n        text = text.replace(\n            \"-\\n\", \"\"\n        )  # Remove hyphenated line breaks from the middle of the span\n        text = html.escape(text)\n        text = cleanup_text(text)\n\n        if self.has_superscript:\n            text = re.sub(r\"^([0-9\\W]+)(.*)\", r\"<sup>\\1</sup>\\2\", text)\n\n            # Handle full block superscript\n            if \"<sup>\" not in text:\n                text = f\"<sup>{text}</sup>\"\n\n        if self.url:\n            text = f\"<a href='{self.url}'>{text}</a>\"\n\n        # TODO Support multiple formats\n        if self.italic:\n            text = f\"<i>{text}</i>\"\n        elif self.bold:\n            text = f\"<b>{text}</b>\"\n        elif self.math:\n            block_envs = [\"split\", \"align\", \"gather\", \"multline\"]\n            if any(f\"\\\\begin{{{env}}}\" in text for env in block_envs):\n                display_mode = \"block\"\n            else:\n                display_mode = \"inline\"\n            text = f\"<math display='{display_mode}'>{text}</math>\"\n        elif self.highlight:\n            text = f\"<mark>{text}</mark>\"\n        elif self.subscript:\n            text = f\"<sub>{text}</sub>\"\n        elif self.superscript:\n            text = f\"<sup>{text}</sup>\"\n        elif self.underline:\n            text = f\"<u>{text}</u>\"\n        elif self.small:\n            text = f\"<small>{text}</small>\"\n        elif self.code:\n            text = f\"<code>{text}</code>\"\n\n        text = unwrap_math(text)\n        return text\n", "n_tokens": 502, "byte_len": 2061, "file_sha1": "4beb85f4a797308635ce01dbd9255ad10b0b65b9", "start_line": 82, "end_line": 147}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/footnote.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/footnote.py", "rel_path": "marker/processors/footnote.py", "module": "marker.processors.footnote", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "push_footnotes_to_bottom", "FootnoteProcessor", "check", "remove", "class", "bottom", "text", "contained", "blocks", "footnote", "document", "schema", "self", "processor", "from", "assign", "superscripts", "push", "base", "pushing", "relabeling", "block", "types", "structure", "processors", "pages", "import", "add", "marker", "assign_superscripts", "break", "has", "superscript", "span", "groups", "mislabeled", "footnotes", "true", "page", "level", "match", "move", "call", "group"], "ast_kind": "class_or_type", "text": "import re\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\n\n\nclass FootnoteProcessor(BaseProcessor):\n    \"\"\"\n    A processor for pushing footnotes to the bottom, and relabeling mislabeled text blocks.\n    \"\"\"\n    block_types = (BlockTypes.Footnote,)\n\n    def __call__(self, document: Document):\n        for page in document.pages:\n            self.push_footnotes_to_bottom(page, document)\n            self.assign_superscripts(page, document)\n\n    def push_footnotes_to_bottom(self, page: PageGroup, document: Document):\n        footnote_blocks = page.contained_blocks(document, self.block_types)\n\n        # Push footnotes to the bottom\n        for block in footnote_blocks:\n            # Check if it is top-level\n            if block.id in page.structure:\n                # Move to bottom if it is\n                page.structure.remove(block.id)\n                page.add_structure(block)\n", "n_tokens": 203, "byte_len": 1008, "file_sha1": "83519c911497dd7c1052e40c028c73ee88122738", "start_line": 1, "end_line": 30}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/footnote.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/footnote.py", "rel_path": "marker/processors/footnote.py", "module": "marker.processors.footnote", "ext": "py", "chunk_number": 2, "symbols": ["assign_superscripts", "has", "superscript", "document", "footnote", "blocks", "self", "contained", "block", "types", "text", "assign", "superscripts", "true", "span", "page", "match", "break", "group", "__call__", "push_footnotes_to_bottom", "FootnoteProcessor", "check", "remove", "class", "bottom", "schema", "processor", "from", "push", "base", "pushing", "relabeling", "structure", "processors", "pages", "import", "add", "marker", "groups", "mislabeled", "footnotes", "level", "move", "call"], "ast_kind": "function_or_method", "text": "    def assign_superscripts(self, page: PageGroup, document: Document):\n        footnote_blocks = page.contained_blocks(document, self.block_types)\n\n        for block in footnote_blocks:\n            for span in block.contained_blocks(document, (BlockTypes.Span,)):\n                if re.match(r\"^[0-9\\W]+\", span.text):\n                    span.has_superscript = True\n                break\n", "n_tokens": 83, "byte_len": 389, "file_sha1": "83519c911497dd7c1052e40c028c73ee88122738", "start_line": 31, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py", "rel_path": "marker/processors/list.py", "module": "marker.processors.list", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "ListProcessor", "determine", "class", "init", "min", "indent", "percentage", "tuple", "float", "blocks", "lists", "annotated", "indentation", "relationships", "merging", "document", "schema", "required", "types", "self", "config", "from", "used", "list", "processor", "base", "within", "group", "when", "__call__", "list_group_continuation", "list_group_indentation", "column", "break", "next", "current", "parent", "same", "breaks", "item", "processors", "page", "columns", "continue", "marker", "header", "true", "call", "block"], "ast_kind": "class_or_type", "text": "from typing import Annotated, List, Tuple\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import ListItem\nfrom marker.schema.document import Document\n\n\nclass ListProcessor(BaseProcessor):\n    \"\"\"\n    A processor for merging lists across pages and columns\n    \"\"\"\n    block_types = (BlockTypes.ListGroup,)\n    ignored_block_types: Annotated[\n        Tuple[BlockTypes],\n        \"The list of block types to ignore when merging lists.\",\n    ] = (BlockTypes.PageHeader, BlockTypes.PageFooter)\n    min_x_indent: Annotated[\n        float, \"The minimum horizontal indentation required to consider a block as a nested list item.\",\n        \"This is expressed as a percentage of the page width and is used to determine hierarchical relationships within a list.\",\n    ] = 0.01\n\n    def __init__(self, config):\n        super().__init__(config)\n", "n_tokens": 185, "byte_len": 891, "file_sha1": "9280271009bfdebb19fd54701b762581ea4aa767", "start_line": 1, "end_line": 25}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py", "rel_path": "marker/processors/list.py", "module": "marker.processors.list", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "document", "self", "list", "group", "call", "__init__", "list_group_continuation", "list_group_indentation", "ListProcessor", "determine", "column", "break", "next", "indentation", "required", "current", "parent", "config", "used", "base", "processor", "same", "within", "breaks", "item", "processors", "page", "columns", "continue", "marker", "header", "true", "block", "type", "min", "indent", "blocks", "has", "continuation", "height", "when", "minimum", "structure", "this", "reset", "copy", "across", "expressed", "import"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        self.list_group_continuation(document)\n        self.list_group_indentation(document)\n", "n_tokens": 27, "byte_len": 137, "file_sha1": "9280271009bfdebb19fd54701b762581ea4aa767", "start_line": 26, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py", "rel_path": "marker/processors/list.py", "module": "marker.processors.list", "ext": "py", "chunk_number": 3, "symbols": ["list_group_continuation", "block", "type", "end", "column", "break", "none", "contained", "blocks", "check", "get", "page", "ignore", "for", "next", "else", "has", "continuation", "document", "self", "list", "group", "same", "height", "start", "types", "structure", "pages", "ignored", "continue", "__init__", "__call__", "list_group_indentation", "ListProcessor", "determine", "indentation", "required", "current", "parent", "config", "used", "base", "processor", "within", "breaks", "item", "processors", "columns", "marker", "header"], "ast_kind": "function_or_method", "text": "    def list_group_continuation(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                next_block = document.get_next_block(block, self.ignored_block_types)\n                if next_block is None:\n                    continue\n                if next_block.block_type not in self.block_types:\n                    continue\n                if next_block.structure is None:\n                    continue\n                if next_block.ignore_for_output:\n                    continue\n\n                column_break, page_break = False, False\n                next_block_in_first_quadrant = False\n\n                if next_block.page_id == block.page_id:  # block on the same page\n                    # we check for a column break\n                    column_break = next_block.polygon.y_start <= block.polygon.y_end\n                else:\n                    page_break = True\n                    next_page = document.get_page(next_block.page_id)\n                    next_block_in_first_quadrant = (next_block.polygon.x_start < next_page.polygon.width // 2) and \\\n                        (next_block.polygon.y_start < next_page.polygon.height // 2)\n\n                block.has_continuation = column_break or (page_break and next_block_in_first_quadrant)\n", "n_tokens": 251, "byte_len": 1340, "file_sha1": "9280271009bfdebb19fd54701b762581ea4aa767", "start_line": 30, "end_line": 56}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/list.py", "rel_path": "marker/processors/list.py", "module": "marker.processors.list", "ext": "py", "chunk_number": 4, "symbols": ["list_group_indentation", "block", "type", "min", "indent", "none", "contained", "blocks", "next", "list", "ignore", "for", "else", "document", "append", "self", "current", "parent", "while", "group", "line", "stack", "get", "sometimes", "remove", "structure", "start", "item", "breaks", "types", "__init__", "__call__", "list_group_continuation", "ListProcessor", "determine", "column", "break", "indentation", "required", "config", "used", "base", "processor", "same", "within", "processors", "page", "columns", "continue", "marker"], "ast_kind": "function_or_method", "text": "    def list_group_indentation(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is None:\n                    continue\n                if block.ignore_for_output:\n                    continue\n\n                stack: List[ListItem] = [block.get_next_block(page, None)]\n                for list_item_id in block.structure:\n                    list_item_block: ListItem = page.get_block(list_item_id)\n\n                    # This can be a line sometimes\n                    if list_item_block.block_type != BlockTypes.ListItem:\n                        continue\n\n                    while stack and list_item_block.polygon.x_start <= stack[-1].polygon.x_start + (self.min_x_indent * page.polygon.width):\n                        stack.pop()\n\n                    if stack and list_item_block.polygon.y_start > stack[-1].polygon.y_start:\n                        list_item_block.list_indent_level = stack[-1].list_indent_level\n                        if list_item_block.polygon.x_start > stack[-1].polygon.x_start + (self.min_x_indent * page.polygon.width):\n                            list_item_block.list_indent_level += 1\n\n                    next_list_item_block = block.get_next_block(page, list_item_block)\n                    if next_list_item_block is not None and next_list_item_block.polygon.x_start > list_item_block.polygon.x_end:\n                        stack = [next_list_item_block]  # reset stack on column breaks\n                    else:\n                        stack.append(list_item_block)\n\n                stack: List[ListItem] = [block.get_next_block(page, None)]\n                for list_item_id in block.structure.copy():\n                    list_item_block: ListItem = page.get_block(list_item_id)\n\n                    while stack and list_item_block.list_indent_level <= stack[-1].list_indent_level:\n                        stack.pop()\n\n                    if stack:\n                        current_parent = stack[-1]\n                        current_parent.add_structure(list_item_block)\n                        current_parent.polygon = current_parent.polygon.merge([list_item_block.polygon])\n\n                        block.remove_structure_items([list_item_id])\n                    stack.append(list_item_block)\n", "n_tokens": 419, "byte_len": 2354, "file_sha1": "9280271009bfdebb19fd54701b762581ea4aa767", "start_line": 57, "end_line": 101}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py", "rel_path": "marker/processors/ignoretext.py", "module": "marker.processors.ignoretext", "ext": "py", "chunk_number": 1, "symbols": ["blocks", "annotated", "document", "schema", "itertools", "from", "collections", "base", "processor", "groupby", "rapidfuzz", "list", "processors", "typing", "block", "types", "import", "marker", "counter", "fuzz", "__call__", "clean_text", "filter_common_elements", "IgnoreTextProcessor", "occurrences", "elements", "find", "start", "exceed", "raw", "text", "section", "header", "meet", "required", "filter", "mistakenly", "patterns", "return", "within", "classified", "match", "replace", "staticmethod", "inline", "this", "number", "fuzzy", "page", "rare"], "ast_kind": "imports", "text": "import re\nfrom collections import Counter\nfrom itertools import groupby\nfrom typing import Annotated, List\n\nfrom rapidfuzz import fuzz\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.schema.document import Document\n\n", "n_tokens": 58, "byte_len": 301, "file_sha1": "d8cd25166364cd23fe5dcbe7f81c6a5a026f10f0", "start_line": 1, "end_line": 13}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py", "rel_path": "marker/processors/ignoretext.py", "module": "marker.processors.ignoretext", "ext": "py", "chunk_number": 2, "symbols": ["IgnoreTextProcessor", "occurrences", "elements", "exceed", "section", "header", "document", "meet", "required", "base", "processor", "mistakenly", "patterns", "within", "classified", "text", "match", "inline", "this", "number", "fuzzy", "page", "rare", "allowed", "classify", "blocks", "stricter", "ignoring", "minimum", "similar", "__call__", "clean_text", "filter_common_elements", "find", "start", "raw", "itertools", "filter", "return", "replace", "staticmethod", "processors", "marker", "clean", "true", "call", "check", "collections", "rapidfuzz", "ensures"], "ast_kind": "class_or_type", "text": "class IgnoreTextProcessor(BaseProcessor):\n    \"\"\"\n    A processor for identifying and ignoring common text blocks in a document. \n    These blocks often represent repetitive or non-essential elements, such as headers, footers, or page numbers.\n    \"\"\"\n    block_types = (\n        BlockTypes.Text, BlockTypes.SectionHeader,\n        BlockTypes.TextInlineMath\n    )\n    common_element_threshold: Annotated[\n        float,\n        \"The minimum ratio of pages a text block must appear on to be considered a common element.\",\n        \"Blocks that meet or exceed this threshold are marked as common elements.\",\n    ] = 0.2\n    common_element_min_blocks: Annotated[\n        int,\n        \"The minimum number of occurrences of a text block within a document to consider it a common element.\",\n        \"This ensures that rare blocks are not mistakenly flagged.\",\n    ] = 3\n    max_streak: Annotated[\n        int,\n        \"The maximum number of consecutive occurrences of a text block allowed before it is classified as a common element.\",\n        \"Helps to identify patterns like repeated headers or footers.\",\n    ] = 3\n    text_match_threshold: Annotated[\n        int,\n        \"The minimum fuzzy match score (0-100) required to classify a text block as similar to a common element.\",\n        \"Higher values enforce stricter matching.\",\n    ] = 90\n", "n_tokens": 281, "byte_len": 1338, "file_sha1": "d8cd25166364cd23fe5dcbe7f81c6a5a026f10f0", "start_line": 14, "end_line": 43}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py", "rel_path": "marker/processors/ignoretext.py", "module": "marker.processors.ignoretext", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "clean_text", "remove", "start", "none", "contained", "blocks", "text", "last", "block", "document", "append", "self", "numbers", "line", "return", "first", "types", "replace", "strip", "structure", "staticmethod", "pages", "filter", "common", "page", "initial", "clean", "call", "filter_common_elements", "IgnoreTextProcessor", "occurrences", "elements", "find", "exceed", "raw", "section", "header", "meet", "itertools", "required", "base", "processor", "mistakenly", "patterns", "within", "classified", "match", "processors", "inline"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        first_blocks = []\n        last_blocks = []\n        for page in document.pages:\n            initial_block = None\n            last_block = None\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is not None:\n                    if initial_block is None:\n                        initial_block = block\n\n                    last_block = block\n\n            if initial_block is not None:\n                first_blocks.append(initial_block)\n            if last_block is not None:\n                last_blocks.append(last_block)\n\n        self.filter_common_elements(document, first_blocks)\n        self.filter_common_elements(document, last_blocks)\n\n    @staticmethod\n    def clean_text(text):\n        text = text.replace(\"\\n\", \"\").strip()\n        text = re.sub(r\"^\\d+\\s*\", \"\", text)  # remove numbers at the start of the line\n        text = re.sub(r\"\\s*\\d+$\", \"\", text)  # remove numbers at the end of the line\n        return text\n", "n_tokens": 208, "byte_len": 1033, "file_sha1": "d8cd25166364cd23fe5dcbe7f81c6a5a026f10f0", "start_line": 44, "end_line": 71}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/ignoretext.py", "rel_path": "marker/processors/ignoretext.py", "module": "marker.processors.ignoretext", "ext": "py", "chunk_number": 4, "symbols": ["filter_common_elements", "check", "find", "elements", "text", "enough", "common", "blocks", "group", "ignore", "for", "raw", "document", "self", "filter", "against", "groupby", "return", "counter", "match", "list", "element", "ratio", "max", "streak", "have", "pages", "block", "true", "streaks", "__call__", "clean_text", "IgnoreTextProcessor", "occurrences", "start", "exceed", "section", "header", "meet", "itertools", "required", "base", "processor", "mistakenly", "patterns", "within", "classified", "replace", "staticmethod", "processors"], "ast_kind": "function_or_method", "text": "    def filter_common_elements(self, document, blocks: List[Block]):\n        # We can't filter if we don't have enough pages to find common elements\n        if len(blocks) < self.common_element_min_blocks:\n            return\n\n        text = [self.clean_text(b.raw_text(document)) for b in blocks]\n\n        streaks = {}\n        for key, group in groupby(text):\n            streaks[key] = max(streaks.get(key, 0), len(list(group)))\n\n        counter = Counter(text)\n        common = [\n            k for k, v in counter.items()\n            if (v >= len(blocks) * self.common_element_threshold or streaks[k] >= self.max_streak)\n            and v > self.common_element_min_blocks\n        ]\n        if len(common) == 0:\n            return\n\n        for t, b in zip(text, blocks):\n            # Check against all common elements\n            if any(fuzz.ratio(t, common_element) > self.text_match_threshold for common_element in common):\n                b.ignore_for_output = True\n", "n_tokens": 218, "byte_len": 971, "file_sha1": "d8cd25166364cd23fe5dcbe7f81c6a5a026f10f0", "start_line": 72, "end_line": 96}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/page_header.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/page_header.py", "rel_path": "marker/processors/page_header.py", "module": "marker.processors.page_header", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "move_page_header_to_top", "PageHeaderProcessor", "remove", "class", "contained", "blocks", "move", "page", "header", "document", "schema", "headers", "self", "from", "processor", "base", "block", "types", "structure", "processors", "pages", "import", "marker", "groups", "moving", "call", "group"], "ast_kind": "class_or_type", "text": "from marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups.page import PageGroup\n\n\nclass PageHeaderProcessor(BaseProcessor):\n    \"\"\"\n    A processor for moving PageHeaders to the top\n    \"\"\"\n    block_types = (BlockTypes.PageHeader,)\n\n    def __call__(self, document: Document):\n        for page in document.pages:\n            self.move_page_header_to_top(page, document)\n\n    def move_page_header_to_top(self, page: PageGroup, document: Document):\n        page_header_blocks = page.contained_blocks(document, self.block_types)\n        page_header_block_ids = [block.id for block in page_header_blocks]\n        for block_id in page_header_block_ids:\n            page.structure.remove(block_id)\n        page.structure[:0] = page_header_block_ids\n\n", "n_tokens": 171, "byte_len": 838, "file_sha1": "435b38049e1ab60193fae9410ad858fb61e97613", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py", "rel_path": "marker/processors/util.py", "module": "marker.processors.util", "ext": "py", "chunk_number": 1, "symbols": ["escape_latex_commands", "import", "marker", "groups", "schema", "beautiful", "soup", "text", "replace", "from", "registry", "get", "block", "line", "types", "return", "escape", "latex", "page", "group", "add_math_spans_to_line", "text_to_spans", "spans", "add", "full", "elif", "none", "minimum", "position", "span", "parents", "hasattr", "parser", "corrected", "tag", "content", "font", "size", "formats", "has", "superscript", "else", "html", "append", "subscript", "maximum", "name", "bold", "href", "extraction"], "ast_kind": "function_or_method", "text": "import re\n\nfrom bs4 import BeautifulSoup\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.groups import PageGroup\nfrom marker.schema.registry import get_block_class\nfrom marker.schema.text import Line\n\n\ndef escape_latex_commands(text: str):\n    text = (text\n            .replace('\\n', '\\\\n')\n            .replace('\\t', '\\\\t')\n            .replace('\\r', '\\\\r'))\n    return text\n\n", "n_tokens": 86, "byte_len": 386, "file_sha1": "8179c807fc29a83bb32e8bafcea942b25197ccd7", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py", "rel_path": "marker/processors/util.py", "module": "marker.processors.util", "ext": "py", "chunk_number": 2, "symbols": ["add_math_spans_to_line", "text", "spans", "add", "full", "line", "minimum", "position", "span", "block", "corrected", "content", "font", "size", "formats", "has", "superscript", "append", "subscript", "maximum", "extraction", "structure", "get", "enumerate", "class", "types", "page", "type", "polygon", "math", "escape_latex_commands", "text_to_spans", "elif", "none", "parents", "hasattr", "parser", "tag", "soup", "else", "html", "schema", "from", "name", "bold", "return", "href", "replace", "attrs", "string"], "ast_kind": "function_or_method", "text": "def add_math_spans_to_line(corrected_text: str, text_line: Line, page: PageGroup):\n    SpanClass = get_block_class(BlockTypes.Span)\n    corrected_spans = text_to_spans(corrected_text)\n\n    for span_idx, span in enumerate(corrected_spans):\n        if span_idx == len(corrected_spans) - 1:\n            span['content'] += \"\\n\"\n\n        span_block = page.add_full_block(\n            SpanClass(\n                polygon=text_line.polygon,\n                text=span['content'],\n                font='Unknown',\n                font_weight=0,\n                font_size=0,\n                minimum_position=0,\n                maximum_position=0,\n                formats=[span['type']],\n                url=span.get('url'),\n                page_id=text_line.page_id,\n                text_extraction_method=\"gemini\",\n                has_superscript=span[\"has_superscript\"],\n                has_subscript=span[\"has_subscript\"]\n            )\n        )\n        text_line.structure.append(span_block.id)\n\n", "n_tokens": 208, "byte_len": 988, "file_sha1": "8179c807fc29a83bb32e8bafcea942b25197ccd7", "start_line": 19, "end_line": 46}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/util.py", "rel_path": "marker/processors/util.py", "module": "marker.processors.util", "ext": "py", "chunk_number": 3, "symbols": ["text_to_spans", "text", "spans", "elif", "none", "parents", "hasattr", "parser", "tag", "types", "soup", "content", "else", "has", "superscript", "html", "append", "subscript", "bold", "return", "href", "math", "attrs", "get", "string", "continue", "type", "italic", "escape", "latex", "escape_latex_commands", "add_math_spans_to_line", "add", "full", "line", "minimum", "position", "span", "block", "corrected", "font", "size", "formats", "schema", "from", "maximum", "name", "extraction", "replace", "structure"], "ast_kind": "function_or_method", "text": "def text_to_spans(text):\n    soup = BeautifulSoup(text, 'html.parser')\n\n    tag_types = {\n        'b': 'bold',\n        'i': 'italic',\n        'math': 'math',\n        'sub': 'plain',\n        'sup': 'plain',\n        'span': 'plain'\n    }\n    spans = []\n\n    for element in soup.descendants:\n        if not len(list(element.parents)) == 1:\n            continue\n\n        url = element.attrs.get('href') if hasattr(element, 'attrs') else None\n\n        if element.name in tag_types:\n            text = element.get_text()\n            if element.name == \"math\":\n                text = escape_latex_commands(text)\n            spans.append({\n                'type': tag_types[element.name],\n                'content': text,\n                'url': url,\n                \"has_superscript\": element.name == \"sup\",\n                \"has_subscript\": element.name == \"sub\"\n            })\n        elif element.string:\n            spans.append({\n                'type': 'plain',\n                'content': element.string,\n                'url': url,\n                \"has_superscript\": False,\n                \"has_subscript\": False\n            })\n\n    return spans", "n_tokens": 247, "byte_len": 1143, "file_sha1": "8179c807fc29a83bb32e8bafcea942b25197ccd7", "start_line": 47, "end_line": 86}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 1, "symbols": ["text", "fixer", "image", "fix", "tuple", "ocr", "result", "annotated", "recognition", "predictor", "document", "schema", "settings", "from", "base", "processor", "surya", "list", "ftfy", "math", "processors", "typing", "block", "types", "import", "marker", "beautiful", "soup", "compile", "mat", "__init__", "get_batch_size", "__call__", "fix_latex", "get_latex_batched", "EquationProcessor", "find", "process", "drop", "repeated", "equation", "blocks", "found", "config", "format", "return", "rescale", "latex", "sometimes", "unescape"], "ast_kind": "imports", "text": "from typing import Annotated, List, Tuple\nfrom PIL import Image\nimport re\nfrom bs4 import BeautifulSoup\n\nfrom ftfy import fix_text, TextFixerConfig\nfrom surya.recognition import RecognitionPredictor, OCRResult\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.settings import settings\n\nMATH_TAG_PATTERN = re.compile(r\"<math[^>]*>(.*?)</math>\")\n\n", "n_tokens": 97, "byte_len": 433, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 2, "symbols": ["EquationProcessor", "results", "class", "allow", "disable", "tqdm", "none", "equation", "processor", "text", "tuple", "model", "process", "default", "tokens", "drop", "repeated", "annotated", "batch", "progress", "document", "types", "while", "size", "whether", "base", "recognition", "block", "will", "bool", "__init__", "get_batch_size", "__call__", "fix_latex", "get_latex_batched", "find", "blocks", "found", "config", "format", "return", "rescale", "fix", "latex", "sometimes", "unescape", "html", "math", "ftfy", "page"], "ast_kind": "class_or_type", "text": "class EquationProcessor(BaseProcessor):\n    \"\"\"\n    A processor for recognizing equations in the document.\n    \"\"\"\n\n    block_types: Annotated[\n        Tuple[BlockTypes],\n        \"The block types to process.\",\n    ] = (BlockTypes.Equation,)\n    model_max_length: Annotated[\n        int,\n        \"The maximum number of tokens to allow for the Recognition model.\",\n    ] = 1024\n    equation_batch_size: Annotated[\n        int,\n        \"The batch size to use for the recognition model while processing equations.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    disable_tqdm: Annotated[\n        bool,\n        \"Whether to disable the tqdm progress bar.\",\n    ] = False\n    drop_repeated_text: Annotated[bool, \"Drop repeated text in OCR results.\"] = False\n", "n_tokens": 180, "byte_len": 802, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 17, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "get_batch_size", "elif", "init", "none", "recognition", "predictor", "equation", "batch", "self", "config", "settings", "torc", "devic", "model", "size", "return", "super", "length", "with", "get", "tiling", "sequence", "cuda", "__call__", "fix_latex", "get_latex_batched", "EquationProcessor", "find", "process", "drop", "repeated", "blocks", "document", "found", "base", "processor", "format", "rescale", "fix", "latex", "sometimes", "unescape", "html", "math", "ftfy", "page", "processors", "opening", "max"], "ast_kind": "function_or_method", "text": "    def __init__(self, recognition_model: RecognitionPredictor, config=None):\n        super().__init__(config)\n\n        self.recognition_model = recognition_model\n\n    def get_batch_size(self):\n        # Set to 1/4th of OCR batch size due to sequence length with tiling\n        if self.equation_batch_size is not None:\n            return self.equation_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 32\n        elif settings.TORCH_DEVICE_MODEL == \"mps\":\n            return 6\n        return 6\n", "n_tokens": 119, "byte_len": 526, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 41, "end_line": 55}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "bbox", "page", "image", "size", "assert", "equation", "total", "contained", "blocks", "highres", "predictions", "images", "html", "document", "append", "self", "block", "prediction", "corresponding", "height", "rescale", "return", "get", "fix", "latex", "types", "have", "should", "pages", "__init__", "get_batch_size", "fix_latex", "get_latex_batched", "EquationProcessor", "find", "process", "drop", "repeated", "found", "config", "base", "processor", "format", "sometimes", "unescape", "math", "ftfy", "processors", "opening"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        images = []\n        equation_boxes = []\n        equation_block_ids = []\n        total_equation_blocks = 0\n\n        for page in document.pages:\n            page_image = page.get_image(highres=True)\n            page_size = page.polygon.width, page.polygon.height\n            image_size = page_image.size\n\n            page_equation_boxes = []\n            page_equation_block_ids = []\n            equation_blocks = page.contained_blocks(document, self.block_types)\n            for block in equation_blocks:\n                page_equation_boxes.append(\n                    block.polygon.rescale(page_size, image_size).bbox\n                )\n                page_equation_block_ids.append(block.id)\n                total_equation_blocks += 1\n\n            images.append(page_image)\n            equation_boxes.append(page_equation_boxes)\n            equation_block_ids.append(page_equation_block_ids)\n\n        if total_equation_blocks == 0:\n            return\n\n        predictions = self.get_latex_batched(images, equation_boxes)\n        for page_predictions, page_equation_block_ids in zip(\n            predictions, equation_block_ids\n        ):\n            assert len(page_predictions) == len(page_equation_block_ids), (\n                \"Every equation block should have a corresponding prediction\"\n            )\n            for block_prediction, block_id in zip(\n                page_predictions, page_equation_block_ids\n            ):\n                block = document.get_block(block_id)\n                block.html = self.fix_latex(block_prediction)\n", "n_tokens": 298, "byte_len": 1597, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 56, "end_line": 96}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 5, "symbols": ["fix_latex", "text", "fixer", "find", "fix", "model", "parser", "soup", "force", "html", "display", "found", "self", "config", "format", "return", "sometimes", "latex", "newlines", "unescape", "math", "strip", "opening", "tags", "attrs", "beginning", "outputs", "fixed", "beautiful", "block", "__init__", "get_batch_size", "__call__", "get_latex_batched", "EquationProcessor", "process", "drop", "repeated", "equation", "blocks", "document", "base", "processor", "rescale", "ftfy", "page", "processors", "max", "sliding", "default"], "ast_kind": "function_or_method", "text": "    def fix_latex(self, math_html: str):\n        math_html = math_html.strip()\n        soup = BeautifulSoup(math_html, \"html.parser\")\n        opening_math_tag = soup.find(\"math\")\n\n        # No math block found\n        if not opening_math_tag:\n            return \"\"\n\n        # Force block format\n        opening_math_tag.attrs[\"display\"] = \"block\"\n        fixed_math_html = str(soup)\n\n        # Sometimes model outputs newlines at the beginning/end of tags\n        fixed_math_html = re.sub(\n            r\"^<math display=\\\"block\\\">\\\\n(?![a-zA-Z])\",\n            '<math display=\"block\">',\n            fixed_math_html,\n        )\n        fixed_math_html = re.sub(r\"\\\\n</math>$\", \"</math>\", fixed_math_html)\n        fixed_math_html = re.sub(r\"<br>\", \"\", fixed_math_html)\n        fixed_math_html = fix_text(\n            fixed_math_html, config=TextFixerConfig(unescape_html=True)\n        )\n        return fixed_math_html\n", "n_tokens": 210, "byte_len": 913, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 97, "end_line": 122}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/equation.py", "rel_path": "marker/processors/equation.py", "module": "marker.processors.equation", "ext": "py", "chunk_number": 6, "symbols": ["get_latex_batched", "image", "disable", "tqdm", "text", "float", "ocr", "result", "page", "prediction", "predictions", "drop", "repeated", "images", "lines", "self", "line", "max", "tokens", "recognition", "model", "return", "batch", "sort", "list", "equation", "with", "strip", "sliding", "get", "__init__", "get_batch_size", "__call__", "fix_latex", "EquationProcessor", "find", "process", "blocks", "document", "found", "config", "base", "processor", "format", "rescale", "fix", "latex", "sometimes", "unescape", "html"], "ast_kind": "function_or_method", "text": "    def get_latex_batched(\n        self,\n        page_images: List[Image.Image],\n        bboxes: List[List[List[float]]],\n    ):\n        self.recognition_model.disable_tqdm = self.disable_tqdm\n        predictions: List[OCRResult] = self.recognition_model(\n            images=page_images,\n            bboxes=bboxes,\n            task_names=[\"ocr_with_boxes\"] * len(page_images),\n            recognition_batch_size=self.get_batch_size(),\n            sort_lines=False,\n            drop_repeated_text=self.drop_repeated_text,\n            max_tokens=2048,\n            max_sliding_window=2148,\n        )\n\n        equation_predictions = [\n            [line.text.strip() for line in page_prediction.text_lines]\n            for page_prediction in predictions\n        ]\n\n        return equation_predictions\n", "n_tokens": 163, "byte_len": 796, "file_sha1": "93b288dd3d0a743ca6e3463b2decaeb0002f992a", "start_line": 123, "end_line": 146}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/order.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/order.py", "rel_path": "marker/processors/order.py", "module": "marker.processors.order", "ext": "py", "chunk_number": 1, "symbols": ["OrderProcessor", "class", "blocks", "statistics", "image", "document", "schema", "from", "layout", "collections", "processor", "base", "mean", "when", "order", "help", "block", "types", "processors", "this", "needed", "import", "marker", "defaultdict", "sorting", "tuple", "sliced", "__call__", "elif", "already", "contained", "minimum", "position", "skip", "idx", "next", "else", "assigned", "self", "spans", "while", "span", "maximum", "get", "idxs", "text", "extraction", "sorted", "red", "ocred"], "ast_kind": "class_or_type", "text": "from statistics import mean\nfrom collections import defaultdict\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n\nclass OrderProcessor(BaseProcessor):\n    \"\"\"\n    A processor for sorting the blocks in order if needed.  This can help when the layout image was sliced.\n    \"\"\"\n    block_types = tuple()\n", "n_tokens": 71, "byte_len": 379, "file_sha1": "a2e1877813a0806eaff3eff882b419d5a6e7e175", "start_line": 1, "end_line": 14}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/order.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/order.py", "rel_path": "marker/processors/order.py", "module": "marker.processors.order", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "elif", "layout", "sliced", "already", "contained", "blocks", "minimum", "position", "skip", "block", "idx", "next", "else", "assigned", "document", "self", "spans", "while", "span", "maximum", "get", "idxs", "sorted", "text", "extraction", "red", "ocred", "original", "structure", "OrderProcessor", "class", "statistics", "image", "schema", "from", "collections", "processor", "base", "mean", "when", "order", "help", "types", "processors", "this", "needed", "pages", "prev", "continue"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        for page in document.pages:\n            # Skip OCRed pages\n            if page.text_extraction_method != \"pdftext\":\n                continue\n\n            # Skip pages without layout slicing\n            if not page.layout_sliced:\n                continue\n\n            block_idxs = defaultdict(int)\n            for block_id in page.structure:\n                block = document.get_block(block_id)\n                spans = block.contained_blocks(document, (BlockTypes.Span, ))\n                if len(spans) == 0:\n                    continue\n\n                # Avg span position in original PDF\n                block_idxs[block_id] = (spans[0].minimum_position + spans[-1].maximum_position) / 2\n\n            for block_id in page.structure:\n                # Already assigned block id via span position\n                if block_idxs[block_id] > 0:\n                    continue\n\n                block = document.get_block(block_id)\n                prev_block = document.get_prev_block(block)\n                next_block = document.get_next_block(block)\n\n                block_idx_add = 0\n                if prev_block:\n                    block_idx_add = 1\n\n                while prev_block and prev_block.id not in block_idxs:\n                    prev_block = document.get_prev_block(prev_block)\n                    block_idx_add += 1\n\n                if not prev_block:\n                    block_idx_add = -1\n                    while next_block and next_block.id not in block_idxs:\n                        next_block = document.get_next_block(next_block)\n                        block_idx_add -= 1\n\n                if not next_block and not prev_block:\n                    pass\n                elif prev_block:\n                    block_idxs[block_id] = block_idxs[prev_block.id] + block_idx_add\n                else:\n                    block_idxs[block_id] = block_idxs[next_block.id] + block_idx_add\n\n            page.structure = sorted(page.structure, key=lambda x: block_idxs[x])\n\n", "n_tokens": 381, "byte_len": 2033, "file_sha1": "a2e1877813a0806eaff3eff882b419d5a6e7e175", "start_line": 15, "end_line": 67}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/code.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/code.py", "rel_path": "marker/processors/code.py", "module": "marker.processors.code", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "CodeProcessor", "class", "contained", "blocks", "formatting", "document", "schema", "self", "from", "code", "processor", "base", "format", "block", "types", "processors", "pages", "import", "marker", "page", "call", "format_block", "lines", "bbox", "coord", "text", "line", "contain", "else", "raw", "total", "spaces", "prefix", "chars", "rstrip", "min", "left", "new", "endswith", "will", "width", "avg", "char", "polygon", "false", "column"], "ast_kind": "class_or_type", "text": "from marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Code\nfrom marker.schema.document import Document\n\n\nclass CodeProcessor(BaseProcessor):\n    \"\"\"\n    A processor for formatting code blocks.\n    \"\"\"\n    block_types = (BlockTypes.Code, )\n\n    def __call__(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                self.format_block(document, block)\n\n", "n_tokens": 97, "byte_len": 508, "file_sha1": "efc87f0c3e8ab34d1831fe45fd282e73e7629243", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/code.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/code.py", "rel_path": "marker/processors/code.py", "module": "marker.processors.code", "ext": "py", "chunk_number": 2, "symbols": ["format_block", "contained", "lines", "bbox", "coord", "text", "blocks", "line", "contain", "else", "raw", "total", "spaces", "document", "self", "prefix", "chars", "format", "block", "code", "rstrip", "min", "left", "types", "new", "endswith", "will", "width", "avg", "char", "__call__", "CodeProcessor", "class", "formatting", "schema", "from", "processor", "base", "processors", "pages", "import", "marker", "polygon", "false", "column", "page", "call"], "ast_kind": "function_or_method", "text": "    def format_block(self, document: Document, block: Code):\n        min_left = 9999  # will contain x- coord of column 0\n        total_width = 0\n        total_chars = 0\n        \n        contained_lines = block.contained_blocks(document, (BlockTypes.Line,))\n        for line in contained_lines:\n            min_left = min(line.polygon.bbox[0], min_left)\n            total_width += line.polygon.width\n            total_chars += len(line.raw_text(document))\n\n        avg_char_width = total_width / max(total_chars, 1)\n        code_text = \"\"\n        is_new_line = False\n        for line in contained_lines:\n            text = line.raw_text(document)\n            if avg_char_width == 0:\n                prefix = \"\"\n            else:\n                total_spaces = int((line.polygon.bbox[0] - min_left) / avg_char_width)\n                prefix = \" \" * max(0, total_spaces)\n\n            if is_new_line:\n                text = prefix + text\n\n            code_text += text\n            is_new_line = text.endswith(\"\\n\")\n\n        block.code = code_text.rstrip()\n", "n_tokens": 235, "byte_len": 1052, "file_sha1": "efc87f0c3e8ab34d1831fe45fd282e73e7629243", "start_line": 19, "end_line": 48}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/__init__.py", "rel_path": "marker/processors/__init__.py", "module": "marker.processors.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "__call__", "BaseProcessor", "args", "class", "init", "assign", "config", "none", "tuple", "pydantic", "document", "schema", "self", "types", "from", "dict", "processor", "base", "kwargs", "not", "implemented", "model", "block", "what", "typing", "optional", "raise", "import", "marker", "util", "this", "responsible", "call"], "ast_kind": "class_or_type", "text": "from typing import Optional, Tuple\n\nfrom pydantic import BaseModel\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.util import assign_config\n\n\nclass BaseProcessor:\n    block_types: Tuple[BlockTypes] | None = None  # What block types this processor is responsible for\n\n    def __init__(self, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n\n    def __call__(self, document: Document, *args, **kwargs):\n        raise NotImplementedError\n", "n_tokens": 110, "byte_len": 513, "file_sha1": "5fd83fe09dd2fc3c6a6fc996aab448025375e1ac", "start_line": 1, "end_line": 18}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/document_toc.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/document_toc.py", "rel_path": "marker/processors/document_toc.py", "module": "marker.processors.document_toc", "ext": "py", "chunk_number": 1, "symbols": ["__call__", "DocumentTOCProcessor", "class", "contained", "blocks", "table", "contents", "document", "toc", "generating", "raw", "text", "section", "header", "schema", "self", "append", "from", "processor", "base", "block", "types", "strip", "processors", "pages", "page", "heading", "level", "import", "marker", "polygon", "title", "call"], "ast_kind": "class_or_type", "text": "from marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n\nclass DocumentTOCProcessor(BaseProcessor):\n    \"\"\"\n    A processor for generating a table of contents for the document.\n    \"\"\"\n    block_types = (BlockTypes.SectionHeader, )\n\n    def __call__(self, document: Document):\n        toc = []\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                toc.append({\n                    \"title\": block.raw_text(document).strip(),\n                    \"heading_level\": block.heading_level,\n                    \"page_id\": page.page_id,\n                    \"polygon\": block.polygon.polygon\n                })\n        document.table_of_contents = toc\n", "n_tokens": 147, "byte_len": 784, "file_sha1": "1d505e9e81d486a0d9f7a2fe1b4898f39ca6a247", "start_line": 1, "end_line": 23}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py", "rel_path": "marker/processors/block_relabel.py", "module": "marker.processors.block_relabel", "ext": "py", "chunk_number": 1, "symbols": ["BlockRelabelProcessor", "class", "certain", "based", "rules", "heuristically", "blocks", "get", "logger", "rule", "comma", "annotated", "label", "block", "relabel", "confidence", "threshold", "document", "schema", "from", "original", "table", "processor", "base", "format", "new", "maps", "relabeling", "exceeds", "when", "__init__", "__call__", "exception", "failed", "config", "relabelled", "return", "except", "processors", "page", "string", "continue", "source", "marker", "each", "relabeled", "replace", "call", "type", "split"], "ast_kind": "class_or_type", "text": "from copy import deepcopy\nfrom typing import Annotated\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import BlockId\nfrom marker.schema.document import Document\nfrom marker.schema.registry import get_block_class\n\nfrom marker.logger import get_logger\nlogger = get_logger()\n\nclass BlockRelabelProcessor(BaseProcessor):\n    \"\"\"\n    A processor to heuristically relabel blocks based on a confidence threshold.\n    \n    Each rule in the relabel string maps an original block label to a new one\n    if the confidence exceeds a given threshold.\n    \"\"\"\n    \n    block_relabel_str: Annotated[\n        str,\n        \"Comma-separated relabeling rules in the format '<original_label>:<new_label>:<confidence_threshold>'.\",\n        \"Each rule defines how blocks of a certain type should be relabeled when the confidence exceeds the threshold.\",\n        \"Example: 'Table:Picture:0.85,Form:Picture:0.9'\"\n    ] = \"\"\n", "n_tokens": 203, "byte_len": 961, "file_sha1": "b0fcceafc455f6f63cae8877e31a1cbd038289a5", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py", "rel_path": "marker/processors/block_relabel.py", "module": "marker.processors.block_relabel", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "block", "type", "exception", "split", "parse", "init", "failed", "none", "skip", "float", "rule", "expected", "relabel", "confidence", "str", "threshold", "thresh", "self", "config", "label", "original", "segments", "format", "new", "return", "super", "except", "strip", "enumerate", "__call__", "BlockRelabelProcessor", "based", "comma", "document", "base", "processor", "relabelled", "exceeds", "processors", "page", "string", "continue", "source", "marker", "each", "relabeled", "replace", "call", "certain"], "ast_kind": "function_or_method", "text": "    def __init__(self, config=None):\n        super().__init__(config)\n        self.block_relabel_map = {}\n\n        if not self.block_relabel_str:\n            return\n\n        for i, block_config_str in enumerate(self.block_relabel_str.split(',')):\n            block_config_str = block_config_str.strip()\n            if not block_config_str:\n                continue  # Skip empty segments\n\n            try:\n                parts = block_config_str.split(':')\n                if len(parts) != 3:\n                    raise ValueError(f\"Expected 3 parts, got {len(parts)}\")\n\n                block_label, block_relabel, confidence_str = parts\n                confidence_thresh = float(confidence_str)\n\n                block_type = BlockTypes[block_label]\n                relabel_block_type = BlockTypes[block_relabel]\n\n                self.block_relabel_map[block_type] = (\n                    confidence_thresh,\n                    relabel_block_type\n                )\n            except Exception as e:\n                logger.warning(f\"Failed to parse relabel rule '{block_config_str}' at index {i}: {e}. Expected format is <original_label>:<new_label>:<confidence_threshold>\")\n", "n_tokens": 227, "byte_len": 1175, "file_sha1": "b0fcceafc455f6f63cae8877e31a1cbd038289a5", "start_line": 28, "end_line": 57}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/block_relabel.py", "rel_path": "marker/processors/block_relabel.py", "module": "marker.processors.block_relabel", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "block", "type", "skipping", "new", "relabel", "metadata", "heuristics", "document", "confidence", "thresh", "self", "relabelled", "return", "text", "extraction", "structure", "threshold", "get", "blockid", "top", "pages", "page", "deepcopy", "logger", "continue", "source", "blocks", "polygon", "debug", "__init__", "BlockRelabelProcessor", "exception", "failed", "based", "comma", "config", "label", "base", "processor", "format", "exceeds", "except", "processors", "string", "marker", "each", "relabeled", "replace", "call"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        if len(self.block_relabel_map) == 0:\n            return\n\n        for page in document.pages:\n            for block in page.structure_blocks(document):\n                if block.block_type not in self.block_relabel_map:\n                    continue\n                \n                block_id = BlockId(page_id=page.page_id, block_id=block.block_id, block_type=block.block_type)\n                confidence_thresh, relabel_block_type = self.block_relabel_map[block.block_type]\n                confidence = block.top_k.get(block.block_type)\n                if confidence > confidence_thresh:\n                    logger.debug(f\"Skipping relabel for {block_id}; Confidence: {confidence} > Confidence Threshold {confidence_thresh} for re-labelling\")\n                    continue\n\n                new_block_cls = get_block_class(relabel_block_type)\n                new_block = new_block_cls(\n                    polygon=deepcopy(block.polygon),\n                    page_id=block.page_id,\n                    structure=deepcopy(block.structure),\n                    text_extraction_method=block.text_extraction_method,\n                    source=\"heuristics\",\n                    top_k=block.top_k,\n                    metadata=block.metadata\n                )\n                page.replace_block(block, new_block)\n                logger.debug(f\"Relabelled {block_id} to {relabel_block_type}\")", "n_tokens": 263, "byte_len": 1433, "file_sha1": "b0fcceafc455f6f63cae8877e31a1cbd038289a5", "start_line": 58, "end_line": 85}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 1, "symbols": ["DebugProcessor", "debug", "pdf", "image", "class", "debugging", "data", "process", "get", "logger", "images", "annotated", "font", "document", "schema", "json", "types", "settings", "from", "draw", "dump", "whether", "layout", "processor", "base", "folder", "block", "processors", "typing", "default", "__call__", "draw_pdf_debug_images", "draw_layout_debug_images", "render_layout_boxes", "dump_block_debug_data", "get_text_size", "render_on_image", "black", "truetype", "text", "position", "raw", "doc", "exclude", "labels", "lowres", "model", "path", "rescale", "return"], "ast_kind": "class_or_type", "text": "import json\nimport os\nfrom typing import Annotated\n\nfrom PIL import Image, ImageDraw, ImageFont\nfrom marker.logger import get_logger\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.settings import settings\n\nlogger = get_logger()\n\n\nclass DebugProcessor(BaseProcessor):\n    \"\"\"\n    A processor for debugging the document.\n    \"\"\"\n\n    block_types: Annotated[\n        tuple, \"The block types to process.\", \"Default is an empty tuple.\"\n    ] = tuple()\n    debug_data_folder: Annotated[\n        str,\n        \"The folder to dump debug data to.\",\n    ] = \"debug_data\"\n    debug_layout_images: Annotated[\n        bool,\n        \"Whether to dump layout debug images.\",\n    ] = False\n    debug_pdf_images: Annotated[\n        bool,\n        \"Whether to dump PDF debug images.\",\n    ] = False\n    debug_json: Annotated[\n        bool,\n        \"Whether to dump block debug data.\",\n    ] = False\n", "n_tokens": 212, "byte_len": 969, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 1, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "debug", "pdf", "remove", "data", "images", "doc", "base", "draw", "document", "json", "self", "dump", "block", "from", "layout", "path", "exist", "folder", "info", "filepath", "extension", "makedirs", "logger", "dumped", "rsplit", "join", "true", "call", "name", "draw_pdf_debug_images", "draw_layout_debug_images", "render_layout_boxes", "dump_block_debug_data", "get_text_size", "render_on_image", "DebugProcessor", "black", "truetype", "process", "text", "position", "get", "image", "raw", "font", "exclude", "labels", "lowres", "model"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        # Remove extension from doc name\n        doc_base = os.path.basename(document.filepath).rsplit(\".\", 1)[0]\n        self.debug_folder = os.path.join(self.debug_data_folder, doc_base)\n        if any([self.debug_layout_images, self.debug_pdf_images, self.debug_json]):\n            os.makedirs(self.debug_folder, exist_ok=True)\n\n        document.debug_data_path = self.debug_folder\n\n        if self.debug_layout_images:\n            self.draw_layout_debug_images(document)\n            logger.info(f\"Dumped layout debug images to {self.debug_data_folder}\")\n\n        if self.debug_pdf_images:\n            self.draw_pdf_debug_images(document)\n            logger.info(f\"Dumped PDF debug images to {self.debug_data_folder}\")\n\n        if self.debug_json:\n            self.dump_block_debug_data(document)\n            logger.info(f\"Dumped block debug data to {self.debug_data_folder}\")\n", "n_tokens": 188, "byte_len": 924, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 41, "end_line": 61}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 3, "symbols": ["draw_pdf_debug_images", "block", "type", "bbox", "elif", "highres", "span", "bboxes", "skip", "save", "line", "ids", "blocks", "debug", "file", "color", "render", "layout", "draw", "pdf", "document", "append", "self", "labels", "size", "path", "folder", "rescale", "children", "label", "__call__", "draw_layout_debug_images", "render_layout_boxes", "dump_block_debug_data", "get_text_size", "render_on_image", "DebugProcessor", "black", "truetype", "process", "text", "position", "get", "image", "raw", "font", "doc", "base", "json", "exclude"], "ast_kind": "function_or_method", "text": "    def draw_pdf_debug_images(self, document: Document):\n        for page in document.pages:\n            png_image = page.get_image(highres=True).copy()\n\n            line_bboxes = []\n            span_bboxes = []\n            line_ids = []\n            for child in page.children:\n                # Skip any blocks that have been removed\n                if child.removed:\n                    continue\n\n                if child.block_type == BlockTypes.Line:\n                    bbox = child.polygon.rescale(page.polygon.size, png_image.size).bbox\n                    line_bboxes.append(bbox)\n                    line_ids.append(child.block_id)\n                elif child.block_type == BlockTypes.Span:\n                    bbox = child.polygon.rescale(page.polygon.size, png_image.size).bbox\n                    span_bboxes.append(bbox)\n\n            self.render_on_image(\n                line_bboxes,\n                png_image,\n                color=\"blue\",\n                draw_bbox=True,\n                label_font_size=24,\n                labels=[str(i) for i in line_ids],\n            )\n\n            png_image = self.render_layout_boxes(page, png_image)\n\n            debug_file = os.path.join(self.debug_folder, f\"pdf_page_{page.page_id}.png\")\n            png_image.save(debug_file)\n", "n_tokens": 243, "byte_len": 1283, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 62, "end_line": 95}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 4, "symbols": ["draw_layout_debug_images", "block", "type", "image", "bbox", "black", "highres", "save", "line", "debug", "file", "color", "raw", "text", "render", "layout", "page", "document", "append", "self", "labels", "size", "path", "folder", "rescale", "bboxes", "children", "label", "font", "draw", "__call__", "draw_pdf_debug_images", "render_layout_boxes", "dump_block_debug_data", "get_text_size", "render_on_image", "DebugProcessor", "truetype", "process", "position", "get", "doc", "base", "pdf", "json", "exclude", "lowres", "model", "dump", "processor"], "ast_kind": "function_or_method", "text": "    def draw_layout_debug_images(self, document: Document, pdf_mode=False):\n        for page in document.pages:\n            img_size = page.get_image(highres=True).size\n            png_image = Image.new(\"RGB\", img_size, color=\"white\")\n\n            line_bboxes = []\n            line_text = []\n            for child in page.children:\n                if child.removed:\n                    continue\n\n                if child.block_type != BlockTypes.Line:\n                    continue\n\n                bbox = child.polygon.rescale(page.polygon.size, img_size).bbox\n                line_bboxes.append(bbox)\n                line_text.append(child.raw_text(document))\n\n            self.render_on_image(\n                line_bboxes,\n                png_image,\n                labels=line_text,\n                color=\"black\",\n                draw_bbox=False,\n                label_font_size=24,\n            )\n\n            png_image = self.render_layout_boxes(page, png_image)\n\n            debug_file = os.path.join(\n                self.debug_folder, f\"layout_page_{page.page_id}.png\"\n            )\n            png_image.save(debug_file)\n", "n_tokens": 211, "byte_len": 1129, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 96, "end_line": 129}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 5, "symbols": ["render_layout_boxes", "block", "type", "bbox", "line", "range", "green", "color", "render", "layout", "append", "self", "labels", "span", "size", "label", "offset", "rescale", "get", "return", "bboxes", "font", "draw", "structure", "types", "continue", "image", "child", "polygon", "png", "__call__", "draw_pdf_debug_images", "draw_layout_debug_images", "dump_block_debug_data", "get_text_size", "render_on_image", "DebugProcessor", "black", "truetype", "process", "text", "position", "raw", "doc", "base", "pdf", "document", "debug", "json", "exclude"], "ast_kind": "function_or_method", "text": "    def render_layout_boxes(self, page, png_image):\n        layout_bboxes = []\n        layout_labels = []\n        for block_id in page.structure:\n            child = page.get_block(block_id)\n            if child.block_type in [BlockTypes.Line, BlockTypes.Span]:\n                continue\n\n            bbox = child.polygon.rescale(page.polygon.size, png_image.size).bbox\n            layout_bboxes.append(bbox)\n            layout_labels.append(str(child.block_type))\n\n        self.render_on_image(\n            layout_bboxes,\n            png_image,\n            labels=layout_labels,\n            color=\"red\",\n            label_font_size=24,\n        )\n\n        order_labels = [str(i) for i in range(len(layout_bboxes))]\n        self.render_on_image(\n            layout_bboxes,\n            png_image,\n            labels=order_labels,\n            color=\"green\",\n            draw_bbox=False,\n            label_offset=5,\n            label_font_size=24,\n        )\n        return png_image\n", "n_tokens": 196, "byte_len": 978, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 130, "end_line": 161}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 6, "symbols": ["dump_block_debug_data", "get_text_size", "image", "text", "draw", "mode", "all", "blocks", "get", "debug", "file", "textbbox", "dump", "block", "document", "append", "self", "exclude", "lowres", "model", "path", "size", "data", "folder", "height", "return", "children", "highres", "json", "open", "__call__", "draw_pdf_debug_images", "draw_layout_debug_images", "render_layout_boxes", "render_on_image", "DebugProcessor", "black", "truetype", "process", "position", "raw", "font", "doc", "base", "pdf", "labels", "processor", "rescale", "label", "filepath"], "ast_kind": "function_or_method", "text": "    def dump_block_debug_data(self, document: Document):\n        debug_file = os.path.join(self.debug_folder, \"blocks.json\")\n        debug_data = []\n        for page in document.pages:\n            page_data = page.model_dump(\n                exclude={\n                    \"lowres_image\": True,\n                    \"highres_image\": True,\n                    \"children\": {\n                        \"__all__\": {\"lowres_image\": True, \"highres_image\": True}\n                    },\n                }\n            )\n            debug_data.append(page_data)\n\n        with open(debug_file, \"w+\") as f:\n            json.dump(debug_data, f)\n\n    def get_text_size(self, text, font):\n        im = Image.new(mode=\"P\", size=(0, 0))\n        draw = ImageDraw.Draw(im)\n        _, _, width, height = draw.textbbox((0, 0), text=text, font=font)\n        return width, height\n", "n_tokens": 187, "byte_len": 853, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 162, "end_line": 185}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/debug.py", "rel_path": "marker/processors/debug.py", "module": "marker.processors.debug", "ext": "py", "chunk_number": 7, "symbols": ["render_on_image", "bbox", "rectangle", "none", "text", "truetype", "draw", "position", "get", "image", "color", "fon", "path", "else", "font", "label", "self", "settings", "labels", "offset", "return", "box", "fill", "outline", "enumerate", "white", "continue", "render", "width", "size", "__call__", "draw_pdf_debug_images", "draw_layout_debug_images", "render_layout_boxes", "dump_block_debug_data", "get_text_size", "DebugProcessor", "black", "process", "raw", "doc", "base", "pdf", "document", "debug", "json", "exclude", "lowres", "model", "dump"], "ast_kind": "function_or_method", "text": "    def render_on_image(\n        self,\n        bboxes,\n        image,\n        labels=None,\n        label_offset=1,\n        label_font_size=10,\n        color: str | list = \"red\",\n        draw_bbox=True,\n    ):\n        draw = ImageDraw.Draw(image)\n        font_path = settings.FONT_PATH\n        label_font = ImageFont.truetype(font_path, label_font_size)\n\n        for i, bbox in enumerate(bboxes):\n            bbox = [int(p) for p in bbox]\n            if draw_bbox:\n                draw.rectangle(\n                    bbox,\n                    outline=color[i] if isinstance(color, list) else color,\n                    width=1,\n                )\n\n            if labels is not None:\n                label = labels[i]\n                text_position = (bbox[0] + label_offset, bbox[1] + label_offset)\n                text_size = self.get_text_size(label, label_font)\n                if text_size[0] <= 0 or text_size[1] <= 0:\n                    continue\n                box_position = (\n                    text_position[0],\n                    text_position[1],\n                    text_position[0] + text_size[0],\n                    text_position[1] + text_size[1],\n                )\n                draw.rectangle(box_position, fill=\"white\")\n                draw.text(\n                    text_position,\n                    label,\n                    fill=color[i] if isinstance(color, list) else color,\n                    font=label_font,\n                )\n\n        return image\n", "n_tokens": 295, "byte_len": 1481, "file_sha1": "7744331928d23426148a41b3659b94656b89b342", "start_line": 186, "end_line": 230}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/text.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/text.py", "rel_path": "marker/processors/text.py", "module": "marker.processors.text", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "TextProcessor", "class", "init", "text", "float", "line", "break", "annotated", "merging", "document", "schema", "column", "gap", "self", "config", "from", "processor", "base", "super", "list", "minimum", "math", "block", "types", "ratio", "processors", "typing", "across", "pages", "__call__", "indentation", "raw", "found", "same", "lines", "page", "columns", "continue", "inline", "marker", "skip", "dotall", "header", "true", "match", "call", "type", "blocks", "ceil"], "ast_kind": "class_or_type", "text": "import math\nfrom typing import Annotated, List\n\nimport regex\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.text.line import Line\n\n\nclass TextProcessor(BaseProcessor):\n    \"\"\"\n    A processor for merging text across pages and columns.\n    \"\"\"\n\n    block_types = (BlockTypes.Text, BlockTypes.TextInlineMath)\n    ignored_block_types = (BlockTypes.PageHeader, BlockTypes.PageFooter)\n    column_gap_ratio: Annotated[\n        float,\n        \"The minimum ratio of the page width to the column gap to consider a column break.\",\n    ] = 0.02\n\n    def __init__(self, config):\n        super().__init__(config)\n", "n_tokens": 150, "byte_len": 698, "file_sha1": "4913f188098608dd44768f054fb3632c8420a76c", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/text.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/text.py", "rel_path": "marker/processors/text.py", "module": "marker.processors.text", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "block", "type", "column", "break", "none", "contained", "blocks", "text", "floor", "check", "skip", "line", "ceil", "get", "page", "ignore", "for", "next", "max", "else", "indentation", "raw", "has", "continuation", "ignored", "document", "found", "self", "gap", "__init__", "TextProcessor", "config", "base", "processor", "same", "processors", "lines", "columns", "continue", "inline", "marker", "dotall", "header", "true", "match", "call", "height", "min", "minimum"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is None:\n                    continue\n\n                if not len(block.structure) >= 2:  # Skip single lines\n                    continue\n\n                next_block = document.get_next_block(block, self.ignored_block_types)\n                if next_block is None:  # we've reached the end of the document\n                    continue\n                if next_block.block_type not in self.block_types:\n                    continue  # we found a non-text block\n                if next_block.structure is None:\n                    continue  # This is odd though, why do we have text blocks with no structure?\n                if next_block.ignore_for_output:\n                    continue  # skip ignored blocks\n\n                column_gap = block.polygon.width * self.column_gap_ratio\n\n                column_break, page_break = False, False\n                next_block_starts_indented = True\n                next_block_in_first_quadrant = False\n                last_line_is_full_width = False\n                last_line_is_hyphentated = False\n\n                if next_block.page_id == block.page_id:  # block on the same page\n                    # we check for a column break\n                    column_break = math.floor(next_block.polygon.y_start) <= math.ceil(\n                        block.polygon.y_start\n                    ) and next_block.polygon.x_start > (\n                        block.polygon.x_end + column_gap\n                    )\n                else:\n                    page_break = True\n                    next_page = document.get_page(next_block.page_id)\n                    next_block_in_first_quadrant = (\n                        next_block.polygon.x_start < next_page.polygon.width // 2\n                    ) and (next_block.polygon.y_start < next_page.polygon.height // 2)\n\n                if not (column_break or page_break):\n                    continue\n\n                new_block_lines = next_block.structure_blocks(document)\n\n                # we check for next_block indentation\n                if len(new_block_lines):\n                    min_x = math.ceil(\n                        min([line.polygon.x_start for line in new_block_lines])\n                    )\n                    next_block_starts_indented = (\n                        new_block_lines[0].polygon.x_start > min_x\n                    )\n\n                lines: List[Line] = [\n                    line\n                    for line in block.structure_blocks(document)\n                    if line.polygon.width > 1\n                ]\n                if len(lines):\n                    max_x = math.floor(max([line.polygon.x_end for line in lines]))\n                    last_line_is_full_width = lines[-1].polygon.x_end >= max_x\n\n                    last_line_is_hyphentated = regex.compile(\n                        r\".*[\\p{Ll}|\\d][-]\\s?$\", regex.DOTALL\n                    ).match(lines[-1].raw_text(document).strip())\n\n                if (\n                    (last_line_is_full_width or last_line_is_hyphentated)\n                    and not next_block_starts_indented\n                    and ((next_block_in_first_quadrant and page_break) or column_break)\n                ):\n                    block.has_continuation = True\n", "n_tokens": 643, "byte_len": 3408, "file_sha1": "4913f188098608dd44768f054fb3632c8420a76c", "start_line": 27, "end_line": 101}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py", "rel_path": "marker/processors/blockquote.py", "module": "marker.processors.blockquote", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "import", "document", "marker", "schema", "tuple", "from", "processors", "typing", "base", "processor", "block", "types", "__init__", "__call__", "BlockquoteProcessor", "consecutive", "type", "end", "elif", "class", "init", "min", "indent", "percentage", "contained", "blocks", "none", "process", "float", "ending", "expressed", "aligned", "tagging", "tolerance", "ignore", "for", "between", "next", "indentation", "start", "required", "self", "config", "allowable", "blockquote", "coordinates", "super", "call", "matching"], "ast_kind": "imports", "text": "from typing import Annotated, Tuple\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n", "n_tokens": 30, "byte_len": 163, "file_sha1": "4cf562eab97344158bf346fcfcbb5468dae45c08", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py", "rel_path": "marker/processors/blockquote.py", "module": "marker.processors.blockquote", "ext": "py", "chunk_number": 2, "symbols": ["BlockquoteProcessor", "consecutive", "class", "min", "indent", "percentage", "tuple", "process", "float", "blocks", "ending", "expressed", "aligned", "tagging", "end", "tolerance", "between", "annotated", "indentation", "required", "types", "start", "processor", "base", "allowable", "blockquote", "coordinates", "minimum", "block", "text", "__init__", "__call__", "type", "elif", "init", "contained", "none", "ignore", "for", "next", "document", "schema", "self", "config", "from", "super", "call", "matching", "structure", "processors"], "ast_kind": "class_or_type", "text": "class BlockquoteProcessor(BaseProcessor):\n    \"\"\"\n    A processor for tagging blockquotes.\n    \"\"\"\n    block_types: Annotated[\n        Tuple[BlockTypes],\n        \"The block types to process.\",\n    ] = (BlockTypes.Text, BlockTypes.TextInlineMath)\n    min_x_indent: Annotated[\n        float,\n        \"The minimum horizontal indentation required to consider a block as part of a blockquote.\",\n        \"Expressed as a percentage of the block width.\",\n    ] = 0.1\n    x_start_tolerance: Annotated[\n        float,\n        \"The maximum allowable difference between the starting x-coordinates of consecutive blocks to consider them aligned.\",\n        \"Expressed as a percentage of the block width.\",\n    ] = 0.01\n    x_end_tolerance: Annotated[\n        float,\n        \"The maximum allowable difference between the ending x-coordinates of consecutive blocks to consider them aligned.\",\n        \"Expressed as a percentage of the block width.\",\n    ] = 0.01\n", "n_tokens": 205, "byte_len": 947, "file_sha1": "4cf562eab97344158bf346fcfcbb5468dae45c08", "start_line": 8, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py", "rel_path": "marker/processors/blockquote.py", "module": "marker.processors.blockquote", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "self", "config", "init", "super", "__call__", "BlockquoteProcessor", "consecutive", "block", "type", "end", "elif", "class", "min", "indent", "percentage", "contained", "blocks", "none", "tuple", "process", "float", "ending", "expressed", "aligned", "tagging", "tolerance", "ignore", "for", "between", "next", "annotated", "indentation", "start", "document", "schema", "required", "types", "from", "processor", "base", "allowable", "blockquote", "coordinates", "call", "matching", "minimum", "text", "structure", "processors"], "ast_kind": "function_or_method", "text": "    def __init__(self, config):\n        super().__init__(config)\n", "n_tokens": 16, "byte_len": 65, "file_sha1": "4cf562eab97344158bf346fcfcbb5468dae45c08", "start_line": 32, "end_line": 34}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blockquote.py", "rel_path": "marker/processors/blockquote.py", "module": "marker.processors.blockquote", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "block", "type", "end", "elif", "min", "indent", "none", "contained", "blocks", "tolerance", "ignore", "for", "next", "document", "self", "start", "blockquote", "matching", "types", "structure", "pages", "continue", "width", "polygon", "true", "level", "page", "get", "call", "__init__", "BlockquoteProcessor", "consecutive", "class", "init", "percentage", "tuple", "process", "float", "ending", "expressed", "aligned", "tagging", "between", "annotated", "indentation", "schema", "required", "config", "from"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is None:\n                    continue\n\n                if not len(block.structure) >= 2:\n                    continue\n\n                next_block = page.get_next_block(block)\n                if next_block is None:\n                    continue\n                if next_block.block_type not in self.block_types:\n                    continue\n                if next_block.structure is None:\n                    continue\n                if next_block.ignore_for_output:\n                    continue\n\n                matching_x_end = abs(next_block.polygon.x_end - block.polygon.x_end) < self.x_end_tolerance * block.polygon.width\n                matching_x_start = abs(next_block.polygon.x_start - block.polygon.x_start) < self.x_start_tolerance * block.polygon.width\n                x_indent = next_block.polygon.x_start > block.polygon.x_start + (self.min_x_indent * block.polygon.width)\n                y_indent = next_block.polygon.y_start > block.polygon.y_end\n\n                if block.blockquote:\n                    next_block.blockquote = (matching_x_end and matching_x_start) or (x_indent and y_indent)\n                    next_block.blockquote_level = block.blockquote_level\n                    if (x_indent and y_indent):\n                        next_block.blockquote_level += 1\n                elif len(next_block.structure) >= 2 and (x_indent and y_indent):\n                    next_block.blockquote = True\n                    next_block.blockquote_level = 1", "n_tokens": 313, "byte_len": 1658, "file_sha1": "4cf562eab97344158bf346fcfcbb5468dae45c08", "start_line": 35, "end_line": 66}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/reference.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/reference.py", "rel_path": "marker/processors/reference.py", "module": "marker.processors.reference", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "ReferenceProcessor", "table", "group", "class", "init", "blocks", "numpy", "reference", "document", "schema", "processor", "self", "config", "from", "figure", "base", "references", "list", "super", "adding", "processors", "get", "block", "types", "import", "marker", "groups", "registry", "__call__", "bbox", "axis", "add", "full", "coord", "none", "distances", "starts", "range", "ignore", "for", "else", "append", "idx", "insert", "array", "norm", "ref", "refs", "structure"], "ast_kind": "class_or_type", "text": "import numpy as np\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Reference\nfrom marker.schema.document import Document\nfrom marker.schema.groups.list import ListGroup\nfrom marker.schema.groups.table import TableGroup\nfrom marker.schema.registry import get_block_class\nfrom marker.schema.groups.figure import FigureGroup\n\n\nclass ReferenceProcessor(BaseProcessor):\n    \"\"\"\n    A processor for adding references to the document.\n    \"\"\"\n\n    def __init__(self, config):\n        super().__init__(config)\n", "n_tokens": 106, "byte_len": 569, "file_sha1": "75b254e6ee510f1cc02d7252d04f29376b92adaa", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/reference.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/reference.py", "rel_path": "marker/processors/reference.py", "module": "marker.processors.reference", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "table", "group", "bbox", "axis", "add", "full", "coord", "none", "blocks", "distances", "block", "starts", "range", "ignore", "for", "else", "reference", "document", "append", "self", "idx", "figure", "class", "get", "insert", "list", "array", "norm", "ref", "__init__", "ReferenceProcessor", "init", "numpy", "schema", "processor", "config", "from", "base", "references", "super", "adding", "refs", "processors", "structure", "types", "pages", "linalg", "page", "extend"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        ReferenceClass: Reference = get_block_class(BlockTypes.Reference)\n\n        for page in document.pages:\n            refs = page.refs\n            ref_starts = np.array([ref.coord for ref in refs])\n\n            blocks = []\n            for block_id in page.structure:\n                block = page.get_block(block_id)\n                if isinstance(block, (ListGroup, FigureGroup, TableGroup)):\n                    blocks.extend([page.get_block(b) for b in block.structure])\n                else:\n                    blocks.append(block)\n            blocks = [b for b in blocks if not b.ignore_for_output]\n\n            block_starts = np.array([block.polygon.bbox[:2] for block in blocks])\n\n            if not (len(refs) and len(block_starts)):\n                continue\n\n            distances = np.linalg.norm(block_starts[:, np.newaxis, :] - ref_starts[np.newaxis, :, :], axis=2)\n            for ref_idx in range(len(ref_starts)):\n                block_idx = np.argmin(distances[:, ref_idx])\n                block = blocks[block_idx]\n\n                ref_block = page.add_full_block(ReferenceClass(\n                    ref=refs[ref_idx].ref,\n                    polygon=block.polygon,\n                    page_id=page.page_id\n                ))\n                if block.structure is None:\n                    block.structure = []\n                block.structure.insert(0, ref_block.id)\n", "n_tokens": 278, "byte_len": 1432, "file_sha1": "75b254e6ee510f1cc02d7252d04f29376b92adaa", "start_line": 21, "end_line": 55}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 1, "symbols": ["image", "fix", "text", "matrix", "intersection", "surya", "table", "extraction", "blocks", "get", "logger", "annotated", "recognition", "predictor", "document", "schema", "utils", "settings", "detection", "from", "collections", "base", "processor", "line", "rec", "list", "ftfy", "tablecell", "copy", "processors", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex"], "ast_kind": "imports", "text": "import re\nfrom collections import defaultdict\nfrom copy import deepcopy\nfrom typing import Annotated, List\nfrom collections import Counter\nfrom PIL import Image\n\nfrom ftfy import fix_text\nfrom surya.detection import DetectionPredictor, TextDetectionResult\nfrom surya.recognition import RecognitionPredictor, TextLine\nfrom surya.table_rec import TableRecPredictor\nfrom surya.table_rec.schema import TableResult, TableCell as SuryaTableCell\nfrom pdftext.extraction import table_output\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks.tablecell import TableCell\nfrom marker.schema.document import Document\nfrom marker.schema.polygon import PolygonBox\nfrom marker.settings import settings\nfrom marker.util import matrix_intersection_area, unwrap_math\nfrom marker.utils.image import is_blank_image\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n", "n_tokens": 182, "byte_len": 913, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 2, "symbols": ["TableProcessor", "drop", "repeated", "remove", "results", "split", "class", "disable", "tqdm", "none", "tables", "percentage", "text", "model", "contained", "block", "float", "inline", "table", "processor", "active", "splitting", "default", "ocr", "pdftext", "workers", "annotated", "progress", "document", "types", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "class_or_type", "text": "class TableProcessor(BaseProcessor):\n    \"\"\"\n    A processor for recognizing tables in the document.\n    \"\"\"\n\n    block_types = (BlockTypes.Table, BlockTypes.TableOfContents, BlockTypes.Form)\n    table_rec_batch_size: Annotated[\n        int,\n        \"The batch size to use for the table recognition model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    detection_batch_size: Annotated[\n        int,\n        \"The batch size to use for the table detection model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    recognition_batch_size: Annotated[\n        int,\n        \"The batch size to use for the table recognition model.\",\n        \"Default is None, which will use the default batch size for the model.\",\n    ] = None\n    contained_block_types: Annotated[\n        List[BlockTypes],\n        \"Block types to remove if they're contained inside the tables.\",\n    ] = (BlockTypes.Text, BlockTypes.TextInlineMath)\n    row_split_threshold: Annotated[\n        float,\n        \"The percentage of rows that need to be split across the table before row splitting is active.\",\n    ] = 0.5\n    pdftext_workers: Annotated[\n        int,\n        \"The number of workers to use for pdftext.\",\n    ] = 1\n    disable_tqdm: Annotated[\n        bool,\n        \"Whether to disable the tqdm progress bar.\",\n    ] = False\n    drop_repeated_table_text: Annotated[bool, \"Drop repeated text in OCR results.\"] = (\n        False\n    )\n    filter_tag_list = [\"p\", \"table\", \"td\", \"tr\", \"th\", \"tbody\"]\n    disable_ocr_math: Annotated[bool, \"Disable inline math recognition in OCR\"] = False\n    disable_ocr: Annotated[bool, \"Disable OCR entirely.\"] = False\n", "n_tokens": 407, "byte_len": 1724, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 28, "end_line": 71}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "recognition", "predictor", "super", "init", "detection", "table", "rec", "self", "config", "none", "model", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace", "drop", "repeated", "disable", "ocr", "back", "utils", "det", "images", "entirely", "cells", "rescale", "current", "bbox", "file", "smallest", "colspan", "account", "within"], "ast_kind": "function_or_method", "text": "    def __init__(\n        self,\n        recognition_model: RecognitionPredictor,\n        table_rec_model: TableRecPredictor,\n        detection_model: DetectionPredictor,\n        config=None,\n    ):\n        super().__init__(config)\n\n        self.recognition_model = recognition_model\n        self.table_rec_model = table_rec_model\n        self.detection_model = detection_model\n", "n_tokens": 75, "byte_len": 377, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 72, "end_line": 84}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "row", "finalize", "cell", "matrix", "intersection", "exists", "assign", "ocr", "image", "document", "adjust", "table", "idx", "cells", "rescale", "child", "contained", "corner", "file", "colspan", "filepath", "lines", "page", "pct", "columns", "img", "size", "were", "bool", "__init__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        filepath = document.filepath  # Path to original pdf file\n\n        table_data = []\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.block_type == BlockTypes.Table:\n                    block.polygon = block.polygon.expand(0.01, 0.01)\n                image = block.get_image(document, highres=True)\n                image_poly = block.polygon.rescale(\n                    (page.polygon.width, page.polygon.height),\n                    page.get_image(highres=True).size,\n                )\n\n                table_data.append(\n                    {\n                        \"block_id\": block.id,\n                        \"page_id\": page.page_id,\n                        \"table_image\": image,\n                        \"table_bbox\": image_poly.bbox,\n                        \"img_size\": page.get_image(highres=True).size,\n                        \"ocr_block\": any(\n                            [\n                                page.text_extraction_method in [\"surya\"],\n                                page.ocr_errors_detected,\n                            ]\n                        ),\n                    }\n                )\n\n        # Detect tables and cells\n        self.table_rec_model.disable_tqdm = self.disable_tqdm\n        tables: List[TableResult] = self.table_rec_model(\n            [t[\"table_image\"] for t in table_data],\n            batch_size=self.get_table_rec_batch_size(),\n        )\n        assert len(tables) == len(table_data), (\n            \"Number of table results should match the number of tables\"\n        )\n\n        # Assign cell text if we don't need OCR\n        # We do this at a line level\n        extract_blocks = [t for t in table_data if not t[\"ocr_block\"]]\n        self.assign_pdftext_lines(\n            extract_blocks, filepath\n        )  # Handle tables where good text exists in the PDF\n        self.assign_text_to_cells(tables, table_data)\n\n        # Assign OCR lines if needed - we do this at a cell level\n        self.assign_ocr_lines(tables, table_data)\n\n        self.split_combined_rows(tables)  # Split up rows that were combined\n        self.combine_dollar_column(tables)  # Combine columns that are just dollar signs\n\n        # Assign table cells to the table\n        table_idx = 0\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                block.structure = []  # Remove any existing lines, spans, etc.\n                cells: List[SuryaTableCell] = tables[table_idx].cells\n                for cell in cells:\n                    # Rescale the cell polygon to the page size\n                    cell_polygon = PolygonBox(polygon=cell.polygon).rescale(\n                        page.get_image(highres=True).size, page.polygon.size\n                    )\n\n                    # Rescale cell polygon to be relative to the page instead of the table\n                    for corner in cell_polygon.polygon:\n                        corner[0] += block.polygon.bbox[0]\n                        corner[1] += block.polygon.bbox[1]\n\n                    cell_block = TableCell(\n                        polygon=cell_polygon,\n                        text_lines=self.finalize_cell_text(cell),\n                        rowspan=cell.rowspan,\n                        colspan=cell.colspan,\n                        row_id=cell.row_id,\n                        col_id=cell.col_id,\n                        is_header=bool(cell.is_header),\n                        page_id=page.page_id,\n                    )\n                    page.add_full_block(cell_block)\n                    block.add_structure(cell_block)\n                table_idx += 1\n\n        # Clean out other blocks inside the table\n        # This can happen with stray text blocks inside the table post-merging\n        for page in document.pages:\n            child_contained_blocks = page.contained_blocks(\n                document, self.contained_block_types\n            )\n            for block in page.contained_blocks(document, self.block_types):\n                intersections = matrix_intersection_area(\n                    [c.polygon.bbox for c in child_contained_blocks],\n                    [block.polygon.bbox],\n                )\n                for child, intersection in zip(child_contained_blocks, intersections):\n                    # Adjust this to percentage of the child block that is enclosed by the table\n                    intersection_pct = intersection / max(child.polygon.area, 1)\n                    if intersection_pct > 0.95 and child.id in page.structure:\n                        page.structure.remove(child.id)\n", "n_tokens": 886, "byte_len": 4703, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 85, "end_line": 186}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 5, "symbols": ["finalize_cell_text", "remove", "fix", "text", "finalize", "cell", "phantom", "unclosed", "formatting", "overline", "latex", "surya", "table", "handle", "mathbf", "more", "drop", "whole", "else", "digits", "mathsf", "append", "lines", "self", "line", "spaced", "sequences", "left", "normalize", "spaces", "__init__", "__call__", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "replace", "repeated"], "ast_kind": "function_or_method", "text": "    def finalize_cell_text(self, cell: SuryaTableCell):\n        fixed_text = []\n        text_lines = cell.text_lines if cell.text_lines else []\n        for line in text_lines:\n            text = line[\"text\"].strip()\n            if not text or text == \".\":\n                continue\n            # Spaced sequences: \". . .\", \"- - -\", \"_ _ _\", \"  \"\n            text = re.sub(r\"(\\s?[.\\-_]){2,}\", \"\", text)\n            # Unspaced sequences: \"...\", \"---\", \"___\", \"\"\n            text = re.sub(r\"[.\\-_]{2,}\", \"\", text)\n            # Remove mathbf formatting if there is only digits with decimals/commas/currency symbols inside\n            text = re.sub(r\"\\\\mathbf\\{([0-9.,$]+)\\}\", r\"<b>\\1</b>\", text)\n            # Drop empty tags like \\overline{}\n            text = re.sub(r\"\\\\[a-zA-Z]+\\{\\s*\\}\", \"\", text)\n            # Drop \\phantom{...} (remove contents too)\n            text = re.sub(r\"\\\\phantom\\{.*?\\}\", \"\", text)\n            # Drop \\quad\n            text = re.sub(r\"\\\\quad\", \"\", text)\n            # Drop \\,\n            text = re.sub(r\"\\\\,\", \"\", text)\n            # Unwrap \\mathsf{...}\n            text = re.sub(r\"\\\\mathsf\\{([^}]*)\\}\", r\"\\1\", text)\n            # Handle unclosed tags: keep contents, drop the command\n            text = re.sub(r\"\\\\[a-zA-Z]+\\{([^}]*)$\", r\"\\1\", text)\n            # If the whole string is \\text{...}  unwrap\n            text = re.sub(r\"^\\s*\\\\text\\{([^}]*)\\}\\s*$\", r\"\\1\", text)\n\n            # In case the above steps left no more latex math - We can unwrap\n            text = unwrap_math(text)\n            text = self.normalize_spaces(fix_text(text))\n            fixed_text.append(text)\n        return fixed_text\n", "n_tokens": 449, "byte_len": 1667, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 187, "end_line": 220}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 6, "symbols": ["normalize_spaces", "breaking", "u200b", "width", "u2003", "ideographic", "text", "space", "chars", "replace", "staticmethod", "u2002", "u00a0", "zero", "u3000", "normalize", "spaces", "return", "__init__", "__call__", "finalize_cell_text", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "header", "latex", "drop", "repeated", "disable", "ocr", "back", "utils", "det", "images", "entirely", "cells", "rescale", "current", "bbox", "file", "smallest"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def normalize_spaces(text):\n        space_chars = [\n            \"\\u2003\",  # em space\n            \"\\u2002\",  # en space\n            \"\\u00a0\",  # non-breaking space\n            \"\\u200b\",  # zero-width space\n            \"\\u3000\",  # ideographic space\n        ]\n        for space in space_chars:\n            text = text.replace(space, \" \")\n        return text\n", "n_tokens": 96, "byte_len": 379, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 221, "end_line": 233}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 7, "symbols": ["combine_dollar_column", "span", "into", "col", "row", "finalize", "cell", "start", "remove", "tables", "skip", "text", "next", "else", "cells", "append", "lines", "self", "unique", "cols", "entirely", "dollar", "combine", "sorted", "list", "colspan", "rows", "original", "strip", "this", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def combine_dollar_column(self, tables: List[TableResult]):\n        for table in tables:\n            if len(table.cells) == 0:\n                # Skip empty tables\n                continue\n            unique_cols = sorted(list(set([c.col_id for c in table.cells])))\n            max_col = max(unique_cols)\n            dollar_cols = []\n            for col in unique_cols:\n                # Cells in this col\n                col_cells = [c for c in table.cells if c.col_id == col]\n                col_text = [\n                    \"\\n\".join(self.finalize_cell_text(c)).strip() for c in col_cells\n                ]\n                all_dollars = all([ct in [\"\", \"$\"] for ct in col_text])\n                colspans = [c.colspan for c in col_cells]\n                span_into_col = [\n                    c\n                    for c in table.cells\n                    if c.col_id != col and c.col_id + c.colspan > col > c.col_id\n                ]\n\n                # This is a column that is entirely dollar signs\n                if all(\n                    [\n                        all_dollars,\n                        len(col_cells) > 1,\n                        len(span_into_col) == 0,\n                        all([c == 1 for c in colspans]),\n                        col < max_col,\n                    ]\n                ):\n                    next_col_cells = [c for c in table.cells if c.col_id == col + 1]\n                    next_col_rows = [c.row_id for c in next_col_cells]\n                    col_rows = [c.row_id for c in col_cells]\n                    if (\n                        len(next_col_cells) == len(col_cells)\n                        and next_col_rows == col_rows\n                    ):\n                        dollar_cols.append(col)\n\n            if len(dollar_cols) == 0:\n                continue\n\n            dollar_cols = sorted(dollar_cols)\n            col_offset = 0\n            for col in unique_cols:\n                col_cells = [c for c in table.cells if c.col_id == col]\n                if col_offset == 0 and col not in dollar_cols:\n                    continue\n\n                if col in dollar_cols:\n                    col_offset += 1\n                    for cell in col_cells:\n                        text_lines = cell.text_lines if cell.text_lines else []\n                        next_row_col = [\n                            c\n                            for c in table.cells\n                            if c.row_id == cell.row_id and c.col_id == col + 1\n                        ]\n\n                        # Add dollar to start of the next column\n                        next_text_lines = (\n                            next_row_col[0].text_lines\n                            if next_row_col[0].text_lines\n                            else []\n                        )\n                        next_row_col[0].text_lines = deepcopy(text_lines) + deepcopy(\n                            next_text_lines\n                        )\n                        table.cells = [\n                            c for c in table.cells if c.cell_id != cell.cell_id\n                        ]  # Remove original cell\n                        next_row_col[0].col_id -= col_offset\n                else:\n                    for cell in col_cells:\n                        cell.col_id -= col_offset\n", "n_tokens": 624, "byte_len": 3296, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 234, "end_line": 311}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 8, "symbols": ["split_combined_rows", "item", "info", "row", "header", "based", "counter", "keys", "shift", "cells", "current", "bbox", "sorted", "deepcopy", "colspan", "account", "within", "than", "splits", "continue", "added", "this", "making", "isinstance", "number", "partial", "column", "span", "match", "cell", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "ideographic", "latex", "replace", "drop"], "ast_kind": "function_or_method", "text": "    def split_combined_rows(self, tables: List[TableResult]):\n        for table in tables:\n            if len(table.cells) == 0:\n                # Skip empty tables\n                continue\n            unique_rows = sorted(list(set([c.row_id for c in table.cells])))\n            row_info = []\n            for row in unique_rows:\n                # Cells in this row\n                # Deepcopy is because we do an in-place mutation later, and that can cause rows to shift to match rows in unique_rows\n                # making them be processed twice\n                row_cells = deepcopy([c for c in table.cells if c.row_id == row])\n                rowspans = [c.rowspan for c in row_cells]\n                line_lens = [\n                    len(c.text_lines) if isinstance(c.text_lines, list) else 1\n                    for c in row_cells\n                ]\n\n                # Other cells that span into this row\n                rowspan_cells = [\n                    c\n                    for c in table.cells\n                    if c.row_id != row and c.row_id + c.rowspan > row > c.row_id\n                ]\n                should_split_entire_row = all(\n                    [\n                        len(row_cells) > 1,\n                        len(rowspan_cells) == 0,\n                        all([rowspan == 1 for rowspan in rowspans]),\n                        all([line_len > 1 for line_len in line_lens]),\n                        all([line_len == line_lens[0] for line_len in line_lens]),\n                    ]\n                )\n                line_lens_counter = Counter(line_lens)\n                counter_keys = sorted(list(line_lens_counter.keys()))\n                should_split_partial_row = all(\n                    [\n                        len(row_cells) > 3,  # Only split if there are more than 3 cells\n                        len(rowspan_cells) == 0,\n                        all([r == 1 for r in rowspans]),\n                        len(line_lens_counter) == 2\n                        and counter_keys[0] <= 1\n                        and counter_keys[1] > 1\n                        and line_lens_counter[counter_keys[0]]\n                        == 1,  # Allow a single column with a single line - keys are the line lens, values are the counts\n                    ]\n                )\n                should_split = should_split_entire_row or should_split_partial_row\n                row_info.append(\n                    {\n                        \"should_split\": should_split,\n                        \"row_cells\": row_cells,\n                        \"line_lens\": line_lens,\n                    }\n                )\n\n            # Don't split if we're not splitting most of the rows in the table.  This avoids splitting stray multiline rows.\n            if (\n                sum([r[\"should_split\"] for r in row_info]) / len(row_info)\n                < self.row_split_threshold\n            ):\n                continue\n\n            new_cells = []\n            shift_up = 0\n            max_cell_id = max([c.cell_id for c in table.cells])\n            new_cell_count = 0\n            for row, item_info in zip(unique_rows, row_info):\n                max_lines = max(item_info[\"line_lens\"])\n                if item_info[\"should_split\"]:\n                    for i in range(0, max_lines):\n                        for cell in item_info[\"row_cells\"]:\n                            # Calculate height based on number of splits\n                            split_height = cell.bbox[3] - cell.bbox[1]\n                            current_bbox = [\n                                cell.bbox[0],\n                                cell.bbox[1] + i * split_height,\n                                cell.bbox[2],\n                                cell.bbox[1] + (i + 1) * split_height,\n                            ]\n\n                            line = (\n                                [cell.text_lines[i]]\n                                if cell.text_lines and i < len(cell.text_lines)\n                                else None\n                            )\n                            cell_id = max_cell_id + new_cell_count\n                            new_cells.append(\n                                SuryaTableCell(\n                                    polygon=current_bbox,\n                                    text_lines=line,\n                                    rowspan=1,\n                                    colspan=cell.colspan,\n                                    row_id=cell.row_id + shift_up + i,\n                                    col_id=cell.col_id,\n                                    is_header=cell.is_header\n                                    and i == 0,  # Only first line is header\n                                    within_row_id=cell.within_row_id,\n                                    cell_id=cell_id,\n                                )\n                            )\n                            new_cell_count += 1\n\n                    # For each new row we add, shift up subsequent rows\n                    # The max is to account for partial rows\n                    shift_up += max_lines - 1\n                else:\n                    for cell in item_info[\"row_cells\"]:\n                        cell.row_id += shift_up\n                        new_cells.append(cell)\n\n            # Only update the cells if we added new cells\n            if len(new_cells) > len(table.cells):\n                table.cells = new_cells\n", "n_tokens": 977, "byte_len": 5414, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 312, "end_line": 426}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 9, "symbols": ["assign_text_to_cells", "bbox", "text", "line", "assert", "based", "tables", "rotation", "matrix", "intersection", "table", "surya", "cell", "append", "lines", "self", "assign", "max", "ocr", "block", "cells", "todo", "needs", "sorted", "list", "intersections", "argmax", "have", "enumerate", "page", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def assign_text_to_cells(self, tables: List[TableResult], table_data: list):\n        for table_result, table_page_data in zip(tables, table_data):\n            if table_page_data[\"ocr_block\"]:\n                continue\n\n            table_text_lines = table_page_data[\"table_text_lines\"]\n            table_cells: List[SuryaTableCell] = table_result.cells\n            text_line_bboxes = [t[\"bbox\"] for t in table_text_lines]\n            table_cell_bboxes = [c.bbox for c in table_cells]\n\n            intersection_matrix = matrix_intersection_area(\n                text_line_bboxes, table_cell_bboxes\n            )\n\n            cell_text = defaultdict(list)\n            for text_line_idx, table_text_line in enumerate(table_text_lines):\n                intersections = intersection_matrix[text_line_idx]\n                if intersections.sum() == 0:\n                    continue\n\n                max_intersection = intersections.argmax()\n                cell_text[max_intersection].append(table_text_line)\n\n            for k in cell_text:\n                # TODO: see if the text needs to be sorted (based on rotation)\n                text = cell_text[k]\n                assert all(\"text\" in t for t in text), \"All text lines must have text\"\n                assert all(\"bbox\" in t for t in text), \"All text lines must have a bbox\"\n                table_cells[k].text_lines = text\n", "n_tokens": 276, "byte_len": 1377, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 427, "end_line": 456}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#10", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 10, "symbols": ["assign_pdftext_lines", "find", "assert", "none", "tables", "text", "didn", "table", "inputs", "extract", "blocks", "pidx", "number", "pdftext", "workers", "else", "page", "bbox", "append", "self", "pnum", "idx", "ocr", "block", "unique", "pages", "return", "filepath", "enumerate", "cell", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def assign_pdftext_lines(self, extract_blocks: list, filepath: str):\n        table_inputs = []\n        unique_pages = list(set([t[\"page_id\"] for t in extract_blocks]))\n        if len(unique_pages) == 0:\n            return\n\n        for page in unique_pages:\n            tables = []\n            img_size = None\n            for block in extract_blocks:\n                if block[\"page_id\"] == page:\n                    tables.append(block[\"table_bbox\"])\n                    img_size = block[\"img_size\"]\n\n            table_inputs.append({\"tables\": tables, \"img_size\": img_size})\n        cell_text = table_output(\n            filepath,\n            table_inputs,\n            page_range=unique_pages,\n            workers=self.pdftext_workers,\n        )\n        assert len(cell_text) == len(unique_pages), (\n            \"Number of pages and table inputs must match\"\n        )\n\n        for pidx, (page_tables, pnum) in enumerate(zip(cell_text, unique_pages)):\n            table_idx = 0\n            for block in extract_blocks:\n                if block[\"page_id\"] == pnum:\n                    table_text = page_tables[table_idx]\n                    if len(table_text) == 0:\n                        block[\"ocr_block\"] = (\n                            True  # Re-OCR the block if pdftext didn't find any text\n                        )\n                    else:\n                        block[\"table_text_lines\"] = page_tables[table_idx]\n                    table_idx += 1\n            assert table_idx == len(page_tables), (\n                \"Number of tables and table inputs must match\"\n            )\n", "n_tokens": 318, "byte_len": 1590, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 457, "end_line": 497}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#11", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 11, "symbols": ["align_table_cells", "bbox", "text", "line", "rectangle", "moves", "new", "bottom", "most", "based", "shrunken", "assigned", "lines", "matrix", "intersection", "table", "current", "replace", "detection", "cell", "find", "append", "self", "largest", "adjust", "from", "only", "max", "intersecting", "cells", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "drop"], "ast_kind": "function_or_method", "text": "    def align_table_cells(\n        self, table: TableResult, table_detection_result: TextDetectionResult\n    ):\n        table_cells = table.cells\n        table_text_lines = table_detection_result.bboxes\n\n        text_line_bboxes = [t.bbox for t in table_text_lines]\n        table_cell_bboxes = [c.bbox for c in table_cells]\n\n        intersection_matrix = matrix_intersection_area(\n            text_line_bboxes, table_cell_bboxes\n        )\n\n        # Map cells -> list of assigned text lines\n        cell_text = defaultdict(list)\n        for text_line_idx, table_text_line in enumerate(table_text_lines):\n            intersections = intersection_matrix[text_line_idx]\n            if intersections.sum() == 0:\n                continue\n            max_intersection = intersections.argmax()\n            cell_text[max_intersection].append(table_text_line)\n\n        # Adjust cell polygons in place\n        for cell_idx, cell in enumerate(table_cells):\n            # all intersecting lines\n            intersecting_line_indices = [\n                i for i, area in enumerate(intersection_matrix[:, cell_idx]) if area > 0\n            ]\n            if not intersecting_line_indices:\n                continue\n\n            assigned_lines = cell_text.get(cell_idx, [])\n            # Expand to fit assigned lines - **Only in the y direction**\n            for assigned_line in assigned_lines:\n                x1 = cell.bbox[0]\n                x2 = cell.bbox[2]\n                y1 = min(cell.bbox[1], assigned_line.bbox[1])\n                y2 = max(cell.bbox[3], assigned_line.bbox[3])\n                cell.polygon = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n\n            # Clear out non-assigned lines\n            non_assigned_lines = [\n                table_text_lines[i]\n                for i in intersecting_line_indices\n                if table_text_lines[i] not in cell_text.get(cell_idx, [])\n            ]\n            if non_assigned_lines:\n                # Find top-most and bottom-most non-assigned boxes\n                top_box = min(\n                    non_assigned_lines, key=lambda line: line.bbox[1]\n                )  # smallest y0\n                bottom_box = max(\n                    non_assigned_lines, key=lambda line: line.bbox[3]\n                )  # largest y1\n\n                # Current cell bbox (from polygon)\n                x0, y0, x1, y1 = cell.bbox\n\n                # Adjust y-limits based on non-assigned boxes\n                new_y0 = max(y0, top_box.bbox[3])  # top moves down\n                new_y1 = min(y1, bottom_box.bbox[1])  # bottom moves up\n\n                if new_y0 < new_y1:\n                    # Replace polygon with a new shrunken rectangle\n                    cell.polygon = [\n                        [x0, new_y0],\n                        [x1, new_y0],\n                        [x1, new_y1],\n                        [x0, new_y1],\n                    ]\n", "n_tokens": 632, "byte_len": 2883, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 498, "end_line": 568}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#12", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 12, "symbols": ["needs_ocr", "assert", "none", "tables", "text", "ocr", "idxs", "polys", "surya", "table", "needs", "detection", "disable", "images", "block", "requires", "append", "lines", "self", "result", "dict", "cells", "return", "red", "ocred", "list", "get", "align", "blocks", "enumerate", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "get_ocr_results", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def needs_ocr(self, tables: List[TableResult], table_blocks: List[dict]):\n        ocr_tables = []\n        ocr_idxs = []\n        for j, (table_result, table_block) in enumerate(zip(tables, table_blocks)):\n            table_cells: List[SuryaTableCell] = table_result.cells\n            text_lines_need_ocr = any([tc.text_lines is None for tc in table_cells])\n            if (\n                table_block[\"ocr_block\"]\n                and text_lines_need_ocr\n                and not self.disable_ocr\n            ):\n                logger.debug(\n                    f\"Table {j} needs OCR, info table block needs ocr: {table_block['ocr_block']}, text_lines {text_lines_need_ocr}\"\n                )\n                ocr_tables.append(table_result)\n                ocr_idxs.append(j)\n\n        detection_results: List[TextDetectionResult] = self.detection_model(\n            images=[table_blocks[i][\"table_image\"] for i in ocr_idxs],\n            batch_size=self.get_detection_batch_size(),\n        )\n        assert len(detection_results) == len(ocr_idxs), (\n            \"Every OCRed table requires a text detection result\"\n        )\n\n        for idx, table_detection_result in zip(ocr_idxs, detection_results):\n            self.align_table_cells(tables[idx], table_detection_result)\n\n        ocr_polys = []\n        for ocr_idx in ocr_idxs:\n            table_cells = tables[ocr_idx].cells\n            polys = [tc for tc in table_cells if tc.text_lines is None]\n            ocr_polys.append(polys)\n        return ocr_tables, ocr_polys, ocr_idxs\n", "n_tokens": 341, "byte_len": 1536, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 569, "end_line": 603}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#13", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 13, "symbols": ["get_ocr_results", "drop", "repeated", "image", "bbox", "ocr", "results", "round", "text", "none", "bad", "polys", "surya", "table", "some", "predictions", "filtered", "range", "images", "else", "append", "math", "mode", "self", "lines", "updated", "max", "tokens", "disable", "recognition", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "assign_ocr_lines", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def get_ocr_results(\n        self, table_images: List[Image.Image], ocr_polys: List[List[SuryaTableCell]]\n    ):\n        ocr_polys_bad = []\n\n        for table_image, polys in zip(table_images, ocr_polys):\n            table_polys_bad = [\n                any(\n                    [\n                        poly.height < 6,\n                        is_blank_image(table_image.crop(poly.bbox), poly.polygon),\n                    ]\n                )\n                for poly in polys\n            ]\n            ocr_polys_bad.append(table_polys_bad)\n\n        filtered_polys = []\n        for table_polys, table_polys_bad in zip(ocr_polys, ocr_polys_bad):\n            filtered_table_polys = []\n            for p, is_bad in zip(table_polys, table_polys_bad):\n                if is_bad:\n                    continue\n                polygon = p.polygon\n                # Round the polygon\n                for corner in polygon:\n                    for i in range(2):\n                        corner[i] = int(corner[i])\n\n                filtered_table_polys.append(polygon)\n            filtered_polys.append(filtered_table_polys)\n\n        ocr_results = self.recognition_model(\n            images=table_images,\n            task_names=[\"ocr_with_boxes\"] * len(table_images),\n            recognition_batch_size=self.get_recognition_batch_size(),\n            drop_repeated_text=self.drop_repeated_table_text,\n            polygons=filtered_polys,\n            filter_tag_list=self.filter_tag_list,\n            max_tokens=2048,\n            max_sliding_window=2148,\n            math_mode=not self.disable_ocr_math,\n        )\n\n        # Re-align the predictions to the original length, since we skipped some predictions\n        for table_ocr_result, table_polys_bad in zip(ocr_results, ocr_polys_bad):\n            updated_lines = []\n            idx = 0\n            for is_bad in table_polys_bad:\n                if is_bad:\n                    updated_lines.append(\n                        TextLine(\n                            text=\"\",\n                            polygon=[[0, 0], [0, 0], [0, 0], [0, 0]],\n                            confidence=1,\n                            chars=[],\n                            original_text_good=False,\n                            words=None,\n                        )\n                    )\n                else:\n                    updated_lines.append(table_ocr_result.text_lines[idx])\n                    idx += 1\n            table_ocr_result.text_lines = updated_lines\n\n        return ocr_results\n", "n_tokens": 494, "byte_len": 2518, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 604, "end_line": 670}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#14", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 14, "symbols": ["assign_ocr_lines", "cell", "text", "results", "split", "ocr", "relative", "assert", "disable", "tqdm", "none", "tables", "idxs", "polys", "surya", "table", "needs", "assign", "number", "back", "images", "image", "res", "lines", "self", "result", "recognition", "model", "det", "cells", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace"], "ast_kind": "function_or_method", "text": "    def assign_ocr_lines(self, tables: List[TableResult], table_blocks: list):\n        ocr_tables, ocr_polys, ocr_idxs = self.needs_ocr(tables, table_blocks)\n        det_images = [\n            t[\"table_image\"] for i, t in enumerate(table_blocks) if i in ocr_idxs\n        ]\n        assert len(det_images) == len(ocr_polys), (\n            f\"Number of detection images and OCR polygons must match: {len(det_images)} != {len(ocr_polys)}\"\n        )\n        self.recognition_model.disable_tqdm = self.disable_tqdm\n        ocr_results = self.get_ocr_results(table_images=det_images, ocr_polys=ocr_polys)\n\n        for result, ocr_res in zip(ocr_tables, ocr_results):\n            table_cells: List[SuryaTableCell] = result.cells\n            cells_need_text = [tc for tc in table_cells if tc.text_lines is None]\n\n            assert len(cells_need_text) == len(ocr_res.text_lines), (\n                \"Number of cells needing text and OCR results must match\"\n            )\n\n            for cell_text, cell_needs_text in zip(ocr_res.text_lines, cells_need_text):\n                # Don't need to correct back to image size\n                # Table rec boxes are relative to the table\n                cell_text_lines = [{\"text\": t} for t in cell_text.text.split(\"<br>\")]\n                cell_needs_text.text_lines = cell_text_lines\n", "n_tokens": 315, "byte_len": 1316, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 671, "end_line": 695}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py#15", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/table.py", "rel_path": "marker/processors/table.py", "module": "marker.processors.table", "ext": "py", "chunk_number": 15, "symbols": ["get_table_rec_batch_size", "get_recognition_batch_size", "get_detection_batch_size", "elif", "recognition", "batch", "detection", "get", "self", "none", "settings", "table", "rec", "torc", "devic", "cuda", "return", "__init__", "__call__", "finalize_cell_text", "normalize_spaces", "combine_dollar_column", "split_combined_rows", "assign_text_to_cells", "assign_pdftext_lines", "align_table_cells", "needs_ocr", "get_ocr_results", "assign_ocr_lines", "TableProcessor", "breaking", "header", "ideographic", "latex", "replace", "drop", "repeated", "disable", "ocr", "back", "utils", "det", "images", "entirely", "cells", "rescale", "current", "bbox", "file", "smallest"], "ast_kind": "function_or_method", "text": "    def get_table_rec_batch_size(self):\n        if self.table_rec_batch_size is not None:\n            return self.table_rec_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"mps\":\n            return 6\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 14\n        return 6\n\n    def get_recognition_batch_size(self):\n        if self.recognition_batch_size is not None:\n            return self.recognition_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"mps\":\n            return 32\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 48\n        return 32\n\n    def get_detection_batch_size(self):\n        if self.detection_batch_size is not None:\n            return self.detection_batch_size\n        elif settings.TORCH_DEVICE_MODEL == \"cuda\":\n            return 10\n        return 4\n", "n_tokens": 183, "byte_len": 832, "file_sha1": "ac5d07bbd1c8542dcc7d00c7fbaf3d9267eb9729", "start_line": 696, "end_line": 720}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "import", "document", "marker", "schema", "from", "processors", "typing", "base", "processor", "block", "types", "__init__", "__call__", "ignore_line_number_spans", "ignore_line_number_blocks", "ignore_line_starts_ends", "LineNumbersProcessor", "small", "raw", "text", "required", "prefixes", "config", "ignore", "line", "number", "wide", "ends", "with", "ensures", "during", "than", "lines", "count", "continue", "inline", "total", "processing", "page", "span", "true", "strip", "numbers", "call", "split", "significant", "blocks", "tokens", "positives"], "ast_kind": "imports", "text": "from typing import Annotated\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n", "n_tokens": 28, "byte_len": 156, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 1, "end_line": 7}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 2, "symbols": ["LineNumbersProcessor", "class", "significant", "treat", "short", "float", "consider", "characters", "min", "line", "blocks", "prevents", "tokens", "contain", "unlikely", "small", "checking", "annotated", "positives", "ignored", "fraction", "required", "prefixes", "ignoring", "numbers", "spans", "processor", "base", "meaningful", "when", "__init__", "__call__", "ignore_line_number_spans", "ignore_line_number_blocks", "ignore_line_starts_ends", "raw", "text", "document", "config", "ignore", "number", "wide", "ends", "with", "ensures", "during", "than", "processors", "lines", "count"], "ast_kind": "class_or_type", "text": "class LineNumbersProcessor(BaseProcessor):\n    \"\"\"\n    A processor for ignoring line numbers.\n    \"\"\"\n    block_types = (BlockTypes.Text, BlockTypes.TextInlineMath)\n    strip_numbers_threshold: Annotated[\n        float,\n        \"The fraction of lines or tokens in a block that must be numeric to consider them as line numbers.\",\n    ] = 0.6\n    min_lines_in_block: Annotated[\n        int,\n        \"The minimum number of lines required in a block for it to be considered during processing.\",\n        \"Ensures that small blocks are ignored as they are unlikely to contain meaningful line numbers.\",\n    ] = 4\n    min_line_length: Annotated[\n        int,\n        \"The minimum length of a line (in characters) to consider it significant when checking for\",\n        \"numeric prefixes or suffixes. Prevents false positives for short lines.\",\n    ] = 10\n    min_line_number_span_ratio: Annotated[\n        float,\n        \"The minimum ratio of detected line number spans to total lines required to treat them as line numbers.\",\n    ] = .6\n", "n_tokens": 224, "byte_len": 1030, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 8, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "__call__", "super", "init", "document", "ignore", "line", "self", "config", "call", "ignore_line_number_spans", "ignore_line_number_blocks", "ignore_line_starts_ends", "LineNumbersProcessor", "small", "raw", "text", "required", "prefixes", "number", "wide", "base", "processor", "ends", "with", "ensures", "during", "than", "processors", "lines", "count", "continue", "inline", "marker", "total", "processing", "page", "span", "true", "strip", "numbers", "split", "significant", "blocks", "tokens", "positives", "fraction", "are", "ignoring", "vertical"], "ast_kind": "function_or_method", "text": "    def __init__(self, config):\n        super().__init__(config)\n\n    def __call__(self, document: Document):\n        self.ignore_line_number_spans(document)\n        self.ignore_line_starts_ends(document)\n        self.ignore_line_number_blocks(document)\n", "n_tokens": 52, "byte_len": 254, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 32, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 4, "symbols": ["ignore_line_number_spans", "none", "contained", "blocks", "text", "min", "line", "leftmost", "span", "ignore", "for", "document", "append", "self", "number", "isnumeric", "start", "strip", "structure", "block", "types", "count", "pages", "continue", "polygon", "page", "true", "__init__", "__call__", "ignore_line_number_blocks", "ignore_line_starts_ends", "LineNumbersProcessor", "small", "raw", "required", "prefixes", "config", "wide", "base", "processor", "ends", "with", "ensures", "during", "than", "processors", "lines", "inline", "marker", "total"], "ast_kind": "function_or_method", "text": "    def ignore_line_number_spans(self, document: Document):\n        for page in document.pages:\n            line_count = 0\n            line_number_spans = []\n            for block in page.contained_blocks(document, (BlockTypes.Line,)):\n                if block.structure is None:\n                    continue\n\n                line_count += 1\n                leftmost_span = None\n                for span in block.contained_blocks(document, (BlockTypes.Span,)):\n                    if leftmost_span is None or span.polygon.x_start < leftmost_span.polygon.x_start:\n                        leftmost_span = span\n\n                if leftmost_span is not None and leftmost_span.text.strip().isnumeric():\n                    line_number_spans.append(leftmost_span)\n\n            if line_count > 0 and len(line_number_spans) / line_count > self.min_line_number_span_ratio:\n                for span in line_number_spans:\n                    span.ignore_for_output = True\n", "n_tokens": 189, "byte_len": 961, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 40, "end_line": 60}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 5, "symbols": ["ignore_line_number_blocks", "split", "contained", "blocks", "tokens", "ignore", "for", "raw", "text", "are", "document", "line", "self", "numbers", "vertical", "wide", "height", "ensure", "block", "types", "taller", "strip", "than", "pages", "continue", "width", "polygon", "true", "page", "like", "__init__", "__call__", "ignore_line_number_spans", "ignore_line_starts_ends", "LineNumbersProcessor", "small", "required", "prefixes", "config", "number", "base", "processor", "ends", "with", "ensures", "during", "processors", "lines", "count", "inline"], "ast_kind": "function_or_method", "text": "    def ignore_line_number_blocks(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                raw_text = block.raw_text(document)\n                tokens = raw_text.strip().split()\n                if len(tokens) < 4:\n                    continue\n\n                tokens_are_numbers = [token.isdigit() for token in tokens]\n                if all([\n                    sum(tokens_are_numbers) / len(tokens) > self.strip_numbers_threshold,\n                    block.polygon.height > block.polygon.width  # Ensure block is taller than it is wide, like vertical page numbers\n                ]):\n                    block.ignore_for_output = True\n", "n_tokens": 134, "byte_len": 735, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 61, "end_line": 75}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_numbers.py", "rel_path": "marker/processors/line_numbers.py", "module": "marker.processors.line_numbers", "ext": "py", "chunk_number": 6, "symbols": ["ignore_line_starts_ends", "none", "contained", "blocks", "text", "starts", "with", "ignore", "for", "raw", "min", "line", "document", "append", "self", "spans", "ends", "all", "lines", "get", "block", "types", "strip", "structure", "pages", "continue", "false", "page", "span", "true", "__init__", "__call__", "ignore_line_number_spans", "ignore_line_number_blocks", "LineNumbersProcessor", "small", "required", "prefixes", "config", "number", "wide", "base", "processor", "ensures", "during", "than", "processors", "count", "inline", "marker"], "ast_kind": "function_or_method", "text": "    def ignore_line_starts_ends(self, document: Document):\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is None:\n                    continue\n\n                all_lines = block.structure_blocks(document)\n                if len(all_lines) < self.min_lines_in_block:\n                    continue\n\n                starts_with_number = []\n                ends_with_number = []\n                for line in all_lines:\n                    spans = line.structure_blocks(document)\n                    if len(spans) < 2:\n                        starts_with_number.append(False)\n                        ends_with_number.append(False)\n                        continue\n\n                    raw_text = line.raw_text(document)\n                    starts = all([\n                        spans[0].text.strip().isdigit(),\n                        len(raw_text) - len(spans[0].text.strip()) > self.min_line_length\n                    ])\n\n                    ends = all([\n                        spans[-1].text.strip().isdigit(),\n                        len(raw_text) - len(spans[-1].text.strip()) > self.min_line_length\n                    ])\n\n                    starts_with_number.append(starts)\n                    ends_with_number.append(ends)\n\n                if sum(starts_with_number) / len(starts_with_number) > self.strip_numbers_threshold:\n                    for starts, line in zip(starts_with_number, all_lines):\n                        if starts:\n                            span = page.get_block(line.structure[0])\n                            span.ignore_for_output = True\n\n                if sum(ends_with_number) / len(ends_with_number) > self.strip_numbers_threshold:\n                    for ends, line in zip(ends_with_number, all_lines):\n                        if ends:\n                            span = page.get_block(line.structure[-1])\n                            span.ignore_for_output = True\n", "n_tokens": 341, "byte_len": 2001, "file_sha1": "24ba746da6f7adb4cdf33ea7e963fb3a349e41ed", "start_line": 76, "end_line": 120}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py", "rel_path": "marker/processors/blank_page.py", "module": "marker.processors.blank_page", "ext": "py", "chunk_number": 1, "symbols": ["BlankPageProcessor", "image", "class", "remove", "detect", "float", "blocks", "get", "logger", "numpy", "images", "annotated", "document", "schema", "filter", "from", "layout", "processor", "base", "blank", "page", "single", "processors", "threshold", "typing", "block", "types", "pages", "full", "import", "is_blank", "__call__", "shape", "background", "adaptive", "zeros", "like", "labels", "return", "case", "gaussian", "blur", "continue", "bool", "skip", "marker", "num", "dilate", "gray", "true"], "ast_kind": "class_or_type", "text": "from typing import Annotated\n\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.schema.document import Document\n\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n\nclass BlankPageProcessor(BaseProcessor):\n    \"\"\"\n    A processor to filter out blank pages detected as a single layout block\n    \"\"\"\n\n    full_page_block_intersection_threshold: Annotated[\n        float, \"Threshold to detect blank pages at\"\n    ] = 0.8\n    filter_blank_pages: Annotated[bool, \"Remove blank pages detected as images.\"] = (\n        False\n    )\n", "n_tokens": 141, "byte_len": 669, "file_sha1": "ffcce2dac8d3cc921996133ec704ae110a92976a", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py", "rel_path": "marker/processors/blank_page.py", "module": "marker.processors.blank_page", "ext": "py", "chunk_number": 2, "symbols": ["is_blank", "image", "text", "iterations", "shape", "background", "handle", "kernel", "uint", "uint8", "adaptive", "connectivity", "range", "inverse", "zeros", "like", "self", "labels", "asarray", "size", "cleaned", "stats", "return", "cvt", "color", "colo", "gray", "threshold", "case", "connected", "__call__", "BlankPageProcessor", "document", "filter", "base", "processor", "processors", "full", "page", "gaussian", "blur", "continue", "bool", "skip", "marker", "num", "dilate", "get", "true", "call"], "ast_kind": "function_or_method", "text": "    def is_blank(self, image: Image.Image):\n        image = np.asarray(image)\n        if image.size == 0 or image.shape[0] == 0 or image.shape[1] == 0:\n            # Handle empty image case\n            return True\n\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n\n        # Adaptive threshold (inverse for text as white)\n        binarized = cv2.adaptiveThreshold(\n            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 15\n        )\n\n        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n            binarized, connectivity=8\n        )\n        cleaned = np.zeros_like(binarized)\n        for i in range(1, num_labels):  # skip background\n            cleaned[labels == i] = 255\n\n        kernel = np.ones((1, 5), np.uint8)\n        dilated = cv2.dilate(cleaned, kernel, iterations=3)\n        b = dilated / 255\n        return b.sum() == 0\n", "n_tokens": 259, "byte_len": 935, "file_sha1": "ffcce2dac8d3cc921996133ec704ae110a92976a", "start_line": 29, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/blank_page.py", "rel_path": "marker/processors/blank_page.py", "module": "marker.processors.blank_page", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "block", "type", "removing", "document", "self", "intersection", "area", "return", "remove", "structure", "filter", "blank", "figure", "types", "picture", "pages", "full", "page", "logger", "removed", "conditions", "continue", "blocks", "polygon", "get", "image", "debug", "true", "call", "is_blank", "BlankPageProcessor", "shape", "background", "adaptive", "zeros", "like", "labels", "base", "processor", "case", "processors", "threshold", "gaussian", "blur", "bool", "skip", "marker", "num", "dilate"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        if not self.filter_blank_pages:\n            return\n\n        for page in document.pages:\n            structure_blocks = page.structure_blocks(document)\n            if not structure_blocks or len(structure_blocks) > 1:\n                continue\n\n            full_page_block: Block = structure_blocks[0]\n\n            conditions = [\n                full_page_block.block_type in [BlockTypes.Picture, BlockTypes.Figure],\n                self.is_blank(full_page_block.get_image(document)),\n                page.polygon.intersection_area(full_page_block.polygon)\n                > self.full_page_block_intersection_threshold,\n            ]\n\n            if all(conditions):\n                logger.debug(f\"Removing blank block {full_page_block.id}\")\n                page.remove_structure_items([full_page_block.id])\n                full_page_block.removed = True\n", "n_tokens": 164, "byte_len": 905, "file_sha1": "ffcce2dac8d3cc921996133ec704ae110a92976a", "start_line": 55, "end_line": 77}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py", "rel_path": "marker/processors/line_merge.py", "module": "marker.processors.line_merge", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "import", "document", "marker", "util", "list", "block", "schema", "text", "from", "processors", "matrix", "intersection", "line", "typing", "blocks", "base", "processor", "types", "__init__", "merge_lines", "__call__", "LineMergeProcessor", "pct", "footnote", "overlaps", "merge", "lines", "merged", "expand", "formats", "section", "header", "row", "horizontally", "config", "same", "return", "improve", "provider", "overlap", "only", "next", "continue", "bool", "inline", "total", "this", "caption", "llms"], "ast_kind": "imports", "text": "from typing import Annotated, List\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.schema.document import Document\nfrom marker.schema.text import Line\nfrom marker.util import matrix_intersection_area\n\n", "n_tokens": 52, "byte_len": 286, "file_sha1": "b6f5c588f8b871207e4efd93f5eea7391d08f0a9", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py", "rel_path": "marker/processors/line_merge.py", "module": "marker.processors.line_merge", "ext": "py", "chunk_number": 2, "symbols": ["LineMergeProcessor", "intersection", "pct", "class", "percentage", "inline", "footnote", "float", "amount", "min", "merge", "block", "expand", "between", "annotated", "section", "header", "merging", "vertical", "overlap", "concentrated", "whether", "processor", "base", "bounding", "area", "minimum", "math", "types", "text", "__init__", "merge_lines", "__call__", "matrix", "overlaps", "lines", "merged", "formats", "row", "horizontally", "document", "config", "same", "return", "processors", "improve", "provider", "only", "next", "continue"], "ast_kind": "class_or_type", "text": "class LineMergeProcessor(BaseProcessor):\n    \"\"\"\n    A processor for merging inline math lines.\n    \"\"\"\n    block_types = (BlockTypes.Text, BlockTypes.TextInlineMath, BlockTypes.Caption, BlockTypes.Footnote, BlockTypes.SectionHeader)\n    min_merge_pct: Annotated[\n        float,\n        \"The minimum percentage of intersection area to consider merging.\"\n    ] = .015\n    block_expand_threshold: Annotated[\n        float,\n        \"The percentage of the block width to expand the bounding box.\"\n    ] = .05\n    min_merge_ydist: Annotated[\n        float,\n        \"The minimum y distance between lines to consider merging.\"\n    ] = 5\n    intersection_pct_threshold: Annotated[\n        float,\n        \"The total amount of intersection area concentrated in the max intersection block.\"\n    ] = .5\n    vertical_overlap_pct_threshold: Annotated[\n        float,\n        \"The minimum percentage of vertical overlap to consider merging.\"\n    ] = .8\n    use_llm: Annotated[\n        bool,\n        \"Whether to use LLMs to improve accuracy.\"\n    ] = False\n", "n_tokens": 230, "byte_len": 1041, "file_sha1": "b6f5c588f8b871207e4efd93f5eea7391d08f0a9", "start_line": 11, "end_line": 40}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py", "rel_path": "marker/processors/line_merge.py", "module": "marker.processors.line_merge", "ext": "py", "chunk_number": 3, "symbols": ["__init__", "self", "config", "init", "super", "merge_lines", "__call__", "LineMergeProcessor", "intersection", "pct", "footnote", "matrix", "overlaps", "merge", "lines", "merged", "block", "expand", "formats", "section", "header", "row", "horizontally", "document", "base", "processor", "same", "return", "processors", "improve", "provider", "overlap", "only", "next", "continue", "bool", "text", "inline", "marker", "util", "total", "this", "caption", "llms", "page", "true", "min", "merges", "line", "amount"], "ast_kind": "function_or_method", "text": "    def __init__(self, config):\n        super().__init__(config)\n", "n_tokens": 16, "byte_len": 65, "file_sha1": "b6f5c588f8b871207e4efd93f5eea7391d08f0a9", "start_line": 41, "end_line": 43}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py", "rel_path": "marker/processors/line_merge.py", "module": "marker.processors.line_merge", "ext": "py", "chunk_number": 4, "symbols": ["merge_lines", "end", "bbox", "within", "remove", "intersection", "pct", "elif", "probably", "line", "start", "vertical", "overlap", "enough", "skip", "zero", "matrix", "overlaps", "anything", "like", "merge", "lines", "range", "merged", "block", "expand", "previous", "else", "formats", "row", "__init__", "__call__", "LineMergeProcessor", "footnote", "section", "header", "horizontally", "document", "config", "base", "processor", "same", "return", "processors", "improve", "provider", "only", "next", "continue", "bool"], "ast_kind": "function_or_method", "text": "    def merge_lines(self, lines: List[Line], block: Block):\n        lines = [l for l in lines if l.polygon.width * 5 > l.polygon.height]  # Skip vertical lines\n        line_bboxes = [l.polygon.expand(self.block_expand_threshold, 0).bbox for l in lines]  # Expand horizontally\n        intersections = matrix_intersection_area(line_bboxes, line_bboxes)\n\n        merges = []\n        merge = []\n        for i in range(len(line_bboxes)):\n            intersection_row = intersections[i]\n            intersection_row[i] = 0  # Zero out the current idx\n\n            if i < len(line_bboxes) - 1:\n                intersection_row[i+1] = 0 # Zero out the next idx, so we only evaluate merge from the left\n\n            if len(merge) == 0:\n                merge.append(i)\n                continue\n\n            # Zero out previous merge segments\n            merge_intersection = sum([intersection_row[m] for m in merge])\n            line_area = lines[i].polygon.area\n            intersection_pct = merge_intersection / max(1, line_area)\n\n            total_intersection = max(1, sum(intersection_row))\n\n            line_start = lines[merge[0]].polygon.y_start\n            line_end = lines[merge[0]].polygon.y_end\n\n            vertical_overlap_start = max(line_start, lines[i].polygon.y_start)\n            vertical_overlap_end = min(line_end, lines[i].polygon.y_end)\n            vertical_overlap = max(0, vertical_overlap_end - vertical_overlap_start)\n            vertical_overlap_pct = vertical_overlap / max(1, lines[i].polygon.height)\n\n            if all([\n                # Overlaps enough\n                intersection_pct >= self.min_merge_pct,\n                # Within same line\n                vertical_overlap_pct > self.vertical_overlap_pct_threshold,\n                # doesn't overlap with anything else\n                merge_intersection / total_intersection > self.intersection_pct_threshold\n            ]):\n                merge.append(i)\n            else:\n                merges.append(merge)\n                merge = []\n\n        if merge:\n            merges.append(merge)\n\n        merges = [m for m in merges if len(m) > 1]\n        merged = set()\n        for merge in merges:\n            merge = [m for m in merge if m not in merged]\n            if len(merge) < 2:\n                continue\n\n            line: Line = lines[merge[0]]\n            merged.add(merge[0])\n            for idx in merge[1:]:\n                other_line: Line = lines[idx]\n                line.merge(other_line)\n                block.structure.remove(other_line.id)\n                other_line.removed = True  # Mark line as removed\n                merged.add(idx)\n\n            # It is probably math if we are merging provider lines like this\n            if not line.formats:\n                line.formats = [\"math\"]\n            elif \"math\" not in line.formats:\n                line.formats.append(\"math\")\n\n", "n_tokens": 602, "byte_len": 2875, "file_sha1": "b6f5c588f8b871207e4efd93f5eea7391d08f0a9", "start_line": 44, "end_line": 115}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/line_merge.py", "rel_path": "marker/processors/line_merge.py", "module": "marker.processors.line_merge", "ext": "py", "chunk_number": 5, "symbols": ["__call__", "none", "contained", "blocks", "inline", "skip", "line", "merge", "lines", "document", "self", "return", "single", "math", "block", "types", "structure", "needed", "pages", "only", "continue", "merging", "page", "use", "llm", "call", "__init__", "merge_lines", "LineMergeProcessor", "intersection", "pct", "footnote", "matrix", "overlaps", "merged", "expand", "formats", "section", "header", "row", "horizontally", "config", "base", "processor", "same", "processors", "improve", "provider", "overlap", "next"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        # Merging lines only needed for inline math\n        if not self.use_llm:\n            return\n\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                if block.structure is None:\n                    continue\n\n                if not len(block.structure) >= 2:  # Skip single lines\n                    continue\n\n                lines = block.contained_blocks(document, (BlockTypes.Line,))\n                self.merge_lines(lines, block)\n", "n_tokens": 106, "byte_len": 556, "file_sha1": "b6f5c588f8b871207e4efd93f5eea7391d08f0a9", "start_line": 116, "end_line": 131}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py", "rel_path": "marker/processors/sectionheader.py", "module": "marker.processors.sectionheader", "ext": "py", "chunk_number": 1, "symbols": ["sklearn", "about", "numpy", "exceptions", "warnings", "annotated", "document", "schema", "filterwarnings", "converging", "from", "base", "processor", "dict", "cluster", "list", "means", "kmeans", "processors", "ignore", "typing", "block", "types", "import", "marker", "warning", "convergence", "category", "__call__", "bucket_headings", "SectionHeaderProcessor", "iterate", "header", "data", "labels", "default", "level", "heading", "ranges", "break", "section", "max", "height", "count", "same", "return", "mean", "sorted", "children", "unique"], "ast_kind": "imports", "text": "import warnings\nfrom typing import Annotated, Dict, List\n\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.exceptions import ConvergenceWarning\n\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n# Ignore sklearn warning about not converging\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n\n", "n_tokens": 76, "byte_len": 399, "file_sha1": "ad02a9f6688b81dab0448bd2e088461bb8be2ba3", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py", "rel_path": "marker/processors/sectionheader.py", "module": "marker.processors.sectionheader", "ext": "py", "chunk_number": 2, "symbols": ["SectionHeaderProcessor", "class", "default", "level", "headers", "float", "group", "between", "annotated", "section", "header", "count", "document", "levels", "processor", "base", "same", "height", "tolerance", "minimum", "block", "types", "heading", "merge", "threshold", "number", "part", "detected", "them", "recognizing", "__call__", "bucket_headings", "iterate", "data", "labels", "ranges", "about", "break", "exceptions", "warnings", "max", "converging", "return", "mean", "sorted", "children", "means", "kmeans", "unique", "processors"], "ast_kind": "class_or_type", "text": "class SectionHeaderProcessor(BaseProcessor):\n    \"\"\"\n    A processor for recognizing section headers in the document.\n    \"\"\"\n    block_types = (BlockTypes.SectionHeader, )\n    level_count: Annotated[\n        int,\n        \"The number of levels to use for headings.\",\n    ] = 4\n    merge_threshold: Annotated[\n        float,\n        \"The minimum gap between headings to consider them part of the same group.\",\n    ] = 0.25\n    default_level: Annotated[\n        int,\n        \"The default heading level to use if no heading level is detected.\",\n    ] = 2\n    height_tolerance: Annotated[\n        float,\n        \"The minimum height of a heading to consider it a heading.\",\n    ] = 0.99\n", "n_tokens": 157, "byte_len": 682, "file_sha1": "ad02a9f6688b81dab0448bd2e088461bb8be2ba3", "start_line": 16, "end_line": 37}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py", "rel_path": "marker/processors/sectionheader.py", "module": "marker.processors.sectionheader", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "block", "type", "iterate", "header", "line", "heights", "none", "min", "height", "default", "level", "headers", "float", "heading", "ranges", "break", "ignore", "for", "else", "max", "document", "self", "flat", "dict", "children", "tolerance", "types", "structure", "enumerate", "bucket_headings", "SectionHeaderProcessor", "data", "labels", "about", "exceptions", "warnings", "section", "count", "converging", "base", "processor", "same", "return", "mean", "sorted", "means", "kmeans", "unique", "processors"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        line_heights: Dict[int, float] = {}\n        for page in document.pages:\n            # Iterate children to grab all section headers\n            for block in page.children:\n                if block.block_type not in self.block_types:\n                    continue\n                if block.structure is not None:\n                    line_heights[block.id] = block.line_height(document)\n                else:\n                    line_heights[block.id] = 0\n                    block.ignore_for_output = True  # Don't output an empty section header\n\n        flat_line_heights = list(line_heights.values())\n        heading_ranges = self.bucket_headings(flat_line_heights)\n\n        for page in document.pages:\n            # Iterate children to grab all section headers\n            for block in page.children:\n                if block.block_type not in self.block_types:\n                    continue\n                block_height = line_heights.get(block.id, 0)\n                if block_height > 0:\n                    for idx, (min_height, max_height) in enumerate(heading_ranges):\n                        if block_height >= min_height * self.height_tolerance:\n                            block.heading_level = idx + 1\n                            break\n\n                if block.heading_level is None:\n                    block.heading_level = self.default_level\n", "n_tokens": 258, "byte_len": 1405, "file_sha1": "ad02a9f6688b81dab0448bd2e088461bb8be2ba3", "start_line": 38, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/sectionheader.py", "rel_path": "marker/processors/sectionheader.py", "module": "marker.processors.sectionheader", "ext": "py", "chunk_number": 4, "symbols": ["bucket_headings", "init", "axis", "random", "state", "fit", "predict", "line", "heights", "data", "labels", "none", "float", "heading", "ranges", "prev", "cluster", "means", "mean", "else", "label", "auto", "level", "count", "append", "self", "num", "levels", "asarray", "reverse", "__call__", "SectionHeaderProcessor", "iterate", "header", "default", "about", "break", "exceptions", "warnings", "section", "max", "height", "document", "converging", "base", "processor", "same", "return", "sorted", "children"], "ast_kind": "function_or_method", "text": "    def bucket_headings(self, line_heights: List[float], num_levels=4):\n        if len(line_heights) <= self.level_count:\n            return []\n\n        data = np.asarray(line_heights).reshape(-1, 1)\n        labels = KMeans(n_clusters=num_levels, random_state=0, n_init=\"auto\").fit_predict(data)\n        data_labels = np.concatenate([data, labels.reshape(-1, 1)], axis=1)\n        data_labels = np.sort(data_labels, axis=0)\n\n        cluster_means = {int(label): float(np.mean(data_labels[data_labels[:, 1] == label, 0])) for label in np.unique(labels)}\n        label_max = None\n        label_min = None\n        heading_ranges = []\n        prev_cluster = None\n        for row in data_labels:\n            value, label = row\n            value = float(value)\n            label = int(label)\n            if prev_cluster is not None and label != prev_cluster:\n                prev_cluster_mean = cluster_means[prev_cluster]\n                cluster_mean = cluster_means[label]\n                if cluster_mean * self.merge_threshold < prev_cluster_mean:\n                    heading_ranges.append((label_min, label_max))\n                    label_min = None\n                    label_max = None\n\n            label_min = value if label_min is None else min(label_min, value)\n            label_max = value if label_max is None else max(label_max, value)\n            prev_cluster = label\n\n        if label_min is not None:\n            heading_ranges.append((label_min, label_max))\n\n        heading_ranges = sorted(heading_ranges, reverse=True)\n\n        return heading_ranges\n", "n_tokens": 333, "byte_len": 1561, "file_sha1": "ad02a9f6688b81dab0448bd2e088461bb8be2ba3", "start_line": 69, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py", "rel_path": "marker/processors/llm/llm_meta.py", "module": "marker.processors.llm.llm_meta", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "LLMSimpleBlockMetaProcessor", "services", "class", "init", "none", "futures", "base", "llm", "get", "logger", "service", "document", "schema", "self", "processor", "lst", "config", "from", "dict", "parallel", "super", "list", "processors", "they", "typing", "wrapper", "import", "marker", "simple", "__call__", "get_response", "exception", "prompt", "map", "disable", "tqdm", "desc", "max", "concurrency", "pending", "running", "future", "data", "image", "append", "result", "finalize", "all", "prompts"], "ast_kind": "class_or_type", "text": "from concurrent.futures import ThreadPoolExecutor\nfrom typing import List, Dict, Any\n\nfrom marker.logger import get_logger\nfrom tqdm import tqdm\n\nfrom marker.processors.llm import BaseLLMSimpleBlockProcessor, BaseLLMProcessor\nfrom marker.schema.document import Document\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n\nclass LLMSimpleBlockMetaProcessor(BaseLLMProcessor):\n    \"\"\"\n    A wrapper for simple LLM processors, so they can all run in parallel.\n    \"\"\"\n\n    def __init__(\n        self,\n        processor_lst: List[BaseLLMSimpleBlockProcessor],\n        llm_service: BaseService,\n        config=None,\n    ):\n        super().__init__(llm_service, config)\n        self.processors = processor_lst\n", "n_tokens": 152, "byte_len": 717, "file_sha1": "c4e38fac62e16da43ee2e6e61c69101a8dfe0000", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py", "rel_path": "marker/processors/llm/llm_meta.py", "module": "marker.processors.llm.llm_meta", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "exception", "prompt", "futures", "map", "disable", "tqdm", "none", "desc", "max", "concurrency", "pending", "base", "llm", "running", "service", "future", "data", "document", "append", "self", "finalize", "result", "processor", "all", "prompts", "block", "return", "except", "pbar", "__init__", "get_response", "LLMSimpleBlockMetaProcessor", "services", "class", "init", "get", "logger", "image", "schema", "lst", "config", "from", "dict", "parallel", "super", "list", "call", "processors", "inference"], "ast_kind": "function_or_method", "text": "    def __call__(self, document: Document):\n        if not self.use_llm or self.llm_service is None:\n            return\n\n        total = sum(\n            [len(processor.inference_blocks(document)) for processor in self.processors]\n        )\n        pbar = tqdm(\n            desc=\"LLM processors running\", disable=self.disable_tqdm, total=total\n        )\n\n        all_prompts = [\n            processor.block_prompts(document) for processor in self.processors\n        ]\n        pending = []\n        futures_map = {}\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for i, prompt_lst in enumerate(all_prompts):\n                for prompt in prompt_lst:\n                    future = executor.submit(self.get_response, prompt)\n                    pending.append(future)\n                    futures_map[future] = {\"processor_idx\": i, \"prompt_data\": prompt}\n\n            for future in pending:\n                try:\n                    result = future.result()\n                    future_data = futures_map.pop(future)\n                    processor: BaseLLMSimpleBlockProcessor = self.processors[\n                        future_data[\"processor_idx\"]\n                    ]\n                    # finalize the result\n                    processor(result, future_data[\"prompt_data\"], document)\n                except Exception as e:\n                    logger.warning(f\"Error processing LLM response: {e}\")\n\n                pbar.update(1)\n\n        pbar.close()\n", "n_tokens": 278, "byte_len": 1491, "file_sha1": "c4e38fac62e16da43ee2e6e61c69101a8dfe0000", "start_line": 28, "end_line": 66}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_meta.py", "rel_path": "marker/processors/llm/llm_meta.py", "module": "marker.processors.llm.llm_meta", "ext": "py", "chunk_number": 3, "symbols": ["get_response", "image", "prompt", "schema", "self", "data", "block", "llm", "service", "return", "get", "response", "dict", "__init__", "__call__", "LLMSimpleBlockMetaProcessor", "exception", "services", "class", "init", "futures", "map", "disable", "tqdm", "none", "desc", "max", "concurrency", "base", "pending", "running", "logger", "future", "document", "processor", "lst", "config", "append", "result", "from", "finalize", "all", "prompts", "parallel", "super", "list", "call", "except", "pbar", "processors"], "ast_kind": "function_or_method", "text": "    def get_response(self, prompt_data: Dict[str, Any]):\n        return self.llm_service(\n            prompt_data[\"prompt\"],\n            prompt_data[\"image\"],\n            prompt_data[\"block\"],\n            prompt_data[\"schema\"],\n        )\n", "n_tokens": 47, "byte_len": 238, "file_sha1": "c4e38fac62e16da43ee2e6e61c69101a8dfe0000", "start_line": 67, "end_line": 74}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 1, "symbols": ["tuple", "blocks", "get", "logger", "pydantic", "document", "base", "llm", "schema", "from", "model", "list", "processors", "typing", "json", "block", "types", "import", "marker", "groups", "tqdm", "page", "group", "get_selected_blocks", "process_rewriting", "load_blocks", "rewrite_blocks", "LLMSectionHeaderProcessor", "BlockSchema", "SectionHeaderSchema", "header", "normalize", "process", "section", "make", "goal", "selected", "addition", "dict", "handle", "rewrites", "correct", "carefully", "return", "identify", "pbar", "replace", "approximate", "rewriting", "been"], "ast_kind": "imports", "text": "import json\nfrom typing import List, Tuple\n\nfrom tqdm import tqdm\n\nfrom marker.logger import get_logger\nfrom marker.processors.llm import BaseLLMComplexBlockProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\nfrom pydantic import BaseModel\n\nlogger = get_logger()\n\n", "n_tokens": 77, "byte_len": 385, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 2, "symbols": ["LLMSectionHeaderProcessor", "header", "section", "make", "goal", "document", "llm", "addition", "correct", "carefully", "identify", "approximate", "been", "tags", "output", "only", "their", "along", "this", "number", "normalized", "documents", "right", "page", "text", "vector", "accurately", "blocks", "analysis", "levels", "get_selected_blocks", "process_rewriting", "load_blocks", "rewrite_blocks", "BlockSchema", "SectionHeaderSchema", "normalize", "block", "process", "selected", "dict", "handle", "rewrites", "return", "pbar", "replace", "processors", "rewriting", "marker", "isinstance"], "ast_kind": "class_or_type", "text": "class LLMSectionHeaderProcessor(BaseLLMComplexBlockProcessor):\n    page_prompt = \"\"\"You're a text correction expert specializing in accurately analyzing complex PDF documents. You will be given a list of all of the section headers from a document, along with their page number and approximate dimensions.  The headers will be formatted like below, and will be presented in order.\n\n```json\n[\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"width\": x2 - x1,\n        \"height\": y2 - y1,\n        \"page\": 0,\n        \"id\": \"/page/0/SectionHeader/1\",\n        \"html\": \"<h1>Introduction</h1>\",\n    }, ...\n]\n```\n\nBboxes have been normalized to 0-1000.\n\nYour goal is to make sure that the section headers have the correct levels (h1, h2, h3, h4, h5, or h6).  If a section header does not have the right level, edit the html to fix it.\n\nGuidelines:\n- Edit the blocks to ensure that the section headers have the correct levels.\n- Only edit the h1, h2, h3, h4, h5, and h6 tags.  Do not change any other tags or content in the headers.\n- Only output the headers that changed (if nothing changed, output nothing).\n- Every header you output needs to have one and only one level tag (h1, h2, h3, h4, h5, or h6).\n\n**Instructions:**\n1. Carefully examine the provided section headers and JSON.\n2. Identify any changes you'll need to make, and write a short analysis.\n3. Output \"no_corrections\", or \"corrections_needed\", depending on whether you need to make changes.\n4. If corrections are needed, output any blocks that need updates.  Only output the block ids and html, like this:\n        ```json\n        [\n            {\n                \"id\": \"/page/0/SectionHeader/1\",\n                \"html\": \"<h2>Introduction</h2>\"\n            },\n            ...\n        ]\n        ```\n\n**Example:**\nInput:\nSection Headers\n```json\n[\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"id\": \"/page/0/SectionHeader/1\",\n        \"page\": 0,\n        \"html\": \"1 Vector Operations\",\n    },\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"id\": \"/page/0/SectionHeader/2\",\n        \"page\": 0,\n        \"html\": \"1.1 Vector Addition\",\n    },\n]\n```\nOutput:\nAnalysis: The first section header is missing the h1 tag, and the second section header is missing the h2 tag.\n```json\n[\n    {\n        \"id\": \"/page/0/SectionHeader/1\",\n        \"html\": \"<h1>1 Vector Operations</h1>\"\n    },\n    {\n        \"id\": \"/page/0/SectionHeader/2\",\n        \"html\": \"<h2>1.1 Vector Addition</h2>\"\n    }\n]\n```\n\n**Input:**\nSection Headers\n```json\n{{section_header_json}}\n```\n\"\"\"\n", "n_tokens": 691, "byte_len": 2500, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 17, "end_line": 98}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 3, "symbols": ["get_selected_blocks", "document", "structure", "blocks", "list", "normalize", "block", "self", "selected", "dict", "page", "enumerate", "get", "json", "return", "group", "process_rewriting", "load_blocks", "rewrite_blocks", "LLMSectionHeaderProcessor", "BlockSchema", "SectionHeaderSchema", "header", "process", "section", "make", "goal", "llm", "addition", "handle", "rewrites", "correct", "carefully", "identify", "pbar", "replace", "approximate", "processors", "rewriting", "been", "tags", "output", "only", "their", "marker", "along", "number", "this", "isinstance", "total"], "ast_kind": "function_or_method", "text": "    def get_selected_blocks(\n        self,\n        document: Document,\n        page: PageGroup,\n    ) -> List[dict]:\n        selected_blocks = page.structure_blocks(document)\n        json_blocks = [\n            self.normalize_block_json(block, document, page, i)\n            for i, block in enumerate(selected_blocks)\n        ]\n        return json_blocks\n", "n_tokens": 71, "byte_len": 355, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 99, "end_line": 110}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 4, "symbols": ["process_rewriting", "block", "type", "bbox", "prompt", "split", "correction", "header", "load", "blocks", "none", "tuple", "headers", "llm", "service", "document", "self", "corrections", "from", "since", "dict", "valid", "handle", "rewrites", "height", "return", "list", "page", "dumps", "replace", "get_selected_blocks", "load_blocks", "rewrite_blocks", "LLMSectionHeaderProcessor", "BlockSchema", "SectionHeaderSchema", "normalize", "process", "section", "make", "goal", "selected", "addition", "correct", "carefully", "identify", "pbar", "approximate", "processors", "rewriting"], "ast_kind": "function_or_method", "text": "    def process_rewriting(\n        self, document: Document, section_headers: List[Tuple[Block, dict]]\n    ):\n        section_header_json = [sh[1] for sh in section_headers]\n        for item in section_header_json:\n            _, _, page_id, block_type, block_id = item[\"id\"].split(\"/\")\n            item[\"page\"] = page_id\n            item[\"width\"] = item[\"bbox\"][2] - item[\"bbox\"][0]\n            item[\"height\"] = item[\"bbox\"][3] - item[\"bbox\"][1]\n            del item[\"block_type\"]  # Not needed, since they're all section headers\n\n        prompt = self.page_prompt.replace(\n            \"{{section_header_json}}\", json.dumps(section_header_json)\n        )\n        response = self.llm_service(\n            prompt, None, document.pages[0], SectionHeaderSchema\n        )\n        logger.debug(f\"Got section header reponse from LLM: {response}\")\n\n        if not response or \"correction_type\" not in response:\n            logger.warning(\"LLM did not return a valid response\")\n            return\n\n        correction_type = response[\"correction_type\"]\n        if correction_type == \"no_corrections\":\n            return\n\n        self.load_blocks(response)\n        self.handle_rewrites(response[\"blocks\"], document)\n", "n_tokens": 268, "byte_len": 1206, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 111, "end_line": 140}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 5, "symbols": ["load_blocks", "rewrite_blocks", "BlockSchema", "block", "type", "class", "running", "normalize", "load", "blocks", "disable", "tqdm", "desc", "process", "show", "section", "header", "progress", "html", "document", "self", "name", "return", "base", "model", "there", "pbar", "rewriting", "json", "types", "get_selected_blocks", "process_rewriting", "LLMSectionHeaderProcessor", "SectionHeaderSchema", "make", "goal", "selected", "llm", "addition", "dict", "handle", "rewrites", "correct", "carefully", "identify", "replace", "approximate", "processors", "been", "tags"], "ast_kind": "class_or_type", "text": "    def load_blocks(self, response):\n        if isinstance(response[\"blocks\"], str):\n            response[\"blocks\"] = json.loads(response[\"blocks\"])\n\n    def rewrite_blocks(self, document: Document):\n        # Don't show progress if there are no blocks to process\n        section_headers = [\n            (block, self.normalize_block_json(block, document, page))\n            for page in document.pages\n            for block in page.structure_blocks(document)\n            if block.block_type == BlockTypes.SectionHeader\n        ]\n        if len(section_headers) == 0:\n            return\n\n        pbar = tqdm(\n            total=1,\n            desc=f\"Running {self.__class__.__name__}\",\n            disable=self.disable_tqdm,\n        )\n\n        self.process_rewriting(document, section_headers)\n        pbar.update(1)\n        pbar.close()\n\n\nclass BlockSchema(BaseModel):\n    id: str\n    html: str\n\n", "n_tokens": 186, "byte_len": 894, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 141, "end_line": 171}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_sectionheader.py", "rel_path": "marker/processors/llm/llm_sectionheader.py", "module": "marker.processors.llm.llm_sectionheader", "ext": "py", "chunk_number": 6, "symbols": ["SectionHeaderSchema", "correction", "type", "base", "model", "class", "block", "schema", "list", "section", "header", "blocks", "analysis", "get_selected_blocks", "process_rewriting", "load_blocks", "rewrite_blocks", "LLMSectionHeaderProcessor", "BlockSchema", "normalize", "process", "make", "goal", "document", "selected", "llm", "addition", "dict", "handle", "rewrites", "correct", "carefully", "return", "identify", "pbar", "replace", "approximate", "processors", "rewriting", "been", "tags", "page", "output", "only", "their", "marker", "along", "number", "this", "isinstance"], "ast_kind": "class_or_type", "text": "class SectionHeaderSchema(BaseModel):\n    analysis: str\n    correction_type: str\n    blocks: List[BlockSchema]\n", "n_tokens": 26, "byte_len": 111, "file_sha1": "a4a0ac59448f52f68a541076c8baab4252e22944", "start_line": 172, "end_line": 176}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 1, "symbols": ["PromptData", "BlockData", "image", "prompt", "services", "class", "completed", "assign", "config", "none", "traceback", "block", "data", "futures", "blocks", "get", "logger", "additional", "annotated", "pydantic", "document", "schema", "from", "dict", "json", "html", "base", "processor", "typed", "sequence", "__init__", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "expansion", "normalize", "process", "parsing", "exceptions"], "ast_kind": "class_or_type", "text": "import json\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import Annotated, TypedDict, List, Sequence\n\nfrom pydantic import BaseModel\nfrom tqdm import tqdm\nfrom PIL import Image\n\nfrom marker.output import json_to_html\nfrom marker.processors import BaseProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, BlockId\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\nfrom marker.services import BaseService\nfrom marker.util import assign_config\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n\nclass PromptData(TypedDict):\n    prompt: str\n    image: Image.Image\n    block: Block\n    schema: BaseModel\n    page: PageGroup\n    additional_data: dict | None\n\n\nclass BlockData(TypedDict):\n    page: PageGroup\n    block: Block\n\n", "n_tokens": 180, "byte_len": 849, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 1, "end_line": 36}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 2, "symbols": ["__init__", "BaseLLMProcessor", "class", "image", "expansion", "init", "disable", "tqdm", "none", "max", "concurrency", "model", "gemini", "float", "blocks", "llm", "service", "annotated", "make", "base", "progress", "self", "config", "whether", "processor", "convert", "return", "cropping", "when", "super", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "completed", "normalize", "block", "traceback", "futures"], "ast_kind": "class_or_type", "text": "class BaseLLMProcessor(BaseProcessor):\n    \"\"\"\n    A processor for using LLMs to convert blocks.\n    \"\"\"\n\n    max_concurrency: Annotated[\n        int,\n        \"The maximum number of concurrent requests to make to the Gemini model.\",\n    ] = 3\n    image_expansion_ratio: Annotated[\n        float,\n        \"The ratio to expand the image by when cropping.\",\n    ] = 0.01\n    use_llm: Annotated[\n        bool,\n        \"Whether to use the LLM model.\",\n    ] = False\n    disable_tqdm: Annotated[\n        bool,\n        \"Whether to disable the tqdm progress bar.\",\n    ] = False\n    block_types = None\n\n    def __init__(self, llm_service: BaseService, config=None):\n        super().__init__(config)\n\n        self.llm_service = None\n        if not self.use_llm:\n            return\n\n        self.llm_service = llm_service\n", "n_tokens": 199, "byte_len": 812, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 37, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 3, "symbols": ["extract_image", "sequence", "image", "document", "block", "expansion", "self", "none", "get", "remove", "blocks", "highres", "types", "true", "return", "extract", "__init__", "normalize_block_json", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "completed", "normalize", "traceback", "futures", "process", "parsing", "exceptions", "make", "base", "llm", "found", "config", "result", "dict", "future", "processor", "handle", "rewrites"], "ast_kind": "function_or_method", "text": "    def extract_image(\n        self,\n        document: Document,\n        image_block: Block,\n        remove_blocks: Sequence[BlockTypes] | None = None,\n    ) -> Image.Image:\n        return image_block.get_image(\n            document,\n            highres=True,\n            expansion=(self.image_expansion_ratio, self.image_expansion_ratio),\n            remove_blocks=remove_blocks,\n        )\n", "n_tokens": 78, "byte_len": 391, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 69, "end_line": 81}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 4, "symbols": ["normalize_block_json", "block", "type", "bbox", "normalize", "json", "range", "html", "page", "group", "document", "self", "height", "return", "render", "normalized", "width", "polygon", "representation", "__init__", "extract_image", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "image", "expansion", "completed", "traceback", "futures", "process", "parsing", "exceptions", "make", "base", "llm", "found", "config", "remove", "blocks"], "ast_kind": "function_or_method", "text": "    def normalize_block_json(self, block: Block, document: Document, page: PageGroup):\n        \"\"\"\n        Get the normalized JSON representation of a block for the LLM.\n        \"\"\"\n        page_width = page.polygon.width\n        page_height = page.polygon.height\n        block_bbox = block.polygon.bbox\n\n        # Normalize bbox to 0-1000 range\n        normalized_bbox = [\n            (block_bbox[0] / page_width) * 1000,\n            (block_bbox[1] / page_height) * 1000,\n            (block_bbox[2] / page_width) * 1000,\n            (block_bbox[3] / page_height) * 1000,\n        ]\n\n        block_json = {\n            \"id\": str(block.id),\n            \"block_type\": str(block.id.block_type),\n            \"bbox\": normalized_bbox,\n            \"html\": json_to_html(block.render(document)),\n        }\n\n        return block_json\n", "n_tokens": 198, "byte_len": 823, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 82, "end_line": 106}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 5, "symbols": ["load_blocks", "handle_rewrites", "block", "type", "exception", "split", "data", "load", "blocks", "parsing", "html", "document", "found", "self", "lstrip", "dict", "handle", "rewrites", "return", "get", "except", "getattr", "strip", "blockid", "error", "json", "types", "page", "logger", "loads", "__init__", "extract_image", "normalize_block_json", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "image", "expansion", "completed", "normalize", "traceback", "futures"], "ast_kind": "function_or_method", "text": "    def load_blocks(self, response: dict):\n        return [json.loads(block) for block in response[\"blocks\"]]\n\n    def handle_rewrites(self, blocks: list, document: Document):\n        for block_data in blocks:\n            try:\n                block_id = block_data[\"id\"].strip().lstrip(\"/\")\n                _, page_id, block_type, block_id = block_id.split(\"/\")\n                block_id = BlockId(\n                    page_id=page_id,\n                    block_id=block_id,\n                    block_type=getattr(BlockTypes, block_type),\n                )\n                block = document.get_block(block_id)\n                if not block:\n                    logger.debug(f\"Block {block_id} not found in document\")\n                    continue\n\n                if hasattr(block, \"html\"):\n                    block.html = block_data[\"html\"]\n            except Exception as e:\n                logger.debug(f\"Error parsing block ID {block_data['id']}: {e}\")\n                continue\n\n", "n_tokens": 190, "byte_len": 981, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 107, "end_line": 131}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 6, "symbols": ["__call__", "process_rewriting", "BaseLLMComplexBlockProcessor", "exception", "logic", "class", "none", "blocks", "llm", "service", "more", "base", "complex", "page", "group", "document", "self", "processor", "name", "convert", "not", "implemented", "return", "except", "process", "rewriting", "error", "with", "logger", "raise", "__init__", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "rewrite_blocks", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMSimpleBlockProcessor", "image", "expansion", "completed", "normalize", "block", "traceback", "futures"], "ast_kind": "class_or_type", "text": "class BaseLLMComplexBlockProcessor(BaseLLMProcessor):\n    \"\"\"\n    A processor for using LLMs to convert blocks with more complex logic.\n    \"\"\"\n\n    def __call__(self, document: Document):\n        if not self.use_llm or self.llm_service is None:\n            return\n\n        try:\n            self.rewrite_blocks(document)\n        except Exception as e:\n            logger.warning(f\"Error rewriting blocks in {self.__class__.__name__}: {e}\")\n\n    def process_rewriting(self, document: Document, page: PageGroup, block: Block):\n        raise NotImplementedError()\n", "n_tokens": 121, "byte_len": 561, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 132, "end_line": 148}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 7, "symbols": ["rewrite_blocks", "completed", "disable", "tqdm", "contained", "blocks", "desc", "max", "concurrency", "process", "running", "show", "exceptions", "total", "progress", "document", "self", "result", "future", "name", "return", "class", "there", "block", "types", "pbar", "rewriting", "workers", "pages", "with", "__init__", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "inference_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "image", "expansion", "normalize", "traceback"], "ast_kind": "function_or_method", "text": "    def rewrite_blocks(self, document: Document):\n        # Don't show progress if there are no blocks to process\n        total_blocks = sum(\n            len(page.contained_blocks(document, self.block_types))\n            for page in document.pages\n        )\n        if total_blocks == 0:\n            return\n\n        pbar = tqdm(\n            total=total_blocks,\n            desc=f\"{self.__class__.__name__} running\",\n            disable=self.disable_tqdm\n        )\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for future in as_completed(\n                [\n                    executor.submit(self.process_rewriting, document, page, block)\n                    for page in document.pages\n                    for block in page.contained_blocks(document, self.block_types)\n                ]\n            ):\n                future.result()  # Raise exceptions if any occurred\n                pbar.update(1)\n\n        pbar.close()\n\n", "n_tokens": 183, "byte_len": 969, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 149, "end_line": 176}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 8, "symbols": ["__init__", "__call__", "inference_blocks", "BaseLLMSimpleBlockProcessor", "exception", "here", "class", "init", "assign", "config", "none", "override", "traceback", "block", "data", "contained", "blocks", "base", "llm", "document", "append", "self", "result", "since", "dict", "processor", "name", "convert", "return", "except", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "process_rewriting", "rewrite_blocks", "block_prompts", "rewrite_block", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "image", "expansion", "completed", "normalize", "futures", "process", "parsing", "exceptions"], "ast_kind": "class_or_type", "text": "class BaseLLMSimpleBlockProcessor(BaseLLMProcessor):\n    \"\"\"\n    A processor for using LLMs to convert single blocks.\n    \"\"\"\n\n    # Override init since we don't need an llmservice here\n    def __init__(self, config=None):\n        assign_config(self, config)\n\n    def __call__(self, result: dict, prompt_data: PromptData, document: Document):\n        try:\n            self.rewrite_block(result, prompt_data, document)\n        except Exception as e:\n            logger.warning(f\"Error rewriting block in {self.__class__.__name__}: {e}\")\n            traceback.print_exc()\n\n    def inference_blocks(self, document: Document) -> List[BlockData]:\n        blocks = []\n        for page in document.pages:\n            for block in page.contained_blocks(document, self.block_types):\n                blocks.append({\"page\": page, \"block\": block})\n        return blocks\n", "n_tokens": 186, "byte_len": 858, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 177, "end_line": 199}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/__init__.py", "rel_path": "marker/processors/llm/__init__.py", "module": "marker.processors.llm.__init__", "ext": "py", "chunk_number": 9, "symbols": ["block_prompts", "rewrite_block", "document", "list", "prompt", "data", "self", "rewrite", "block", "dict", "prompts", "not", "implemented", "raise", "response", "__init__", "extract_image", "normalize_block_json", "load_blocks", "handle_rewrites", "__call__", "process_rewriting", "rewrite_blocks", "inference_blocks", "PromptData", "BlockData", "BaseLLMProcessor", "BaseLLMComplexBlockProcessor", "BaseLLMSimpleBlockProcessor", "exception", "image", "expansion", "completed", "normalize", "traceback", "futures", "process", "parsing", "exceptions", "make", "base", "llm", "found", "config", "remove", "blocks", "result", "future", "processor", "handle"], "ast_kind": "function_or_method", "text": "    def block_prompts(self, document: Document) -> List[PromptData]:\n        raise NotImplementedError()\n\n    def rewrite_block(\n        self, response: dict, prompt_data: PromptData, document: Document\n    ):\n        raise NotImplementedError()\n", "n_tokens": 49, "byte_len": 246, "file_sha1": "fe4555aae31edf596214e6922002b8641541b479", "start_line": 200, "end_line": 207}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 1, "symbols": ["completed", "unwrap", "outer", "tuple", "futures", "blocks", "annotated", "pydantic", "document", "base", "llm", "schema", "from", "json", "html", "inline", "math", "model", "list", "processors", "typing", "block", "types", "output", "import", "marker", "groups", "concurrent", "tqdm", "thread", "rewrite_blocks", "get_block_text", "get_block_lines", "process_rewriting", "LLMMathBlockProcessor", "LLMTextSchema", "cannot", "analyze", "assume", "compare", "footnote", "reproducing", "process", "exists", "additional", "inlinemath", "exceptions", "image", "indentation", "spelling"], "ast_kind": "imports", "text": "from concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import List, Tuple, Annotated\n\nfrom pydantic import BaseModel\nfrom tqdm import tqdm\n\nfrom marker.output import json_to_html, unwrap_outer_tag\nfrom marker.processors.llm import BaseLLMComplexBlockProcessor\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, InlineMath\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\n\n", "n_tokens": 91, "byte_len": 458, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 1, "end_line": 15}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 2, "symbols": ["LLMMathBlockProcessor", "cannot", "analyze", "assume", "compare", "footnote", "reproducing", "inlinemath", "image", "indentation", "spelling", "section", "header", "middle", "document", "expression", "error", "handwritten", "then", "bold", "format", "correct", "carefully", "surround", "convert", "must", "href", "references", "inaccuracies", "case", "rewrite_blocks", "get_block_text", "get_block_lines", "process_rewriting", "LLMTextSchema", "completed", "math", "block", "futures", "process", "exists", "additional", "exceptions", "formats", "result", "future", "return", "page", "pbar", "replace"], "ast_kind": "class_or_type", "text": "class LLMMathBlockProcessor(BaseLLMComplexBlockProcessor):\n    redo_inline_math: Annotated[\n        bool,\n        \"If True, the inline math will be re-done, otherwise it will be left as is.\",\n    ] = False\n    inlinemath_min_ratio: Annotated[\n        float,\n        \"If more than this ratio of blocks are inlinemath blocks, assume everything has math.\",\n    ] = 0.4\n\n    block_types = (BlockTypes.TextInlineMath,)  # Primary block type\n    additional_block_types = (\n        BlockTypes.Text,\n        BlockTypes.Caption,\n        BlockTypes.SectionHeader,\n        BlockTypes.Footnote,\n    )  # Seconday, can also contain math\n\n    text_math_rewriting_prompt = \"\"\"You are a text correction expert specializing in accurately reproducing text from images.\nYou will receive an image of a text block and extracted text corresponding to the text in the image.\nYour task is to correct any errors in the extracted text, including math, formatting, and other inaccuracies, and output the corrected block in html format.  Stay as faithful to the text in the image as possible.\n\n**Instructions:**\n\n1. Carefully examine the provided text block image .\n2. Analyze the text that has been extracted from the block.\n3. Compare the extracted text to the corresponding text in the image.\n4. Write a short analysis of the text block, including any errors you see in the extracted text.\n5. If there are no errors in any of the extracted text, output \"No corrections needed\".\n6. Correct any errors in the extracted text, including:\n    * Inline math: Ensure all mathematical expressions are correctly formatted and rendered.  Surround them with <math>...</math> tags.  The math expressions should be rendered in simple, concise, KaTeX-compatible LaTeX.  Do not use $ or $$ as delimiters.\n    * If a math expression is not in LaTeX format, convert it to LaTeX format, and surround it with <math>...</math> tags.\n    * Formatting: Maintain consistent formatting with the text block image, including spacing, indentation, subscripts/superscripts, and special characters.  Use the <i>, <b>, <sup>, <sub>, and <span> tags to format the text as needed.\n    * Other inaccuracies:  If the image is handwritten then you may correct any spelling errors, or other discrepancies.\n    * Ensure lines wrap properly, and that newlines are not in the middle of sentences.\n7. Do not remove any formatting i.e bold, italics, math, superscripts, subscripts, etc from the extracted text unless it is necessary to correct an error.\n8. Output the corrected text in html format, as shown in the example below.  Only use the p, math, br, a, i, b, sup, sub, and span tags.\n9. You absolutely cannot remove any <a href='#...'>...</a> tags, those are extremely important for references and are coming directly from the document, you MUST always preserve them.\n\n**Example:**\n\nInput:\n```html\nAdversarial training (AT) <a href='#page-9-1'>[23]</a>, which aims to minimize the model's risk under the worst-case perturbations, \nis currently the most effective approach for improving the robustness of deep neural networks. For a given neural network f(x, w) \nwith parameters w, the optimization objective of AT can be formulated as follows:\n```\n\nOutput:\nanalysis: The inline math is not in LaTeX format and is not surrounded by <math>...</math> tags.\n```html\nAdversarial training <i>(AT)</i> <a href='#page-9-1'>[23]</a>, which aims to minimize the model's risk under the worst-case perturbations, is currently the most effective approach for improving the robustness of deep neural networks. For a given neural network <math>f(x, w)</math> with parameters <math>w</math>, the optimization objective of AT can be formulated as follows:\n```\n\n**Input:**\n```html\n{extracted_html}\n```\n\"\"\"\n", "n_tokens": 863, "byte_len": 3729, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 16, "end_line": 75}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 3, "symbols": ["rewrite_blocks", "assume", "completed", "math", "block", "footnote", "process", "additional", "exceptions", "formats", "section", "header", "document", "result", "future", "page", "inlinemath", "return", "pbar", "rewriting", "max", "workers", "continue", "total", "caption", "executor", "tqdm", "check", "disable", "blocks", "get_block_text", "get_block_lines", "process_rewriting", "LLMMathBlockProcessor", "LLMTextSchema", "cannot", "analyze", "compare", "futures", "reproducing", "exists", "image", "indentation", "spelling", "middle", "expression", "error", "handwritten", "then", "bold"], "ast_kind": "function_or_method", "text": "    def rewrite_blocks(self, document: Document):\n        if not self.redo_inline_math:\n            return\n\n        # Get inline math blocks\n        inline_blocks: List[InlineMath] = [\n            (page, block)\n            for page in document.pages\n            for block in page.contained_blocks(document, self.block_types)\n        ]\n\n        # Get other blocks with detected math in them\n        detected_blocks = [\n            (page, block)\n            for page in document.pages\n            for block in page.contained_blocks(\n                document,\n                (\n                    BlockTypes.Text,\n                    BlockTypes.Caption,\n                    BlockTypes.SectionHeader,\n                    BlockTypes.Footnote,\n                    BlockTypes.ListItem,\n                ),\n            )\n            if any(\n                [\n                    b.formats and \"math\" in b.formats\n                    for b in block.contained_blocks(document, (BlockTypes.Line,))\n                ]\n            )\n        ]\n\n        # If a page has enough math blocks, assume all blocks can contain math\n        additional_text_blocks = []\n        for page in document.pages:\n            # Check for inline math blocks\n            page_inlinemath_blocks = [\n                im for im in inline_blocks if im[0].page_id == page.page_id\n            ]\n            page_detected_blocks = [\n                db for db in detected_blocks if db[0].page_id == page.page_id\n            ]\n            math_block_count = len(page_inlinemath_blocks) + len(page_detected_blocks)\n\n            # Find all potential blocks\n            additional_blocks = page.contained_blocks(\n                document, self.additional_block_types + self.block_types\n            )\n\n            # Check if the ratio of math blocks to additional blocks is high enough\n            if (\n                math_block_count / max(1, len(additional_blocks))\n                < self.inlinemath_min_ratio\n            ):\n                continue\n\n            for b in additional_blocks:\n                if b not in detected_blocks and b not in inline_blocks:\n                    additional_text_blocks.append((page, b))\n\n        inference_blocks = inline_blocks + detected_blocks + additional_text_blocks\n\n        # Don't show progress if there are no blocks to process\n        total_blocks = len(inference_blocks)\n        if total_blocks == 0:\n            return\n\n        pbar = tqdm(\n            total=total_blocks,\n            desc=f\"{self.__class__.__name__} running\",\n            disable=self.disable_tqdm\n        )\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for future in as_completed(\n                [\n                    executor.submit(self.process_rewriting, document, b[0], b[1])\n                    for b in inference_blocks\n                ]\n            ):\n                future.result()  # Raise exceptions if any occurred\n                pbar.update(1)\n\n        pbar.close()\n", "n_tokens": 567, "byte_len": 2998, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 76, "end_line": 160}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 4, "symbols": ["get_block_text", "get_block_lines", "formatted", "text", "remove", "unwrap", "outer", "contained", "blocks", "tuple", "line", "exists", "html", "document", "get", "block", "self", "lines", "json", "return", "render", "types", "extracted", "list", "rewrite_blocks", "process_rewriting", "LLMMathBlockProcessor", "LLMTextSchema", "cannot", "analyze", "assume", "completed", "compare", "math", "futures", "footnote", "reproducing", "process", "additional", "inlinemath", "exceptions", "image", "indentation", "spelling", "section", "header", "formats", "middle", "expression", "result"], "ast_kind": "function_or_method", "text": "    def get_block_text(self, block: Block, document: Document) -> str:\n        html = json_to_html(block.render(document))\n        html = unwrap_outer_tag(html)  # Remove an outer p tag if it exists\n        return html\n\n    def get_block_lines(self, block: Block, document: Document) -> Tuple[list, list]:\n        text_lines = block.contained_blocks(document, (BlockTypes.Line,))\n        extracted_lines = [line.formatted_text(document) for line in text_lines]\n        return text_lines, extracted_lines\n", "n_tokens": 112, "byte_len": 504, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 161, "end_line": 170}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 5, "symbols": ["process_rewriting", "prompt", "llm", "error", "block", "text", "service", "image", "html", "page", "group", "document", "self", "lower", "extracted", "return", "get", "replace", "process", "rewriting", "needed", "extract", "corrected", "corrections", "math", "update", "metadata", "fine", "response", "rewrite_blocks", "get_block_text", "get_block_lines", "LLMMathBlockProcessor", "LLMTextSchema", "cannot", "analyze", "assume", "completed", "compare", "futures", "footnote", "reproducing", "exists", "additional", "inlinemath", "exceptions", "indentation", "spelling", "section", "header"], "ast_kind": "function_or_method", "text": "    def process_rewriting(self, document: Document, page: PageGroup, block: Block):\n        block_text = self.get_block_text(block, document)\n        prompt = self.text_math_rewriting_prompt.replace(\"{extracted_html}\", block_text)\n\n        image = self.extract_image(document, block)\n        response = self.llm_service(prompt, image, block, LLMTextSchema)\n\n        if not response or \"corrected_html\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        corrected_html = response[\"corrected_html\"]\n        if not corrected_html:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        # Block is fine\n        if \"no corrections needed\" in corrected_html.lower():\n            return\n\n        if len(corrected_html) < len(block_text) * 0.6:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        block.html = corrected_html\n\n", "n_tokens": 196, "byte_len": 920, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 171, "end_line": 197}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_mathblock.py", "rel_path": "marker/processors/llm/llm_mathblock.py", "module": "marker.processors.llm.llm_mathblock", "ext": "py", "chunk_number": 6, "symbols": ["LLMTextSchema", "base", "model", "class", "corrected", "html", "llm", "text", "analysis", "rewrite_blocks", "get_block_text", "get_block_lines", "process_rewriting", "LLMMathBlockProcessor", "cannot", "analyze", "assume", "completed", "compare", "math", "block", "futures", "footnote", "reproducing", "process", "exists", "additional", "inlinemath", "exceptions", "image", "indentation", "spelling", "section", "header", "formats", "middle", "document", "expression", "result", "future", "error", "handwritten", "then", "bold", "format", "correct", "carefully", "surround", "convert", "must"], "ast_kind": "class_or_type", "text": "class LLMTextSchema(BaseModel):\n    analysis: str\n    corrected_html: str\n", "n_tokens": 19, "byte_len": 74, "file_sha1": "3fd9b65215bc80e1c3744b5acc38ee14fda81637", "start_line": 198, "end_line": 201}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py", "rel_path": "marker/processors/llm/llm_form.py", "module": "marker.processors.llm.llm_form", "ext": "py", "chunk_number": 1, "symbols": ["import", "base", "model", "document", "marker", "pydantic", "list", "prompt", "data", "schema", "block", "from", "processors", "llm", "typing", "json", "html", "types", "output", "inference_blocks", "block_prompts", "rewrite_block", "LLMFormProcessor", "FormSchema", "cannot", "analyze", "compare", "reproducing", "image", "make", "form", "rewriting", "labels", "dict", "then", "format", "correct", "carefully", "prompts", "return", "children", "replace", "tags", "value", "only", "continue", "corrected", "partial", "either", "right"], "ast_kind": "imports", "text": "from typing import List\n\nfrom pydantic import BaseModel\n\nfrom marker.output import json_to_html\nfrom marker.processors.llm import PromptData, BaseLLMSimpleBlockProcessor, BlockData\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n", "n_tokens": 54, "byte_len": 264, "file_sha1": "4037f24573c716fdd6ca461f3cc2f79b6a528b3d", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py", "rel_path": "marker/processors/llm/llm_form.py", "module": "marker.processors.llm.llm_form", "ext": "py", "chunk_number": 2, "symbols": ["LLMFormProcessor", "cannot", "analyze", "compare", "reproducing", "image", "make", "form", "rewriting", "labels", "then", "format", "correct", "carefully", "tags", "value", "only", "either", "right", "span", "llm", "generate", "text", "tables", "accurately", "omit", "output", "between", "images", "contains", "inference_blocks", "block_prompts", "rewrite_block", "FormSchema", "document", "dict", "block", "prompts", "return", "schema", "children", "replace", "processors", "continue", "marker", "corrected", "html", "partial", "prompt", "data"], "ast_kind": "class_or_type", "text": "class LLMFormProcessor(BaseLLMSimpleBlockProcessor):\n    block_types = (BlockTypes.Form,)\n    form_rewriting_prompt = \"\"\"You are a text correction expert specializing in accurately reproducing text from images.\nYou will receive an image of a text block and an html representation of the form in the image.\nYour task is to correct any errors in the html representation, and format it properly.\nValues and labels should appear in html tables, with the labels on the left side, and values on the right.  Other text in the form can appear between the tables.  Only use the tags `table, p, span, i, b, th, td, tr, and div`.  Do not omit any text from the form - make sure everything is included in the html representation.  It should be as faithful to the original form as possible.\n**Instructions:**\n1. Carefully examine the provided form block image.\n2. Analyze the html representation of the form.\n3. Compare the html representation to the image.\n4. If the html representation is correct, or you cannot read the image properly, then write \"No corrections needed.\"\n5. If the html representation contains errors, generate the corrected html representation.\n6. Output only either the corrected html representation or \"No corrections needed.\"\n**Example:**\nInput:\n```html\n<table>\n    <tr>\n        <td>Label 1</td>\n        <td>Label 2</td>\n        <td>Label 3</td>\n    </tr>\n    <tr>\n        <td>Value 1</td>\n        <td>Value 2</td>\n        <td>Value 3</td>\n    </tr>\n</table> \n```\nOutput:\nComparison: The html representation has the labels in the first row and the values in the second row.  It should be corrected to have the labels on the left side and the values on the right side.\n```html\n<table>\n    <tr>\n        <td>Label 1</td>\n        <td>Value 1</td>\n    </tr>\n    <tr>\n        <td>Label 2</td>\n        <td>Value 2</td>\n    </tr>\n    <tr>\n        <td>Label 3</td>\n        <td>Value 3</td>\n    </tr>\n</table>\n```\n**Input:**\n```html\n{block_html}\n```\n\"\"\"\n", "n_tokens": 507, "byte_len": 1955, "file_sha1": "4037f24573c716fdd6ca461f3cc2f79b6a528b3d", "start_line": 12, "end_line": 64}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py", "rel_path": "marker/processors/llm/llm_form.py", "module": "marker.processors.llm.llm_form", "ext": "py", "chunk_number": 3, "symbols": ["inference_blocks", "continue", "out", "blocks", "document", "super", "block", "data", "list", "children", "append", "self", "contained", "inference", "table", "cell", "types", "return", "block_prompts", "rewrite_block", "LLMFormProcessor", "FormSchema", "cannot", "analyze", "compare", "reproducing", "image", "make", "form", "rewriting", "labels", "dict", "then", "format", "correct", "carefully", "prompts", "schema", "replace", "processors", "tags", "value", "output", "only", "marker", "corrected", "html", "partial", "either", "prompt"], "ast_kind": "function_or_method", "text": "    def inference_blocks(self, document: Document) -> List[BlockData]:\n        blocks = super().inference_blocks(document)\n        out_blocks = []\n        for block_data in blocks:\n            block = block_data[\"block\"]\n            children = block.contained_blocks(document, (BlockTypes.TableCell,))\n            if not children:\n                continue\n            out_blocks.append(block_data)\n        return out_blocks\n\n", "n_tokens": 81, "byte_len": 425, "file_sha1": "4037f24573c716fdd6ca461f3cc2f79b6a528b3d", "start_line": 65, "end_line": 76}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py", "rel_path": "marker/processors/llm/llm_form.py", "module": "marker.processors.llm.llm_form", "ext": "py", "chunk_number": 4, "symbols": ["block_prompts", "prompt", "block", "data", "image", "form", "rewriting", "document", "append", "self", "schema", "json", "html", "prompts", "return", "render", "list", "replace", "inference", "blocks", "extract", "page", "inference_blocks", "rewrite_block", "LLMFormProcessor", "FormSchema", "cannot", "analyze", "compare", "reproducing", "make", "labels", "dict", "then", "format", "correct", "carefully", "children", "processors", "tags", "value", "output", "only", "continue", "marker", "corrected", "partial", "either", "right", "rewrite"], "ast_kind": "function_or_method", "text": "    def block_prompts(self, document: Document) -> List[PromptData]:\n        prompt_data = []\n        for block_data in self.inference_blocks(document):\n            block = block_data[\"block\"]\n            block_html = json_to_html(block.render(document))\n            prompt = self.form_rewriting_prompt.replace(\"{block_html}\", block_html)\n            image = self.extract_image(document, block)\n            prompt_data.append({\n                \"prompt\": prompt,\n                \"image\": image,\n                \"block\": block,\n                \"schema\": FormSchema,\n                \"page\": block_data[\"page\"]\n            })\n        return prompt_data\n\n", "n_tokens": 124, "byte_len": 650, "file_sha1": "4037f24573c716fdd6ca461f3cc2f79b6a528b3d", "start_line": 77, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_form.py", "rel_path": "marker/processors/llm/llm_form.py", "module": "marker.processors.llm.llm_form", "ext": "py", "chunk_number": 5, "symbols": ["rewrite_block", "FormSchema", "class", "llm", "error", "html", "document", "self", "lstrip", "dict", "json", "lower", "form", "schema", "return", "potentially", "base", "model", "rstrip", "render", "prompt", "data", "original", "strip", "needed", "table", "block", "corrected", "partial", "comparison", "inference_blocks", "block_prompts", "LLMFormProcessor", "cannot", "analyze", "compare", "reproducing", "image", "make", "rewriting", "labels", "then", "format", "correct", "carefully", "prompts", "children", "replace", "processors", "tags"], "ast_kind": "class_or_type", "text": "    def rewrite_block(self, response: dict, prompt_data: PromptData, document: Document):\n        block = prompt_data[\"block\"]\n        block_html = json_to_html(block.render(document))\n\n        if not response or \"corrected_html\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        corrected_html = response[\"corrected_html\"]\n\n        # The original table is okay\n        if \"no corrections needed\" in corrected_html.lower():\n            return\n\n        # Potentially a partial response\n        if len(corrected_html) < len(block_html) * .33:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        corrected_html = corrected_html.strip().lstrip(\"```html\").rstrip(\"```\").strip()\n        block.html = corrected_html\n\nclass FormSchema(BaseModel):\n    comparison: str\n    corrected_html: str", "n_tokens": 181, "byte_len": 859, "file_sha1": "4037f24573c716fdd6ca461f3cc2f79b6a528b3d", "start_line": 94, "end_line": 118}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 1, "symbols": ["image", "completed", "tuple", "futures", "blocks", "get", "logger", "annotated", "pydantic", "document", "base", "llm", "schema", "from", "json", "html", "model", "list", "processors", "typing", "block", "types", "output", "import", "marker", "concurrent", "table", "cell", "tqdm", "literal", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "validate_merge", "join_cells", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "pair", "exceptions", "joined", "join", "images", "cells", "colspan", "col", "same", "page"], "ast_kind": "imports", "text": "from concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import Annotated, List, Tuple, Literal\n\nfrom pydantic import BaseModel\nfrom tqdm import tqdm\nfrom PIL import Image\n\nfrom marker.output import json_to_html\nfrom marker.processors.llm import BaseLLMComplexBlockProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, TableCell\nfrom marker.schema.document import Document\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n", "n_tokens": 97, "byte_len": 485, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 1, "end_line": 16}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 2, "symbols": ["LLMTableMergeProcessor", "table", "height", "cannot", "analyze", "name", "start", "process", "reproducing", "pair", "additional", "merged", "image", "explanation", "joined", "then", "format", "same", "carefully", "description", "llm", "default", "merge", "tables", "augment", "columns", "only", "string", "horizontal", "bool", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "validate_merge", "join_cells", "join_images", "MergeSchema", "completed", "exceptions", "join", "images", "cells", "colspan", "col", "page", "rewriting", "part", "tqdm", "okay"], "ast_kind": "class_or_type", "text": "class LLMTableMergeProcessor(BaseLLMComplexBlockProcessor):\n    block_types: Annotated[\n        Tuple[BlockTypes],\n        \"The block types to process.\",\n    ] = (BlockTypes.Table, BlockTypes.TableOfContents)\n    table_height_threshold: Annotated[\n        float,\n        \"The minimum height ratio relative to the page for the first table in a pair to be considered for merging.\",\n    ] = 0.6\n    table_start_threshold: Annotated[\n        float,\n        \"The maximum percentage down the page the second table can start to be considered for merging.\"\n    ] = 0.2\n    vertical_table_height_threshold: Annotated[\n        float,\n        \"The height tolerance for 2 adjacent tables to be merged into one.\"\n    ] = 0.25\n    vertical_table_distance_threshold: Annotated[\n        int,\n        \"The maximum distance between table edges for adjacency.\"\n    ] = 20\n    horizontal_table_width_threshold: Annotated[\n        float,\n        \"The width tolerance for 2 adjacent tables to be merged into one.\"\n    ] = 0.25\n    horizontal_table_distance_threshold: Annotated[\n        int,\n        \"The maximum distance between table edges for adjacency.\"\n    ] = 10\n    column_gap_threshold: Annotated[\n        int,\n        \"The maximum gap between columns to merge tables\"\n    ] = 50\n    disable_tqdm: Annotated[\n        bool,\n        \"Whether to disable the tqdm progress bar.\",\n    ] = False\n    no_merge_tables_across_pages: Annotated[\n        bool,\n        \"Whether to disable merging tables across pages and keep page delimiters.\",\n    ] = False\n    table_merge_prompt: Annotated[\n        str,\n        \"The prompt to use for rewriting text.\",\n        \"Default is a string containing the Gemini rewriting prompt.\"\n    ] = \"\"\"You're a text correction expert specializing in accurately reproducing tables from PDFs.\nYou'll receive two images of tables from successive pages of a PDF.  Table 1 is from the first page, and Table 2 is from the second page.  Both tables may actually be part of the same larger table. Your job is to decide if Table 2 should be merged with Table 1, and how they should be joined.  The should only be merged if they're part of the same larger table, and Table 2 cannot be interpreted without merging.\n\nYou'll specify your judgement in json format - first whether Table 2 should be merged with Table 1, then the direction of the merge, either `bottom` or `right`.  A bottom merge means that the rows of Table 2 are joined to the rows of Table 1. A right merge means that the columns of Table 2 are joined to the columns of Table 1.  (bottom merge is equal to np.vstack, right merge is equal to np.hstack)\n\nTable 2 should be merged at the bottom of Table 1 if Table 2 has no headers, and the rows have similar values, meaning that Table 2 continues Table 1. Table 2 should be merged to the right of Table 1 if each row in Table 2 matches a row in Table 1, meaning that Table 2 contains additional columns that augment Table 1.\n\nOnly merge Table 1 and Table 2 if Table 2 cannot be interpreted without merging.  Only merge Table 1 and Table 2 if you can read both images properly.\n\n**Instructions:**\n1. Carefully examine the provided table images.  Table 1 is the first image, and Table 2 is the second image.\n2. Examine the provided html representations of Table 1 and Table 2.\n3. Write a description of Table 1.\n4. Write a description of Table 2.\n5. Analyze whether Table 2 should be merged into Table 1, and write an explanation.\n6. Output your decision on whether they should be merged, and merge direction.\n**Example:**\nInput:\nTable 1\n```html\n<table>\n    <tr>\n        <th>Name</th>\n        <th>Age</th>\n        <th>City</th>\n        <th>State</th>\n    </tr>\n    <tr>\n        <td>John</td>\n        <td>25</td>\n        <td>Chicago</td>\n        <td>IL</td>\n    </tr>\n```\nTable 2\n```html\n<table>\n    <tr>\n        <td>Jane</td>\n        <td>30</td>\n        <td>Los Angeles</td>\n        <td>CA</td>\n    </tr>\n```\nOutput:\n```json\n{\n    \"table1_description\": \"Table 1 has 4 headers, and 1 row.  The headers are Name, Age, City, and State.\",\n    \"table2_description\": \"Table 2 has no headers, but the values appear to represent a person's name, age, city, and state.\",\n    \"explanation\": \"The values in Table 2 match the headers in Table 1, and Table 2 has no headers. Table 2 should be merged to the bottom of Table 1.\",\n    \"merge\": \"true\",\n    \"direction\": \"bottom\"\n}\n```\n**Input:**\nTable 1\n```html\n{{table1}}\nTable 2\n```html\n{{table2}}\n```\n\"\"\"\n", "n_tokens": 1125, "byte_len": 4451, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 17, "end_line": 125}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 3, "symbols": ["get_row_count", "get_column_count", "col", "row", "none", "cells", "max", "cols", "cell", "return", "list", "colspan", "get", "column", "rows", "staticmethod", "table", "rowspan", "rewrite_blocks", "process_rewriting", "validate_merge", "join_cells", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "completed", "pair", "exceptions", "joined", "join", "images", "same", "page", "process", "rewriting", "default", "horizontal", "part", "tqdm", "okay", "your", "tables", "didn", "gemini", "jane", "llm", "service", "interpreted", "larger"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def get_row_count(cells: List[TableCell]):\n        if not cells:\n            return 0\n\n        max_rows = None\n        for col_id in set([cell.col_id for cell in cells]):\n            col_cells = [cell for cell in cells if cell.col_id == col_id]\n            rows = 0\n            for cell in col_cells:\n                rows += cell.rowspan\n            if max_rows is None or rows > max_rows:\n                max_rows = rows\n        return max_rows\n\n    @staticmethod\n    def get_column_count(cells: List[TableCell]):\n        if not cells:\n            return 0\n\n        max_cols = None\n        for row_id in set([cell.row_id for cell in cells]):\n            row_cells = [cell for cell in cells if cell.row_id == row_id]\n            cols = 0\n            for cell in row_cells:\n                cols += cell.colspan\n            if max_cols is None or cols > max_cols:\n                max_cols = cols\n        return max_cols\n", "n_tokens": 214, "byte_len": 940, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 126, "end_line": 155}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 4, "symbols": ["rewrite_blocks", "table", "runs", "take", "height", "together", "completed", "same", "page", "process", "exceptions", "document", "config", "result", "future", "return", "prev", "get", "column", "pbar", "rewriting", "max", "workers", "subsequent", "merge", "tables", "block", "horizontal", "vertical", "number", "get_row_count", "get_column_count", "process_rewriting", "validate_merge", "join_cells", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "pair", "joined", "join", "images", "cells", "colspan", "col", "default", "part", "tqdm", "okay"], "ast_kind": "function_or_method", "text": "    def rewrite_blocks(self, document: Document):\n        # Skip table merging if disabled via config\n        if self.no_merge_tables_across_pages:\n            logger.info(\"Skipping table merging across pages due to --no_merge_tables_across_pages flag\")\n            return\n\n        table_runs = []\n        table_run = []\n        prev_block = None\n        prev_page_block_count = None\n        for page in document.pages:\n            page_blocks = page.contained_blocks(document, self.block_types)\n            for block in page_blocks:\n                merge_condition = False\n                if prev_block is not None:\n                    prev_cells = prev_block.contained_blocks(document, (BlockTypes.TableCell,))\n                    curr_cells = block.contained_blocks(document, (BlockTypes.TableCell,))\n                    row_match = abs(self.get_row_count(prev_cells) - self.get_row_count(curr_cells)) < 5, # Similar number of rows\n                    col_match = abs(self.get_column_count(prev_cells) - self.get_column_count(curr_cells)) < 2\n\n                    subsequent_page_table = all([\n                        prev_block.page_id == block.page_id - 1, # Subsequent pages\n                        max(prev_block.polygon.height / page.polygon.height,\n                            block.polygon.height / page.polygon.height) > self.table_height_threshold, # Take up most of the page height\n                            (len(page_blocks) == 1 or prev_page_block_count == 1), # Only table on the page\n                            (row_match or col_match)\n                        ])\n\n                    same_page_vertical_table = all([\n                        prev_block.page_id == block.page_id, # On the same page\n                        (1 - self.vertical_table_height_threshold) < prev_block.polygon.height / block.polygon.height < (1 + self.vertical_table_height_threshold), # Similar height\n                        abs(block.polygon.x_start - prev_block.polygon.x_end) < self.vertical_table_distance_threshold, # Close together in x\n                        abs(block.polygon.y_start - prev_block.polygon.y_start) < self.vertical_table_distance_threshold, # Close together in y\n                        row_match\n                    ])\n\n                    same_page_horizontal_table = all([\n                        prev_block.page_id == block.page_id, # On the same page\n                        (1 - self.horizontal_table_width_threshold) < prev_block.polygon.width / block.polygon.width < (1 + self.horizontal_table_width_threshold), # Similar width\n                        abs(block.polygon.y_start - prev_block.polygon.y_end) < self.horizontal_table_distance_threshold, # Close together in y\n                        abs(block.polygon.x_start - prev_block.polygon.x_start) < self.horizontal_table_distance_threshold, # Close together in x\n                        col_match\n                    ])\n\n                    same_page_new_column = all([\n                        prev_block.page_id == block.page_id, # On the same page\n                        abs(block.polygon.x_start - prev_block.polygon.x_end) < self.column_gap_threshold,\n                        block.polygon.y_start < prev_block.polygon.y_end,\n                        block.polygon.width * (1 - self.vertical_table_height_threshold) < prev_block.polygon.width  < block.polygon.width * (1 + self.vertical_table_height_threshold), # Similar width\n                        col_match\n                    ])\n                    merge_condition = any([subsequent_page_table, same_page_vertical_table, same_page_new_column, same_page_horizontal_table])\n\n                if prev_block is not None and merge_condition:\n                    if prev_block not in table_run:\n                        table_run.append(prev_block)\n                    table_run.append(block)\n                else:\n                    if table_run:\n                        table_runs.append(table_run)\n                    table_run = []\n                prev_block = block\n            prev_page_block_count = len(page_blocks)\n\n        if table_run:\n            table_runs.append(table_run)\n\n        # Don't show progress if there is nothing to process\n        total_table_runs = len(table_runs)\n        if total_table_runs == 0:\n            return\n\n        pbar = tqdm(\n            total=total_table_runs,\n            desc=f\"{self.__class__.__name__} running\",\n            disable=self.disable_tqdm,\n        )\n\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for future in as_completed([\n                executor.submit(self.process_rewriting, document, blocks)\n                for blocks in table_runs\n            ]):\n                future.result()  # Raise exceptions if any occurred\n                pbar.update(1)\n\n        pbar.close()\n", "n_tokens": 897, "byte_len": 4818, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 156, "end_line": 243}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 5, "symbols": ["process_rewriting", "prompt", "merge", "schema", "llm", "error", "tables", "contained", "blocks", "didn", "highres", "table", "table1", "service", "form", "true", "break", "range", "images", "join", "cells", "start", "html", "document", "self", "lowres", "image", "curr", "block", "json", "get_row_count", "get_column_count", "rewrite_blocks", "validate_merge", "join_cells", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "completed", "pair", "exceptions", "joined", "colspan", "col", "same", "page", "process", "rewriting", "default"], "ast_kind": "function_or_method", "text": "    def process_rewriting(self, document: Document, blocks: List[Block]):\n        if len(blocks) < 2:\n            # Can't merge single tables\n            return\n\n        start_block = blocks[0]\n        for i in range(1, len(blocks)):\n            curr_block = blocks[i]\n            children = start_block.contained_blocks(document, (BlockTypes.TableCell,))\n            children_curr = curr_block.contained_blocks(document, (BlockTypes.TableCell,))\n            if not children or not children_curr:\n                # Happens if table/form processors didn't run\n                break\n\n            start_image = start_block.get_image(document, highres=False)\n            curr_image = curr_block.get_image(document, highres=False)\n            start_html = json_to_html(start_block.render(document))\n            curr_html = json_to_html(curr_block.render(document))\n\n            prompt = self.table_merge_prompt.replace(\"{{table1}}\", start_html).replace(\"{{table2}}\", curr_html)\n\n            response = self.llm_service(\n                prompt,\n                [start_image, curr_image],\n                curr_block,\n                MergeSchema,\n            )\n\n            if not response or (\"direction\" not in response or \"merge\" not in response):\n                curr_block.update_metadata(llm_error_count=1)\n                break\n\n            merge = response[\"merge\"]\n\n            # The original table is okay\n            if \"true\" not in merge:\n                start_block = curr_block\n                continue\n\n            # Merge the cells and images of the tables\n            direction = response[\"direction\"]\n            if not self.validate_merge(children, children_curr, direction):\n                start_block = curr_block\n                continue\n\n            merged_image = self.join_images(start_image, curr_image, direction)\n            merged_cells = self.join_cells(children, children_curr, direction)\n            curr_block.structure = []\n            start_block.structure = [b.id for b in merged_cells]\n            start_block.lowres_image = merged_image\n", "n_tokens": 396, "byte_len": 2069, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 244, "end_line": 294}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 6, "symbols": ["validate_merge", "check", "elif", "bottom", "cells", "row", "self", "col", "same", "validate", "merge", "return", "list", "get", "column", "cells2", "direction", "rows", "cells1", "columns", "number", "right", "table", "cell", "literal", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "join_cells", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "completed", "pair", "exceptions", "joined", "join", "images", "colspan", "page", "process", "rewriting", "default", "horizontal", "part", "tqdm", "okay", "your"], "ast_kind": "function_or_method", "text": "    def validate_merge(self, cells1: List[TableCell], cells2: List[TableCell], direction: Literal['right', 'bottom'] = 'right'):\n        if direction == \"right\":\n            # Check if the number of rows is the same\n            cells1_row_count = self.get_row_count(cells1)\n            cells2_row_count = self.get_row_count(cells2)\n            return abs(cells1_row_count - cells2_row_count) < 5\n        elif direction == \"bottom\":\n            # Check if the number of columns is the same\n            cells1_col_count = self.get_column_count(cells1)\n            cells2_col_count = self.get_column_count(cells2)\n            return abs(cells1_col_count - cells2_col_count) < 2\n\n", "n_tokens": 157, "byte_len": 676, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 295, "end_line": 307}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 7, "symbols": ["join_cells", "row", "count", "col", "bottom", "new", "cells", "join", "else", "shift", "self", "return", "list", "get", "column", "cells2", "direction", "rows", "cells1", "columns", "right", "table", "cell", "literal", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "validate_merge", "join_images", "LLMTableMergeProcessor", "MergeSchema", "analyze", "completed", "pair", "exceptions", "joined", "images", "colspan", "same", "page", "process", "rewriting", "default", "horizontal", "part", "tqdm", "okay", "your", "tables"], "ast_kind": "function_or_method", "text": "    def join_cells(self, cells1: List[TableCell], cells2: List[TableCell], direction: Literal['right', 'bottom'] = 'right') -> List[TableCell]:\n        if direction == 'right':\n            # Shift columns right\n            col_count = self.get_column_count(cells1)\n            for cell in cells2:\n                cell.col_id += col_count\n            new_cells = cells1 + cells2\n        else:\n            # Shift rows up\n            row_count = self.get_row_count(cells1)\n            for cell in cells2:\n                cell.row_id += row_count\n            new_cells = cells1 + cells2\n        return new_cells\n", "n_tokens": 137, "byte_len": 609, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 308, "end_line": 322}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 8, "symbols": ["join_images", "image", "dimensions", "else", "image1", "bottom", "direction", "join", "images", "return", "right", "staticmethod", "new", "img", "size", "paste", "image2", "height", "width", "literal", "white", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "validate_merge", "join_cells", "LLMTableMergeProcessor", "MergeSchema", "analyze", "completed", "pair", "exceptions", "joined", "cells", "colspan", "col", "same", "page", "process", "rewriting", "default", "horizontal", "table", "part", "tqdm", "okay", "cell", "your", "tables"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def join_images(image1: Image.Image, image2: Image.Image, direction: Literal['right', 'bottom'] = 'right') -> Image.Image:\n        # Get dimensions\n        w1, h1 = image1.size\n        w2, h2 = image2.size\n\n        if direction == 'right':\n            new_height = max(h1, h2)\n            new_width = w1 + w2\n            new_img = Image.new('RGB', (new_width, new_height), 'white')\n            new_img.paste(image1, (0, 0))\n            new_img.paste(image2, (w1, 0))\n        else:\n            new_width = max(w1, w2)\n            new_height = h1 + h2\n            new_img = Image.new('RGB', (new_width, new_height), 'white')\n            new_img.paste(image1, (0, 0))\n            new_img.paste(image2, (0, h1))\n        return new_img\n\n", "n_tokens": 216, "byte_len": 754, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 323, "end_line": 343}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table_merge.py", "rel_path": "marker/processors/llm/llm_table_merge.py", "module": "marker.processors.llm.llm_table_merge", "ext": "py", "chunk_number": 9, "symbols": ["MergeSchema", "table", "description", "base", "model", "merge", "schema", "class", "bottom", "explanation", "direction", "right", "true", "false", "literal", "get_row_count", "get_column_count", "rewrite_blocks", "process_rewriting", "validate_merge", "join_cells", "join_images", "LLMTableMergeProcessor", "analyze", "completed", "pair", "exceptions", "joined", "join", "images", "cells", "colspan", "col", "same", "page", "process", "rewriting", "default", "horizontal", "part", "tqdm", "okay", "cell", "your", "tables", "didn", "gemini", "jane", "llm", "service"], "ast_kind": "class_or_type", "text": "class MergeSchema(BaseModel):\n    table1_description: str\n    table2_description: str\n    explanation: str\n    merge: Literal[\"true\", \"false\"]\n    direction: Literal[\"bottom\", \"right\"]", "n_tokens": 45, "byte_len": 184, "file_sha1": "c1380ed346ece1aabbb74e580cc5b25e35963098", "start_line": 344, "end_line": 349}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py", "rel_path": "marker/processors/llm/llm_complex.py", "module": "marker.processors.llm.llm_complex", "ext": "py", "chunk_number": 1, "symbols": ["import", "base", "model", "document", "marker", "list", "pydantic", "prompt", "data", "schema", "from", "processors", "llm", "typing", "block", "types", "markdown", "markdown2", "block_prompts", "rewrite_block", "LLMComplexRegionProcessor", "ComplexSchema", "sales", "analyze", "header", "display", "reproducing", "image", "make", "raw", "text", "expression", "labels", "unordered", "dict", "bold", "carefully", "prompts", "complex", "return", "smallest", "replace", "bolded", "partial", "either", "right", "extracted", "rewrite", "page", "generate"], "ast_kind": "imports", "text": "from typing import List\n\nimport markdown2\nfrom pydantic import BaseModel\n\nfrom marker.processors.llm import PromptData, BaseLLMSimpleBlockProcessor\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\n", "n_tokens": 47, "byte_len": 231, "file_sha1": "9c8b17ef687ee86d874d564a91a4db85e96f7504", "start_line": 1, "end_line": 11}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py", "rel_path": "marker/processors/llm/llm_complex.py", "module": "marker.processors.llm.llm_complex", "ext": "py", "chunk_number": 2, "symbols": ["LLMComplexRegionProcessor", "sales", "markdown", "analyze", "header", "display", "reproducing", "image", "make", "expression", "labels", "unordered", "bold", "carefully", "smallest", "bolded", "either", "right", "extracted", "text", "generate", "tables", "rules", "accurately", "omit", "blocks", "form", "output", "between", "images", "block_prompts", "rewrite_block", "ComplexSchema", "raw", "document", "dict", "block", "prompts", "complex", "schema", "return", "replace", "processors", "marker", "partial", "prompt", "data", "rewrite", "page", "okay"], "ast_kind": "class_or_type", "text": "class LLMComplexRegionProcessor(BaseLLMSimpleBlockProcessor):\n    block_types = (BlockTypes.ComplexRegion,)\n    complex_region_prompt = \"\"\"You are a text correction expert specializing in accurately reproducing text from images.\nYou will receive an image of a text block and the text that can be extracted from the image.\nYour task is to generate markdown to properly represent the content of the image.  Do not omit any text present in the image - make sure everything is included in the markdown representation.  The markdown representation should be as faithful to the original image as possible.\n\nFormatting should be in markdown, with the following rules:\n- * for italics, ** for bold, and ` for inline code.\n- Use <sup>...</sup> for superscripts.\n- Headers should be formatted with #, with one # for the largest header, and up to 6 for the smallest.\n- Lists should be formatted with either - or 1. for unordered and ordered lists, respectively.\n- Links should be formatted with [text](url).\n- Use ``` for code blocks.\n- Inline math should be formatted with <math>math expression</math>.\n- Display math should be formatted with <math display=\"block\">math expression</math>.\n- Values and labels should be extracted from forms, and put into markdown tables, with the labels on the left side, and values on the right.  The headers should be \"Labels\" and \"Values\".  Other text in the form can appear between the tables.\n- Tables should be formatted with markdown tables, with the headers bolded.\n\n**Instructions:**\n1. Carefully examine the provided block image.\n2. Analyze the existing text representation.\n3. Generate the markdown representation of the content in the image.\n**Example:**\nInput:\n```text\nTable 1: Car Sales\n```\nOutput:\n```markdown\n## Table 1: Car Sales\n\n| Car | Sales |\n| --- | --- |\n| Honda | 100 |\n| Toyota | 200 |\n```\n**Input:**\n```text\n{extracted_text}\n```\n\"\"\"\n", "n_tokens": 427, "byte_len": 1882, "file_sha1": "9c8b17ef687ee86d874d564a91a4db85e96f7504", "start_line": 12, "end_line": 53}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py", "rel_path": "marker/processors/llm/llm_complex.py", "module": "marker.processors.llm.llm_complex", "ext": "py", "chunk_number": 3, "symbols": ["block_prompts", "prompt", "text", "image", "raw", "document", "append", "self", "schema", "block", "prompts", "complex", "return", "list", "data", "replace", "inference", "blocks", "extract", "extracted", "page", "region", "rewrite_block", "LLMComplexRegionProcessor", "ComplexSchema", "sales", "markdown", "analyze", "header", "display", "reproducing", "make", "expression", "labels", "unordered", "dict", "bold", "carefully", "smallest", "processors", "bolded", "marker", "partial", "either", "right", "rewrite", "generate", "okay", "extras", "tables"], "ast_kind": "function_or_method", "text": "    def block_prompts(self, document: Document) -> List[PromptData]:\n        prompt_data = []\n        for block in self.inference_blocks(document):\n            text = block[\"block\"].raw_text(document)\n            prompt = self.complex_region_prompt.replace(\"{extracted_text}\", text)\n            image = self.extract_image(document, block[\"block\"])\n            prompt_data.append({\n                \"prompt\": prompt,\n                \"image\": image,\n                \"block\": block[\"block\"],\n                \"schema\": ComplexSchema,\n                \"page\": block[\"page\"]\n            })\n        return prompt_data\n", "n_tokens": 118, "byte_len": 609, "file_sha1": "9c8b17ef687ee86d874d564a91a4db85e96f7504", "start_line": 54, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_complex.py", "rel_path": "marker/processors/llm/llm_complex.py", "module": "marker.processors.llm.llm_complex", "ext": "py", "chunk_number": 4, "symbols": ["rewrite_block", "ComplexSchema", "markdown", "class", "extras", "text", "llm", "error", "tables", "markdown2", "raw", "html", "document", "self", "lstrip", "dict", "corrected", "lower", "complex", "schema", "return", "potentially", "base", "model", "rstrip", "prompt", "data", "original", "strip", "table", "block_prompts", "LLMComplexRegionProcessor", "sales", "analyze", "header", "display", "reproducing", "image", "make", "expression", "labels", "unordered", "bold", "carefully", "block", "prompts", "smallest", "replace", "processors", "bolded"], "ast_kind": "class_or_type", "text": "    def rewrite_block(self, response: dict, prompt_data: PromptData, document: Document):\n        block = prompt_data[\"block\"]\n        text = block.raw_text(document)\n\n        if not response or \"corrected_markdown\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        corrected_markdown = response[\"corrected_markdown\"]\n\n        # The original table is okay\n        if \"no corrections\" in corrected_markdown.lower():\n            return\n\n        # Potentially a partial response\n        if len(corrected_markdown) < len(text) * .5:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        # Convert LLM markdown to html\n        corrected_markdown = corrected_markdown.strip().lstrip(\"```markdown\").rstrip(\"```\").strip()\n        block.html = markdown2.markdown(corrected_markdown, extras=[\"tables\"])\n\nclass ComplexSchema(BaseModel):\n    corrected_markdown: str", "n_tokens": 198, "byte_len": 928, "file_sha1": "9c8b17ef687ee86d874d564a91a4db85e96f7504", "start_line": 69, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 1, "symbols": ["input", "completed", "tags", "all", "textarea", "futures", "blocks", "get", "logger", "form", "bloc", "map", "annotated", "section", "header", "pydantic", "forma", "document", "base", "llm", "schema", "from", "table", "code", "contents", "list", "group", "model", "math", "text", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_reorder", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "footnote", "exceptions", "user", "found", "labels", "correctness", "cells", "underlying", "href", "insert"], "ast_kind": "imports", "text": "import json\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import List, Annotated\n\nfrom marker.logger import get_logger\nfrom marker.processors.llm import BaseLLMComplexBlockProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import BlockId\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\nfrom pydantic import BaseModel\nfrom tqdm import tqdm\n\nlogger = get_logger()\n\nFORMAT_TAGS = [\"b\", \"i\", \"u\", \"del\", \"math\", \"sub\", \"sup\", \"a\", \"code\", \"p\", \"img\"]\nBLOCK_MAP = {\n    \"Text\": [],\n    \"TextInlineMath\": [],\n    \"Table\": [\"table\", \"tbody\", \"tr\", \"td\", \"th\"],\n    \"ListGroup\": [\"ul\", \"li\"],\n    \"SectionHeader\": [],\n    \"Form\": [\"form\", \"input\", \"select\", \"textarea\", \"table\", \"tbody\", \"tr\", \"td\", \"th\"],\n    \"Figure\": [],\n    \"Picture\": [],\n    \"Code\": [\"pre\"],\n    \"TableOfContents\": [\"table\", \"tbody\", \"tr\", \"td\", \"th\"],\n}\nALL_TAGS = FORMAT_TAGS + [tag for tags in BLOCK_MAP.values() for tag in tags]\n\n", "n_tokens": 267, "byte_len": 990, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 1, "end_line": 31}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 2, "symbols": ["LLMPageCorrectionProcessor", "analyze", "well", "vector", "process", "reproducing", "footnote", "additional", "image", "make", "user", "section", "header", "goal", "reordering", "labels", "then", "correctness", "cells", "correct", "carefully", "underlying", "href", "within", "here", "list", "group", "insert", "identify", "case", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_reorder", "handle_rewrites", "rewrite_blocks", "BlockSchema", "PageSchema", "completed", "exceptions", "found", "colspan", "rewriting", "page", "page1", "next", "prompt", "along", "issue", "isinstance"], "ast_kind": "class_or_type", "text": "class LLMPageCorrectionProcessor(BaseLLMComplexBlockProcessor):\n    block_correction_prompt: Annotated[\n        str, \"The user prompt to guide the block correction process.\"\n    ] = None\n    default_user_prompt = \"\"\"Your goal is to reformat the blocks to be as correct as possible, without changing the underlying meaning of the text within the blocks.  Mostly focus on reformatting the content.  Ignore minor formatting issues like extra <i> tags.\"\"\"\n    page_prompt = \"\"\"You're a text correction expert specializing in accurately reproducing text from PDF pages. You will be given a JSON list of blocks on a PDF page, along with the image for that page.  The blocks will be formatted like the example below.  The blocks will be presented in reading order.\n\n```json\n[\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"id\": \"/page/0/Text/1\",\n        \"block_type\": \"Text\",\n        \"html\": \"<p>Some text here</p>\",\n    }, ...\n]\n```\n\nYou will also be given a prompt from the user that tells you how to correct the blocks.  Your task is to analyze the blocks and the image, then follow the prompt to correct the blocks.\n\nHere are the types of changes you can make in response to the prompt:\n\n- Reorder the blocks to reflect the correct reading order.\n- Change the block type to the correct type - the potential types are \"SectionHeader\", \"Form\", \"Text\", \"Table\", \"Figure\", \"Picture\", \"ListGroup\", \"PageFooter\", \"PageHeader\", \"Footnote\", or \"Equation\".  In this case, update the html as well to match the new block type.\n- Make edits to block content by changing the HTML.\n\nGuidelines:\n- Only use the following tags: {{format_tags}}.  Do not use any other tags.  \n- The math tag can have the attribute `display=\"block\"` to indicate display math, the a tag can have the attribute `href=\"...\"` to indicate a link, and td and th tags can have the attribute `colspan=\"...\"` and `rowspan=\"...\"` to indicate table cells that span multiple columns or rows.  There can be a \"block-type\" attribute on p tags.  Do not use any other attributes.\n- Keep LaTeX formulas inside <math> tags - these are important for downstream processing.\n- Bboxes are normalized 0-1000\n- The order of the JSON list is the reading order for the blocks\n- Follow the user prompt faithfully, and only make additional changes if there is a significant issue with correctness.\n- Stay faithful to the original image, and do not insert any content that is not present in the image or the blocks, unless specifically requested by the user prompt.\n\n**Instructions:**\n1. Carefully examine the provided JSON representation of the page, along with the image.\n2. Analyze the user prompt.\n3. Identify any issues you'll need to fix, and write a short analysis.\n4. If everything is fine, output \"no_corrections\"  Otherwise, output the type of correction needed: [\"reorder\", \"rewrite\", \"reorder_first\"].  Rewrite includes rewriting html and changing the block type.  If you need to do both, then perform only the reordering, and output \"reorder_first\", so we can do the rewriting later.\n5. If corrections are needed, output any blocks that need updates:\n    a. If reading order needs to be changed, output the IDs of the blocks in the correct order, and keep block_type and html blank, like this:\n    ```json\n    [\n        {\n            \"id\": \"/page/0/Text/1\",\n            \"block_type\": \"\",\n            \"html\": \"\"\n        },\n        ...\n    ]\n\n    b. If blocks need to be rewritten, output the block ids and new HTML for the blocks, like this:\n        ```json\n        [\n            {\n                \"id\": \"/page/0/Text/1\",\n                \"block_type\": \"Text\",\n                \"html\": \"<p>New HTML content here</p>\"\n            },\n            ...\n        ]\n        ```\n\n**Example:**\nInput:\nBlocks\n```json\n[\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"id\": \"/page/0/Text/1\",\n        \"block_type\": \"Text\",\n        \"html\": \"1.14 Vector Operations\",\n    },\n    {\n        \"bbox\": [x1, y1, x2, y2],\n        \"id\": \"/page/0/Text/2\",\n        \"block_type\": \"Text\",\n        \"html\": \"<p>You can perform many operations on a vector, including...</p>\",\n    },\n]\n```\nUser Prompt\nEnsure that all blocks have the correct labels, and that reading order is correct.\nOutput:\nAnalysis: The blocks are in the correct reading order, but the first block should actually be a SectionHeader.\n```json\n[\n    {\n        \"id\": \"/page/0/Text/1\",\n        \"block_type\": \"SectionHeader\",\n        \"html\": \"<h1>1.14 Vector Operations</h1>\"\n    }\n]\n```\n\n**Input:**\nBlocks\n```json\n{{page_json}}\n```\nUser Prompt\n{{user_prompt}}\n\"\"\"\n", "n_tokens": 1109, "byte_len": 4543, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 32, "end_line": 137}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 3, "symbols": ["get_selected_blocks", "document", "structure", "blocks", "list", "normalize", "block", "self", "selected", "dict", "page", "enumerate", "get", "json", "return", "group", "process_rewriting", "load_blocks", "handle_reorder", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "completed", "footnote", "exceptions", "user", "found", "labels", "correctness", "cells", "underlying", "href", "insert", "colspan", "process", "rewriting", "page1", "next", "prompt", "along", "issue", "isinstance", "normalized", "downstream", "processing", "just", "tqdm"], "ast_kind": "function_or_method", "text": "    def get_selected_blocks(\n        self,\n        document: Document,\n        page: PageGroup,\n    ) -> List[dict]:\n        selected_blocks = page.structure_blocks(document)\n        json_blocks = [\n            self.normalize_block_json(block, document, page)\n            for i, block in enumerate(selected_blocks)\n        ]\n        return json_blocks\n", "n_tokens": 69, "byte_len": 352, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 138, "end_line": 149}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 4, "symbols": ["process_rewriting", "correction", "type", "prompt", "elif", "tags", "all", "load", "blocks", "rewriting", "highres", "handle", "llm", "service", "image", "else", "reorder", "document", "self", "page", "schema", "corrections", "first", "from", "user", "get", "selected", "valid", "rewrites", "return", "get_selected_blocks", "load_blocks", "handle_reorder", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "completed", "footnote", "exceptions", "found", "labels", "correctness", "cells", "underlying", "href", "insert", "list"], "ast_kind": "function_or_method", "text": "    def process_rewriting(self, document: Document, page1: PageGroup):\n        page_blocks = self.get_selected_blocks(document, page1)\n        image = page1.get_image(document, highres=False)\n\n        prompt = (\n            self.page_prompt.replace(\"{{page_json}}\", json.dumps(page_blocks))\n            .replace(\"{{format_tags}}\", json.dumps(ALL_TAGS))\n            .replace(\"{{user_prompt}}\", self.block_correction_prompt)\n        )\n        response = self.llm_service(prompt, image, page1, PageSchema)\n        logger.debug(f\"Got reponse from LLM: {response}\")\n\n        if not response or \"correction_type\" not in response:\n            logger.warning(\"LLM did not return a valid response\")\n            return\n\n        correction_type = response[\"correction_type\"]\n        if correction_type == \"no_corrections\":\n            return\n        elif correction_type in [\"reorder\", \"reorder_first\"]:\n            self.load_blocks(response)\n            self.handle_reorder(response[\"blocks\"], page1)\n\n            # If we needed to reorder first, we will handle the rewriting next\n            if correction_type == \"reorder_first\":\n                self.process_rewriting(document, page1)\n        elif correction_type == \"rewrite\":\n            self.load_blocks(response)\n            self.handle_rewrites(response[\"blocks\"], document)\n        else:\n            logger.warning(f\"Unknown correction type: {correction_type}\")\n            return\n", "n_tokens": 292, "byte_len": 1430, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 150, "end_line": 182}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 5, "symbols": ["load_blocks", "loads", "isinstance", "load", "blocks", "self", "json", "response", "get_selected_blocks", "process_rewriting", "handle_reorder", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "completed", "footnote", "exceptions", "user", "found", "labels", "correctness", "cells", "underlying", "href", "insert", "list", "group", "colspan", "process", "rewriting", "page", "page1", "next", "prompt", "along", "issue", "normalized", "downstream", "processing", "just", "tqdm", "llm", "service", "everything", "lstrip", "indicate", "dumps"], "ast_kind": "function_or_method", "text": "    def load_blocks(self, response):\n        if isinstance(response[\"blocks\"], str):\n            response[\"blocks\"] = json.loads(response[\"blocks\"])\n", "n_tokens": 29, "byte_len": 149, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 183, "end_line": 186}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 6, "symbols": ["handle_reorder", "exception", "unique", "page", "block", "type", "split", "data", "blocks", "parsing", "swap", "document", "append", "self", "found", "both", "same", "ids", "return", "except", "pages", "getattr", "order", "reordered", "structure", "have", "page1", "error", "blockid", "types", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "completed", "footnote", "exceptions", "user", "labels", "correctness", "cells", "underlying", "href", "insert", "list"], "ast_kind": "function_or_method", "text": "    def handle_reorder(self, blocks: list, page1: PageGroup):\n        unique_page_ids = set()\n        document_page_ids = [str(page1.page_id)]\n        document_pages = [page1]\n\n        for block_data in blocks:\n            try:\n                page_id, _, _ = block_data[\"id\"].split(\"/\")\n                unique_page_ids.add(page_id)\n            except Exception as e:\n                logger.debug(f\"Error parsing block ID {block_data['id']}: {e}\")\n                continue\n\n        if set(document_page_ids) != unique_page_ids:\n            logger.debug(\n                \"Some page IDs in the response do not match the document's pages\"\n            )\n            return\n\n        for page_id, document_page in zip(unique_page_ids, document_pages):\n            block_ids_for_page = []\n            for block_data in blocks:\n                try:\n                    page_id, block_type, block_id = block_data[\"id\"].split(\"/\")\n                    block_id = BlockId(\n                        page_id=page_id,\n                        block_id=block_id,\n                        block_type=getattr(BlockTypes, block_type),\n                    )\n                    block_ids_for_page.append(block_id)\n                except Exception as e:\n                    logger.debug(f\"Error parsing block ID {block_data['id']}: {e}\")\n                    continue\n\n                # Both sides should have the same values, just be reordered\n                if not all(\n                    [\n                        block_id in document_page.structure\n                        for block_id in block_ids_for_page\n                    ]\n                ):\n                    logger.debug(\n                        f\"Some blocks for page {page_id} not found in document\"\n                    )\n                    continue\n\n                if not all(\n                    [\n                        block_id in block_ids_for_page\n                        for block_id in document_page.structure\n                    ]\n                ):\n                    logger.debug(\n                        f\"Some blocks in document page {page_id} not found in response\"\n                    )\n                    continue\n\n                # Swap the order of blocks in the document page\n                document_page.structure = block_ids_for_page\n", "n_tokens": 405, "byte_len": 2305, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 187, "end_line": 246}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 7, "symbols": ["handle_rewrites", "block", "type", "exception", "split", "data", "blocks", "parsing", "html", "document", "found", "self", "lstrip", "handle", "rewrites", "get", "except", "getattr", "strip", "blockid", "error", "types", "page", "logger", "continue", "debug", "hasattr", "list", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_reorder", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "PageSchema", "analyze", "completed", "footnote", "exceptions", "user", "labels", "correctness", "cells", "underlying", "href", "insert", "group", "colspan", "process"], "ast_kind": "function_or_method", "text": "    def handle_rewrites(self, blocks: list, document: Document):\n        for block_data in blocks:\n            try:\n                block_id = block_data[\"id\"].strip().lstrip(\"/\")\n                _, page_id, block_type, block_id = block_id.split(\"/\")\n                block_id = BlockId(\n                    page_id=page_id,\n                    block_id=block_id,\n                    block_type=getattr(BlockTypes, block_type),\n                )\n                block = document.get_block(block_id)\n                if not block:\n                    logger.debug(f\"Block {block_id} not found in document\")\n                    continue\n\n                if hasattr(block, \"html\"):\n                    block.html = block_data[\"html\"]\n            except Exception as e:\n                logger.debug(f\"Error parsing block ID {block_data['id']}: {e}\")\n                continue\n", "n_tokens": 165, "byte_len": 869, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 247, "end_line": 267}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 8, "symbols": ["rewrite_blocks", "BlockSchema", "block", "type", "class", "completed", "disable", "tqdm", "desc", "max", "concurrency", "process", "running", "blocks", "show", "exceptions", "total", "progress", "html", "document", "self", "result", "future", "name", "return", "base", "model", "there", "pbar", "rewriting", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_reorder", "handle_rewrites", "LLMPageCorrectionProcessor", "PageSchema", "analyze", "footnote", "user", "found", "labels", "correctness", "cells", "underlying", "href", "insert", "list", "group", "colspan"], "ast_kind": "class_or_type", "text": "    def rewrite_blocks(self, document: Document):\n        if not self.block_correction_prompt:\n            return\n\n        # Don't show progress if there are no blocks to process\n        total_blocks = len(document.pages)\n        if total_blocks == 0:\n            return\n\n        pbar = tqdm(\n            total=max(1, total_blocks - 1),\n            desc=f\"{self.__class__.__name__} running\",\n            disable=self.disable_tqdm,\n        )\n\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for future in as_completed(\n                [\n                    executor.submit(self.process_rewriting, document, page)\n                    for page in document.pages\n                ]\n            ):\n                future.result()  # Raise exceptions if any occurred\n                pbar.update(1)\n\n        pbar.close()\n\n\nclass BlockSchema(BaseModel):\n    id: str\n    html: str\n    block_type: str\n\n", "n_tokens": 187, "byte_len": 935, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 268, "end_line": 301}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py#9", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_page_correction.py", "rel_path": "marker/processors/llm/llm_page_correction.py", "module": "marker.processors.llm.llm_page_correction", "ext": "py", "chunk_number": 9, "symbols": ["PageSchema", "correction", "type", "base", "model", "class", "block", "schema", "list", "page", "blocks", "analysis", "get_selected_blocks", "process_rewriting", "load_blocks", "handle_reorder", "handle_rewrites", "rewrite_blocks", "LLMPageCorrectionProcessor", "BlockSchema", "analyze", "completed", "footnote", "exceptions", "user", "found", "labels", "correctness", "cells", "underlying", "href", "insert", "group", "colspan", "process", "rewriting", "page1", "next", "prompt", "along", "issue", "isinstance", "normalized", "downstream", "processing", "just", "tqdm", "llm", "service", "everything"], "ast_kind": "class_or_type", "text": "class PageSchema(BaseModel):\n    analysis: str\n    correction_type: str\n    blocks: List[BlockSchema]\n", "n_tokens": 25, "byte_len": 102, "file_sha1": "b9f2977239b17763c899663cd30ea74b6e0460d4", "start_line": 302, "end_line": 306}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py", "rel_path": "marker/processors/llm/llm_equation.py", "module": "marker.processors.llm.llm_equation", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "base", "model", "import", "document", "marker", "pydantic", "list", "prompt", "data", "schema", "block", "from", "processors", "llm", "typing", "types", "inference_blocks", "block_prompts", "rewrite_block", "LLMEquationProcessor", "EquationSchema", "image", "expansion", "analyze", "generating", "raw", "text", "dict", "then", "format", "correct", "carefully", "prompts", "return", "replace", "tags", "default", "delimiter", "output", "string", "only", "equation", "latex", "bool", "continue", "along", "which", "this", "expand"], "ast_kind": "imports", "text": "from pydantic import BaseModel\n\nfrom marker.processors.llm import BaseLLMSimpleBlockProcessor, PromptData, BlockData\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\nfrom typing import Annotated, List\n\n", "n_tokens": 49, "byte_len": 235, "file_sha1": "3e39b7bad7fcf330ddd076d8db405b24455c056a", "start_line": 1, "end_line": 9}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py", "rel_path": "marker/processors/llm/llm_equation.py", "module": "marker.processors.llm.llm_equation", "ext": "py", "chunk_number": 2, "symbols": ["LLMEquationProcessor", "image", "expansion", "analyze", "generating", "then", "format", "correct", "carefully", "tags", "default", "delimiter", "output", "string", "only", "equation", "latex", "bool", "along", "which", "this", "expand", "processing", "equations", "page", "bboxes", "generate", "simple", "compatible", "prompt", "inference_blocks", "block_prompts", "rewrite_block", "EquationSchema", "raw", "text", "document", "dict", "block", "prompts", "return", "replace", "processors", "continue", "marker", "data", "rewrite", "llm", "error", "gemini"], "ast_kind": "class_or_type", "text": "class LLMEquationProcessor(BaseLLMSimpleBlockProcessor):\n    block_types = (BlockTypes.Equation,)\n    min_equation_height: Annotated[\n        float,\n        \"The minimum ratio between equation height and page height to consider for processing.\",\n     ] = 0.06\n    image_expansion_ratio: Annotated[\n        float,\n        \"The ratio to expand the image by when cropping.\",\n    ] = 0.05 # Equations sometimes get bboxes that are too tight\n    redo_inline_math: Annotated[\n        bool,\n        \"Whether to redo inline math blocks.\",\n    ] = False\n    equation_latex_prompt: Annotated[\n        str,\n        \"The prompt to use for generating LaTeX from equations.\",\n        \"Default is a string containing the Gemini prompt.\"\n    ] = r\"\"\"You're an expert mathematician who is good at writing LaTeX code and html for equations.\nYou'll receive an image of a math block, along with the text extracted from the block.  It may contain one or more equations. Your job is to write html that represents the content of the image, with the equations in LaTeX format.\n\nSome guidelines:\n- Output valid html, where all the equations can render properly.\n- Use <math display=\"block\"> as a block equation delimiter and <math> for inline equations.  Do not use $ or $$ as delimiters.\n- Keep the LaTeX code inside the math tags simple, concise, and KaTeX compatible.\n- Enclose all equations in the correct math tags. Use multiple math tags inside the html to represent multiple equations.\n- Only use the html tags math, i, b, p, and br.\n- Make sure to include all the equations in the image in the html output.\n- Make sure to include other text in the image in the correct positions along with the equations.\n\n**Instructions:**\n1. Carefully examine the provided image.\n2. Analyze the existing html, which may include LaTeX code.\n3. Write a short analysis of how the html should be corrected to represent the image.\n4. If the html and LaTeX are correct, write \"No corrections needed.\"\n5. If the html and LaTeX are incorrect, generate the corrected html.\n6. Output only the analysis, then the corrected html or \"No corrections needed.\"\n**Example:**\nInput:\n```html\nThe following equation illustrates the Pythagorean theorem:\nx2 + y2 = z2\n\nAnd this equation is a bit more complex:\n(ab * x5 + x2 + 2 * x + 123)/t\n```\nOutput:\nanalysis: The equations are not formatted as LaTeX, or enclosed in math tags.\n```html\n<p>The following equation illustrates the Pythagorean theorem:</p> \n<math display=\"block\">x^{2} + y^{2} = z^{2}</math>\n\n<p>And this equation is a bit more complex, and contains <math>ab \\cdot x^{5}</math>:</p>\n<math display=\"block\">\\frac{ab \\cdot x^{5} + x^{2} + 2 \\cdot x + 123}{t}</math>\n```\n**Input:**\n```html\n{equation}\n```\n\"\"\"\n", "n_tokens": 660, "byte_len": 2717, "file_sha1": "3e39b7bad7fcf330ddd076d8db405b24455c056a", "start_line": 10, "end_line": 70}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py", "rel_path": "marker/processors/llm/llm_equation.py", "module": "marker.processors.llm.llm_equation", "ext": "py", "chunk_number": 3, "symbols": ["inference_blocks", "block", "data", "inline", "blocks", "min", "equation", "document", "append", "self", "redo", "height", "return", "out", "super", "list", "math", "inference", "continue", "equations", "polygon", "page", "block_prompts", "rewrite_block", "LLMEquationProcessor", "EquationSchema", "image", "expansion", "analyze", "generating", "raw", "text", "dict", "then", "format", "correct", "carefully", "prompts", "replace", "processors", "tags", "default", "delimiter", "output", "string", "only", "latex", "bool", "marker", "along"], "ast_kind": "function_or_method", "text": "    def inference_blocks(self, document: Document) -> List[BlockData]:\n        blocks = super().inference_blocks(document)\n        out_blocks = []\n        for block_data in blocks:\n            block = block_data[\"block\"]\n            page = block_data[\"page\"]\n\n            # If we redo inline math, we redo all equations\n            if all([\n                block.polygon.height / page.polygon.height < self.min_equation_height,\n                not self.redo_inline_math\n            ]):\n                continue\n            out_blocks.append(block_data)\n        return out_blocks\n", "n_tokens": 114, "byte_len": 579, "file_sha1": "3e39b7bad7fcf330ddd076d8db405b24455c056a", "start_line": 71, "end_line": 86}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py", "rel_path": "marker/processors/llm/llm_equation.py", "module": "marker.processors.llm.llm_equation", "ext": "py", "chunk_number": 4, "symbols": ["block_prompts", "prompt", "block", "data", "equation", "text", "image", "else", "raw", "html", "document", "append", "self", "schema", "prompts", "return", "list", "replace", "inference", "blocks", "extract", "latex", "page", "inference_blocks", "rewrite_block", "LLMEquationProcessor", "EquationSchema", "expansion", "analyze", "generating", "dict", "then", "format", "correct", "carefully", "processors", "tags", "default", "delimiter", "output", "string", "only", "bool", "continue", "marker", "along", "which", "this", "expand", "processing"], "ast_kind": "function_or_method", "text": "    def block_prompts(self, document: Document) -> List[PromptData]:\n        prompt_data = []\n        for block_data in self.inference_blocks(document):\n            block = block_data[\"block\"]\n            text = block.html if block.html else block.raw_text(document)\n            prompt = self.equation_latex_prompt.replace(\"{equation}\", text)\n            image = self.extract_image(document, block)\n\n            prompt_data.append({\n                \"prompt\": prompt,\n                \"image\": image,\n                \"block\": block,\n                \"schema\": EquationSchema,\n                \"page\": block_data[\"page\"]\n            })\n\n        return prompt_data\n\n", "n_tokens": 127, "byte_len": 660, "file_sha1": "3e39b7bad7fcf330ddd076d8db405b24455c056a", "start_line": 87, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_equation.py", "rel_path": "marker/processors/llm/llm_equation.py", "module": "marker.processors.llm.llm_equation", "ext": "py", "chunk_number": 5, "symbols": ["rewrite_block", "EquationSchema", "class", "html", "equation", "text", "llm", "error", "analysis", "else", "raw", "document", "self", "schema", "balanced", "tags", "dict", "count", "lower", "return", "corrected", "base", "model", "prompt", "data", "math", "needed", "block", "corrections", "rewrite", "inference_blocks", "block_prompts", "LLMEquationProcessor", "image", "expansion", "analyze", "generating", "then", "format", "correct", "carefully", "prompts", "replace", "processors", "default", "delimiter", "output", "string", "only", "latex"], "ast_kind": "class_or_type", "text": "    def rewrite_block(self, response: dict, prompt_data: PromptData, document: Document):\n        block = prompt_data[\"block\"]\n        text = block.html if block.html else block.raw_text(document)\n\n        if not response or \"corrected_equation\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        html_equation = response[\"corrected_equation\"]\n\n        if \"no corrections needed\" in html_equation.lower():\n            return\n\n        balanced_tags = html_equation.count(\"<math\") == html_equation.count(\"</math>\")\n        if not all([\n            html_equation,\n            balanced_tags,\n            len(html_equation) > len(text) * .3,\n        ]):\n            block.update_metadata(llm_error_count=1)\n            return\n\n        block.html = html_equation\n\nclass EquationSchema(BaseModel):\n    analysis: str\n    corrected_equation: str", "n_tokens": 188, "byte_len": 883, "file_sha1": "3e39b7bad7fcf330ddd076d8db405b24455c056a", "start_line": 106, "end_line": 132}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 1, "symbols": ["image", "tuple", "blocks", "get", "logger", "annotated", "pydantic", "document", "base", "llm", "schema", "from", "table", "model", "list", "processors", "typing", "block", "types", "import", "marker", "groups", "polygon", "beautiful", "soup", "box", "cell", "page", "group", "handle_image_rotation", "process_rewriting", "rewrite_single_chunk", "get_cell_text", "parse_html_table", "LLMTableProcessor", "TableSchema", "analyze", "replace", "iteration", "found", "cells", "rescale", "invalid", "colspan", "process", "rewriting", "default", "issue", "corrected", "html"], "ast_kind": "imports", "text": "from typing import Annotated, List, Tuple\n\nfrom bs4 import BeautifulSoup\nfrom PIL import Image\nfrom marker.logger import get_logger\nfrom pydantic import BaseModel\n\nfrom marker.processors.llm import BaseLLMComplexBlockProcessor\nfrom marker.schema import BlockTypes\nfrom marker.schema.blocks import Block, TableCell, Table\nfrom marker.schema.document import Document\nfrom marker.schema.groups.page import PageGroup\nfrom marker.schema.polygon import PolygonBox\n\nlogger = get_logger()\n\n", "n_tokens": 97, "byte_len": 482, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 2, "symbols": ["LLMTableProcessor", "cannot", "analyze", "name", "well", "process", "reproducing", "replace", "break", "attention", "image", "make", "full", "style", "then", "llm", "table", "cells", "correct", "description", "carefully", "colspan", "than", "lines", "tags", "necessary", "default", "columns", "only", "string", "handle_image_rotation", "process_rewriting", "rewrite_single_chunk", "get_cell_text", "parse_html_table", "TableSchema", "iteration", "found", "rescale", "invalid", "rewriting", "issue", "corrected", "html", "llms", "batch", "page", "okay", "cell", "your"], "ast_kind": "class_or_type", "text": "class LLMTableProcessor(BaseLLMComplexBlockProcessor):\n    block_types: Annotated[\n        Tuple[BlockTypes],\n        \"The block types to process.\",\n    ] = (BlockTypes.Table, BlockTypes.TableOfContents)\n    max_rows_per_batch: Annotated[\n        int,\n        \"If the table has more rows than this, chunk the table. (LLMs can be inaccurate with a lot of rows)\",\n    ] = 60\n    max_table_rows: Annotated[\n        int,\n        \"The maximum number of rows in a table to process with the LLM processor.  Beyond this will be skipped.\",\n    ] = 175\n    table_image_expansion_ratio: Annotated[\n        float,\n        \"The ratio to expand the image by when cropping.\",\n    ] = 0\n    rotation_max_wh_ratio: Annotated[\n        float,\n        \"The maximum width/height ratio for table cells for a table to be considered rotated.\",\n    ] = 0.6\n    max_table_iterations: Annotated[\n        int,\n        \"The maximum number of iterations to attempt rewriting a table.\",\n    ] = 2\n    table_rewriting_prompt: Annotated[\n        str,\n        \"The prompt to use for rewriting text.\",\n        \"Default is a string containing the Gemini rewriting prompt.\",\n    ] = \"\"\"You are a text correction expert specializing in accurately reproducing text from images.\nYou will receive an image and an html representation of the table in the image.\nYour task is to correct any errors in the html representation.  The html representation should be as faithful to the original table image as possible.  The table image may be rotated, but ensure the html representation is not rotated.  Make sure to include HTML for the full table, including the opening and closing table tags.\n\nSome guidelines:\n- Reproduce the original values from the image as faithfully as possible.  \n- There may be stray characters in the html representation that don't match the image - fix these.\n- Ensure column headers match the correct column values.\n- If you see any inline math in a table cell, fence it with the <math> tag.  Block math should be fenced with <math display=\"block\">.\n- Replace any images in table cells with a description, like \"Image: [description]\".\n- Only use the tags th, td, tr, br, span, sup, sub, i, b, math, and table.  Only use the attributes display, style, colspan, and rowspan if necessary.  You can use br to break up text lines in cells.\n- Make sure the columns and rows match the image faithfully, and are easily readable and interpretable by a human.\n\n**Instructions:**\n1. Carefully examine the provided text block image.\n2. Analyze the html representation of the table.\n3. Write a comparison of the image and the html representation, paying special attention to the column headers matching the correct column values.\n4. If the html representation is completely correct, or you cannot read the image properly, then write \"No corrections needed.\"  If the html representation has errors, generate the corrected html representation.  Output only either the corrected html representation or \"No corrections needed.\"\n5. If you made corrections, analyze your corrections against the original image, and provide a score from 1-5, indicating how well the corrected html matches the image, with 5 being perfect.\n**Example:**\nInput:\n```html\n<table>\n    <tr>\n        <th>First Name</th>\n        <th>Last Name</th>\n        <th>Age</th>\n    </tr>\n    <tr>\n        <td>John</td>\n        <td>Doe</td>\n    </tr>\n</table>\n```\nOutput:\ncomparison: The image shows a table with 2 rows and 3 columns.  The text and formatting of the html table matches the image.  The column headers match the correct column values.\n```html\nNo corrections needed.\n```\nanalysis: I did not make any corrections, as the html representation was already accurate.\nscore: 5\n**Input:**\n```html\n{block_html}\n```\n\"\"\"\n", "n_tokens": 854, "byte_len": 3750, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 18, "end_line": 93}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 3, "symbols": ["handle_image_rotation", "last", "col", "image", "handle", "else", "ratios", "rotate", "self", "return", "height", "children", "list", "rotated", "first", "start", "width", "polygon", "rotation", "max", "expand", "table", "cell", "diff", "true", "process_rewriting", "rewrite_single_chunk", "get_cell_text", "parse_html_table", "LLMTableProcessor", "TableSchema", "analyze", "replace", "iteration", "found", "cells", "rescale", "invalid", "colspan", "process", "rewriting", "default", "issue", "corrected", "html", "llms", "batch", "page", "okay", "your"], "ast_kind": "function_or_method", "text": "    def handle_image_rotation(self, children: List[TableCell], image: Image.Image):\n        ratios = [c.polygon.width / c.polygon.height for c in children]\n        if len(ratios) < 2:\n            return image\n\n        is_rotated = all([r < self.rotation_max_wh_ratio for r in ratios])\n        if not is_rotated:\n            return image\n\n        first_col_id = min([c.col_id for c in children])\n        first_col = [c for c in children if c.col_id == first_col_id]\n        first_col_cell = first_col[0]\n\n        last_col_id = max([c.col_id for c in children])\n        if last_col_id == first_col_id:\n            return image\n\n        last_col_cell = [c for c in children if c.col_id == last_col_id][0]\n        cell_diff = first_col_cell.polygon.y_start - last_col_cell.polygon.y_start\n        if cell_diff == 0:\n            return image\n\n        if cell_diff > 0:\n            return image.rotate(270, expand=True)\n        else:\n            return image.rotate(90, expand=True)\n", "n_tokens": 239, "byte_len": 977, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 94, "end_line": 120}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 4, "symbols": ["process_rewriting", "row", "well", "batch", "cell", "image", "document", "return", "rescale", "sorted", "children", "processors", "process", "rewriting", "get", "llms", "cells", "page", "true", "relative", "happens", "tables", "inference", "didn", "handle", "form", "height", "structure", "extract", "very", "handle_image_rotation", "rewrite_single_chunk", "get_cell_text", "parse_html_table", "LLMTableProcessor", "TableSchema", "analyze", "replace", "iteration", "found", "invalid", "colspan", "default", "issue", "corrected", "html", "okay", "your", "find", "all"], "ast_kind": "function_or_method", "text": "    def process_rewriting(self, document: Document, page: PageGroup, block: Table):\n        children: List[TableCell] = block.contained_blocks(\n            document, (BlockTypes.TableCell,)\n        )\n        if not children:\n            # Happens if table/form processors didn't run\n            return\n\n        # LLMs don't handle tables with a lot of rows very well\n        unique_rows = set([cell.row_id for cell in children])\n        row_count = len(unique_rows)\n        row_idxs = sorted(list(unique_rows))\n\n        if row_count > self.max_table_rows:\n            return\n\n        # Inference by chunk to handle long tables better\n        parsed_cells = []\n        row_shift = 0\n        block_image = self.extract_image(document, block)\n        block_rescaled_bbox = block.polygon.rescale(\n            page.polygon.size, page.get_image(highres=True).size\n        ).bbox\n        for i in range(0, row_count, self.max_rows_per_batch):\n            batch_row_idxs = row_idxs[i : i + self.max_rows_per_batch]\n            batch_cells = [cell for cell in children if cell.row_id in batch_row_idxs]\n            batch_cell_bboxes = [\n                cell.polygon.rescale(\n                    page.polygon.size, page.get_image(highres=True).size\n                ).bbox\n                for cell in batch_cells\n            ]\n            # bbox relative to the block\n            batch_bbox = [\n                min([bbox[0] for bbox in batch_cell_bboxes]) - block_rescaled_bbox[0],\n                min([bbox[1] for bbox in batch_cell_bboxes]) - block_rescaled_bbox[1],\n                max([bbox[2] for bbox in batch_cell_bboxes]) - block_rescaled_bbox[0],\n                max([bbox[3] for bbox in batch_cell_bboxes]) - block_rescaled_bbox[1],\n            ]\n            if i == 0:\n                # Ensure first image starts from the beginning\n                batch_bbox[0] = 0\n                batch_bbox[1] = 0\n            elif i > row_count - self.max_rows_per_batch + 1:\n                # Ensure final image grabs the entire height and width\n                batch_bbox[2] = block_image.size[0]\n                batch_bbox[3] = block_image.size[1]\n\n            batch_image = block_image.crop(batch_bbox)\n            block_html = block.format_cells(document, [], None, batch_cells)\n            batch_image = self.handle_image_rotation(batch_cells, batch_image)\n            batch_parsed_cells = self.rewrite_single_chunk(\n                page, block, block_html, batch_cells, batch_image\n            )\n            if batch_parsed_cells is None:\n                return  # Error occurred or no corrections needed\n\n            for cell in batch_parsed_cells:\n                cell.row_id += row_shift\n                parsed_cells.append(cell)\n            row_shift += max([cell.row_id for cell in batch_parsed_cells])\n\n        block.structure = []\n        for cell in parsed_cells:\n            page.add_full_block(cell)\n            block.add_structure(cell)\n", "n_tokens": 632, "byte_len": 2941, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 121, "end_line": 187}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 5, "symbols": ["rewrite_single_chunk", "image", "prompt", "total", "iterations", "llm", "error", "rewriting", "corrected", "table", "rewrite", "single", "parsed", "cells", "service", "analysis", "parsing", "html", "page", "group", "iteration", "found", "self", "lstrip", "does", "lower", "return", "rstrip", "children", "list", "handle_image_rotation", "process_rewriting", "get_cell_text", "parse_html_table", "LLMTableProcessor", "TableSchema", "analyze", "replace", "rescale", "invalid", "colspan", "process", "default", "issue", "llms", "batch", "okay", "cell", "your", "tables"], "ast_kind": "function_or_method", "text": "    def rewrite_single_chunk(\n        self,\n        page: PageGroup,\n        block: Block,\n        block_html: str,\n        children: List[TableCell],\n        image: Image.Image,\n        total_iterations: int = 0,\n    ):\n        prompt = self.table_rewriting_prompt.replace(\"{block_html}\", block_html)\n\n        response = self.llm_service(prompt, image, block, TableSchema)\n\n        if not response or \"corrected_html\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        corrected_html = response[\"corrected_html\"]\n\n        # The original table is okay\n        if \"no corrections needed\" in corrected_html.lower():\n            return\n\n        corrected_html = corrected_html.strip().lstrip(\"```html\").rstrip(\"```\").strip()\n\n        # Re-iterate if low score\n        total_iterations += 1\n        score = response.get(\"score\", 5)\n        analysis = response.get(\"analysis\", \"\")\n        logger.debug(f\"Got table rewriting score {score} with analysis: {analysis}\")\n        if total_iterations < self.max_table_iterations and score < 4:\n            logger.info(\n                f\"Table rewriting low score {score}, on iteration {total_iterations}\"\n            )\n            block_html = corrected_html\n            return self.rewrite_single_chunk(\n                page, block, block_html, children, image, total_iterations\n            )\n\n        parsed_cells = self.parse_html_table(corrected_html, block, page)\n        if len(parsed_cells) <= 1:\n            block.update_metadata(llm_error_count=1)\n            logger.debug(f\"Table parsing issue, only {len(parsed_cells)} cells found\")\n            return\n\n        if not corrected_html.endswith(\"</table>\"):\n            logger.debug(\n                \"Table parsing issue, corrected html does not end with </table>\"\n            )\n            block.update_metadata(llm_error_count=1)\n            return\n\n        return parsed_cells\n", "n_tokens": 394, "byte_len": 1923, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 188, "end_line": 241}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 6, "symbols": ["get_cell_text", "decode", "contents", "unwrap", "math", "true", "find", "all", "staticmethod", "get", "cell", "keep", "tags", "span", "element", "return", "name", "handle_image_rotation", "process_rewriting", "rewrite_single_chunk", "parse_html_table", "LLMTableProcessor", "TableSchema", "analyze", "replace", "iteration", "found", "cells", "rescale", "invalid", "colspan", "process", "rewriting", "default", "issue", "corrected", "html", "llms", "batch", "page", "okay", "your", "tables", "inference", "didn", "table", "gemini", "handle", "image", "llm"], "ast_kind": "function_or_method", "text": "    @staticmethod\n    def get_cell_text(element, keep_tags=(\"br\", \"i\", \"b\", \"span\", \"math\")) -> str:\n        for tag in element.find_all(True):\n            if tag.name not in keep_tags:\n                tag.unwrap()\n        return element.decode_contents()\n", "n_tokens": 59, "byte_len": 256, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 242, "end_line": 248}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 7, "symbols": ["parse_html_table", "bbox", "find", "col", "row", "all", "parser", "initialize", "tds", "soup", "break", "range", "cell", "rows", "parsing", "cur", "html", "append", "found", "self", "text", "lines", "while", "from", "table", "grid", "cells", "name", "max", "cols", "handle_image_rotation", "process_rewriting", "rewrite_single_chunk", "get_cell_text", "LLMTableProcessor", "TableSchema", "analyze", "replace", "iteration", "rescale", "invalid", "colspan", "process", "rewriting", "default", "issue", "corrected", "llms", "batch", "page"], "ast_kind": "function_or_method", "text": "    def parse_html_table(\n        self, html_text: str, block: Block, page: PageGroup\n    ) -> List[TableCell]:\n        soup = BeautifulSoup(html_text, \"html.parser\")\n        table = soup.find(\"table\")\n        if not table:\n            return []\n\n        # Initialize grid\n        rows = table.find_all(\"tr\")\n        cells = []\n\n        # Find maximum number of columns in colspan-aware way\n        max_cols = 0\n        for row in rows:\n            row_tds = row.find_all([\"td\", \"th\"])\n            curr_cols = 0\n            for cell in row_tds:\n                colspan = int(cell.get(\"colspan\", 1))\n                curr_cols += colspan\n            if curr_cols > max_cols:\n                max_cols = curr_cols\n\n        grid = [[True] * max_cols for _ in range(len(rows))]\n\n        for i, row in enumerate(rows):\n            cur_col = 0\n            row_cells = row.find_all([\"td\", \"th\"])\n            for j, cell in enumerate(row_cells):\n                while cur_col < max_cols and not grid[i][cur_col]:\n                    cur_col += 1\n\n                if cur_col >= max_cols:\n                    logger.info(\"Table parsing warning: too many columns found\")\n                    break\n\n                cell_text = self.get_cell_text(cell).strip()\n                rowspan = min(int(cell.get(\"rowspan\", 1)), len(rows) - i)\n                colspan = min(int(cell.get(\"colspan\", 1)), max_cols - cur_col)\n                cell_rows = list(range(i, i + rowspan))\n                cell_cols = list(range(cur_col, cur_col + colspan))\n\n                if colspan == 0 or rowspan == 0:\n                    logger.info(\"Table parsing issue: invalid colspan or rowspan\")\n                    continue\n\n                for r in cell_rows:\n                    for c in cell_cols:\n                        grid[r][c] = False\n\n                cell_bbox = [\n                    block.polygon.bbox[0] + cur_col,\n                    block.polygon.bbox[1] + i,\n                    block.polygon.bbox[0] + cur_col + colspan,\n                    block.polygon.bbox[1] + i + rowspan,\n                ]\n                cell_polygon = PolygonBox.from_bbox(cell_bbox)\n\n                cell_obj = TableCell(\n                    text_lines=[cell_text],\n                    row_id=i,\n                    col_id=cur_col,\n                    rowspan=rowspan,\n                    colspan=colspan,\n                    is_header=cell.name == \"th\",\n                    polygon=cell_polygon,\n                    page_id=page.page_id,\n                )\n                cells.append(cell_obj)\n                cur_col += colspan\n\n        return cells\n\n", "n_tokens": 544, "byte_len": 2608, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 249, "end_line": 322}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py#8", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_table.py", "rel_path": "marker/processors/llm/llm_table.py", "module": "marker.processors.llm.llm_table", "ext": "py", "chunk_number": 8, "symbols": ["TableSchema", "base", "model", "class", "corrected", "html", "comparison", "table", "schema", "score", "analysis", "handle_image_rotation", "process_rewriting", "rewrite_single_chunk", "get_cell_text", "parse_html_table", "LLMTableProcessor", "analyze", "replace", "iteration", "found", "cells", "rescale", "invalid", "colspan", "process", "rewriting", "default", "issue", "llms", "batch", "page", "okay", "cell", "your", "tables", "find", "all", "inference", "didn", "gemini", "handle", "image", "llm", "service", "row", "tds", "rotate", "lstrip", "lower"], "ast_kind": "class_or_type", "text": "class TableSchema(BaseModel):\n    comparison: str\n    corrected_html: str\n    analysis: str\n    score: int\n", "n_tokens": 27, "byte_len": 107, "file_sha1": "e8bcb55b817b9525c6dbef9c7974b8bdcf2211ca", "start_line": 323, "end_line": 328}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py", "rel_path": "marker/processors/llm/llm_image_description.py", "module": "marker.processors.llm.llm_image_description", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "base", "model", "import", "document", "marker", "pydantic", "list", "prompt", "data", "schema", "block", "from", "processors", "llm", "typing", "types", "inference_blocks", "block_prompts", "rewrite_block", "LLMImageDescriptionProcessor", "ImageSchema", "analyze", "generating", "create", "image", "raw", "text", "descriptions", "bananas", "dict", "carefully", "description", "prompts", "return", "fruit", "within", "replace", "default", "output", "string", "bool", "this", "showing", "number", "rewrite", "page", "true", "extract", "fruits"], "ast_kind": "imports", "text": "from pydantic import BaseModel\n\nfrom marker.processors.llm import PromptData, BaseLLMSimpleBlockProcessor, BlockData\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\nfrom typing import Annotated, List\n\n", "n_tokens": 49, "byte_len": 236, "file_sha1": "3da14268fde7eabbfcd6146bfec2e1d13575add5", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py", "rel_path": "marker/processors/llm/llm_image_description.py", "module": "marker.processors.llm.llm_image_description", "ext": "py", "chunk_number": 2, "symbols": ["LLMImageDescriptionProcessor", "analyze", "generating", "create", "image", "raw", "text", "descriptions", "document", "bananas", "carefully", "description", "fruit", "within", "default", "output", "string", "bool", "showing", "this", "number", "true", "extract", "prompt", "fruits", "preference", "accurately", "gemini", "analysis", "specializes", "inference_blocks", "block_prompts", "rewrite_block", "ImageSchema", "dict", "block", "prompts", "return", "replace", "processors", "schema", "marker", "data", "rewrite", "page", "llm", "error", "blocks", "images", "contains"], "ast_kind": "class_or_type", "text": "class LLMImageDescriptionProcessor(BaseLLMSimpleBlockProcessor):\n    block_types = (\n        BlockTypes.Picture,\n        BlockTypes.Figure,\n    )\n    extract_images: Annotated[bool, \"Extract images from the document.\"] = True\n    image_description_prompt: Annotated[\n        str,\n        \"The prompt to use for generating image descriptions.\",\n        \"Default is a string containing the Gemini prompt.\",\n    ] = \"\"\"You are a document analysis expert who specializes in creating text descriptions for images.\nYou will receive an image of a picture or figure.  Your job will be to create a short description of the image.\n**Instructions:**\n1. Carefully examine the provided image.\n2. Analyze any text that was extracted from within the image.\n3. Output a faithful description of the image.  Make sure there is enough specific detail to accurately reconstruct the image.  If the image is a figure or contains numeric data, include the numeric data in the output.\n**Example:**\nInput:\n```text\n\"Fruit Preference Survey\"\n20, 15, 10\nApples, Bananas, Oranges\n```\nOutput:\nIn this figure, a bar chart titled \"Fruit Preference Survey\" is showing the number of people who prefer different types of fruits.  The x-axis shows the types of fruits, and the y-axis shows the number of people.  The bar chart shows that most people prefer apples, followed by bananas and oranges.  20 people prefer apples, 15 people prefer bananas, and 10 people prefer oranges.\n**Input:**\n```text\n{raw_text}\n```\n\"\"\"\n", "n_tokens": 332, "byte_len": 1482, "file_sha1": "3da14268fde7eabbfcd6146bfec2e1d13575add5", "start_line": 11, "end_line": 41}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py", "rel_path": "marker/processors/llm/llm_image_description.py", "module": "marker.processors.llm.llm_image_description", "ext": "py", "chunk_number": 3, "symbols": ["inference_blocks", "block_prompts", "prompt", "block", "data", "blocks", "extract", "images", "image", "raw", "text", "document", "append", "self", "schema", "prompts", "return", "super", "list", "replace", "inference", "description", "page", "rewrite_block", "LLMImageDescriptionProcessor", "ImageSchema", "analyze", "generating", "create", "descriptions", "bananas", "dict", "carefully", "fruit", "within", "processors", "default", "output", "string", "bool", "marker", "this", "showing", "number", "rewrite", "true", "fruits", "llm", "error", "preference"], "ast_kind": "function_or_method", "text": "    def inference_blocks(self, document: Document) -> List[BlockData]:\n        blocks = super().inference_blocks(document)\n        if self.extract_images:\n            return []\n        return blocks\n\n    def block_prompts(self, document: Document) -> List[PromptData]:\n        prompt_data = []\n        for block_data in self.inference_blocks(document):\n            block = block_data[\"block\"]\n            prompt = self.image_description_prompt.replace(\n                \"{raw_text}\", block.raw_text(document)\n            )\n            image = self.extract_image(document, block)\n\n            prompt_data.append(\n                {\n                    \"prompt\": prompt,\n                    \"image\": image,\n                    \"block\": block,\n                    \"schema\": ImageSchema,\n                    \"page\": block_data[\"page\"],\n                }\n            )\n\n        return prompt_data\n", "n_tokens": 161, "byte_len": 890, "file_sha1": "3da14268fde7eabbfcd6146bfec2e1d13575add5", "start_line": 42, "end_line": 68}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_image_description.py", "rel_path": "marker/processors/llm/llm_image_description.py", "module": "marker.processors.llm.llm_image_description", "ext": "py", "chunk_number": 4, "symbols": ["rewrite_block", "ImageSchema", "base", "model", "document", "class", "image", "schema", "prompt", "data", "self", "block", "description", "llm", "error", "rewrite", "dict", "update", "metadata", "return", "response", "inference_blocks", "block_prompts", "LLMImageDescriptionProcessor", "analyze", "generating", "create", "raw", "text", "descriptions", "bananas", "carefully", "prompts", "fruit", "within", "replace", "processors", "default", "output", "string", "bool", "marker", "this", "showing", "number", "page", "true", "extract", "fruits", "preference"], "ast_kind": "class_or_type", "text": "    def rewrite_block(\n        self, response: dict, prompt_data: PromptData, document: Document\n    ):\n        block = prompt_data[\"block\"]\n\n        if not response or \"image_description\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        image_description = response[\"image_description\"]\n        if len(image_description) < 10:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        block.description = image_description\n\n\nclass ImageSchema(BaseModel):\n    image_description: str\n", "n_tokens": 111, "byte_len": 555, "file_sha1": "3da14268fde7eabbfcd6146bfec2e1d13575add5", "start_line": 69, "end_line": 88}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py", "rel_path": "marker/processors/llm/llm_handwriting.py", "module": "marker.processors.llm.llm_handwriting", "ext": "py", "chunk_number": 1, "symbols": ["annotated", "import", "base", "model", "document", "marker", "pydantic", "list", "prompt", "data", "schema", "block", "from", "processors", "llm", "typing", "types", "markdown", "markdown2", "inference_blocks", "block_prompts", "rewrite_block", "LLMHandwritingProcessor", "HandwritingSchema", "header", "display", "process", "reproducing", "image", "make", "raw", "text", "expression", "labels", "unordered", "dict", "bold", "carefully", "prompts", "return", "smallest", "lines", "editor", "default", "bolded", "representing", "string", "continue", "either", "right"], "ast_kind": "imports", "text": "import markdown2\nfrom pydantic import BaseModel\nfrom marker.processors.llm import PromptData, BaseLLMSimpleBlockProcessor, BlockData\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\n\nfrom typing import Annotated, List\n\n", "n_tokens": 53, "byte_len": 252, "file_sha1": "d1111d9fb682fa91eac6bd610e7a4658c4a0e5cc", "start_line": 1, "end_line": 10}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py", "rel_path": "marker/processors/llm/llm_handwriting.py", "module": "marker.processors.llm.llm_handwriting", "ext": "py", "chunk_number": 2, "symbols": ["LLMHandwritingProcessor", "markdown", "header", "display", "reproducing", "image", "make", "expression", "labels", "unordered", "bold", "carefully", "smallest", "editor", "default", "bolded", "representing", "string", "either", "right", "generate", "prompt", "text", "tables", "rules", "accurately", "gemini", "omit", "blocks", "form", "inference_blocks", "block_prompts", "rewrite_block", "HandwritingSchema", "process", "raw", "document", "dict", "block", "prompts", "return", "processors", "lines", "continue", "marker", "data", "rewrite", "page", "type", "extras"], "ast_kind": "class_or_type", "text": "class LLMHandwritingProcessor(BaseLLMSimpleBlockProcessor):\n    block_types = (BlockTypes.Handwriting, BlockTypes.Text)\n    handwriting_generation_prompt: Annotated[\n        str,\n        \"The prompt to use for OCRing handwriting.\",\n        \"Default is a string containing the Gemini prompt.\"\n    ] = \"\"\"You are an expert editor specializing in accurately reproducing text from images.\nYou will receive an image of a text block. Your task is to generate markdown to properly represent the content of the image.  Do not omit any text present in the image - make sure everything is included in the markdown representation.  The markdown representation should be as faithful to the original image as possible.\n\nFormatting should be in markdown, with the following rules:\n- * for italics, ** for bold, and ` for inline code.\n- Headers should be formatted with #, with one # for the largest header, and up to 6 for the smallest.\n- Lists should be formatted with either - or 1. for unordered and ordered lists, respectively.\n- Links should be formatted with [text](url).\n- Use ``` for code blocks.\n- Inline math should be formatted with <math>math expression</math>.\n- Display math should be formatted with <math display=\"block\">math expression</math>.\n- Values and labels should be extracted from forms, and put into markdown tables, with the labels on the left side, and values on the right.  The headers should be \"Labels\" and \"Values\".  Other text in the form can appear between the tables.\n- Tables should be formatted with markdown tables, with the headers bolded.\n\n**Instructions:**\n1. Carefully examine the provided block image.\n2. Output the markdown representing the content of the image.\n\"\"\"\n", "n_tokens": 359, "byte_len": 1696, "file_sha1": "d1111d9fb682fa91eac6bd610e7a4658c4a0e5cc", "start_line": 11, "end_line": 35}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py", "rel_path": "marker/processors/llm/llm_handwriting.py", "module": "marker.processors.llm.llm_handwriting", "ext": "py", "chunk_number": 3, "symbols": ["inference_blocks", "block", "type", "already", "data", "text", "contained", "blocks", "process", "line", "contain", "raw", "document", "append", "self", "return", "out", "super", "list", "strip", "inference", "lines", "types", "that", "continue", "block_prompts", "rewrite_block", "LLMHandwritingProcessor", "HandwritingSchema", "markdown", "header", "display", "reproducing", "image", "make", "expression", "labels", "unordered", "dict", "bold", "carefully", "prompts", "smallest", "processors", "editor", "default", "bolded", "representing", "string", "marker"], "ast_kind": "function_or_method", "text": "    def inference_blocks(self, document: Document) -> List[BlockData]:\n        blocks = super().inference_blocks(document)\n        out_blocks = []\n        for block_data in blocks:\n            raw_text = block_data[\"block\"].raw_text(document)\n            block = block_data[\"block\"]\n\n            # Don't process text blocks that contain lines already\n            if block.block_type == BlockTypes.Text:\n                lines = block.contained_blocks(document, (BlockTypes.Line,))\n                if len(lines) > 0 or len(raw_text.strip()) > 0:\n                    continue\n            out_blocks.append(block_data)\n        return out_blocks\n\n", "n_tokens": 128, "byte_len": 642, "file_sha1": "d1111d9fb682fa91eac6bd610e7a4658c4a0e5cc", "start_line": 36, "end_line": 51}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py", "rel_path": "marker/processors/llm/llm_handwriting.py", "module": "marker.processors.llm.llm_handwriting", "ext": "py", "chunk_number": 4, "symbols": ["block_prompts", "prompt", "block", "data", "handwriting", "generation", "image", "document", "append", "self", "schema", "prompts", "return", "list", "inference", "blocks", "extract", "page", "inference_blocks", "rewrite_block", "LLMHandwritingProcessor", "HandwritingSchema", "markdown", "header", "display", "process", "reproducing", "make", "raw", "text", "expression", "labels", "unordered", "dict", "bold", "carefully", "smallest", "processors", "lines", "editor", "default", "bolded", "representing", "string", "continue", "marker", "either", "right", "rewrite", "generate"], "ast_kind": "function_or_method", "text": "    def block_prompts(self, document: Document) -> List[PromptData]:\n        prompt_data = []\n        for block_data in self.inference_blocks(document):\n            block = block_data[\"block\"]\n            prompt = self.handwriting_generation_prompt\n            image = self.extract_image(document, block)\n\n            prompt_data.append({\n                \"prompt\": prompt,\n                \"image\": image,\n                \"block\": block,\n                \"schema\": HandwritingSchema,\n                \"page\": block_data[\"page\"]\n            })\n        return prompt_data\n", "n_tokens": 107, "byte_len": 567, "file_sha1": "d1111d9fb682fa91eac6bd610e7a4658c4a0e5cc", "start_line": 52, "end_line": 67}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/processors/llm/llm_handwriting.py", "rel_path": "marker/processors/llm/llm_handwriting.py", "module": "marker.processors.llm.llm_handwriting", "ext": "py", "chunk_number": 5, "symbols": ["rewrite_block", "HandwritingSchema", "markdown", "class", "extras", "llm", "error", "tables", "raw", "text", "html", "document", "self", "lstrip", "dict", "return", "base", "model", "rstrip", "prompt", "data", "strip", "handwriting", "schema", "response", "block", "rewrite", "update", "metadata", "markdown2", "inference_blocks", "block_prompts", "LLMHandwritingProcessor", "header", "display", "process", "reproducing", "image", "make", "expression", "labels", "unordered", "bold", "carefully", "prompts", "smallest", "processors", "lines", "editor", "default"], "ast_kind": "class_or_type", "text": "    def rewrite_block(self, response: dict, prompt_data: PromptData, document: Document):\n        block = prompt_data[\"block\"]\n        raw_text = block.raw_text(document)\n\n        if not response or \"markdown\" not in response:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        markdown = response[\"markdown\"]\n        if len(markdown) < len(raw_text) * .5:\n            block.update_metadata(llm_error_count=1)\n            return\n\n        markdown = markdown.strip().lstrip(\"```markdown\").rstrip(\"```\").strip()\n        block.html = markdown2.markdown(markdown, extras=[\"tables\"])\n\nclass HandwritingSchema(BaseModel):\n    markdown: str\n", "n_tokens": 144, "byte_len": 664, "file_sha1": "d1111d9fb682fa91eac6bd610e7a4658c4a0e5cc", "start_line": 68, "end_line": 86}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 1, "symbols": ["create", "model", "uploads", "traceback", "click", "app", "data", "parser", "upload", "file", "annotated", "pydantic", "field", "base", "base64", "converters", "config", "responses", "settings", "from", "exist", "contextlib", "asynccontextmanager", "text", "form", "yield", "typing", "starlette", "uploa", "directory", "server_cli", "CommonParams", "exception", "contents", "defaults", "markdown", "renderer", "cases", "pdftext", "workers", "byte", "stream", "get", "processors", "media", "type", "dump", "error", "format", "convert"], "ast_kind": "imports", "text": "import traceback\n\nimport click\nimport os\n\nfrom pydantic import BaseModel, Field\nfrom starlette.responses import HTMLResponse\n\nfrom marker.config.parser import ConfigParser\nfrom marker.output import text_from_rendered\n\nimport base64\nfrom contextlib import asynccontextmanager\nfrom typing import Optional, Annotated\nimport io\n\nfrom fastapi import FastAPI, Form, File, UploadFile\nfrom marker.converters.pdf import PdfConverter\nfrom marker.models import create_model_dict\nfrom marker.settings import settings\n\napp_data = {}\n\n\nUPLOAD_DIRECTORY = \"./uploads\"\nos.makedirs(UPLOAD_DIRECTORY, exist_ok=True)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    app_data[\"models\"] = create_model_dict()\n\n    yield\n\n    if \"models\" in app_data:\n        del app_data[\"models\"]\n\n\napp = FastAPI(lifespan=lifespan)\n\n", "n_tokens": 178, "byte_len": 808, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 1, "end_line": 41}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 2, "symbols": ["html", "response", "async", "docs", "marker", "post", "only", "root", "documentation", "request", "return", "href", "server_cli", "CommonParams", "exception", "file", "contents", "defaults", "markdown", "traceback", "click", "renderer", "cases", "pdftext", "workers", "byte", "stream", "base", "base64", "field", "converters", "get", "processors", "media", "type", "config", "responses", "model", "dump", "error", "format", "convert", "description", "outpu", "imag", "asynccontextmanager", "decode", "filename", "except", "pdf"], "ast_kind": "unknown", "text": "@app.get(\"/\")\nasync def root():\n    return HTMLResponse(\n        \"\"\"\n<h1>Marker API</h1>\n<ul>\n    <li><a href=\"/docs\">API Documentation</a></li>\n    <li><a href=\"/marker\">Run marker (post request only)</a></li>\n</ul>\n\"\"\"\n    )\n\n", "n_tokens": 67, "byte_len": 228, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 42, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 3, "symbols": ["CommonParams", "results", "defaults", "class", "ranges", "markdown", "your", "none", "force", "ocr", "text", "most", "characters", "each", "true", "cases", "page", "rule", "range", "worse", "output", "format", "annotated", "html", "contains", "field", "pag", "number", "numbers", "specify", "server_cli", "exception", "file", "contents", "traceback", "click", "renderer", "pdftext", "workers", "byte", "stream", "base", "base64", "converters", "get", "processors", "media", "type", "config", "responses"], "ast_kind": "class_or_type", "text": "class CommonParams(BaseModel):\n    filepath: Annotated[\n        Optional[str], Field(description=\"The path to the PDF file to convert.\")\n    ]\n    page_range: Annotated[\n        Optional[str],\n        Field(\n            description=\"Page range to convert, specify comma separated page numbers or ranges.  Example: 0,5-10,20\",\n            example=None,\n        ),\n    ] = None\n    force_ocr: Annotated[\n        bool,\n        Field(\n            description=\"Force OCR on all pages of the PDF.  Defaults to False.  This can lead to worse results if you have good text in your PDFs (which is true in most cases).\"\n        ),\n    ] = False\n    paginate_output: Annotated[\n        bool,\n        Field(\n            description=\"Whether to paginate the output.  Defaults to False.  If set to True, each page of the output will be separated by a horizontal rule that contains the page number (2 newlines, {PAGE_NUMBER}, 48 - characters, 2 newlines).\"\n        ),\n    ] = False\n    output_format: Annotated[\n        str,\n        Field(\n            description=\"The format to output the text in.  Can be 'markdown', 'json', or 'html'.  Defaults to 'markdown'.\"\n        ),\n    ] = \"markdown\"\n\n", "n_tokens": 275, "byte_len": 1180, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 55, "end_line": 85}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 4, "symbols": ["exception", "chunks", "markdown", "assert", "rendered", "text", "traceback", "app", "data", "save", "encoded", "renderer", "outpu", "encoding", "llm", "service", "config", "parser", "output", "format", "pdftext", "workers", "images", "byte", "stream", "converter", "cls", "metadata", "html", "base", "server_cli", "CommonParams", "file", "contents", "defaults", "click", "cases", "base64", "field", "converters", "get", "processors", "media", "type", "responses", "model", "dump", "error", "convert", "description"], "ast_kind": "unknown", "text": "async def _convert_pdf(params: CommonParams):\n    assert params.output_format in [\"markdown\", \"json\", \"html\", \"chunks\"], (\n        \"Invalid output format\"\n    )\n    try:\n        options = params.model_dump()\n        config_parser = ConfigParser(options)\n        config_dict = config_parser.generate_config_dict()\n        config_dict[\"pdftext_workers\"] = 1\n        converter_cls = PdfConverter\n        converter = converter_cls(\n            config=config_dict,\n            artifact_dict=app_data[\"models\"],\n            processor_list=config_parser.get_processors(),\n            renderer=config_parser.get_renderer(),\n            llm_service=config_parser.get_llm_service(),\n        )\n        rendered = converter(params.filepath)\n        text, _, images = text_from_rendered(rendered)\n        metadata = rendered.metadata\n    except Exception as e:\n        traceback.print_exc()\n        return {\n            \"success\": False,\n            \"error\": str(e),\n        }\n\n    encoded = {}\n    for k, v in images.items():\n        byte_stream = io.BytesIO()\n        v.save(byte_stream, format=settings.OUTPUT_IMAGE_FORMAT)\n        encoded[k] = base64.b64encode(byte_stream.getvalue()).decode(\n            settings.OUTPUT_ENCODING\n        )\n\n    return {\n        \"format\": params.output_format,\n        \"output\": text,\n        \"images\": encoded,\n        \"metadata\": metadata,\n        \"success\": True,\n    }\n\n", "n_tokens": 284, "byte_len": 1398, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 86, "end_line": 129}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 5, "symbols": ["async", "marker", "await", "params", "post", "convert", "pdf", "common", "return", "server_cli", "CommonParams", "exception", "file", "contents", "defaults", "markdown", "traceback", "click", "renderer", "cases", "pdftext", "workers", "byte", "stream", "base", "base64", "field", "converters", "get", "processors", "media", "type", "config", "responses", "model", "dump", "error", "format", "description", "outpu", "imag", "asynccontextmanager", "href", "decode", "filename", "except", "paginate", "filepath", "options", "invalid"], "ast_kind": "unknown", "text": "@app.post(\"/marker\")\nasync def convert_pdf(params: CommonParams):\n    return await _convert_pdf(params)\n\n", "n_tokens": 22, "byte_len": 105, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 130, "end_line": 134}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 6, "symbols": ["file", "contents", "results", "remove", "markdown", "none", "force", "ocr", "upload", "default", "output", "format", "media", "type", "path", "convert", "description", "filename", "return", "pdf", "form", "params", "paginate", "filepath", "uploa", "directory", "open", "with", "optional", "bool", "server_cli", "CommonParams", "exception", "defaults", "traceback", "click", "renderer", "cases", "pdftext", "workers", "byte", "stream", "base", "base64", "field", "converters", "get", "processors", "config", "responses"], "ast_kind": "unknown", "text": "@app.post(\"/marker/upload\")\nasync def convert_pdf_upload(\n    page_range: Optional[str] = Form(default=None),\n    force_ocr: Optional[bool] = Form(default=False),\n    paginate_output: Optional[bool] = Form(default=False),\n    output_format: Optional[str] = Form(default=\"markdown\"),\n    file: UploadFile = File(\n        ..., description=\"The PDF file to convert.\", media_type=\"application/pdf\"\n    ),\n):\n    upload_path = os.path.join(UPLOAD_DIRECTORY, file.filename)\n    with open(upload_path, \"wb+\") as upload_file:\n        file_contents = await file.read()\n        upload_file.write(file_contents)\n\n    params = CommonParams(\n        filepath=upload_path,\n        page_range=page_range,\n        force_ocr=force_ocr,\n        paginate_output=paginate_output,\n        output_format=output_format,\n    )\n    results = await _convert_pdf(params)\n    os.remove(upload_path)\n    return results\n\n", "n_tokens": 196, "byte_len": 891, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 135, "end_line": 161}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py#7", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/server.py", "rel_path": "marker/scripts/server.py", "module": "marker.scripts.server", "ext": "py", "chunk_number": 7, "symbols": ["server_cli", "type", "import", "host", "server", "cli", "help", "port", "click", "option", "default", "uvicorn", "command", "CommonParams", "exception", "file", "contents", "defaults", "markdown", "traceback", "renderer", "cases", "pdftext", "workers", "byte", "stream", "base", "base64", "field", "converters", "get", "processors", "media", "config", "responses", "model", "dump", "error", "format", "convert", "description", "outpu", "imag", "return", "asynccontextmanager", "href", "decode", "filename", "except", "pdf"], "ast_kind": "function_or_method", "text": "@click.command()\n@click.option(\"--port\", type=int, default=8000, help=\"Port to run the server on\")\n@click.option(\"--host\", type=str, default=\"127.0.0.1\", help=\"Host to run the server on\")\ndef server_cli(port: int, host: str):\n    import uvicorn\n\n    # Run the server\n    uvicorn.run(\n        app,\n        host=host,\n        port=port,\n    )\n", "n_tokens": 94, "byte_len": 341, "file_sha1": "2f26c64d8ed9aa74e3f9f6e451746f8512d5cb52", "start_line": 162, "end_line": 174}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py", "rel_path": "marker/scripts/convert.py", "module": "marker.scripts.convert", "ext": "py", "chunk_number": 1, "symbols": ["streamlit", "supported", "dynamic", "omp", "grp", "verbosity", "contend", "traceback", "atexit", "click", "mkl", "true", "issues", "isin", "threads", "utils", "error", "from", "pytorc", "enabl", "glo", "minloglevel", "uses", "surya", "time", "ensure", "transformers", "open", "openmp", "math", "worker_init", "worker_exit", "process_single_pdf", "convert_cli", "exception", "cleanup", "inferenced", "throughput", "set", "start", "exit", "argument", "process", "renderer", "disable", "multiprocessing", "pdfs", "get", "processors", "config"], "ast_kind": "imports", "text": "import atexit\nimport os\nimport time\n\nimport psutil\nimport torch\n\nfrom marker.utils.batch import get_batch_sizes_worker_counts\n\n# Ensure threads don't contend\nos.environ[\"MKL_DYNAMIC\"] = \"FALSE\"\nos.environ[\"OMP_DYNAMIC\"] = \"FALSE\"\nos.environ[\"OMP_NUM_THREADS\"] = \"2\"  # Avoid OpenMP issues with multiprocessing\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\nos.environ[\"MKL_NUM_THREADS\"] = \"2\"\nos.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\nos.environ[\"GLOG_minloglevel\"] = \"2\"\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = (\n    \"1\"  # Transformers uses .isin for a simple op, which is not supported on MPS\n)\nos.environ[\"IN_STREAMLIT\"] = \"true\"  # Avoid multiprocessing inside surya\n\nimport math\nimport traceback\n\nimport click\nimport torch.multiprocessing as mp\nfrom tqdm import tqdm", "n_tokens": 206, "byte_len": 767, "file_sha1": "8869ec480453e3a57e23ff92d19a2df5f6b5cf66", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py", "rel_path": "marker/scripts/convert.py", "module": "marker.scripts.convert", "ext": "py", "chunk_number": 2, "symbols": ["worker_init", "worker_exit", "exception", "create", "model", "dict", "exit", "atexit", "parser", "get", "logger", "gpu", "manager", "register", "utils", "config", "save", "output", "global", "from", "worker", "init", "clean", "references", "except", "ensure", "custom", "click", "exists", "models", "process_single_pdf", "convert_cli", "streamlit", "cleanup", "inferenced", "grp", "verbosity", "throughput", "set", "start", "contend", "traceback", "argument", "process", "renderer", "disable", "multiprocessing", "pdfs", "threads", "omp"], "ast_kind": "function_or_method", "text": "import gc\n\nfrom marker.config.parser import ConfigParser\nfrom marker.config.printer import CustomClickPrinter\nfrom marker.logger import configure_logging, get_logger\nfrom marker.models import create_model_dict\nfrom marker.output import output_exists, save_output\nfrom marker.utils.gpu import GPUManager\n\nconfigure_logging()\nlogger = get_logger()\n\n\ndef worker_init():\n    model_dict = create_model_dict()\n\n    global model_refs\n    model_refs = model_dict\n\n    # Ensure we clean up the model references on exit\n    atexit.register(worker_exit)\n\n\ndef worker_exit():\n    global model_refs\n    try:\n        del model_refs\n    except Exception:\n        pass\n\n", "n_tokens": 132, "byte_len": 654, "file_sha1": "8869ec480453e3a57e23ff92d19a2df5f6b5cf66", "start_line": 29, "end_line": 59}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py", "rel_path": "marker/scripts/convert.py", "module": "marker.scripts.convert", "ext": "py", "chunk_number": 3, "symbols": ["process_single_pdf", "exception", "argument", "traceback", "click", "process", "renderer", "pdfs", "get", "processors", "config", "converter", "error", "maximum", "convert", "return", "debug", "print", "folder", "single", "except", "parallel", "files", "fpath", "processes", "output", "exists", "cli", "options", "finally", "worker_init", "worker_exit", "convert_cli", "streamlit", "cleanup", "inferenced", "grp", "verbosity", "throughput", "set", "start", "contend", "exit", "atexit", "disable", "multiprocessing", "threads", "omp", "utils", "global"], "ast_kind": "function_or_method", "text": "def process_single_pdf(args):\n    page_count = 0\n    fpath, cli_options = args\n    torch.set_num_threads(cli_options[\"total_torch_threads\"])\n    del cli_options[\"total_torch_threads\"]\n\n    config_parser = ConfigParser(cli_options)\n\n    out_folder = config_parser.get_output_folder(fpath)\n    base_name = config_parser.get_base_filename(fpath)\n    if cli_options.get(\"skip_existing\") and output_exists(out_folder, base_name):\n        return page_count\n\n    converter_cls = config_parser.get_converter_cls()\n    config_dict = config_parser.generate_config_dict()\n    config_dict[\"disable_tqdm\"] = True\n\n    try:\n        if cli_options.get(\"debug_print\"):\n            logger.debug(f\"Converting {fpath}\")\n        converter = converter_cls(\n            config=config_dict,\n            artifact_dict=model_refs,\n            processor_list=config_parser.get_processors(),\n            renderer=config_parser.get_renderer(),\n            llm_service=config_parser.get_llm_service(),\n        )\n        rendered = converter(fpath)\n        out_folder = config_parser.get_output_folder(fpath)\n        save_output(rendered, out_folder, base_name)\n        page_count = converter.page_count\n\n        if cli_options.get(\"debug_print\"):\n            logger.debug(f\"Converted {fpath}\")\n        del rendered\n        del converter\n    except Exception as e:\n        logger.error(f\"Error converting {fpath}: {e}\")\n        traceback.print_exc()\n    finally:\n        gc.collect()\n\n    return page_count\n\n\n@click.command(cls=CustomClickPrinter)\n@click.argument(\"in_folder\", type=str)\n@click.option(\"--chunk_idx\", type=int, default=0, help=\"Chunk index to convert\")\n@click.option(\n    \"--num_chunks\",\n    type=int,\n    default=1,\n    help=\"Number of chunks being processed in parallel\",\n)\n@click.option(\n    \"--max_files\", type=int, default=None, help=\"Maximum number of pdfs to convert\"\n)\n@click.option(\n    \"--skip_existing\",\n    is_flag=True,\n    default=False,\n    help=\"Skip existing converted files.\",\n)\n@click.option(\n    \"--debug_print\", is_flag=True, default=False, help=\"Print debug information.\"\n)\n@click.option(\n    \"--max_tasks_per_worker\",\n    type=int,\n    default=10,\n    help=\"Maximum number of tasks per worker process before recycling.\",\n)\n@click.option(\n    \"--workers\",\n    type=int,\n    default=None,\n    help=\"Number of worker processes to use.  Set automatically by default, but can be overridden.\",\n)", "n_tokens": 513, "byte_len": 2397, "file_sha1": "8869ec480453e3a57e23ff92d19a2df5f6b5cf66", "start_line": 60, "end_line": 137}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert.py", "rel_path": "marker/scripts/convert.py", "module": "marker.scripts.convert", "ext": "py", "chunk_number": 4, "symbols": ["convert_cli", "cleanup", "inferenced", "throughput", "set", "start", "disable", "multiprocessing", "pdfs", "cpu", "count", "work", "processing", "convert", "cli", "folder", "process", "single", "time", "except", "parallel", "sizes", "pbar", "files", "processes", "setup", "total", "pages", "idx", "issue", "worker_init", "worker_exit", "process_single_pdf", "streamlit", "exception", "grp", "verbosity", "contend", "exit", "traceback", "argument", "atexit", "click", "renderer", "threads", "omp", "get", "processors", "utils", "config"], "ast_kind": "function_or_method", "text": "@ConfigParser.common_options\ndef convert_cli(in_folder: str, **kwargs):\n    total_pages = 0\n    in_folder = os.path.abspath(in_folder)\n    files = [os.path.join(in_folder, f) for f in os.listdir(in_folder)]\n    files = [f for f in files if os.path.isfile(f)]\n\n    # Handle chunks if we're processing in parallel\n    # Ensure we get all files into a chunk\n    chunk_size = math.ceil(len(files) / kwargs[\"num_chunks\"])\n    start_idx = kwargs[\"chunk_idx\"] * chunk_size\n    end_idx = start_idx + chunk_size\n    files_to_convert = files[start_idx:end_idx]\n\n    # Limit files converted if needed\n    if kwargs[\"max_files\"]:\n        files_to_convert = files_to_convert[: kwargs[\"max_files\"]]\n\n    # Disable nested multiprocessing\n    kwargs[\"disable_multiprocessing\"] = True\n\n    try:\n        mp.set_start_method(\"spawn\")  # Required for CUDA, forkserver doesn't work\n    except RuntimeError:\n        raise RuntimeError(\n            \"Set start method to spawn twice. This may be a temporary issue with the script. Please try running it again.\"\n        )\n\n    chunk_idx = kwargs[\"chunk_idx\"]\n\n    # Use GPU context manager for automatic setup/cleanup\n    with GPUManager(chunk_idx) as gpu_manager:\n        batch_sizes, workers = get_batch_sizes_worker_counts(gpu_manager, 7)\n\n        # Override workers if specified\n        if kwargs[\"workers\"] is not None:\n            workers = kwargs[\"workers\"]\n\n        # Set proper batch sizes and thread counts\n        total_processes = max(1, min(len(files_to_convert), workers))\n        kwargs[\"total_torch_threads\"] = max(\n            2, psutil.cpu_count(logical=False) // total_processes\n        )\n        kwargs.update(batch_sizes)\n\n        logger.info(\n            f\"Converting {len(files_to_convert)} pdfs in chunk {kwargs['chunk_idx'] + 1}/{kwargs['num_chunks']} with {total_processes} processes and saving to {kwargs['output_dir']}\"\n        )\n        task_args = [(f, kwargs) for f in files_to_convert]\n\n        start_time = time.time()\n        with mp.Pool(\n            processes=total_processes,\n            initializer=worker_init,\n            maxtasksperchild=kwargs[\"max_tasks_per_worker\"],\n        ) as pool:\n            pbar = tqdm(total=len(task_args), desc=\"Processing PDFs\", unit=\"pdf\")\n            for page_count in pool.imap_unordered(process_single_pdf, task_args):\n                pbar.update(1)\n                total_pages += page_count\n            pbar.close()\n\n        total_time = time.time() - start_time\n        print(\n            f\"Inferenced {total_pages} pages in {total_time:.2f} seconds, for a throughput of {total_pages / total_time:.2f} pages/sec for chunk {chunk_idx + 1}/{kwargs['num_chunks']}\"\n        )\n", "n_tokens": 612, "byte_len": 2674, "file_sha1": "8869ec480453e3a57e23ff92d19a2df5f6b5cf66", "start_line": 138, "end_line": 204}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/extraction_app.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/extraction_app.py", "rel_path": "marker/scripts/extraction_app.py", "module": "marker.scripts.extraction_app", "ext": "py", "chunk_number": 1, "symbols": ["streamlit", "scripts", "load", "models", "parser", "common", "true", "ace", "extraction", "runtime", "tempfile", "pydantic", "converters", "config", "uploaded", "file", "from", "pytorc", "enabl", "get", "page", "dict", "converter", "base", "model", "parse", "args", "root", "typing", "json", "extract_data", "Schema", "exception", "markdown", "schema", "click", "enter", "renderer", "original", "validate", "temp", "pdf", "pdftext", "workers", "image", "extract", "data", "processors", "document", "exclude"], "ast_kind": "imports", "text": "import json\nimport os\n\nfrom streamlit_ace import st_ace\nfrom pydantic import BaseModel\n\nfrom marker.converters.extraction import ExtractionConverter\nfrom marker.scripts.common import (\n    parse_args,\n    load_models,\n    get_page_image,\n    page_count,\n    get_root_class,\n)\n\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\nos.environ[\"IN_STREAMLIT\"] = \"true\"\n\nfrom streamlit.runtime.uploaded_file_manager import UploadedFile\n\nimport tempfile\nfrom typing import Any, Dict\n\nimport streamlit as st\n\nfrom marker.config.parser import ConfigParser\n\n", "n_tokens": 127, "byte_len": 545, "file_sha1": "d77ae1f47c458458577876a1ffd71da29f2d6bd2", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/extraction_app.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/extraction_app.py", "rel_path": "marker/scripts/extraction_app.py", "module": "marker.scripts.extraction_app", "ext": "py", "chunk_number": 2, "symbols": ["extract_data", "Schema", "exception", "markdown", "json", "schema", "click", "enter", "renderer", "original", "validate", "temp", "pdf", "pdftext", "workers", "image", "extract", "data", "get", "processors", "document", "config", "exclude", "page", "model", "dump", "clear", "dict", "wide", "error", "streamlit", "converters", "uploaded", "file", "pytorc", "enabl", "stop", "convert", "entered", "properties", "return", "except", "language", "unique", "email", "pptx", "session", "valid", "invalid", "successfully"], "ast_kind": "class_or_type", "text": "def extract_data(\n    fname: str, config: dict, schema: str, markdown: str | None = None\n) -> (str, Dict[str, Any], dict):\n    config[\"pdftext_workers\"] = 1\n    config[\"page_schema\"] = schema\n    config[\"existing_markdown\"] = markdown\n    config_parser = ConfigParser(config)\n    config_dict = config_parser.generate_config_dict()\n\n    converter_cls = ExtractionConverter\n    converter = converter_cls(\n        config=config_dict,\n        artifact_dict=model_dict,\n        processor_list=config_parser.get_processors(),\n        renderer=config_parser.get_renderer(),\n        llm_service=config_parser.get_llm_service(),\n    )\n    return converter(fname)\n\n\nst.set_page_config(layout=\"wide\")\ncol1, col2 = st.columns([0.5, 0.5])\n\nmodel_dict = load_models()\ncli_options = parse_args()\n\nst.markdown(\"\"\"\n# Marker Extraction Demo\n\nThis app will let you use marker to do structured extraction.\n\nWarning: This can execute untrusted code entered into the schema panel.\n\"\"\")\n\nin_file: UploadedFile = st.sidebar.file_uploader(\n    \"PDF, document, or image file:\",\n    type=[\"pdf\", \"png\", \"jpg\", \"jpeg\", \"gif\", \"pptx\", \"docx\", \"xlsx\", \"html\", \"epub\"],\n)\n\n# Initialize session state variables\nif \"rendered_pydantic_schema\" not in st.session_state:\n    st.session_state.rendered_pydantic_schema = \"\"\n\nif \"markdown\" not in st.session_state:\n    st.session_state.markdown = \"\"\n\nif \"current_file_id\" not in st.session_state:\n    st.session_state.current_file_id = None\n\n# Detect file changes and clear markdown when new file is uploaded\nif in_file is not None:\n    # Create a unique identifier for the current file\n    current_file_id = f\"{in_file.name}_{in_file.size}_{hash(in_file.getvalue())}\"\n\n    # Check if this is a new file\n    if st.session_state.current_file_id != current_file_id:\n        st.session_state.current_file_id = current_file_id\n        st.session_state.markdown = \"\"  # Clear markdown for new file\nelse:\n    # No file uploaded, clear the current file ID\n    if st.session_state.current_file_id is not None:\n        st.session_state.current_file_id = None\n        st.session_state.markdown = \"\"  # Clear markdown when no file\n        st.session_state.rendered_pydantic_schema = \"\"\n\nif in_file is None:\n    st.stop()\n\nfiletype = in_file.type\n\nwith col1:\n    page_count = page_count(in_file)\n    page_number = st.number_input(\n        f\"Page number out of {page_count}:\", min_value=0, value=0, max_value=page_count\n    )\n    pil_image = get_page_image(in_file, page_number)\n    st.image(pil_image, use_container_width=True)\nwith col2:\n    tab1, tab2 = st.tabs([\"JSON Schema\", \"Pydantic Schema\"])\n\n    # Initialize schema variable\n    schema = None\n\n    with tab1:\n        st.write(\"Enter an existing JSON schema here:\")\n        default_json_value = (\n            st.session_state.rendered_pydantic_schema\n            if st.session_state.rendered_pydantic_schema\n            else \"\"\n        )\n        json_schema_input = st.text_area(\n            \"JSON Schema\",\n            value=default_json_value,\n            height=300,\n            placeholder='{\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"integer\"}}}',\n            key=\"json_schema_input\",\n            label_visibility=\"collapsed\",\n        )\n\n        # Set schema if JSON input is provided\n        if json_schema_input and json_schema_input.strip():\n            try:\n                # Validate JSON\n                json.loads(json_schema_input)\n                schema = json_schema_input.strip()\n                st.success(\" Valid JSON schema detected\")\n            except json.JSONDecodeError as e:\n                st.error(f\" Invalid JSON: {e}\")\n                schema = None\n\n    with tab2:\n        st.write(\"Enter pydantic schema here:\")\n        pydantic_schema_input = st_ace(\n            value=\"\"\"from pydantic import BaseModel\n\nclass Schema(BaseModel):\n    # Add your fields here\n    # Example:\n    name: str\n    age: int\n    # email: str\n    pass\"\"\",\n            language=\"python\",\n            height=300,\n            key=\"pydantic_editor\",\n        )\n\n        render_schema = st.button(\" Render Pydantic schema to JSON\")\n\n        if render_schema and pydantic_schema_input:\n            try:\n                pydantic_root: BaseModel = get_root_class(pydantic_schema_input)\n                json_schema = pydantic_root.model_json_schema()\n                schema = json.dumps(json_schema, indent=2)\n                st.success(\" Schema rendered successfully!\")\n                st.json(json_schema)\n                st.session_state.rendered_pydantic_schema = schema\n            except Exception as e:\n                st.error(f\" Could not parse your schema: {e}\")\n                schema = None\n        elif (\n            pydantic_schema_input\n            and pydantic_schema_input.strip()\n            and not render_schema\n        ):\n            # If there's Pydantic code but not rendered yet, show a message\n            if (\n                \"class Schema(BaseModel):\" in pydantic_schema_input\n                and \"pass\" not in pydantic_schema_input\n            ):\n                st.info(\n                    \" Click 'Render Pydantic schema to JSON' to convert your Pydantic model to JSON schema\"\n                )\n\n# Move the run logic outside of col2\nrun_marker = st.sidebar.button(\"Run Extraction\")\n\nuse_llm = st.sidebar.checkbox(\n    \"Use LLM\", help=\"Use LLM for higher quality text\", value=False\n)\nforce_ocr = st.sidebar.checkbox(\"Force OCR\", help=\"Force OCR on all pages\", value=False)\nstrip_existing_ocr = st.sidebar.checkbox(\n    \"Strip existing OCR\",\n    help=\"Strip existing OCR text from the PDF and re-OCR.\",\n    value=False,\n)\n\n# Check if schema is provided before running\nif run_marker:\n    if not schema:\n        st.error(\n            \" Please provide a schema in either the JSON Schema or Pydantic Schema tab before running extraction.\"\n        )\n        st.stop()\n\n    # Run Marker\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        temp_pdf = os.path.join(tmp_dir, \"temp.pdf\")\n        with open(temp_pdf, \"wb\") as f:\n            f.write(in_file.getvalue())\n\n        cli_options.update(\n            {\n                \"force_ocr\": force_ocr,\n                \"use_llm\": use_llm,\n                \"strip_existing_ocr\": strip_existing_ocr,\n            }\n        )\n\n        try:\n            rendered = extract_data(\n                temp_pdf, cli_options, schema, st.session_state.markdown\n            )\n\n            with col2:\n                st.write(\"## Output JSON\")\n                st.json(rendered.model_dump(exclude=[\"original_markdown\"]))\n                st.session_state.markdown = rendered.original_markdown\n\n        except Exception as e:\n            st.error(f\" Extraction failed: {e}\")\n\nelse:\n    # Show instruction when not running\n    if not schema:\n        st.info(\" Please provide a schema and click 'Run Extraction' to begin.\")\n", "n_tokens": 1541, "byte_len": 6888, "file_sha1": "d77ae1f47c458458577876a1ffd71da29f2d6bd2", "start_line": 29, "end_line": 235}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py", "rel_path": "marker/scripts/streamlit_app.py", "module": "marker.scripts.streamlit_app", "ext": "py", "chunk_number": 1, "symbols": ["streamlit", "image", "scripts", "load", "models", "parser", "common", "true", "runtime", "tempfile", "converters", "img", "html", "config", "settings", "uploaded", "file", "from", "pytorc", "enabl", "get", "page", "dict", "text", "parse", "args", "typing", "output", "import", "pdf", "convert_pdf", "markdown_insert_images", "markdown", "renderer", "vik", "paruchuri", "https", "temp", "pdftext", "workers", "project", "processors", "document", "disable", "ocr", "wide", "stop", "format", "caption", "github"], "ast_kind": "imports", "text": "import os\n\nfrom marker.scripts.common import (\n    load_models,\n    parse_args,\n    img_to_html,\n    get_page_image,\n    page_count,\n)\n\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\nos.environ[\"IN_STREAMLIT\"] = \"true\"\n\nfrom marker.settings import settings\nfrom streamlit.runtime.uploaded_file_manager import UploadedFile\n\nimport re\nimport tempfile\nfrom typing import Any, Dict\n\nimport streamlit as st\nfrom PIL import Image\n\nfrom marker.converters.pdf import PdfConverter\nfrom marker.config.parser import ConfigParser\nfrom marker.output import text_from_rendered\n\n", "n_tokens": 129, "byte_len": 565, "file_sha1": "7a5eb57fd527a1620677cdc158559b573715e7de", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py", "rel_path": "marker/scripts/streamlit_app.py", "module": "marker.scripts.streamlit_app", "ext": "py", "chunk_number": 2, "symbols": ["convert_pdf", "model", "dict", "renderer", "llm", "service", "config", "parser", "pdftext", "workers", "converter", "cls", "get", "processors", "generate", "convert", "pdf", "return", "artifact", "fname", "processor", "list", "markdown_insert_images", "streamlit", "markdown", "vik", "paruchuri", "https", "temp", "image", "project", "converters", "document", "uploaded", "file", "disable", "ocr", "pytorc", "enabl", "wide", "stop", "page", "format", "caption", "github", "debug", "extracts", "language", "replace", "pptx"], "ast_kind": "function_or_method", "text": "def convert_pdf(fname: str, config_parser: ConfigParser) -> (str, Dict[str, Any], dict):\n    config_dict = config_parser.generate_config_dict()\n    config_dict[\"pdftext_workers\"] = 1\n    converter_cls = PdfConverter\n    converter = converter_cls(\n        config=config_dict,\n        artifact_dict=model_dict,\n        processor_list=config_parser.get_processors(),\n        renderer=config_parser.get_renderer(),\n        llm_service=config_parser.get_llm_service(),\n    )\n    return converter(fname)\n\n", "n_tokens": 104, "byte_len": 499, "file_sha1": "7a5eb57fd527a1620677cdc158559b573715e7de", "start_line": 29, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/streamlit_app.py", "rel_path": "marker/scripts/streamlit_app.py", "module": "marker.scripts.streamlit_app", "ext": "py", "chunk_number": 3, "symbols": ["markdown_insert_images", "markdown", "vik", "paruchuri", "https", "temp", "pdf", "image", "project", "document", "disable", "ocr", "wide", "stop", "get", "page", "format", "caption", "github", "return", "debug", "extracts", "file", "language", "replace", "pptx", "open", "columns", "epub", "output", "convert_pdf", "streamlit", "renderer", "pdftext", "workers", "processors", "converters", "config", "uploaded", "dict", "pytorc", "enabl", "set", "cli", "options", "value", "marker", "converter", "number", "environ"], "ast_kind": "function_or_method", "text": "def markdown_insert_images(markdown, images):\n    image_tags = re.findall(\n        r'(!\\[(?P<image_title>[^\\]]*)\\]\\((?P<image_path>[^\\)\"\\s]+)\\s*([^\\)]*)\\))',\n        markdown,\n    )\n\n    for image in image_tags:\n        image_markdown = image[0]\n        image_alt = image[1]\n        image_path = image[2]\n        if image_path in images:\n            markdown = markdown.replace(\n                image_markdown, img_to_html(images[image_path], image_alt)\n            )\n    return markdown\n\n\nst.set_page_config(layout=\"wide\")\ncol1, col2 = st.columns([0.5, 0.5])\n\nmodel_dict = load_models()\ncli_options = parse_args()\n\nst.markdown(\"\"\"\n# Marker Demo\n\nThis app will let you try marker, a PDF or image -> Markdown, HTML, JSON converter. It works with any language, and extracts images, tables, equations, etc.\n\nFind the project [here](https://github.com/VikParuchuri/marker).\n\"\"\")\n\nin_file: UploadedFile = st.sidebar.file_uploader(\n    \"PDF, document, or image file:\",\n    type=[\"pdf\", \"png\", \"jpg\", \"jpeg\", \"gif\", \"pptx\", \"docx\", \"xlsx\", \"html\", \"epub\"],\n)\n\nif in_file is None:\n    st.stop()\n\nfiletype = in_file.type\n\nwith col1:\n    page_count = page_count(in_file)\n    page_number = st.number_input(\n        f\"Page number out of {page_count}:\", min_value=0, value=0, max_value=page_count\n    )\n    pil_image = get_page_image(in_file, page_number)\n    st.image(pil_image, use_container_width=True)\n\npage_range = st.sidebar.text_input(\n    \"Page range to parse, comma separated like 0,5-10,20\",\n    value=f\"{page_number}-{page_number}\",\n)\noutput_format = st.sidebar.selectbox(\n    \"Output format\", [\"markdown\", \"json\", \"html\", \"chunks\"], index=0\n)\nrun_marker = st.sidebar.button(\"Run Marker\")\n\nuse_llm = st.sidebar.checkbox(\n    \"Use LLM\", help=\"Use LLM for higher quality processing\", value=False\n)\nforce_ocr = st.sidebar.checkbox(\"Force OCR\", help=\"Force OCR on all pages\", value=False)\nstrip_existing_ocr = st.sidebar.checkbox(\n    \"Strip existing OCR\",\n    help=\"Strip existing OCR text from the PDF and re-OCR.\",\n    value=False,\n)\ndebug = st.sidebar.checkbox(\"Debug\", help=\"Show debug information\", value=False)\ndisable_ocr_math = st.sidebar.checkbox(\n    \"Disable math\",\n    help=\"Disable math in OCR output - no inline math\",\n    value=False,\n)\n\nif not run_marker:\n    st.stop()\n\n# Run Marker\nwith tempfile.TemporaryDirectory() as tmp_dir:\n    temp_pdf = os.path.join(tmp_dir, \"temp.pdf\")\n    with open(temp_pdf, \"wb\") as f:\n        f.write(in_file.getvalue())\n\n    cli_options.update(\n        {\n            \"output_format\": output_format,\n            \"page_range\": page_range,\n            \"force_ocr\": force_ocr,\n            \"debug\": debug,\n            \"output_dir\": settings.DEBUG_DATA_FOLDER if debug else None,\n            \"use_llm\": use_llm,\n            \"strip_existing_ocr\": strip_existing_ocr,\n            \"disable_ocr_math\": disable_ocr_math,\n        }\n    )\n    config_parser = ConfigParser(cli_options)\n    rendered = convert_pdf(temp_pdf, config_parser)\n    page_range = config_parser.generate_config_dict()[\"page_range\"]\n    first_page = page_range[0] if page_range else 0\n\ntext, ext, images = text_from_rendered(rendered)\nwith col2:\n    if output_format == \"markdown\":\n        text = markdown_insert_images(text, images)\n        st.markdown(text, unsafe_allow_html=True)\n    elif output_format == \"json\":\n        st.json(text)\n    elif output_format == \"html\":\n        st.html(text)\n    elif output_format == \"chunks\":\n        st.json(text)\n\nif debug:\n    with col1:\n        debug_data_path = rendered.metadata.get(\"debug_data_path\")\n        if debug_data_path:\n            pdf_image_path = os.path.join(debug_data_path, f\"pdf_page_{first_page}.png\")\n            img = Image.open(pdf_image_path)\n            st.image(img, caption=\"PDF debug image\", use_container_width=True)\n            layout_image_path = os.path.join(\n                debug_data_path, f\"layout_page_{first_page}.png\"\n            )\n            img = Image.open(layout_image_path)\n            st.image(img, caption=\"Layout debug image\", use_container_width=True)\n        st.write(\"Raw output:\")\n        st.code(text, language=output_format)\n", "n_tokens": 1012, "byte_len": 4123, "file_sha1": "7a5eb57fd527a1620677cdc158559b573715e7de", "start_line": 43, "end_line": 169}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/run_streamlit_app.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/run_streamlit_app.py", "rel_path": "marker/scripts/run_streamlit_app.py", "module": "marker.scripts.run_streamlit_app", "ext": "py", "chunk_number": 1, "symbols": ["streamlit_app_cli", "extraction_app_cli", "headless", "streamlit", "subprocess", "file", "watcher", "true", "app", "server", "cur", "dir", "path", "none", "abspath", "extraction", "import", "name", "dirname", "environ", "argv", "join"], "ast_kind": "function_or_method", "text": "import subprocess\nimport os\nimport sys\n\n\ndef streamlit_app_cli(app_name: str = \"streamlit_app.py\"):\n    argv = sys.argv[1:]\n    cur_dir = os.path.dirname(os.path.abspath(__file__))\n    app_path = os.path.join(cur_dir, app_name)\n    cmd = [\n        \"streamlit\",\n        \"run\",\n        app_path,\n        \"--server.fileWatcherType\",\n        \"none\",\n        \"--server.headless\",\n        \"true\",\n    ]\n    if argv:\n        cmd += [\"--\"] + argv\n    subprocess.run(cmd, env={**os.environ, \"IN_STREAMLIT\": \"true\"})\n\n\ndef extraction_app_cli():\n    streamlit_app_cli(\"extraction_app.py\")\n", "n_tokens": 149, "byte_len": 578, "file_sha1": "46f16b76309cb16cbb7085885fa13ff41d18347a", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/file_to_s3.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/file_to_s3.py", "rel_path": "marker/scripts/file_to_s3.py", "module": "marker.scripts.file_to_s3", "ext": "py", "chunk_number": 1, "symbols": ["import", "path", "https", "cloudflarestorage", "snapshot", "download", "click", "from", "url", "api", "huggingface", "hub", "shutil", "json", "pathlib", "boto", "boto3", "datetime", "main", "endpoint", "client", "key", "exception", "uploaded", "argument", "default", "bucket", "print", "aws", "access", "region", "name", "uploads", "except", "datalab", "help", "enam", "filepath", "files", "error", "upload", "type", "file", "option", "secret", "uploading", "command"], "ast_kind": "imports", "text": "import json\nimport shutil\nimport datetime\nfrom pathlib import Path\nimport boto3\n\nfrom huggingface_hub import snapshot_download\n\nimport click\n\nS3_API_URL = \"https://1afbe4656a6b40d982ab5e730a39f6b9.r2.cloudflarestorage.com\"\n", "n_tokens": 67, "byte_len": 223, "file_sha1": "afe93c866638f37abadf41837cfcdca3e6701675", "start_line": 1, "end_line": 12}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/file_to_s3.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/file_to_s3.py", "rel_path": "marker/scripts/file_to_s3.py", "module": "marker.scripts.file_to_s3", "ext": "py", "chunk_number": 2, "symbols": ["main", "endpoint", "url", "client", "key", "exception", "uploaded", "argument", "click", "path", "default", "bucket", "print", "aws", "access", "region", "name", "uploads", "except", "datalab", "help", "enam", "filepath", "files", "error", "boto", "boto3", "upload", "type", "file", "huggingface", "hub", "pathlib", "https", "cloudflarestorage", "from", "json", "import", "snapshot", "download", "api", "option", "shutil", "secret", "uploading", "datetime", "command"], "ast_kind": "function_or_method", "text": "@click.command(help=\"Uploads files to an S3 bucket\")\n@click.argument(\"filepath\", type=str)\n@click.argument(\"s3_path\", type=str)\n@click.option(\"--bucket_name\", type=str, default=\"datalab\")\n@click.option(\"--access_key_id\", type=str, default=\"<access_key_id>\")\n@click.option(\"--access_key_secret\", type=str, default=\"<access_key_secret>\")\ndef main(filepath: str, s3_path: str, bucket_name: str, access_key_id: str, access_key_secret: str):\n    filepath = Path(filepath)\n    # Upload the files to S3\n    s3_client = boto3.client(\n        's3',\n        endpoint_url=S3_API_URL,\n        aws_access_key_id=access_key_id,\n        aws_secret_access_key=access_key_secret,\n        region_name=\"enam\"\n    )\n\n    s3_key = f\"{s3_path}/{filepath.name}\"\n\n    try:\n        s3_client.upload_file(\n            str(filepath),\n            bucket_name,\n            s3_key\n        )\n    except Exception as e:\n        print(f\"Error uploading {filepath}: {str(e)}\")\n\n    print(f\"Uploaded files to {s3_path}\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n", "n_tokens": 254, "byte_len": 1028, "file_sha1": "afe93c866638f37abadf41837cfcdca3e6701675", "start_line": 13, "end_line": 48}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 1, "symbols": ["parse_args", "options_func", "image", "create", "model", "click", "parser", "common", "runtime", "pypdfium", "pypdfium2", "base", "base64", "pydantic", "config", "settings", "options", "func", "uploaded", "file", "from", "streamlit", "cache", "data", "parse", "args", "typing", "custom", "models", "optional", "extract_click_params", "load_models", "open_pdf", "img_to_html", "get_page_image", "page_count", "pillow_image_to_base64_string", "extract_root_pydantic_class", "get_root_class", "exception", "name", "other", "class", "candidate", "decorated", "function", "classes", "execute", "buffered", "about"], "ast_kind": "function_or_method", "text": "import ast\nimport base64\nimport io\nimport re\nimport sys\nfrom typing import Optional\n\nfrom PIL import Image\nimport click\nimport pypdfium2\nimport streamlit as st\nfrom pydantic import BaseModel\nfrom streamlit.runtime.uploaded_file_manager import UploadedFile\n\nfrom marker.config.parser import ConfigParser\nfrom marker.config.printer import CustomClickPrinter\nfrom marker.models import create_model_dict\nfrom marker.settings import settings\n\n\n@st.cache_data()\ndef parse_args():\n    # Use to grab common cli options\n    @ConfigParser.common_options\n    def options_func():\n        pass\n", "n_tokens": 126, "byte_len": 581, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 1, "end_line": 27}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 2, "symbols": ["extract_click_params", "load_models", "open_pdf", "create", "model", "load", "models", "decorated", "function", "click", "marker", "pypdfium", "pypdfium2", "exceptions", "options", "func", "exception", "pdf", "file", "error", "params", "cmd", "args", "return", "except", "bytes", "bytesio", "parse", "extracted", "custom", "parse_args", "options_func", "img_to_html", "get_page_image", "page_count", "pillow_image_to_base64_string", "extract_root_pydantic_class", "get_root_class", "name", "other", "class", "candidate", "base", "classes", "execute", "buffered", "about", "bases", "break", "parsing"], "ast_kind": "function_or_method", "text": "    def extract_click_params(decorated_function):\n        if hasattr(decorated_function, \"__click_params__\"):\n            return decorated_function.__click_params__\n        return []\n\n    cmd = CustomClickPrinter(\"Marker app.\")\n    extracted_params = extract_click_params(options_func)\n    cmd.params.extend(extracted_params)\n    ctx = click.Context(cmd)\n    try:\n        cmd_args = sys.argv[1:]\n        cmd.parse_args(ctx, cmd_args)\n        return ctx.params\n    except click.exceptions.ClickException as e:\n        return {\"error\": str(e)}\n\n\n@st.cache_resource()\ndef load_models():\n    return create_model_dict()\n\n\ndef open_pdf(pdf_file):\n    stream = io.BytesIO(pdf_file.getvalue())\n    return pypdfium2.PdfDocument(stream)\n\n", "n_tokens": 156, "byte_len": 728, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 28, "end_line": 54}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 3, "symbols": ["img_to_html", "get_page_image", "image", "img", "bytes", "save", "encoded", "html", "scale", "else", "base", "base64", "style", "settings", "pdf", "file", "page", "num", "get", "format", "lower", "alt", "outpu", "imag", "return", "convert", "decode", "data", "render", "bytesio", "parse_args", "options_func", "extract_click_params", "load_models", "open_pdf", "page_count", "pillow_image_to_base64_string", "extract_root_pydantic_class", "get_root_class", "exception", "name", "other", "class", "candidate", "decorated", "function", "click", "classes", "execute", "buffered"], "ast_kind": "function_or_method", "text": "def img_to_html(img, img_alt):\n    img_bytes = io.BytesIO()\n    img.save(img_bytes, format=settings.OUTPUT_IMAGE_FORMAT)\n    img_bytes = img_bytes.getvalue()\n    encoded = base64.b64encode(img_bytes).decode()\n    img_html = f'<img src=\"data:image/{settings.OUTPUT_IMAGE_FORMAT.lower()};base64,{encoded}\" alt=\"{img_alt}\" style=\"max-width: 100%;\">'\n    return img_html\n\n\n@st.cache_data()\ndef get_page_image(pdf_file, page_num, dpi=96):\n    if \"pdf\" in pdf_file.type:\n        doc = open_pdf(pdf_file)\n        page = doc[page_num]\n        png_image = (\n            page.render(\n                scale=dpi / 72,\n            )\n            .to_pil()\n            .convert(\"RGB\")\n        )\n    else:\n        png_image = Image.open(pdf_file).convert(\"RGB\")\n    return png_image\n\n", "n_tokens": 194, "byte_len": 768, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 55, "end_line": 80}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 4, "symbols": ["page_count", "pillow_image_to_base64_string", "image", "save", "buffered", "jpeg", "else", "base", "base64", "pdf", "file", "pillow", "format", "return", "decode", "bytes", "bytesio", "cache", "data", "type", "getvalue", "open", "uploaded", "page", "count", "encode", "b64encode", "parse_args", "options_func", "extract_click_params", "load_models", "open_pdf", "img_to_html", "get_page_image", "extract_root_pydantic_class", "get_root_class", "exception", "name", "other", "class", "candidate", "decorated", "function", "click", "classes", "execute", "about", "bases", "break", "parsing"], "ast_kind": "function_or_method", "text": "@st.cache_data()\ndef page_count(pdf_file: UploadedFile):\n    if \"pdf\" in pdf_file.type:\n        doc = open_pdf(pdf_file)\n        return len(doc) - 1\n    else:\n        return 1\n\n\ndef pillow_image_to_base64_string(img: Image) -> str:\n    buffered = io.BytesIO()\n    img.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n\n", "n_tokens": 97, "byte_len": 364, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 81, "end_line": 95}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 5, "symbols": ["extract_root_pydantic_class", "exception", "name", "other", "class", "candidate", "base", "classes", "about", "bases", "break", "parsing", "ann", "assign", "walk", "field", "others", "search", "found", "return", "references", "except", "parse", "unparse", "this", "annotation", "str", "isinstance", "true", "check", "parse_args", "options_func", "extract_click_params", "load_models", "open_pdf", "img_to_html", "get_page_image", "page_count", "pillow_image_to_base64_string", "get_root_class", "decorated", "function", "click", "execute", "buffered", "exceptions", "image", "base64", "config", "style"], "ast_kind": "class_or_type", "text": "def extract_root_pydantic_class(schema_code: str) -> Optional[str]:\n    try:\n        # Parse the code into an AST\n        tree = ast.parse(schema_code)\n\n        # Find all class definitions that inherit from BaseModel\n        class_names = set()\n        class_info = {}  # Store information about each class\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.ClassDef):\n                # Check if this class inherits from BaseModel\n                is_pydantic = False\n                for base in node.bases:\n                    if isinstance(base, ast.Name) and base.id == \"BaseModel\":\n                        is_pydantic = True\n                        break\n\n                if is_pydantic:\n                    class_names.add(node.name)\n                    class_info[node.name] = {\n                        \"references\": set(),  # Classes this class references\n                        \"fields\": [],  # Field names in this class\n                    }\n\n                    # Extract field information\n                    for item in node.body:\n                        if isinstance(item, ast.AnnAssign) and isinstance(\n                            item.target, ast.Name\n                        ):\n                            field_name = item.target.id\n                            class_info[node.name][\"fields\"].append(field_name)\n\n                            # Check if this field references another class\n                            annotation_str = ast.unparse(item.annotation)\n\n                            # Look for List[ClassName], Optional[ClassName], Dict[Any, ClassName], etc.\n                            for other_class in class_names:\n                                pattern = rf\"(?:List|Dict|Set|Tuple|Optional|Union)?\\[.*{other_class}.*\\]|{other_class}\"\n                                if re.search(pattern, annotation_str):\n                                    class_info[node.name][\"references\"].add(other_class)\n\n        if len(class_names) == 1:\n            return list(class_names)[0]\n\n        referenced_classes = set()\n        for class_name, info in class_info.items():\n            referenced_classes.update(info[\"references\"])\n\n        # Find classes that reference others but aren't referenced themselves (potential roots)\n        root_candidates = set()\n        for class_name, info in class_info.items():\n            if info[\"references\"] and class_name not in referenced_classes:\n                root_candidates.add(class_name)\n\n        # If we found exactly one root candidate, return it\n        if len(root_candidates) == 1:\n            return list(root_candidates)[0]\n\n        return None\n    except Exception as e:\n        print(f\"Error parsing schema: {e}\")\n        return None\n\n", "n_tokens": 493, "byte_len": 2731, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 96, "end_line": 160}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py#6", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/common.py", "rel_path": "marker/scripts/common.py", "module": "marker.scripts.common", "ext": "py", "chunk_number": 6, "symbols": ["get_root_class", "return", "class", "none", "tuple", "execute", "pydantic", "root", "from", "exec", "dict", "base", "model", "list", "namespace", "union", "get", "typing", "optional", "import", "extract", "code", "object", "schema", "parse_args", "options_func", "extract_click_params", "load_models", "open_pdf", "img_to_html", "get_page_image", "page_count", "pillow_image_to_base64_string", "extract_root_pydantic_class", "exception", "name", "other", "candidate", "decorated", "function", "click", "classes", "buffered", "about", "bases", "break", "parsing", "exceptions", "image", "ann"], "ast_kind": "class_or_type", "text": "def get_root_class(schema_code: str) -> Optional[BaseModel]:\n    root_class_name = extract_root_pydantic_class(schema_code)\n\n    if not root_class_name:\n        return None\n\n    if \"from pydantic\" not in schema_code:\n        schema_code = \"from pydantic import BaseModel\\n\" + schema_code\n    if \"from typing\" not in schema_code:\n        schema_code = (\n            \"from typing import List, Dict, Optional, Set, Tuple, Union, Any\\n\\n\"\n            + schema_code\n        )\n\n    # Execute the code in a new namespace\n    namespace = {}\n    exec(schema_code, namespace)\n\n    # Return the root class object\n    return namespace.get(root_class_name)\n", "n_tokens": 151, "byte_len": 644, "file_sha1": "e4d395cb5b967b1241b095991de57685dd687c45", "start_line": 161, "end_line": 181}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/chunk_convert.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/chunk_convert.py", "rel_path": "marker/scripts/chunk_convert.py", "module": "marker.scripts.chunk_convert", "ext": "py", "chunk_number": 1, "symbols": ["chunk_convert_cli", "args", "script", "path", "chunks", "markdown", "subprocess", "argument", "parser", "chunk", "convert", "construct", "execute", "check", "output", "pdfs", "cur", "dir", "description", "folder", "out", "abspath", "help", "files", "parse", "with", "shell", "argparse", "file", "import", "input", "pkg", "resources", "dirname", "join", "true", "add", "command"], "ast_kind": "function_or_method", "text": "import argparse\nimport os\nimport subprocess\nimport pkg_resources\n\n\ndef chunk_convert_cli():\n    parser = argparse.ArgumentParser(description=\"Convert a folder of PDFs to a folder of markdown files in chunks.\")\n    parser.add_argument(\"in_folder\", help=\"Input folder with pdfs.\")\n    parser.add_argument(\"out_folder\", help=\"Output folder\")\n    args = parser.parse_args()\n\n    cur_dir = os.path.dirname(os.path.abspath(__file__))\n    script_path = os.path.join(cur_dir, \"chunk_convert.sh\")\n\n    # Construct the command\n    cmd = f\"{script_path} {args.in_folder} {args.out_folder}\"\n\n    # Execute the shell script\n    subprocess.run(cmd, shell=True, check=True)", "n_tokens": 146, "byte_len": 658, "file_sha1": "c24a7d7217dd30c793cd8df4bfce9746eb1fc8d4", "start_line": 1, "end_line": 20}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert_single.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert_single.py", "rel_path": "marker/scripts/convert_single.py", "module": "marker.scripts.convert_single", "ext": "py", "chunk_number": 1, "symbols": ["supported", "create", "model", "grp", "verbosity", "click", "parser", "get", "logger", "isin", "error", "config", "save", "output", "from", "pytorc", "enabl", "uses", "glo", "minloglevel", "time", "transformers", "custom", "models", "configure", "logging", "import", "which", "marker", "environ", "convert_single_cli", "markdown", "rendered", "start", "argument", "base", "renderer", "llm", "service", "converter", "cls", "processors", "generate", "saved", "convert", "single", "kwargs", "out", "folder", "help"], "ast_kind": "imports", "text": "import os\n\nos.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\nos.environ[\"GLOG_minloglevel\"] = \"2\"\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = (\n    \"1\"  # Transformers uses .isin for a simple op, which is not supported on MPS\n)\n\nimport time\nimport click\n\nfrom marker.config.parser import ConfigParser\nfrom marker.config.printer import CustomClickPrinter\nfrom marker.logger import configure_logging, get_logger\nfrom marker.models import create_model_dict\nfrom marker.output import save_output\n\nconfigure_logging()\nlogger = get_logger()\n\n", "n_tokens": 124, "byte_len": 525, "file_sha1": "8e72cbde5216d586b537ad17dff06c2261a2ddc7", "start_line": 1, "end_line": 21}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert_single.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/scripts/convert_single.py", "rel_path": "marker/scripts/convert_single.py", "module": "marker.scripts.convert_single", "ext": "py", "chunk_number": 2, "symbols": ["convert_single_cli", "create", "model", "markdown", "rendered", "start", "argument", "get", "base", "click", "renderer", "llm", "service", "config", "parser", "converter", "cls", "processors", "generate", "saved", "output", "save", "convert", "single", "kwargs", "time", "out", "folder", "help", "artifact", "supported", "grp", "verbosity", "logger", "isin", "error", "from", "pytorc", "enabl", "uses", "glo", "minloglevel", "transformers", "dict", "fpath", "custom", "models", "configure", "logging", "total"], "ast_kind": "function_or_method", "text": "@click.command(cls=CustomClickPrinter, help=\"Convert a single PDF to markdown.\")\n@click.argument(\"fpath\", type=str)\n@ConfigParser.common_options\ndef convert_single_cli(fpath: str, **kwargs):\n    models = create_model_dict()\n    start = time.time()\n    config_parser = ConfigParser(kwargs)\n\n    converter_cls = config_parser.get_converter_cls()\n    converter = converter_cls(\n        config=config_parser.generate_config_dict(),\n        artifact_dict=models,\n        processor_list=config_parser.get_processors(),\n        renderer=config_parser.get_renderer(),\n        llm_service=config_parser.get_llm_service(),\n    )\n    rendered = converter(fpath)\n    out_folder = config_parser.get_output_folder(fpath)\n    save_output(rendered, out_folder, config_parser.get_base_filename(fpath))\n\n    logger.info(f\"Saved markdown to {out_folder}\")\n    logger.info(f\"Total time: {time.time() - start}\")\n", "n_tokens": 185, "byte_len": 891, "file_sha1": "8e72cbde5216d586b537ad17dff06c2261a2ddc7", "start_line": 22, "end_line": 44}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/__init__.py", "rel_path": "marker/extractors/__init__.py", "module": "marker.extractors.__init__", "ext": "py", "chunk_number": 1, "symbols": ["__init__", "BaseExtractor", "image", "services", "class", "base", "extractor", "init", "assign", "config", "disable", "tqdm", "none", "max", "concurrency", "model", "gemini", "llm", "service", "annotated", "provided", "make", "progress", "document", "schema", "self", "from", "whether", "uses", "data", "extract_image", "__call__", "args", "highres", "save", "tokens", "remove", "blocks", "kwargs", "return", "not", "implemented", "sequence", "call", "maximum", "extract", "typing", "block", "types", "default"], "ast_kind": "class_or_type", "text": "from typing import Annotated, Sequence\n\nfrom marker.schema import BlockTypes\nfrom marker.schema.document import Document\nfrom marker.schema.groups import PageGroup\nfrom PIL import Image\n\nfrom marker.services import BaseService\nfrom marker.util import assign_config\n\n\nclass BaseExtractor:\n    \"\"\"\n    An extractor that uses a provided service to extract structured data from documents.\n    \"\"\"\n\n    max_concurrency: Annotated[\n        int,\n        \"The maximum number of concurrent requests to make to the Gemini model.\",\n    ] = 3\n    disable_tqdm: Annotated[\n        bool,\n        \"Whether to disable the tqdm progress bar.\",\n    ] = False\n\n    def __init__(self, llm_service: BaseService, config=None):\n        assign_config(self, config)\n        self.llm_service = llm_service\n", "n_tokens": 163, "byte_len": 780, "file_sha1": "a371e9a895a473b4743738556738783e5fee0cdb", "start_line": 1, "end_line": 29}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/__init__.py", "rel_path": "marker/extractors/__init__.py", "module": "marker.extractors.__init__", "ext": "py", "chunk_number": 2, "symbols": ["extract_image", "__call__", "image", "args", "none", "highres", "save", "tokens", "document", "self", "remove", "blocks", "kwargs", "not", "implemented", "return", "sequence", "block", "types", "default", "raise", "extract", "bool", "get", "false", "page", "call", "group", "__init__", "BaseExtractor", "services", "class", "base", "extractor", "init", "assign", "config", "disable", "tqdm", "max", "concurrency", "model", "gemini", "llm", "service", "annotated", "provided", "make", "progress", "schema"], "ast_kind": "function_or_method", "text": "    def extract_image(\n        self,\n        document: Document,\n        page: PageGroup,\n        remove_blocks: Sequence[BlockTypes] | None = None,\n        highres: bool = False,  # Default False to save tokens\n    ) -> Image.Image:\n        return page.get_image(\n            document,\n            highres=highres,\n            remove_blocks=remove_blocks,\n        )\n\n    def __call__(self, document: Document, *args, **kwargs):\n        raise NotImplementedError\n", "n_tokens": 101, "byte_len": 463, "file_sha1": "a371e9a895a473b4743738556738783e5fee0cdb", "start_line": 30, "end_line": 45}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py", "rel_path": "marker/extractors/page.py", "module": "marker.extractors.page", "ext": "py", "chunk_number": 1, "symbols": ["PageExtractionSchema", "class", "base", "extractor", "futures", "get", "logger", "page", "extraction", "annotated", "pydantic", "from", "detailed", "notes", "description", "model", "list", "typing", "json", "optional", "import", "extractors", "marker", "concurrent", "tqdm", "thread", "pool", "chunk_page_markdown", "inference_single_chunk", "__call__", "PageExtractor", "together", "markdown", "analyze", "sales", "find", "exceptions", "make", "image", "that", "document", "required", "result", "schema", "work", "future", "analyst", "pulls", "format", "properties"], "ast_kind": "class_or_type", "text": "import json\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom pydantic import BaseModel\nfrom typing import Annotated, Optional, List\n\nfrom tqdm import tqdm\n\nfrom marker.extractors import BaseExtractor\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n\nclass PageExtractionSchema(BaseModel):\n    description: str\n    detailed_notes: str\n\n", "n_tokens": 72, "byte_len": 354, "file_sha1": "87e9199bc186795a87a3862b4a6c06afc83cca10", "start_line": 1, "end_line": 19}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py", "rel_path": "marker/extractors/page.py", "module": "marker.extractors.page", "ext": "py", "chunk_number": 2, "symbols": ["PageExtractor", "together", "markdown", "base", "extractor", "analyze", "sales", "find", "make", "image", "that", "document", "required", "page", "schema", "analyst", "pulls", "format", "description", "properties", "entities", "integer", "only", "string", "continue", "notes", "this", "number", "extraction", "title", "chunk_page_markdown", "inference_single_chunk", "__call__", "PageExtractionSchema", "futures", "exceptions", "result", "work", "future", "return", "pbar", "replace", "max", "workers", "structured", "marker", "total", "pieces", "executor", "documents"], "ast_kind": "class_or_type", "text": "class PageExtractor(BaseExtractor):\n    \"\"\"\n    An extractor that pulls data from a single page.\n    \"\"\"\n\n    extraction_page_chunk_size: Annotated[\n        int, \"The number of pages to chunk together for extraction.\"\n    ] = 3\n\n    page_schema: Annotated[\n        str,\n        \"The JSON schema to be extracted from the page.\",\n    ] = \"\"\n\n    page_extraction_prompt = \"\"\"You are an expert document analyst who reads documents and pulls data out in JSON format. You will receive the markdown representation of a document page, and a JSON schema that we want to extract from the document. Your task is to write detailed notes on this page, so that when you look at all your notes from across the document, you can fill in the schema.\n    \nSome notes:\n- The schema may contain a single object to extract from the entire document, or an array of objects. \n- The schema may contain nested objects, arrays, and other complex structures.\n\nSome guidelines:\n- Write very thorough notes, and include specific JSON snippets that can be extracted from the page.\n- You may need information from prior or subsequent pages to fully fill in the schema, so make sure to write detailed notes that will let you join entities across pages later on.\n- Estimate your confidence in the values you extract, so you can reconstruct the JSON later when you only have your notes.\n- Some tables and other data structures may continue on a subsequent page, so make sure to store the positions that data comes from where appropriate.\n\n**Instructions:**\n1. Analyze the provided markdown representation of the page.\n2. Analyze the JSON schema.\n3. Write a short description of the fields in the schema, and the associated values in the markdown.\n4. Write detailed notes on the page, including any values that can be extracted from the markdown.  Include snippets of JSON that can be extracted from the page where possible.\n\n**Example:**\nInput:\n\nMarkdown\n```markdown\n| Make   | Sales |\n|--------|-------|\n| Honda  | 100   |\n| Toyota | 200   |\n```\n\nSchema\n\n```json\n{'$defs': {'Cars': {'properties': {'make': {'title': 'Make', 'type': 'string'}, 'sales': {'title': 'Sales', 'type': 'integer'}, 'color': {'title': 'Color', 'type': 'string'}}, 'required': ['make', 'sales', 'color'], 'title': 'Cars', 'type': 'object'}}, 'properties': {'cars': {'items': {'$ref': '#/$defs/Cars'}, 'title': 'Cars', 'type': 'array'}}, 'required': ['cars'], 'title': 'CarsList', 'type': 'object'}\n```\n\nOutput:\n\nDescription: The schema has a list of cars, each with a make, sales, and color. The image and markdown contain a table with 2 cars: Honda with 100 sales and Toyota with 200 sales. The color is not present in the table.\nDetailed Notes: On this page, I see a table with car makes and sales. The makes are Honda and Toyota, with sales of 100 and 200 respectively. The color is not present in the table, so I will leave it blank in the JSON.  That information may be present on another page.  Some JSON snippets I may find useful later are:\n```json\n{\n    \"make\": \"Honda\",\n    \"sales\": 100,\n}\n```\n```json\n{\n    \"make\": \"Toyota\",\n    \"sales\": 200,\n}\n```\n\nHonda is the first row in the table, and Toyota is the second row.  Make is the first column, and sales is the second.\n\n**Input:**\n\nMarkdown\n```markdown\n{{page_md}}\n```\n\nSchema\n```json\n{{schema}}\n```\n\"\"\"\n", "n_tokens": 789, "byte_len": 3306, "file_sha1": "87e9199bc186795a87a3862b4a6c06afc83cca10", "start_line": 20, "end_line": 100}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py", "rel_path": "marker/extractors/page.py", "module": "marker.extractors.page", "ext": "py", "chunk_number": 3, "symbols": ["chunk_page_markdown", "chunk", "page", "markdown", "chunks", "list", "append", "pieces", "self", "smaller", "into", "processing", "join", "range", "return", "extraction", "inference_single_chunk", "__call__", "PageExtractionSchema", "PageExtractor", "together", "base", "extractor", "analyze", "sales", "find", "futures", "exceptions", "make", "image", "that", "document", "required", "result", "schema", "work", "future", "analyst", "pulls", "format", "description", "properties", "entities", "pbar", "replace", "max", "workers", "integer", "structured", "only"], "ast_kind": "function_or_method", "text": "    def chunk_page_markdown(self, page_markdown: List[str]) -> List[str]:\n        \"\"\"\n        Chunk the page markdown into smaller pieces for processing.\n        \"\"\"\n\n        chunks = []\n        for i in range(0, len(page_markdown), self.extraction_page_chunk_size):\n            chunk = page_markdown[i : i + self.extraction_page_chunk_size]\n            chunks.append(\"\\n\\n\".join(chunk))\n\n        return chunks\n", "n_tokens": 89, "byte_len": 411, "file_sha1": "87e9199bc186795a87a3862b4a6c06afc83cca10", "start_line": 101, "end_line": 112}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py", "rel_path": "marker/extractors/page.py", "module": "marker.extractors.page", "ext": "py", "chunk_number": 4, "symbols": ["inference_single_chunk", "prompt", "page", "markdown", "none", "llm", "service", "extraction", "inference", "single", "self", "schema", "detailed", "notes", "description", "return", "dumps", "replace", "json", "logger", "optional", "debug", "response", "chunk_page_markdown", "__call__", "PageExtractionSchema", "PageExtractor", "together", "base", "extractor", "analyze", "sales", "find", "futures", "exceptions", "make", "image", "that", "document", "required", "result", "work", "future", "analyst", "pulls", "format", "properties", "entities", "pbar", "max"], "ast_kind": "function_or_method", "text": "    def inference_single_chunk(\n        self, page_markdown: str\n    ) -> Optional[PageExtractionSchema]:\n        prompt = self.page_extraction_prompt.replace(\n            \"{{page_md}}\", page_markdown\n        ).replace(\"{{schema}}\", json.dumps(self.page_schema))\n        response = self.llm_service(prompt, None, None, PageExtractionSchema)\n        logger.debug(f\"Page extraction response: {response}\")\n\n        if not response or any(\n            [\n                key not in response\n                for key in [\n                    \"description\",\n                    \"detailed_notes\",\n                ]\n            ]\n        ):\n            return None\n\n        return PageExtractionSchema(\n            description=response[\"description\"],\n            detailed_notes=response[\"detailed_notes\"],\n        )\n", "n_tokens": 152, "byte_len": 807, "file_sha1": "87e9199bc186795a87a3862b4a6c06afc83cca10", "start_line": 113, "end_line": 137}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/page.py", "rel_path": "marker/extractors/page.py", "module": "marker.extractors.page", "ext": "py", "chunk_number": 5, "symbols": ["__call__", "results", "page", "markdown", "chunks", "running", "disable", "tqdm", "desc", "max", "concurrency", "extraction", "exceptions", "append", "schema", "self", "inference", "single", "result", "work", "future", "kwargs", "return", "chunk", "call", "list", "pbar", "workers", "with", "structured", "chunk_page_markdown", "inference_single_chunk", "PageExtractionSchema", "PageExtractor", "together", "base", "extractor", "analyze", "sales", "find", "futures", "make", "image", "that", "document", "required", "analyst", "pulls", "format", "description"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        page_markdown: List[str],\n        **kwargs,\n    ) -> List[PageExtractionSchema]:\n        if not self.page_schema:\n            raise ValueError(\n                \"Page schema must be defined for structured extraction to work.\"\n            )\n\n        chunks = self.chunk_page_markdown(page_markdown)\n        results = []\n        pbar = tqdm(\n            desc=\"Running page extraction\",\n            disable=self.disable_tqdm,\n            total=len(chunks),\n        )\n\n        with ThreadPoolExecutor(max_workers=self.max_concurrency) as executor:\n            for future in [\n                executor.submit(self.inference_single_chunk, chunk) for chunk in chunks\n            ]:\n                results.append(future.result())  # Raise exceptions if any occurred\n                pbar.update(1)\n\n        pbar.close()\n        return results\n", "n_tokens": 170, "byte_len": 874, "file_sha1": "87e9199bc186795a87a3862b4a6c06afc83cca10", "start_line": 138, "end_line": 165}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py", "rel_path": "marker/extractors/document.py", "module": "marker.extractors.document", "ext": "py", "chunk_number": 1, "symbols": ["DocumentExtractionSchema", "class", "base", "extractor", "get", "logger", "analysis", "document", "extraction", "page", "annotated", "pydantic", "from", "model", "list", "typing", "json", "optional", "import", "extractors", "marker", "assemble_document_notes", "__call__", "DocumentExtractor", "cannot", "find", "analyze", "header", "sales", "additional", "make", "conflicting", "that", "required", "schema", "work", "assemble", "analyst", "pulls", "format", "properties", "return", "entities", "here", "case", "replace", "combine", "integer", "structured", "output"], "ast_kind": "class_or_type", "text": "import json\n\nfrom pydantic import BaseModel\nfrom typing import Annotated, Optional, List\n\nfrom marker.extractors import BaseExtractor\nfrom marker.extractors.page import PageExtractionSchema\nfrom marker.logger import get_logger\n\nlogger = get_logger()\n\n\nclass DocumentExtractionSchema(BaseModel):\n    analysis: str\n    document_json: str\n\n", "n_tokens": 70, "byte_len": 337, "file_sha1": "e7b3f99d7781fe12656f3af7cedb734c0558bb14", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py", "rel_path": "marker/extractors/document.py", "module": "marker.extractors.document", "ext": "py", "chunk_number": 2, "symbols": ["DocumentExtractor", "cannot", "find", "base", "extractor", "analyze", "header", "sales", "additional", "make", "conflicting", "that", "document", "required", "page", "schema", "analyst", "pulls", "format", "properties", "entities", "here", "case", "combine", "integer", "output", "only", "string", "notes", "value", "assemble_document_notes", "__call__", "DocumentExtractionSchema", "extraction", "work", "assemble", "return", "replace", "structured", "continue", "marker", "which", "this", "title", "documents", "column", "span", "call", "prompt", "arrays"], "ast_kind": "class_or_type", "text": "class DocumentExtractor(BaseExtractor):\n    \"\"\"\n    An extractor that combines data from across all pages.\n    \"\"\"\n\n    page_schema: Annotated[\n        str,\n        \"The JSON schema to be extracted from the page.\",\n    ] = \"\"\n\n    page_extraction_prompt = \"\"\"You are an expert document analyst who reads documents and pulls data out in JSON format. You will receive your detailed notes from all the pages of a document, and a JSON schema that we want to extract from the document. Your task is to extract all the information properly into the JSON schema.\n\nSome notes:\n- The schema may contain a single object to extract from the entire document, or an array of objects. \n- The schema may contain nested objects, arrays, and other complex structures.\n\nSome guidelines:\n- Some entities will span multiple pages, so make sure to consult your notes thoroughly.\n- In the case of potential conflicting values, pull out the values you have the most confidence in, from your notes.\n- If you cannot find a value for a field, leave it blank in the JSON.\n\n**Instructions:**\n1. Analyze your provided notes.\n2. Analyze the JSON schema.\n3. Write a detailed analysis of the notes, and the associated values in the schema.  Make sure to reference which page each piece of information comes from.\n4. Write the output in the JSON schema format, ensuring all required fields are filled out.  Output only the json data, without any additional text or formatting.\n\n**Example:**\nInput:\n\nDetailed Notes\nPage 0\nOn this page, I see a table with car makes and sales. The makes are Honda and Toyota, with sales of 100 and 200 respectively. The color is not present in the table, so I will leave it blank in the JSON.  That information may be present on another page.  Some JSON snippets I may find useful later are:\n```json\n{\n    \"make\": \"Honda\",\n    \"sales\": 100,\n}\n```\n```json\n{\n    \"make\": \"Toyota\",\n    \"sales\": 200,\n}\n```\n\nHonda is the first row in the table, and Toyota is the second row.  Make is the first column, and sales is the second.\n\nPage 1\nI see a table that contains 2 rows, and has a color header.  The first row has the color red, and the second row has the color blue.  Here are some useful snippets:\n\nSchema\n\n```json\n{'$defs': {'Cars': {'properties': {'make': {'title': 'Make', 'type': 'string'}, 'sales': {'title': 'Sales', 'type': 'integer'}, 'color': {'title': 'Color', 'type': 'string'}}, 'required': ['make', 'sales', 'color'], 'title': 'Cars', 'type': 'object'}}, 'properties': {'cars': {'items': {'$ref': '#/$defs/Cars'}, 'title': 'Cars', 'type': 'array'}}, 'required': ['cars'], 'title': 'CarsList', 'type': 'object'}\n```\n\nOutput:\n\nAnalysis: From the notes, it looks like the information I need is in a table that spans 2 pages.  The first page has the makes and sales, while the second page has the colors.  I will combine this information into the JSON schema.\nJSON\n\n{\n    \"cars\": [\n        {\n            \"make\": \"Honda\",\n            \"sales\": 100,\n            \"color\": \"red\"\n        },\n        {\n            \"make\": \"Toyota\",\n            \"sales\": 200,\n            \"color\": \"blue\"\n        }\n    ]\n}\n\n**Input:**\n\nDetailed Notes\n{{document_notes}}\n\nSchema\n```json\n{{schema}}\n```\n\"\"\"\n", "n_tokens": 774, "byte_len": 3184, "file_sha1": "e7b3f99d7781fe12656f3af7cedb734c0558bb14", "start_line": 18, "end_line": 105}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py", "rel_path": "marker/extractors/document.py", "module": "marker.extractors.document", "ext": "py", "chunk_number": 3, "symbols": ["assemble_document_notes", "continue", "notes", "list", "page", "self", "schema", "strip", "assemble", "document", "enumerate", "detailed", "return", "extraction", "__call__", "DocumentExtractionSchema", "DocumentExtractor", "cannot", "find", "base", "extractor", "analyze", "header", "sales", "additional", "make", "conflicting", "that", "required", "work", "analyst", "pulls", "format", "properties", "entities", "here", "case", "replace", "combine", "integer", "structured", "output", "only", "string", "value", "marker", "which", "this", "title", "documents"], "ast_kind": "function_or_method", "text": "    def assemble_document_notes(self, page_notes: List[PageExtractionSchema]) -> str:\n        notes = \"\"\n        for i, page_schema in enumerate(page_notes):\n            if not page_notes:\n                continue\n            notes += f\"Page {i + 1}\\n{page_schema.detailed_notes}\\n\\n\"\n        return notes.strip()\n", "n_tokens": 72, "byte_len": 314, "file_sha1": "e7b3f99d7781fe12656f3af7cedb734c0558bb14", "start_line": 106, "end_line": 113}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/extractors/document.py", "rel_path": "marker/extractors/document.py", "module": "marker.extractors.document", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "prompt", "none", "extraction", "llm", "service", "page", "document", "analysis", "schema", "self", "lstrip", "notes", "work", "assemble", "kwargs", "return", "rstrip", "call", "list", "dumps", "replace", "strip", "json", "structured", "raise", "optional", "logger", "defined", "data", "assemble_document_notes", "DocumentExtractionSchema", "DocumentExtractor", "cannot", "find", "base", "extractor", "analyze", "header", "sales", "additional", "make", "conflicting", "that", "required", "analyst", "pulls", "format", "properties", "entities"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        page_notes: List[PageExtractionSchema],\n        **kwargs,\n    ) -> Optional[DocumentExtractionSchema]:\n        if not self.page_schema:\n            raise ValueError(\n                \"Page schema must be defined for structured extraction to work.\"\n            )\n\n        prompt = self.page_extraction_prompt.replace(\n            \"{{document_notes}}\", self.assemble_document_notes(page_notes)\n        ).replace(\"{{schema}}\", json.dumps(self.page_schema))\n        response = self.llm_service(prompt, None, None, DocumentExtractionSchema)\n\n        logger.debug(f\"Document extraction response: {response}\")\n\n        if not response or any(\n            [\n                key not in response\n                for key in [\n                    \"analysis\",\n                    \"document_json\",\n                ]\n            ]\n        ):\n            return None\n\n        json_data = response[\"document_json\"].strip().lstrip(\"```json\").rstrip(\"```\")\n\n        return DocumentExtractionSchema(\n            analysis=response[\"analysis\"], document_json=json_data\n        )\n", "n_tokens": 206, "byte_len": 1096, "file_sha1": "e7b3f99d7781fe12656f3af7cedb734c0558bb14", "start_line": 114, "end_line": 147}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py", "rel_path": "marker/services/claude.py", "module": "marker.services.claude", "ext": "py", "chunk_number": 1, "symbols": ["ClaudeService", "image", "rate", "limit", "services", "class", "none", "model", "claude", "blocks", "get", "logger", "tokens", "annotated", "pydantic", "schema", "from", "request", "service", "base", "time", "list", "single", "google", "anthropic", "typing", "json", "import", "api", "timeout", "process_images", "validate_response", "get_client", "__call__", "exception", "out", "giving", "break", "create", "user", "base64", "media", "type", "dump", "dict", "messages", "escapes", "error", "format", "return"], "ast_kind": "class_or_type", "text": "import json\nimport time\nfrom typing import List, Annotated, T\n\nimport PIL\nfrom PIL import Image\nimport anthropic\nfrom anthropic import RateLimitError, APITimeoutError\nfrom marker.logger import get_logger\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n\nclass ClaudeService(BaseService):\n    claude_model_name: Annotated[\n        str, \"The name of the Google model to use for the service.\"\n    ] = \"claude-3-7-sonnet-20250219\"\n    claude_api_key: Annotated[str, \"The Claude API key to use for the service.\"] = None\n    max_claude_tokens: Annotated[\n        int, \"The maximum number of tokens to use for a single Claude request.\"\n    ] = 8192\n", "n_tokens": 181, "byte_len": 728, "file_sha1": "562f1b7273668bc174422654e9609880412bda87", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py", "rel_path": "marker/services/claude.py", "module": "marker.services.claude", "ext": "py", "chunk_number": 2, "symbols": ["process_images", "images", "image", "type", "source", "list", "base", "base64", "media", "self", "img", "dict", "return", "process", "webp", "data", "validate_response", "get_client", "__call__", "ClaudeService", "exception", "out", "schema", "giving", "claude", "break", "create", "user", "model", "dump", "messages", "escapes", "error", "format", "validate", "time", "except", "during", "google", "replace", "system", "prompt", "attempt", "only", "marker", "this", "number", "retrying", "api", "json"], "ast_kind": "function_or_method", "text": "    def process_images(self, images: List[Image.Image]) -> List[dict]:\n        return [\n            {\n                \"type\": \"image\",\n                \"source\": {\n                    \"type\": \"base64\",\n                    \"media_type\": \"image/webp\",\n                    \"data\": self.img_to_base64(img),\n                },\n            }\n            for img in images\n        ]\n", "n_tokens": 76, "byte_len": 375, "file_sha1": "562f1b7273668bc174422654e9609880412bda87", "start_line": 27, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py", "rel_path": "marker/services/claude.py", "module": "marker.services.claude", "ext": "py", "chunk_number": 3, "symbols": ["validate_response", "get_client", "exception", "parse", "out", "schema", "api", "key", "startswith", "anthropic", "self", "first", "model", "dump", "escapes", "return", "except", "replace", "strip", "fixed", "json", "with", "escaped", "str", "validate", "get", "client", "response", "text", "type", "process_images", "__call__", "ClaudeService", "giving", "claude", "break", "create", "image", "user", "base", "base64", "media", "dict", "messages", "error", "format", "time", "during", "google", "system"], "ast_kind": "function_or_method", "text": "    def validate_response(self, response_text: str, schema: type[T]) -> T:\n        response_text = response_text.strip()\n        if response_text.startswith(\"```json\"):\n            response_text = response_text[7:]\n        if response_text.endswith(\"```\"):\n            response_text = response_text[:-3]\n\n        try:\n            # Try to parse as JSON first\n            out_schema = schema.model_validate_json(response_text)\n            out_json = out_schema.model_dump()\n            return out_json\n        except Exception:\n            try:\n                # Re-parse with fixed escapes\n                escaped_str = response_text.replace(\"\\\\\", \"\\\\\\\\\")\n                out_schema = schema.model_validate_json(escaped_str)\n                return out_schema.model_dump()\n            except Exception:\n                return\n\n    def get_client(self):\n        return anthropic.Anthropic(\n            api_key=self.claude_api_key,\n        )\n", "n_tokens": 178, "byte_len": 939, "file_sha1": "562f1b7273668bc174422654e9609880412bda87", "start_line": 40, "end_line": 65}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/claude.py", "rel_path": "marker/services/claude.py", "module": "marker.services.claude", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "exception", "giving", "claude", "break", "create", "image", "user", "messages", "error", "format", "return", "validate", "time", "except", "during", "system", "prompt", "attempt", "only", "this", "retrying", "model", "json", "provide", "indent", "total", "tries", "seconds", "rate", "process_images", "validate_response", "get_client", "ClaudeService", "out", "schema", "base", "base64", "media", "type", "dump", "dict", "escapes", "google", "replace", "source", "marker", "number", "api", "call"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        if max_retries is None:\n            max_retries = self.max_retries\n\n        if timeout is None:\n            timeout = self.timeout\n\n        schema_example = response_schema.model_json_schema()\n        system_prompt = f\"\"\"\nFollow the instructions given by the user prompt.  You must provide your response in JSON format matching this schema:\n\n{json.dumps(schema_example, indent=2)}\n\nRespond only with the JSON schema, nothing else.  Do not include ```json, ```,  or any other formatting.\n\"\"\".strip()\n\n        client = self.get_client()\n        image_data = self.format_image_for_llm(image)\n\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    *image_data,\n                    {\"type\": \"text\", \"text\": prompt},\n                ],\n            }\n        ]\n\n        total_tries = max_retries + 1\n        for tries in range(1, total_tries + 1):\n            try:\n                response = client.messages.create(\n                    system=system_prompt,\n                    model=self.claude_model_name,\n                    max_tokens=self.max_claude_tokens,\n                    messages=messages,\n                    timeout=timeout,\n                )\n                # Extract and validate response\n                response_text = response.content[0].text\n                return self.validate_response(response_text, response_schema)\n            except (RateLimitError, APITimeoutError) as e:\n                # Rate limit exceeded\n                if tries == total_tries:\n                    # Last attempt failed. Give up\n                    logger.error(\n                        f\"Rate limit error: {e}. Max retries reached. Giving up. (Attempt {tries}/{total_tries})\",\n                    )\n                    break\n                else:\n                    wait_time = tries * self.retry_wait_time\n                    logger.warning(\n                        f\"Rate limit error: {e}. Retrying in {wait_time} seconds... (Attempt {tries}/{total_tries})\",\n                    )\n                    time.sleep(wait_time)\n            except Exception as e:\n                logger.error(f\"Error during Claude API call: {e}\")\n                break\n\n        return {}\n", "n_tokens": 492, "byte_len": 2503, "file_sha1": "562f1b7273668bc174422654e9609880412bda87", "start_line": 66, "end_line": 135}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/__init__.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/__init__.py", "rel_path": "marker/services/__init__.py", "module": "marker.services.__init__", "ext": "py", "chunk_number": 1, "symbols": ["img_to_base64", "BaseService", "image", "class", "assign", "config", "none", "save", "blocks", "timeout", "tokens", "between", "annotated", "pydantic", "base", "base64", "schema", "self", "from", "retries", "verify", "format", "return", "decode", "model", "time", "service", "bytes", "list", "bytesio", "process_images", "format_image_for_llm", "__init__", "__call__", "prompt", "init", "response", "images", "dict", "not", "implemented", "filled", "ensure", "webp", "have", "typing", "necessary", "keys", "optional", "process"], "ast_kind": "class_or_type", "text": "from typing import Optional, List, Annotated\nfrom io import BytesIO\n\nimport PIL\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.util import assign_config, verify_config_keys\nimport base64\n\n\nclass BaseService:\n    timeout: Annotated[int, \"The timeout to use for the service.\"] = 30\n    max_retries: Annotated[\n        int, \"The maximum number of retries to use for the service.\"\n    ] = 2\n    retry_wait_time: Annotated[int, \"The wait time between retries.\"] = 3\n    max_output_tokens: Annotated[\n        int, \"The maximum number of output tokens to generate.\"\n    ] = None\n\n    def img_to_base64(self, img: PIL.Image.Image, format: str = \"WEBP\"):\n        image_bytes = BytesIO()\n        img.save(image_bytes, format=format)\n        return base64.b64encode(image_bytes.getvalue()).decode(\"utf-8\")\n", "n_tokens": 201, "byte_len": 831, "file_sha1": "4f064a29fe32dd7c8e0b9add52fb53e3fdc4bf11", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/__init__.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/__init__.py", "rel_path": "marker/services/__init__.py", "module": "marker.services.__init__", "ext": "py", "chunk_number": 2, "symbols": ["process_images", "format_image_for_llm", "__init__", "__call__", "image", "prompt", "init", "assign", "config", "none", "response", "schema", "timeout", "images", "self", "dict", "verify", "not", "implemented", "return", "filled", "base", "model", "ensure", "list", "have", "necessary", "keys", "format", "optional", "img_to_base64", "BaseService", "class", "save", "blocks", "tokens", "between", "annotated", "pydantic", "base64", "from", "retries", "decode", "time", "service", "bytes", "bytesio", "webp", "typing", "process"], "ast_kind": "function_or_method", "text": "    def process_images(self, images: List[PIL.Image.Image]) -> list:\n        raise NotImplementedError\n\n    def format_image_for_llm(self, image):\n        if not image:\n            return []\n\n        if not isinstance(image, list):\n            image = [image]\n\n        image_parts = self.process_images(image)\n        return image_parts\n\n    def __init__(self, config: Optional[BaseModel | dict] = None):\n        assign_config(self, config)\n\n        # Ensure we have all necessary fields filled out (API keys, etc.)\n        verify_config_keys(self)\n\n    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        raise NotImplementedError\n", "n_tokens": 187, "byte_len": 854, "file_sha1": "4f064a29fe32dd7c8e0b9add52fb53e3fdc4bf11", "start_line": 27, "end_line": 56}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py", "rel_path": "marker/services/gemini.py", "module": "marker.services.gemini", "ext": "py", "chunk_number": 1, "symbols": ["img_to_bytes", "get_google_client", "BaseGeminiService", "errors", "image", "services", "class", "traceback", "model", "save", "blocks", "get", "logger", "timeout", "annotated", "pydantic", "schema", "base", "gemini", "types", "self", "from", "google", "img", "bytes", "format", "not", "implemented", "return", "time", "process_images", "__call__", "GoogleGeminiService", "exception", "giving", "break", "temperature", "config", "responses", "api", "error", "client", "except", "total", "token", "tokens", "attempt", "flash", "output", "usage"], "ast_kind": "class_or_type", "text": "import json\nimport time\nimport traceback\nfrom io import BytesIO\nfrom typing import List, Annotated\n\nimport PIL\nfrom google import genai\nfrom google.genai import types\nfrom google.genai.errors import APIError\nfrom marker.logger import get_logger\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n\nclass BaseGeminiService(BaseService):\n    gemini_model_name: Annotated[\n        str, \"The name of the Google model to use for the service.\"\n    ] = \"gemini-2.0-flash\"\n\n    def img_to_bytes(self, img: PIL.Image.Image):\n        image_bytes = BytesIO()\n        img.save(image_bytes, format=\"WEBP\")\n        return image_bytes.getvalue()\n\n    def get_google_client(self, timeout: int):\n        raise NotImplementedError\n", "n_tokens": 177, "byte_len": 796, "file_sha1": "df3c5d60101bfdecd1499b1b4bee5a9e8ecac22d", "start_line": 1, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py", "rel_path": "marker/services/gemini.py", "module": "marker.services.gemini", "ext": "py", "chunk_number": 2, "symbols": ["process_images", "images", "image", "mime", "type", "parts", "from", "bytes", "self", "types", "part", "img", "return", "process", "webp", "data", "img_to_bytes", "get_google_client", "__call__", "BaseGeminiService", "GoogleGeminiService", "exception", "giving", "traceback", "break", "temperature", "config", "responses", "gemini", "api", "error", "client", "format", "time", "except", "total", "token", "google", "tokens", "attempt", "flash", "get", "output", "usage", "metadata", "marker", "retrying", "max", "tries", "seconds"], "ast_kind": "function_or_method", "text": "    def process_images(self, images):\n        image_parts = [\n            types.Part.from_bytes(data=self.img_to_bytes(img), mime_type=\"image/webp\")\n            for img in images\n        ]\n        return image_parts\n", "n_tokens": 45, "byte_len": 216, "file_sha1": "df3c5d60101bfdecd1499b1b4bee5a9e8ecac22d", "start_line": 33, "end_line": 39}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py", "rel_path": "marker/services/gemini.py", "module": "marker.services.gemini", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "exception", "giving", "traceback", "break", "image", "temperature", "config", "responses", "error", "return", "time", "except", "total", "token", "tokens", "attempt", "get", "google", "output", "usage", "metadata", "retrying", "max", "tries", "seconds", "rate", "call", "prompt", "text", "img_to_bytes", "get_google_client", "process_images", "BaseGeminiService", "GoogleGeminiService", "gemini", "api", "client", "format", "flash", "marker", "services", "model", "response", "schema", "blocks", "logger", "timeout", "slightly", "images"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        if max_retries is None:\n            max_retries = self.max_retries\n\n        if timeout is None:\n            timeout = self.timeout\n\n        client = self.get_google_client(timeout=timeout)\n        image_parts = self.format_image_for_llm(image)\n\n        total_tries = max_retries + 1\n        temperature = 0\n        for tries in range(1, total_tries + 1):\n            config = {\n                \"temperature\": temperature,\n                \"response_schema\": response_schema,\n                \"response_mime_type\": \"application/json\",\n            }\n            if self.max_output_tokens:\n                config[\"max_output_tokens\"] = self.max_output_tokens\n\n            try:\n                responses = client.models.generate_content(\n                    model=self.gemini_model_name,\n                    contents=image_parts\n                    + [\n                        prompt\n                    ],  # According to gemini docs, it performs better if the image is the first element\n                    config=config,\n                )\n                output = responses.candidates[0].content.parts[0].text\n                total_tokens = responses.usage_metadata.total_token_count\n                if block:\n                    block.update_metadata(\n                        llm_tokens_used=total_tokens, llm_request_count=1\n                    )\n                return json.loads(output)\n            except APIError as e:\n                if e.code in [429, 443, 503]:\n                    # Rate limit exceeded\n                    if tries == total_tries:\n                        # Last attempt failed. Give up\n                        logger.error(\n                            f\"APIError: {e}. Max retries reached. Giving up. (Attempt {tries}/{total_tries})\",\n                        )\n                        break\n                    else:\n                        wait_time = tries * self.retry_wait_time\n                        logger.warning(\n                            f\"APIError: {e}. Retrying in {wait_time} seconds... (Attempt {tries}/{total_tries})\",\n                        )\n                        time.sleep(wait_time)\n                else:\n                    logger.error(f\"APIError: {e}\")\n                    break\n            except json.JSONDecodeError as e:\n                temperature = 0.2  # Increase temperature slightly to try and get a different respons\n\n                # The response was not valid JSON\n                if tries == total_tries:\n                    # Last attempt failed. Give up\n                    logger.error(\n                        f\"JSONDecodeError: {e}. Max retries reached. Giving up. (Attempt {tries}/{total_tries})\",\n                    )\n                    break\n                else:\n                    logger.warning(\n                        f\"JSONDecodeError: {e}. Retrying... (Attempt {tries}/{total_tries})\",\n                    )\n            except Exception as e:\n                logger.error(f\"Exception: {e}\")\n                traceback.print_exc()\n                break\n\n        return {}\n\n", "n_tokens": 621, "byte_len": 3333, "file_sha1": "df3c5d60101bfdecd1499b1b4bee5a9e8ecac22d", "start_line": 40, "end_line": 124}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/gemini.py", "rel_path": "marker/services/gemini.py", "module": "marker.services.gemini", "ext": "py", "chunk_number": 4, "symbols": ["get_google_client", "GoogleGeminiService", "annotated", "milliseconds", "class", "genai", "client", "api", "key", "base", "gemini", "service", "google", "none", "self", "convert", "get", "timeout", "http", "options", "return", "img_to_bytes", "process_images", "__call__", "BaseGeminiService", "exception", "giving", "traceback", "break", "image", "temperature", "config", "responses", "error", "format", "time", "except", "total", "token", "tokens", "attempt", "flash", "output", "usage", "metadata", "marker", "retrying", "max", "tries", "seconds"], "ast_kind": "class_or_type", "text": "class GoogleGeminiService(BaseGeminiService):\n    gemini_api_key: Annotated[str, \"The Google API key to use for the service.\"] = None\n\n    def get_google_client(self, timeout: int):\n        return genai.Client(\n            api_key=self.gemini_api_key,\n            http_options={\"timeout\": timeout * 1000},  # Convert to milliseconds\n        )\n", "n_tokens": 81, "byte_len": 343, "file_sha1": "df3c5d60101bfdecd1499b1b4bee5a9e8ecac22d", "start_line": 125, "end_line": 133}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/vertex.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/vertex.py", "rel_path": "marker/services/vertex.py", "module": "marker.services.vertex", "ext": "py", "chunk_number": 1, "symbols": ["GoogleVertexService", "central", "central1", "services", "class", "none", "dedicated", "model", "vertex", "annotated", "project", "base", "gemini", "from", "google", "whether", "cloud", "genai", "typing", "flash", "location", "import", "bool", "marker", "instance", "service", "false", "name", "get_google_client", "headers", "timeout", "self", "vertexai", "client", "request", "return", "get", "http", "options", "milliseconds", "type", "convert", "true"], "ast_kind": "class_or_type", "text": "from typing import Annotated\n\nfrom google import genai\n\nfrom marker.services.gemini import BaseGeminiService\n\nclass GoogleVertexService(BaseGeminiService):\n    vertex_project_id: Annotated[\n        str,\n        \"Google Cloud Project ID for Vertex AI.\",\n    ] = None\n    vertex_location: Annotated[\n        str,\n        \"Google Cloud Location for Vertex AI.\",\n    ] = \"us-central1\"\n    gemini_model_name: Annotated[\n        str,\n        \"The name of the Google model to use for the service.\"\n    ] = \"gemini-2.0-flash-001\"\n    vertex_dedicated: Annotated[\n        bool,\n        \"Whether to use a dedicated Vertex AI instance.\"\n    ] = False\n", "n_tokens": 154, "byte_len": 640, "file_sha1": "d6dccc5508dbdfc3aba9d469028efa29f077a2ae", "start_line": 1, "end_line": 24}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/vertex.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/vertex.py", "rel_path": "marker/services/vertex.py", "module": "marker.services.vertex", "ext": "py", "chunk_number": 2, "symbols": ["get_google_client", "dedicated", "headers", "timeout", "project", "self", "vertex", "location", "vertexai", "client", "request", "return", "genai", "get", "google", "http", "options", "milliseconds", "type", "convert", "true", "GoogleVertexService", "central", "central1", "services", "class", "none", "model", "annotated", "base", "gemini", "from", "whether", "cloud", "typing", "flash", "import", "bool", "marker", "instance", "service", "false", "name"], "ast_kind": "function_or_method", "text": "    def get_google_client(self, timeout: int):\n        http_options = {\"timeout\": timeout * 1000} # Convert to milliseconds\n        if self.vertex_dedicated:\n            http_options[\"headers\"] = {\"x-vertex-ai-llm-request-type\": \"dedicated\"}\n        return genai.Client(\n            vertexai=True,\n            project=self.vertex_project_id,\n            location=self.vertex_location,\n            http_options=http_options,\n        )", "n_tokens": 92, "byte_len": 433, "file_sha1": "d6dccc5508dbdfc3aba9d469028efa29f077a2ae", "start_line": 25, "end_line": 34}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py", "rel_path": "marker/services/openai.py", "module": "marker.services.openai", "ext": "py", "chunk_number": 1, "symbols": ["image", "rate", "limit", "services", "openai", "blocks", "get", "logger", "annotated", "pydantic", "schema", "from", "base", "model", "time", "service", "list", "typing", "json", "import", "api", "timeout", "marker", "block", "process_images", "__call__", "get_client", "OpenAIService", "exception", "giving", "completions", "compatabile", "beta", "https", "break", "user", "usage", "base64", "send", "dict", "messages", "error", "format", "return", "github", "url", "except", "total", "tokens", "attempt"], "ast_kind": "imports", "text": "import json\nimport time\nfrom typing import Annotated, List\n\nimport openai\nimport PIL\nfrom marker.logger import get_logger\nfrom openai import APITimeoutError, RateLimitError\nfrom PIL import Image\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n", "n_tokens": 72, "byte_len": 330, "file_sha1": "67b329aef7e32f2170ffda359020ce1368c39e5c", "start_line": 1, "end_line": 17}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py", "rel_path": "marker/services/openai.py", "module": "marker.services.openai", "ext": "py", "chunk_number": 2, "symbols": ["OpenAIService", "open", "openai", "class", "better", "none", "api", "base", "model", "image", "compatability", "https", "annotated", "trailing", "format", "webp", "service", "models", "mini", "slash", "like", "name", "process_images", "__call__", "get_client", "exception", "giving", "completions", "compatabile", "beta", "break", "user", "usage", "base64", "send", "dict", "messages", "error", "return", "github", "url", "time", "except", "total", "tokens", "attempt", "message", "marker", "isinstance", "retrying"], "ast_kind": "class_or_type", "text": "class OpenAIService(BaseService):\n    openai_base_url: Annotated[\n        str, \"The base url to use for OpenAI-like models.  No trailing slash.\"\n    ] = \"https://api.openai.com/v1\"\n    openai_model: Annotated[str, \"The model name to use for OpenAI-like model.\"] = (\n        \"gpt-4o-mini\"\n    )\n    openai_api_key: Annotated[\n        str, \"The API key to use for the OpenAI-like service.\"\n    ] = None\n    openai_image_format: Annotated[\n        str,\n        \"The image format to use for the OpenAI-like service. Use 'png' for better compatability\",\n    ] = \"webp\"\n", "n_tokens": 156, "byte_len": 564, "file_sha1": "67b329aef7e32f2170ffda359020ce1368c39e5c", "start_line": 18, "end_line": 32}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py", "rel_path": "marker/services/openai.py", "module": "marker.services.openai", "ext": "py", "chunk_number": 3, "symbols": ["process_images", "image", "open", "openai", "better", "base", "model", "compatabile", "encoded", "containing", "compatability", "images", "base64", "self", "compatbile", "send", "dict", "messages", "format", "return", "returns", "data", "list", "url", "img", "fmt", "multimodal", "process", "message", "type", "__call__", "get_client", "OpenAIService", "exception", "giving", "completions", "beta", "https", "break", "user", "usage", "error", "github", "time", "except", "total", "tokens", "attempt", "marker", "isinstance"], "ast_kind": "function_or_method", "text": "    def process_images(self, images: List[Image.Image]) -> List[dict]:\n        \"\"\"\n        Generate the base-64 encoded message to send to an\n        openAI-compatabile multimodal model.\n\n        Args:\n            images: Image or list of PIL images to include\n            format: Format to use for the image; use \"png\" for better compatability.\n\n        Returns:\n            A list of OpenAI-compatbile multimodal messages containing the base64-encoded images.\n        \"\"\"\n        if isinstance(images, Image.Image):\n            images = [images]\n\n        img_fmt = self.openai_image_format\n        return [\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": \"data:image/{};base64,{}\".format(\n                        img_fmt, self.img_to_base64(img, format=img_fmt)\n                    ),\n                },\n            }\n            for img in images\n        ]\n", "n_tokens": 191, "byte_len": 921, "file_sha1": "67b329aef7e32f2170ffda359020ce1368c39e5c", "start_line": 33, "end_line": 60}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py", "rel_path": "marker/services/openai.py", "module": "marker.services.openai", "ext": "py", "chunk_number": 4, "symbols": ["__call__", "exception", "giving", "completions", "beta", "https", "break", "image", "user", "usage", "messages", "error", "github", "return", "time", "except", "total", "tokens", "attempt", "message", "marker", "retrying", "tries", "seconds", "rate", "extra", "headers", "call", "prompt", "data", "process_images", "get_client", "OpenAIService", "base", "compatabile", "base64", "send", "dict", "format", "url", "open", "openai", "isinstance", "services", "parse", "text", "api", "model", "response", "schema"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        if max_retries is None:\n            max_retries = self.max_retries\n\n        if timeout is None:\n            timeout = self.timeout\n\n        client = self.get_client()\n        image_data = self.format_image_for_llm(image)\n\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    *image_data,\n                    {\"type\": \"text\", \"text\": prompt},\n                ],\n            }\n        ]\n\n        total_tries = max_retries + 1\n        for tries in range(1, total_tries + 1):\n            try:\n                response = client.beta.chat.completions.parse(\n                    extra_headers={\n                        \"X-Title\": \"Marker\",\n                        \"HTTP-Referer\": \"https://github.com/datalab-to/marker\",\n                    },\n                    model=self.openai_model,\n                    messages=messages,\n                    timeout=timeout,\n                    response_format=response_schema,\n                )\n                response_text = response.choices[0].message.content\n                total_tokens = response.usage.total_tokens\n                if block:\n                    block.update_metadata(\n                        llm_tokens_used=total_tokens, llm_request_count=1\n                    )\n                return json.loads(response_text)\n            except (APITimeoutError, RateLimitError) as e:\n                # Rate limit exceeded\n                if tries == total_tries:\n                    # Last attempt failed. Give up\n                    logger.error(\n                        f\"Rate limit error: {e}. Max retries reached. Giving up. (Attempt {tries}/{total_tries})\",\n                    )\n                    break\n                else:\n                    wait_time = tries * self.retry_wait_time\n                    logger.warning(\n                        f\"Rate limit error: {e}. Retrying in {wait_time} seconds... (Attempt {tries}/{total_tries})\",\n                    )\n                    time.sleep(wait_time)\n            except Exception as e:\n                logger.error(f\"OpenAI inference failed: {e}\")\n                break\n\n        return {}\n", "n_tokens": 467, "byte_len": 2435, "file_sha1": "67b329aef7e32f2170ffda359020ce1368c39e5c", "start_line": 61, "end_line": 128}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py#5", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/openai.py", "rel_path": "marker/services/openai.py", "module": "marker.services.openai", "ext": "py", "chunk_number": 5, "symbols": ["get_client", "open", "openai", "base", "api", "key", "self", "return", "get", "client", "url", "process_images", "__call__", "OpenAIService", "exception", "giving", "completions", "compatabile", "beta", "https", "break", "image", "user", "usage", "base64", "send", "dict", "messages", "error", "format", "github", "time", "except", "total", "tokens", "attempt", "message", "marker", "isinstance", "retrying", "tries", "seconds", "rate", "extra", "headers", "call", "prompt", "data", "services", "parse"], "ast_kind": "function_or_method", "text": "    def get_client(self) -> openai.OpenAI:\n        return openai.OpenAI(api_key=self.openai_api_key, base_url=self.openai_base_url)\n", "n_tokens": 34, "byte_len": 132, "file_sha1": "67b329aef7e32f2170ffda359020ce1368c39e5c", "start_line": 129, "end_line": 131}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py", "rel_path": "marker/services/azure_openai.py", "module": "marker.services.azure_openai", "ext": "py", "chunk_number": 1, "symbols": ["AzureOpenAIService", "image", "open", "openai", "rate", "limit", "services", "class", "none", "azure", "deployment", "model", "blocks", "get", "logger", "version", "endpoint", "annotated", "pydantic", "schema", "trailing", "from", "name", "base", "time", "service", "list", "typing", "json", "import", "process_images", "__call__", "get_client", "exception", "giving", "completions", "beta", "https", "break", "user", "usage", "base64", "messages", "error", "format", "github", "return", "except", "total", "tokens"], "ast_kind": "class_or_type", "text": "import json\nimport time\nfrom typing import Annotated, List\n\nimport PIL\nfrom marker.logger import get_logger\nfrom openai import AzureOpenAI, APITimeoutError, RateLimitError\nfrom PIL import Image\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n\nclass AzureOpenAIService(BaseService):\n    azure_endpoint: Annotated[\n        str, \"The Azure OpenAI endpoint URL. No trailing slash.\"\n    ] = None\n    azure_api_key: Annotated[\n        str, \"The API key to use for the Azure OpenAI service.\"\n    ] = None\n    azure_api_version: Annotated[str, \"The Azure OpenAI API version to use.\"] = None\n    deployment_name: Annotated[\n        str, \"The deployment name for the Azure OpenAI model.\"\n    ] = None\n", "n_tokens": 184, "byte_len": 778, "file_sha1": "57df2d8e575a320690960cd889f838e729b5a647", "start_line": 1, "end_line": 28}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py", "rel_path": "marker/services/azure_openai.py", "module": "marker.services.azure_openai", "ext": "py", "chunk_number": 2, "symbols": ["process_images", "images", "image", "type", "list", "isinstance", "base", "base64", "self", "url", "img", "format", "return", "process", "webp", "data", "__call__", "get_client", "AzureOpenAIService", "exception", "giving", "completions", "beta", "https", "break", "endpoint", "user", "usage", "messages", "error", "github", "azure", "time", "except", "total", "tokens", "attempt", "message", "marker", "open", "retrying", "tries", "seconds", "rate", "extra", "headers", "call", "prompt", "services", "parse"], "ast_kind": "function_or_method", "text": "    def process_images(self, images: List[PIL.Image.Image]) -> list:\n        if isinstance(images, Image.Image):\n            images = [images]\n\n        return [\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": \"data:image/webp;base64,{}\".format(self.img_to_base64(img)),\n                },\n            }\n            for img in images\n        ]\n", "n_tokens": 83, "byte_len": 404, "file_sha1": "57df2d8e575a320690960cd889f838e729b5a647", "start_line": 29, "end_line": 42}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py#3", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py", "rel_path": "marker/services/azure_openai.py", "module": "marker.services.azure_openai", "ext": "py", "chunk_number": 3, "symbols": ["__call__", "exception", "giving", "completions", "beta", "https", "break", "image", "user", "usage", "messages", "error", "github", "return", "azure", "time", "except", "total", "tokens", "attempt", "message", "marker", "retrying", "tries", "seconds", "rate", "extra", "headers", "call", "prompt", "process_images", "get_client", "AzureOpenAIService", "endpoint", "base", "base64", "format", "open", "isinstance", "data", "services", "parse", "text", "deployment", "model", "response", "schema", "blocks", "get", "logger"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        if max_retries is None:\n            max_retries = self.max_retries\n\n        if timeout is None:\n            timeout = self.timeout\n\n        client = self.get_client()\n        image_data = self.format_image_for_llm(image)\n\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    *image_data,\n                    {\"type\": \"text\", \"text\": prompt},\n                ],\n            }\n        ]\n\n        total_tries = max_retries + 1\n        for tries in range(1, total_tries + 1):\n            try:\n                response = client.beta.chat.completions.parse(\n                    extra_headers={\n                        \"X-Title\": \"Marker\",\n                        \"HTTP-Referer\": \"https://github.com/datalab-to/marker\",\n                    },\n                    model=self.deployment_name,\n                    messages=messages,\n                    timeout=timeout,\n                    response_format=response_schema,\n                )\n                response_text = response.choices[0].message.content\n                total_tokens = response.usage.total_tokens\n                if block:\n                    block.update_metadata(\n                        llm_tokens_used=total_tokens, llm_request_count=1\n                    )\n                return json.loads(response_text)\n            except (APITimeoutError, RateLimitError) as e:\n                # Rate limit exceeded\n                if tries == total_tries:\n                    # Last attempt failed. Give up\n                    logger.error(\n                        f\"Rate limit error: {e}. Max retries reached. Giving up. (Attempt {tries}/{total_tries})\"\n                    )\n                    break\n                else:\n                    wait_time = tries * self.retry_wait_time\n                    logger.warning(\n                        f\"Rate limit error: {e}. Retrying in {wait_time} seconds... (Attempt {tries}/{total_tries})\"\n                    )\n                    time.sleep(wait_time)\n            except Exception as e:\n                logger.error(f\"Azure OpenAI inference failed: {e}\")\n                break\n\n        return {}\n", "n_tokens": 466, "byte_len": 2442, "file_sha1": "57df2d8e575a320690960cd889f838e729b5a647", "start_line": 43, "end_line": 110}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py#4", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/azure_openai.py", "rel_path": "marker/services/azure_openai.py", "module": "marker.services.azure_openai", "ext": "py", "chunk_number": 4, "symbols": ["get_client", "azure", "endpoint", "api", "key", "self", "open", "return", "version", "get", "client", "process_images", "__call__", "AzureOpenAIService", "exception", "giving", "completions", "beta", "https", "break", "image", "user", "usage", "base", "base64", "messages", "error", "format", "github", "time", "except", "total", "tokens", "attempt", "message", "marker", "isinstance", "retrying", "tries", "seconds", "rate", "extra", "headers", "call", "prompt", "data", "services", "parse", "text", "deployment"], "ast_kind": "function_or_method", "text": "    def get_client(self) -> AzureOpenAI:\n        return AzureOpenAI(\n            api_version=self.azure_api_version,\n            azure_endpoint=self.azure_endpoint,\n            api_key=self.azure_api_key,\n        )\n", "n_tokens": 42, "byte_len": 215, "file_sha1": "57df2d8e575a320690960cd889f838e729b5a647", "start_line": 111, "end_line": 117}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/ollama.py#1", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/ollama.py", "rel_path": "marker/services/ollama.py", "module": "marker.services.ollama", "ext": "py", "chunk_number": 1, "symbols": ["process_images", "OllamaService", "services", "class", "base", "model", "blocks", "get", "logger", "images", "annotated", "pydantic", "vision", "ollama", "schema", "self", "trailing", "from", "return", "localhost", "service", "image", "bytes", "list", "http", "llama", "llama3", "typing", "json", "process", "__call__", "exception", "required", "content", "format", "properties", "except", "total", "tokens", "marker", "generate", "raise", "for", "call", "prompt", "response", "timeout", "inference", "payload", "type"], "ast_kind": "class_or_type", "text": "import json\nfrom typing import Annotated, List\n\nimport PIL\nimport requests\nfrom marker.logger import get_logger\nfrom pydantic import BaseModel\n\nfrom marker.schema.blocks import Block\nfrom marker.services import BaseService\n\nlogger = get_logger()\n\n\nclass OllamaService(BaseService):\n    ollama_base_url: Annotated[\n        str, \"The base url to use for ollama.  No trailing slash.\"\n    ] = \"http://localhost:11434\"\n    ollama_model: Annotated[str, \"The model name to use for ollama.\"] = (\n        \"llama3.2-vision\"\n    )\n\n    def process_images(self, images):\n        image_bytes = [self.img_to_base64(img) for img in images]\n        return image_bytes\n", "n_tokens": 162, "byte_len": 652, "file_sha1": "e5ac45316dc04b3e616ee8e608f4f7f9f2dd6cae", "start_line": 1, "end_line": 26}
{"id": "/Users/zack.alatrash/Downloads/marker-master/marker/services/ollama.py#2", "repo_id": "marker-master", "language": "python", "path": "/Users/zack.alatrash/Downloads/marker-master/marker/services/ollama.py", "rel_path": "marker/services/ollama.py", "module": "marker.services.ollama", "ext": "py", "chunk_number": 2, "symbols": ["__call__", "exception", "image", "prompt", "none", "response", "schema", "headers", "model", "timeout", "requests", "images", "self", "content", "required", "llm", "tokens", "format", "inference", "properties", "return", "data", "eval", "count", "base", "except", "bytes", "list", "payload", "ollama", "process_images", "OllamaService", "total", "marker", "json", "generate", "raise", "for", "call", "services", "blocks", "get", "logger", "localhost", "llama", "llama3", "type", "stream", "process", "service"], "ast_kind": "function_or_method", "text": "    def __call__(\n        self,\n        prompt: str,\n        image: PIL.Image.Image | List[PIL.Image.Image] | None,\n        block: Block | None,\n        response_schema: type[BaseModel],\n        max_retries: int | None = None,\n        timeout: int | None = None,\n    ):\n        url = f\"{self.ollama_base_url}/api/generate\"\n        headers = {\"Content-Type\": \"application/json\"}\n\n        schema = response_schema.model_json_schema()\n        format_schema = {\n            \"type\": \"object\",\n            \"properties\": schema[\"properties\"],\n            \"required\": schema[\"required\"],\n        }\n\n        image_bytes = self.format_image_for_llm(image)\n\n        payload = {\n            \"model\": self.ollama_model,\n            \"prompt\": prompt,\n            \"stream\": False,\n            \"format\": format_schema,\n            \"images\": image_bytes,\n        }\n\n        try:\n            response = requests.post(url, json=payload, headers=headers)\n            response.raise_for_status()\n            response_data = response.json()\n\n            total_tokens = (\n                response_data[\"prompt_eval_count\"] + response_data[\"eval_count\"]\n            )\n\n            if block:\n                block.update_metadata(llm_request_count=1, llm_tokens_used=total_tokens)\n\n            data = response_data[\"response\"]\n            return json.loads(data)\n        except Exception as e:\n            logger.warning(f\"Ollama inference failed: {e}\")\n\n        return {}\n", "n_tokens": 299, "byte_len": 1448, "file_sha1": "e5ac45316dc04b3e616ee8e608f4f7f9f2dd6cae", "start_line": 27, "end_line": 74}
