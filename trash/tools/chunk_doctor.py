#!/usr/bin/env python3
"""
Chunk Doctor - Validates and fixes Go code chunks for quality assurance.

This module provides validation and auto-fixing capabilities for Go code chunks
generated by build_chunks_v3.py, ensuring they meet quality standards for RAG systems.

Usage:
    python -m tools.chunk_doctor --check path/to/chunks.jsonl
    python -m tools.chunk_doctor --fix path/to/chunks.jsonl > fixed.jsonl
"""

import argparse
import json
import logging
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class RuleViolation:
    """Represents a validation rule violation."""
    code: str
    message: str
    chunk_id: str
    severity: str = "ERROR"  # ERROR, WARNING, INFO


class ChunkDoctor:
    """Validates and fixes Go code chunks."""
    
    def __init__(self):
        self.violations: List[RuleViolation] = []
        self.fixes_applied: List[str] = []
    
    def validate_file_chunks(self, chunks: List[Dict[str, Any]]) -> List[RuleViolation]:
        """Validate all chunks for a single file."""
        self.violations = []
        
        if not chunks:
            return self.violations
        
        # Only validate Go chunks
        go_chunks = [c for c in chunks if c.get('language') == 'go']
        if not go_chunks:
            return self.violations
        
        # Run all validators
        self._validate_go_header_present_first(go_chunks)
        self._validate_go_neighbor_chain(go_chunks)
        self._validate_go_ast_path_format(go_chunks)
        self._validate_go_header_context_package(go_chunks)
        self._validate_go_imports_minimal_alphabetical(go_chunks)
        self._validate_go_imports_builtin_leak(go_chunks)
        self._validate_go_symbols_defined_present(go_chunks)
        self._validate_go_symbols_self_reference(go_chunks)
        self._validate_go_symbols_qualified_pref(go_chunks)
        self._validate_go_path_id_normalized(go_chunks)
        self._validate_go_no_empty_chunks(go_chunks)
        self._validate_go_summary_template(go_chunks)
        self._validate_go_qa_terms_count_range(go_chunks)
        
        return self.violations
    
    def fix_file_chunks(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Apply auto-fixes to chunks."""
        self.fixes_applied = []
        fixed_chunks = chunks.copy()
        
        if not fixed_chunks:
            return fixed_chunks
        
        # Only fix Go chunks
        go_chunks = [c for c in fixed_chunks if c.get('language') == 'go']
        if not go_chunks:
            return fixed_chunks
        
        # Apply fixes in order
        fixed_chunks = self._fix_go_header_present_first(fixed_chunks)
        fixed_chunks = self._fix_go_neighbor_chain(fixed_chunks)
        fixed_chunks = self._fix_go_header_context_package(fixed_chunks)
        fixed_chunks = self._fix_go_imports_minimal_alphabetical(fixed_chunks)
        fixed_chunks = self._fix_go_imports_builtin_leak(fixed_chunks)
        fixed_chunks = self._fix_go_symbols_self_reference(fixed_chunks)
        fixed_chunks = self._fix_go_symbols_qualified_pref(fixed_chunks)
        fixed_chunks = self._fix_go_path_id_normalized(fixed_chunks)
        fixed_chunks = self._fix_go_summary_template(fixed_chunks)
        
        return fixed_chunks
    
    # Validation methods
    def _validate_go_header_present_first(self, chunks: List[Dict[str, Any]]):
        """GO_HEADER_PRESENT_FIRST: File header chunk must be present and first."""
        file_headers = [c for c in chunks if c.get('ast_path') == 'go:file_header']
        
        if not file_headers:
            for chunk in chunks:
                self.violations.append(RuleViolation(
                    code="GO_HEADER_PRESENT_FIRST",
                    message="No go:file_header chunk found",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
        elif len(file_headers) > 1:
            for chunk in file_headers:
                self.violations.append(RuleViolation(
                    code="GO_HEADER_PRESENT_FIRST",
                    message="Multiple go:file_header chunks found",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
        else:
            # Check if header is first
            header_chunk = file_headers[0]
            if chunks[0] != header_chunk:
                self.violations.append(RuleViolation(
                    code="GO_HEADER_PRESENT_FIRST",
                    message="go:file_header chunk is not first",
                    chunk_id=header_chunk.get('chunk_id', 'unknown')
                ))
    
    def _validate_go_neighbor_chain(self, chunks: List[Dict[str, Any]]):
        """GO_NEIGHBOR_CHAIN: Neighbor chain must be properly linked."""
        if not chunks:
            return
        
        # Sort chunks by start_line
        sorted_chunks = sorted(chunks, key=lambda c: c.get('start_line', 0))
        
        for i, chunk in enumerate(sorted_chunks):
            neighbors = chunk.get('neighbors', {})
            prev_id = neighbors.get('prev')
            next_id = neighbors.get('next')
            
            # First chunk should have prev = null
            if i == 0 and prev_id is not None:
                self.violations.append(RuleViolation(
                    code="GO_NEIGHBOR_CHAIN",
                    message="First chunk should have prev = null",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
            
            # Last chunk should have next = null
            if i == len(sorted_chunks) - 1 and next_id is not None:
                self.violations.append(RuleViolation(
                    code="GO_NEIGHBOR_CHAIN",
                    message="Last chunk should have next = null",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
            
            # Middle chunks should have proper prev/next
            if 0 < i < len(sorted_chunks) - 1:
                expected_prev = sorted_chunks[i-1].get('chunk_id')
                expected_next = sorted_chunks[i+1].get('chunk_id')
                
                if prev_id != expected_prev:
                    self.violations.append(RuleViolation(
                        code="GO_NEIGHBOR_CHAIN",
                        message=f"prev should be {expected_prev}, got {prev_id}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
                
                if next_id != expected_next:
                    self.violations.append(RuleViolation(
                        code="GO_NEIGHBOR_CHAIN",
                        message=f"next should be {expected_next}, got {next_id}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    def _validate_go_ast_path_format(self, chunks: List[Dict[str, Any]]):
        """GO_AST_PATH_FORMAT: AST paths must follow correct format."""
        for chunk in chunks:
            ast_path = chunk.get('ast_path', '')
            
            if not ast_path:
                self.violations.append(RuleViolation(
                    code="GO_AST_PATH_FORMAT",
                    message="ast_path is empty",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
                continue
            
            # Check format based on type
            if ast_path == 'go:file_header':
                continue  # Valid
            elif ast_path.startswith('go:type:'):
                type_name = ast_path[8:]  # Remove 'go:type:'
                if not type_name or not type_name[0].isupper():
                    self.violations.append(RuleViolation(
                        code="GO_AST_PATH_FORMAT",
                        message=f"Invalid type name in ast_path: {type_name}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
            elif ast_path.startswith('go:function:'):
                func_name = ast_path[12:]  # Remove 'go:function:'
                if not func_name or not func_name[0].isupper():
                    self.violations.append(RuleViolation(
                        code="GO_AST_PATH_FORMAT",
                        message=f"Invalid function name in ast_path: {func_name}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
            elif ast_path.startswith('go:method:'):
                # Format: go:method:(*ReceiverType).MethodName or go:method:ReceiverType.MethodName
                method_part = ast_path[10:]  # Remove 'go:method:'
                if not method_part or '.' not in method_part:
                    self.violations.append(RuleViolation(
                        code="GO_AST_PATH_FORMAT",
                        message=f"Invalid method format in ast_path: {method_part}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
            else:
                self.violations.append(RuleViolation(
                    code="GO_AST_PATH_FORMAT",
                    message=f"Unknown ast_path format: {ast_path}",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
    
    def _validate_go_header_context_package(self, chunks: List[Dict[str, Any]]):
        """GO_HEADER_CONTEXT_PACKAGE: Non-header chunks must start with package declaration."""
        for chunk in chunks:
            if chunk.get('ast_path') == 'go:file_header':
                continue  # Skip file header chunks
            
            header_context = chunk.get('header_context', '')
            if not header_context.strip().startswith('package '):
                self.violations.append(RuleViolation(
                    code="GO_HEADER_CONTEXT_PACKAGE",
                    message="header_context must start with 'package '",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
    
    def _validate_go_imports_minimal_alphabetical(self, chunks: List[Dict[str, Any]]):
        """GO_IMPORTS_MINIMAL_ALPHABETICAL: Imports must be minimal and alphabetically sorted."""
        for chunk in chunks:
            if chunk.get('ast_path') == 'go:file_header':
                continue  # Skip file header chunks
            
            imports_used = chunk.get('imports_used', [])
            header_context = chunk.get('header_context', '')
            
            # Check if imports are alphabetically sorted
            if imports_used != sorted(imports_used):
                self.violations.append(RuleViolation(
                    code="GO_IMPORTS_MINIMAL_ALPHABETICAL",
                    message="imports_used must be alphabetically sorted",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
            
            # Check import formatting in header_context
            if imports_used:
                if len(imports_used) == 1:
                    # Should use single-line format: import "module"
                    expected = f'import "{imports_used[0]}"'
                    if expected not in header_context:
                        self.violations.append(RuleViolation(
                            code="GO_IMPORTS_MINIMAL_ALPHABETICAL",
                            message="Single import should use single-line format",
                            chunk_id=chunk.get('chunk_id', 'unknown')
                        ))
                else:
                    # Should use block format with alphabetical order
                    if 'import (' not in header_context:
                        self.violations.append(RuleViolation(
                            code="GO_IMPORTS_MINIMAL_ALPHABETICAL",
                            message="Multiple imports should use block format",
                            chunk_id=chunk.get('chunk_id', 'unknown')
                        ))
    
    def _validate_go_imports_builtin_leak(self, chunks: List[Dict[str, Any]]):
        """GO_IMPORTS_BUILTIN_LEAK: Builtin types like 'error' and 'nil' should not be in imports."""
        builtin_imports = {'error', 'nil', 'true', 'false', 'string', 'int', 'bool'}
        
        for chunk in chunks:
            imports_used = chunk.get('imports_used', [])
            for imp in imports_used:
                if imp in builtin_imports:
                    self.violations.append(RuleViolation(
                        code="GO_IMPORTS_BUILTIN_LEAK",
                        message=f"Builtin '{imp}' should not be in imports_used",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    def _validate_go_symbols_defined_present(self, chunks: List[Dict[str, Any]]):
        """GO_SYMBOLS_DEFINED_PRESENT: Functions and types should have symbols_defined."""
        for chunk in chunks:
            ast_path = chunk.get('ast_path', '')
            symbols_defined = chunk.get('symbols_defined', [])
            
            if ast_path.startswith('go:function:') or ast_path.startswith('go:type:'):
                if not symbols_defined:
                    self.violations.append(RuleViolation(
                        code="GO_SYMBOLS_DEFINED_PRESENT",
                        message="Functions and types must have symbols_defined",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    def _validate_go_symbols_self_reference(self, chunks: List[Dict[str, Any]]):
        """GO_SYMBOLS_SELF_REFERENCE: symbols_referenced should not contain self-symbols."""
        for chunk in chunks:
            symbols_defined = set(chunk.get('symbols_defined', []))
            symbols_referenced = set(chunk.get('symbols_referenced', []))
            
            self_refs = symbols_defined.intersection(symbols_referenced)
            if self_refs:
                self.violations.append(RuleViolation(
                    code="GO_SYMBOLS_SELF_REFERENCE",
                    message=f"symbols_referenced contains self-references: {list(self_refs)}",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
    
    def _validate_go_symbols_qualified_pref(self, chunks: List[Dict[str, Any]]):
        """GO_SYMBOLS_QUALIFIED_PREF: Prefer qualified symbols over bare names."""
        for chunk in chunks:
            symbols_referenced = chunk.get('symbols_referenced', [])
            
            # Check for both qualified and bare versions of the same symbol
            qualified_symbols = {s for s in symbols_referenced if '.' in s}
            bare_symbols = {s for s in symbols_referenced if '.' not in s}
            
            for qualified in qualified_symbols:
                bare_name = qualified.split('.')[-1]
                if bare_name in bare_symbols:
                    self.violations.append(RuleViolation(
                        code="GO_SYMBOLS_QUALIFIED_PREF",
                        message=f"Both qualified '{qualified}' and bare '{bare_name}' found",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    def _validate_go_path_id_normalized(self, chunks: List[Dict[str, Any]]):
        """GO_PATH_ID_NORMALIZED: Path should be repo-relative and chunk_id should use normalized path."""
        for chunk in chunks:
            path = chunk.get('path', '')
            chunk_id = chunk.get('chunk_id', '')
            
            # Path should be repo-relative (no leading slash)
            if path.startswith('/'):
                self.violations.append(RuleViolation(
                    code="GO_PATH_ID_NORMALIZED",
                    message="path should be repo-relative (no leading slash)",
                    chunk_id=chunk_id
                ))
            
            # chunk_id should contain the normalized path
            if path and path not in chunk_id:
                self.violations.append(RuleViolation(
                    code="GO_PATH_ID_NORMALIZED",
                    message="chunk_id should contain the normalized path",
                    chunk_id=chunk_id
                ))
    
    def _validate_go_no_empty_chunks(self, chunks: List[Dict[str, Any]]):
        """GO_NO_EMPTY_CHUNKS: Chunks should not be empty."""
        for chunk in chunks:
            text = chunk.get('text', '')
            core = chunk.get('core', '')
            
            if not text.strip() or not core.strip():
                self.violations.append(RuleViolation(
                    code="GO_NO_EMPTY_CHUNKS",
                    message="Chunk text and core must not be empty",
                    chunk_id=chunk.get('chunk_id', 'unknown')
                ))
    
    def _validate_go_summary_template(self, chunks: List[Dict[str, Any]]):
        """GO_SUMMARY_TEMPLATE: Summary should use specific templates for known types."""
        for chunk in chunks:
            ast_path = chunk.get('ast_path', '')
            summary_1l = chunk.get('summary_1l', '')
            
            # Check for specific templates
            if 'providerClient' in ast_path and 'interface' in ast_path:
                if 'Go interface that exposes GetForecastForLocation' not in summary_1l:
                    self.violations.append(RuleViolation(
                        code="GO_SUMMARY_TEMPLATE",
                        message="providerClient should use specific template",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
            elif 'Service' in ast_path and 'struct' in ast_path:
                if 'Service aggregates singleflight' not in summary_1l:
                    self.violations.append(RuleViolation(
                        code="GO_SUMMARY_TEMPLATE",
                        message="Service struct should use specific template",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    def _validate_go_qa_terms_count_range(self, chunks: List[Dict[str, Any]]):
        """GO_QA_TERMS_COUNT_RANGE: QA terms should be 6-12 terms."""
        for chunk in chunks:
            qa_terms = chunk.get('qa_terms', '')
            if qa_terms:
                term_count = len([t.strip() for t in qa_terms.split(',') if t.strip()])
                if term_count < 6 or term_count > 12:
                    self.violations.append(RuleViolation(
                        code="GO_QA_TERMS_COUNT_RANGE",
                        message=f"QA terms should be 6-12 terms, got {term_count}",
                        chunk_id=chunk.get('chunk_id', 'unknown')
                    ))
    
    # Fix methods
    def _fix_go_header_present_first(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Move file_header to index 0."""
        file_headers = [c for c in chunks if c.get('ast_path') == 'go:file_header']
        if not file_headers or len(file_headers) > 1:
            return chunks  # Can't fix multiple or missing headers
        
        header_chunk = file_headers[0]
        if chunks[0] == header_chunk:
            return chunks  # Already first
        
        # Move header to front
        other_chunks = [c for c in chunks if c != header_chunk]
        fixed_chunks = [header_chunk] + other_chunks
        self.fixes_applied.append("Moved go:file_header to first position")
        return fixed_chunks
    
    def _fix_go_neighbor_chain(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Rebuild neighbor chain."""
        if not chunks:
            return chunks
        
        # Sort chunks by start_line
        sorted_chunks = sorted(chunks, key=lambda c: c.get('start_line', 0))
        
        for i, chunk in enumerate(sorted_chunks):
            neighbors = chunk.get('neighbors', {})
            
            # Set prev
            if i == 0:
                neighbors['prev'] = None
            else:
                neighbors['prev'] = sorted_chunks[i-1].get('chunk_id')
            
            # Set next
            if i == len(sorted_chunks) - 1:
                neighbors['next'] = None
            else:
                neighbors['next'] = sorted_chunks[i+1].get('chunk_id')
            
            chunk['neighbors'] = neighbors
        
        self.fixes_applied.append("Rebuilt neighbor chain")
        return sorted_chunks
    
    def _fix_go_header_context_package(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Prepend package declaration to non-header chunks if missing."""
        for chunk in chunks:
            if chunk.get('ast_path') == 'go:file_header':
                continue
            
            header_context = chunk.get('header_context', '')
            if not header_context.strip().startswith('package '):
                # Try to extract package name from file header or use 'main' as default
                package_name = 'main'
                for other_chunk in chunks:
                    if other_chunk.get('ast_path') == 'go:file_header':
                        text = other_chunk.get('text', '')
                        for line in text.split('\n'):
                            if line.strip().startswith('package '):
                                package_name = line.strip().split()[1]
                                break
                        break
                
                chunk['header_context'] = f'package {package_name}\n{header_context}'
                self.fixes_applied.append(f"Added package {package_name} to header_context")
        
        return chunks
    
    def _fix_go_imports_minimal_alphabetical(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Reformat header imports (single-line vs block; alphabetize)."""
        for chunk in chunks:
            if chunk.get('ast_path') == 'go:file_header':
                continue
            
            imports_used = chunk.get('imports_used', [])
            if not imports_used:
                continue
            
            # Sort imports alphabetically
            sorted_imports = sorted(imports_used)
            chunk['imports_used'] = sorted_imports
            
            # Rebuild header_context with proper import formatting
            header_context = chunk.get('header_context', '')
            lines = header_context.split('\n')
            
            # Find and replace import section
            new_lines = []
            in_import_section = False
            for line in lines:
                if line.strip().startswith('import '):
                    in_import_section = True
                    if len(sorted_imports) == 1:
                        new_lines.append(f'import "{sorted_imports[0]}"')
                    else:
                        new_lines.append('import (')
                        for imp in sorted_imports:
                            new_lines.append(f'\t"{imp}"')
                        new_lines.append(')')
                elif in_import_section and (line.strip() == '' or line.strip().startswith('//')):
                    continue  # Skip empty lines and comments after import
                else:
                    if in_import_section:
                        in_import_section = False
                    new_lines.append(line)
            
            chunk['header_context'] = '\n'.join(new_lines)
            self.fixes_applied.append("Reformatted imports (alphabetized and proper formatting)")
        
        return chunks
    
    def _fix_go_imports_builtin_leak(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Drop builtin imports (error, nil)."""
        builtin_imports = {'error', 'nil', 'true', 'false', 'string', 'int', 'bool'}
        
        for chunk in chunks:
            imports_used = chunk.get('imports_used', [])
            filtered_imports = [imp for imp in imports_used if imp not in builtin_imports]
            
            if len(filtered_imports) != len(imports_used):
                chunk['imports_used'] = filtered_imports
                self.fixes_applied.append("Removed builtin imports")
        
        return chunks
    
    def _fix_go_symbols_self_reference(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove self from symbols_referenced."""
        for chunk in chunks:
            symbols_defined = set(chunk.get('symbols_defined', []))
            symbols_referenced = chunk.get('symbols_referenced', [])
            
            filtered_symbols = [s for s in symbols_referenced if s not in symbols_defined]
            
            if len(filtered_symbols) != len(symbols_referenced):
                chunk['symbols_referenced'] = filtered_symbols
                self.fixes_applied.append("Removed self-references from symbols_referenced")
        
        return chunks
    
    def _fix_go_symbols_qualified_pref(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Prefer qualified symbols over bare names."""
        for chunk in chunks:
            symbols_referenced = chunk.get('symbols_referenced', [])
            
            # Group by bare name
            qualified_by_bare = {}
            bare_symbols = set()
            
            for symbol in symbols_referenced:
                if '.' in symbol:
                    bare_name = symbol.split('.')[-1]
                    qualified_by_bare[bare_name] = symbol
                else:
                    bare_symbols.add(symbol)
            
            # Keep qualified versions, remove bare duplicates
            filtered_symbols = []
            for symbol in symbols_referenced:
                if '.' in symbol:
                    filtered_symbols.append(symbol)
                else:
                    # Only keep bare symbol if no qualified version exists
                    if symbol not in qualified_by_bare:
                        filtered_symbols.append(symbol)
            
            if len(filtered_symbols) != len(symbols_referenced):
                chunk['symbols_referenced'] = filtered_symbols
                self.fixes_applied.append("Preferred qualified symbols over bare names")
        
        return chunks
    
    def _fix_go_path_id_normalized(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Normalize chunk_id to use repo-relative path."""
        for chunk in chunks:
            path = chunk.get('path', '')
            if path.startswith('/'):
                # Remove leading slash
                normalized_path = path[1:]
                chunk['path'] = normalized_path
                
                # Recompute chunk_id with normalized path
                repo = chunk.get('repo', '')
                file_sha = chunk.get('file_sha', '')
                start_line = chunk.get('start_line', 0)
                end_line = chunk.get('end_line', 0)
                ast_path = chunk.get('ast_path', '')
                
                # Simple hash-based chunk_id (in real implementation, use proper hashing)
                import hashlib
                chunk_data = f"{repo}|{normalized_path}|{file_sha}|{start_line}|{end_line}|{ast_path}"
                chunk['chunk_id'] = hashlib.sha256(chunk_data.encode()).hexdigest()
                
                self.fixes_applied.append("Normalized path and recomputed chunk_id")
        
        return chunks
    
    def _fix_go_summary_template(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Trim generic suffix when specific template fired."""
        for chunk in chunks:
            summary_1l = chunk.get('summary_1l', '')
            ast_path = chunk.get('ast_path', '')
            
            # Remove generic "for weather forecasting" suffix if specific template is used
            if 'for weather forecasting' in summary_1l:
                if ('providerClient' in ast_path and 'interface' in ast_path) or \
                   ('Service' in ast_path and 'struct' in ast_path):
                    chunk['summary_1l'] = summary_1l.replace(' for weather forecasting', '')
                    self.fixes_applied.append("Trimmed generic suffix from specific template")
        
        return chunks


def load_chunks_from_file(file_path: Path) -> List[Dict[str, Any]]:
    """Load chunks from JSONL file."""
    chunks = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                chunks.append(json.loads(line))
    return chunks


def group_chunks_by_file(chunks: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """Group chunks by file path."""
    file_groups = {}
    for chunk in chunks:
        path = chunk.get('path', 'unknown')
        if path not in file_groups:
            file_groups[path] = []
        file_groups[path].append(chunk)
    return file_groups


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(description='Validate and fix Go code chunks')
    parser.add_argument('--check', action='store_true', help='Check for violations')
    parser.add_argument('--fix', action='store_true', help='Apply fixes')
    parser.add_argument('input_file', help='Input JSONL file with chunks')
    
    args = parser.parse_args()
    
    if not args.check and not args.fix:
        parser.error('Must specify either --check or --fix')
    
    if args.check and args.fix:
        parser.error('Cannot specify both --check and --fix')
    
    input_path = Path(args.input_file)
    if not input_path.exists():
        logger.error(f"Input file not found: {input_path}")
        sys.exit(1)
    
    # Load chunks
    all_chunks = load_chunks_from_file(input_path)
    file_groups = group_chunks_by_file(all_chunks)
    
    doctor = ChunkDoctor()
    
    if args.check:
        # Check mode
        total_violations = 0
        for file_path, chunks in file_groups.items():
            violations = doctor.validate_file_chunks(chunks)
            if violations:
                print(f"\nFile: {file_path}")
                for violation in violations:
                    print(f"  {violation.code}: {violation.message} (chunk: {violation.chunk_id})")
                total_violations += len(violations)
        
        if total_violations > 0:
            print(f"\nTotal violations: {total_violations}")
            sys.exit(1)
        else:
            print("All chunks passed validation!")
            sys.exit(0)
    
    elif args.fix:
        # Fix mode
        fixed_chunks = []
        for file_path, chunks in file_groups.items():
            fixed_file_chunks = doctor.fix_file_chunks(chunks)
            fixed_chunks.extend(fixed_file_chunks)
        
        # Output fixed chunks to stdout
        for chunk in fixed_chunks:
            print(json.dumps(chunk))
        
        if doctor.fixes_applied:
            logger.info(f"Applied fixes: {', '.join(doctor.fixes_applied)}")


if __name__ == '__main__':
    main()
