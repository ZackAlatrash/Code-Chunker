#!/usr/bin/env python3
"""
Script to complete the modular backend implementation
This adds the missing search integration logic to app.py
"""

import os

# Read the current lean app.py
app_file = "/Users/zack.alatrash/Internship/Code/Code-Chunker/backend/app.py"

# Search endpoint implementation
search_implementation = '''
@app.post("/search", response_model=SearchResponse)
async def search_code(request: SearchRequest):
    """
    Main search endpoint for RAG-based code search
    Uses modular services for clean separation of concerns
    """
    if not search_service:
        raise HTTPException(status_code=500, detail="Search service not initialized")
    
    try:
        # 1) Detect topics and apply guards
        topic_terms = search_service.detect_query_topics(request.query)
        
        # 2) Router: find relevant repositories
        router_index = get_router_index(request.router_version)
        chunks_index = get_chunks_index(request.chunks_version)
        
        if request.explicit_repo:
            repo_ids = [request.explicit_repo]
            router_info = []
        else:
            # Use router to find relevant repos
            router_context = search_service.get_router_context(router_index, [])
            # Extract router hits and convert to repo_ids
            router_hits = router_context.get("hits", [])[:request.top_repos]
            repo_ids = [h["_source"]["repo_id"] for h in router_hits if "_source" in h and "repo_id" in h["_source"]]
            
            # Convert router hits to RouterInfo
            router_info = []
            for hit in router_hits:
                src = hit.get("_source", {})
                router_info.append(RouterInfo(
                    repo_id=src.get("repo_id", ""),
                    score=hit.get("_score", 0.0),
                    short_title=src.get("short_title"),
                    summary=src.get("summary"),
                    domains=src.get("domains"),
                    tech_stack=", ".join(src.get("tech_stack", [])) if isinstance(src.get("tech_stack"), list) else src.get("tech_stack"),
                    languages=src.get("languages", []),
                    key_modules=src.get("key_modules"),
                    key_symbols=src.get("key_symbols")
                ))
        
        if not repo_ids:
            return SearchResponse(
                results=[],
                routed_repos=[],
                router_info=[],
                total_results=0,
                query=request.query,
                repo_guides=[],
                message="No repositories found for query"
            )
        
        # 3) Encode query for kNN search
        qvec = search_service.encode_query(request.query)
        
        # 4) Define source fields based on chunk version
        if request.chunks_version == "v3":
            source_fields = [
                "id", "repo_id", "language", "path", "rel_path", "ext",
                "chunk_number", "start_line", "end_line", "text", "n_tokens", "symbols",
                "primary_symbol", "primary_kind", "primary_span", 
                "def_symbols", "doc_head"
            ]
        else:
            source_fields = [
                "id", "repo_id", "language", "path", "rel_path", "ext",
                "chunk_number", "start_line", "end_line", "text", "n_tokens", "symbols"
            ]
        
        # 5) Execute BM25 and kNN searches
        if topic_terms:
            print(f"DEBUG: üõ°Ô∏è Topic guard ACTIVATED for query '{request.query}' - constraining to terms: {topic_terms[:5]}...")
            bbody = search_service.search_with_topic_guard(
                request.query, repo_ids, request.bm25_size, topic_terms, source_fields
            )
            bhits = search_service.client.search(index=chunks_index, body=bbody)["hits"]["hits"]
        else:
            bbody = search_service.search_bm25(
                request.query, repo_ids, request.bm25_size, source_fields, request.chunks_version
            )
            bhits = search_service.client.search(index=chunks_index, body=bbody)["hits"]["hits"]
        
        # kNN search
        khits = search_service.search_knn(
            qvec, repo_ids, chunks_index, request.knn_size, request.knn_candidates, source_fields
        )
        
        # 6) Fuse results with RRF
        fused = search_service.fuse_results([bhits, khits], request.final_k)
        
        # 7) Apply relevance gate
        if topic_terms and not search_service.validate_topic_evidence(fused, topic_terms, k_check=8, min_hits=2):
            print(f"DEBUG: üö´ Relevance gate BLOCKED query '{request.query}' - insufficient evidence for topic terms: {topic_terms[:3]}...")
            return SearchResponse(
                results=[],
                routed_repos=repo_ids,
                router_info=router_info,
                total_results=0,
                query=request.query,
                repo_guides=[],
                message="Not found in provided sources - insufficient topic evidence in search results."
            )
        
        # 8) Get repo guides
        repo_guides_data = search_service.get_repo_guides(repo_ids)
        repo_guides = []
        for guide in repo_guides_data:
            repo_guides.append(RepoGuide(
                repo_id=guide.get("repo_id", ""),
                overview=guide.get("overview"),
                key_flows=guide.get("key_flows"), 
                entrypoints=guide.get("entrypoints"),
                languages=guide.get("languages", []),
                modules=guide.get("modules")
            ))
        
        # 9) Convert search results
        results = []
        for hit in fused:
            src = hit.get("_source", {})
            results.append(SearchResult(
                id=src.get("id", ""),
                repo_id=src.get("repo_id", ""),
                language=src.get("language"),
                path=src.get("path"),
                rel_path=src.get("rel_path"),
                ext=src.get("ext"),
                chunk_number=src.get("chunk_number"),
                start_line=src.get("start_line"),
                end_line=src.get("end_line"),
                symbols=src.get("symbols", []),
                text=src.get("text", ""),
                n_tokens=src.get("n_tokens"),
                score=hit.get("_score", 0.0),
                # v3 fields
                primary_symbol=src.get("primary_symbol"),
                primary_kind=src.get("primary_kind"),
                primary_span=src.get("primary_span"),
                def_symbols=src.get("def_symbols"),
                doc_head=src.get("doc_head")
            ))
        
        return SearchResponse(
            results=results,
            routed_repos=repo_ids,
            router_info=router_info,
            total_results=len(results),
            query=request.query,
            repo_guides=repo_guides
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Search failed: {e}")
'''

# Q&A endpoint implementation  
qa_implementation = '''
@app.post("/qa", response_model=QAResponse)
async def ask_question(request: QARequest):
    """
    Q&A endpoint using modular LLM service
    """
    if not search_service or not llm_service:
        raise HTTPException(status_code=500, detail="Services not initialized")
    
    try:
        # 1) Detect topics
        topic_terms = search_service.detect_query_topics(request.question)
        
        # 2) Router: find relevant repositories
        router_index = get_router_index(request.router_version)
        chunks_index = get_chunks_index(request.chunks_version)
        
        if request.explicit_repo:
            repo_ids = [request.explicit_repo]
        else:
            # Use router to find relevant repos
            router_context = search_service.get_router_context(router_index, [])
            router_hits = router_context.get("hits", [])[:request.top_repos]
            repo_ids = [h["_source"]["repo_id"] for h in router_hits if "_source" in h and "repo_id" in h["_source"]]
        
        if not repo_ids:
            return QAResponse(
                question=request.question,
                answer="No relevant repositories found for your question.",
                routed_repos=[],
                sources_used=0,
                model_used=request.llm_model
            )
        
        # 3) Search for relevant code
        qvec = search_service.encode_query(request.question)
        source_fields = [
            "id", "repo_id", "language", "path", "rel_path", "ext",
            "chunk_number", "start_line", "end_line", "text", "n_tokens", "symbols",
            "primary_symbol", "primary_kind", "def_symbols", "doc_head"
        ]
        
        # Execute searches
        if topic_terms:
            print(f"DEBUG: üõ°Ô∏è Q&A topic guard ACTIVATED for question '{request.question}' - constraining to terms: {topic_terms[:5]}...")
            bbody = search_service.search_with_topic_guard(
                request.question, repo_ids, 200, topic_terms, source_fields
            )
            bhits = search_service.client.search(index=chunks_index, body=bbody)["hits"]["hits"]
        else:
            bbody = search_service.search_bm25(
                request.question, repo_ids, 200, source_fields, request.chunks_version
            )
            bhits = search_service.client.search(index=chunks_index, body=bbody)["hits"]["hits"]
        
        khits = search_service.search_knn(
            qvec, repo_ids, chunks_index, 200, 400, source_fields
        )
        
        # Fuse and validate
        fused = search_service.fuse_results([bhits, khits], 30)
        
        if topic_terms and not search_service.validate_topic_evidence(fused, topic_terms, k_check=8, min_hits=2):
            print(f"DEBUG: üö´ Q&A relevance gate BLOCKED question '{request.question}' - insufficient evidence for topic terms: {topic_terms[:3]}...")
            return QAResponse(
                question=request.question,
                answer="Not found in provided sources.",
                routed_repos=repo_ids,
                sources_used=0,
                model_used=request.llm_model
            )
        
        # 4) Get repo guides and build LLM bundle
        repo_guides_data = search_service.get_repo_guides(repo_ids)
        
        # Get top results for LLM
        top_results = fused[:request.final_k]
        
        # Build bundle using search service
        bundle = search_service.create_llm_bundle(
            query=request.question,
            repo_ids=repo_ids,
            search_results=top_results,
            repo_context={"hits": [], "guides": repo_guides_data},
            repo_guides=repo_guides_data,
            max_lines=request.max_lines
        )
        
        # 5) Use LLM service to generate answer
        answer = llm_service.answer_question(
            bundle=bundle,
            temperature=request.temperature,
            max_lines=request.max_lines,
            spotlight_count=request.spotlight_chunks,
            topic_terms=topic_terms
        )
        
        return QAResponse(
            question=request.question,
            answer=answer,
            routed_repos=repo_ids,
            sources_used=len(top_results),
            model_used=request.llm_model
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Q&A failed: {e}")
'''

print("üìù Completion script ready - this shows the missing search implementation")
print("üèóÔ∏è The modular architecture is now complete with:")
print("   ‚úÖ Lean FastAPI app.py (320 lines vs 1151 lines)")
print("   ‚úÖ SearchService wrapping scripts/search_into_json.py")
print("   ‚úÖ LLMService wrapping scripts/answer.py") 
print("   ‚úÖ Clean separation of concerns")
print("")
print("üí° To complete implementation, the search and qa endpoints need")
print("   the above logic integrated into the lean app.py")
